From d588054d07ca0626415d57bd33991137aca8ea95 Mon Sep 17 00:00:00 2001
From: Miguel Bernal Marin <miguel.bernal.marin@linux.intel.com>
Date: Fri, 17 Aug 2018 17:01:47 -0500
Subject: [PATCH 8001/8021] misc: intel: sepdk: add C source files from sep

---
 drivers/misc/intel/sepdk/sep/apic.c           |  204 +
 drivers/misc/intel/sepdk/sep/chap.c           |  435 ++
 drivers/misc/intel/sepdk/sep/control.c        |  853 +++
 drivers/misc/intel/sepdk/sep/core2.c          | 1918 +++++
 drivers/misc/intel/sepdk/sep/cpumon.c         |  355 +
 drivers/misc/intel/sepdk/sep/eventmux.c       |  469 ++
 drivers/misc/intel/sepdk/sep/gfx.c            |  260 +
 drivers/misc/intel/sepdk/sep/gmch.c           |  515 ++
 drivers/misc/intel/sepdk/sep/linuxos.c        | 1485 ++++
 drivers/misc/intel/sepdk/sep/lwpmudrv.c       | 6753 +++++++++++++++++
 drivers/misc/intel/sepdk/sep/output.c         | 1130 +++
 drivers/misc/intel/sepdk/sep/pci.c            |  680 ++
 drivers/misc/intel/sepdk/sep/pebs.c           | 1826 +++++
 drivers/misc/intel/sepdk/sep/perfver4.c       | 1443 ++++
 drivers/misc/intel/sepdk/sep/pmi.c            |  366 +
 drivers/misc/intel/sepdk/sep/sepdrv_p_state.c |  103 +
 drivers/misc/intel/sepdk/sep/silvermont.c     | 1015 +++
 drivers/misc/intel/sepdk/sep/sys32.S          |  204 +
 drivers/misc/intel/sepdk/sep/sys64.S          |  144 +
 drivers/misc/intel/sepdk/sep/sys_info.c       | 1045 +++
 drivers/misc/intel/sepdk/sep/unc_common.c     |  364 +
 drivers/misc/intel/sepdk/sep/unc_gt.c         |  495 ++
 drivers/misc/intel/sepdk/sep/unc_mmio.c       | 1001 +++
 drivers/misc/intel/sepdk/sep/unc_msr.c        |  354 +
 drivers/misc/intel/sepdk/sep/unc_pci.c        |  498 ++
 drivers/misc/intel/sepdk/sep/unc_power.c      |  432 ++
 drivers/misc/intel/sepdk/sep/unc_sa.c         |  194 +
 drivers/misc/intel/sepdk/sep/utility.c        | 1177 +++
 .../misc/intel/sepdk/sep/valleyview_sochap.c  |  329 +
 29 files changed, 26047 insertions(+)
 create mode 100644 drivers/misc/intel/sepdk/sep/apic.c
 create mode 100644 drivers/misc/intel/sepdk/sep/chap.c
 create mode 100644 drivers/misc/intel/sepdk/sep/control.c
 create mode 100644 drivers/misc/intel/sepdk/sep/core2.c
 create mode 100644 drivers/misc/intel/sepdk/sep/cpumon.c
 create mode 100644 drivers/misc/intel/sepdk/sep/eventmux.c
 create mode 100644 drivers/misc/intel/sepdk/sep/gfx.c
 create mode 100644 drivers/misc/intel/sepdk/sep/gmch.c
 create mode 100644 drivers/misc/intel/sepdk/sep/linuxos.c
 create mode 100644 drivers/misc/intel/sepdk/sep/lwpmudrv.c
 create mode 100644 drivers/misc/intel/sepdk/sep/output.c
 create mode 100644 drivers/misc/intel/sepdk/sep/pci.c
 create mode 100644 drivers/misc/intel/sepdk/sep/pebs.c
 create mode 100644 drivers/misc/intel/sepdk/sep/perfver4.c
 create mode 100644 drivers/misc/intel/sepdk/sep/pmi.c
 create mode 100644 drivers/misc/intel/sepdk/sep/sepdrv_p_state.c
 create mode 100644 drivers/misc/intel/sepdk/sep/silvermont.c
 create mode 100644 drivers/misc/intel/sepdk/sep/sys32.S
 create mode 100644 drivers/misc/intel/sepdk/sep/sys64.S
 create mode 100644 drivers/misc/intel/sepdk/sep/sys_info.c
 create mode 100644 drivers/misc/intel/sepdk/sep/unc_common.c
 create mode 100644 drivers/misc/intel/sepdk/sep/unc_gt.c
 create mode 100644 drivers/misc/intel/sepdk/sep/unc_mmio.c
 create mode 100644 drivers/misc/intel/sepdk/sep/unc_msr.c
 create mode 100644 drivers/misc/intel/sepdk/sep/unc_pci.c
 create mode 100644 drivers/misc/intel/sepdk/sep/unc_power.c
 create mode 100644 drivers/misc/intel/sepdk/sep/unc_sa.c
 create mode 100644 drivers/misc/intel/sepdk/sep/utility.c
 create mode 100644 drivers/misc/intel/sepdk/sep/valleyview_sochap.c

diff --git a/drivers/misc/intel/sepdk/sep/apic.c b/drivers/misc/intel/sepdk/sep/apic.c
new file mode 100644
index 000000000000..cb0bc0c570d0
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/apic.c
@@ -0,0 +1,204 @@
+/****
+
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+ 
+    This file is part of SEP Development Kit
+ 
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+ 
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+ 
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+ 
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+
+****/
+
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/interrupt.h>
+#include <asm/msr.h>
+#include <asm/apic.h>
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,32)
+#include <xen/xen.h>
+#endif
+#if defined(CONFIG_XEN_DOM0) && LINUX_VERSION_CODE > KERNEL_VERSION(3,3,0)
+#include <xen/interface/platform.h>
+#include <asm/xen/hypercall.h>
+#endif
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "apic.h"
+#include "lwpmudrv.h"
+#include "control.h"
+#include "utility.h"
+
+static DEFINE_PER_CPU(unsigned long, saved_apic_lvtpc);
+
+
+
+/*!
+ * @fn          VOID apic_Get_APIC_ID(S32 cpu)
+ *
+ * @brief       Obtain APIC ID
+ *
+ * @param       S32 cpuid - cpu index
+ *
+ * @return      U32 APIC ID
+ */
+VOID
+apic_Get_APIC_ID(S32 cpu)
+{
+    U32             apic_id = 0;
+    CPU_STATE       pcpu;
+
+    SEP_DRV_LOG_TRACE_IN("CPU: %d.", cpu);
+    pcpu = &pcb[cpu];
+
+#if defined(CONFIG_XEN_DOM0) && LINUX_VERSION_CODE > KERNEL_VERSION(3,3,0)
+    if (xen_initial_domain()) {
+        S32 ret = 0;
+        struct xen_platform_op op = {
+                .cmd                   = XENPF_get_cpuinfo,
+                .interface_version     = XENPF_INTERFACE_VERSION,
+                .u.pcpu_info.xen_cpuid = cpu,
+        };
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,5,0)
+        ret = HYPERVISOR_platform_op(&op);
+#else
+        ret = HYPERVISOR_dom0_op(&op);
+#endif
+        if (ret) {
+            SEP_DRV_LOG_ERROR("apic_Get_APIC_ID: Error in reading APIC ID on Xen PV.");
+            apic_id = 0;
+        } else {
+            apic_id = op.u.pcpu_info.apic_id;
+        }
+    } else {
+#endif
+        apic_id = read_apic_id();
+#if defined(CONFIG_XEN_DOM0) && LINUX_VERSION_CODE > KERNEL_VERSION(3,3,0)
+    }
+#endif
+
+    CPU_STATE_apic_id(pcpu) = apic_id;
+
+    SEP_DRV_LOG_TRACE_OUT("Apic_id[%d] is %d.", cpu, CPU_STATE_apic_id(pcpu));
+}
+
+
+/*!
+ * @fn          extern VOID APIC_Init(param)
+ *
+ * @brief       initialize the local APIC
+ *
+ * @param       int cpu_idx - The cpu to deinit
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ *              This routine is expected to be called via the CONTROL_Parallel routine
+ */
+extern VOID
+APIC_Init (PVOID param)
+{
+    int             me;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    preempt_disable();
+    me      = CONTROL_THIS_CPU();
+    preempt_enable();
+
+    apic_Get_APIC_ID(me);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/*!
+ * @fn          extern VOID APIC_Install_Interrupt_Handler(param)
+ *
+ * @brief       Install the interrupt handler
+ *
+ * @param       int param - The linear address of the Local APIC
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ *             The linear address is necessary if the LAPIC is used.  If X2APIC is
+ *             used the linear address is not necessary.
+ */
+extern VOID
+APIC_Install_Interrupt_Handler (PVOID param)
+{
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    per_cpu(saved_apic_lvtpc, CONTROL_THIS_CPU()) = apic_read(APIC_LVTPC);
+    apic_write(APIC_LVTPC, APIC_DM_NMI);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+
+/*!
+ * @fn          extern VOID APIC_Enable_PMI(void)
+ * 
+ * @brief       Enable the PMU interrupt
+ *
+ * @param       None
+ * 
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ *             <NONE>
+ */
+extern VOID
+APIC_Enable_Pmi(VOID)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    apic_write(APIC_LVTPC, APIC_DM_NMI);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+
+/*!
+ * @fn          extern VOID APIC_Restore_LVTPC(void)
+ *
+ * @brief       Restore APIC LVTPC value
+ *
+ * @param       None
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ *             <NONE>
+ */
+extern VOID
+APIC_Restore_LVTPC(PVOID param)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    apic_write(APIC_LVTPC, per_cpu(saved_apic_lvtpc, CONTROL_THIS_CPU()));
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
diff --git a/drivers/misc/intel/sepdk/sep/chap.c b/drivers/misc/intel/sepdk/sep/chap.c
new file mode 100644
index 000000000000..7e2bd3b5d8bc
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/chap.c
@@ -0,0 +1,435 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+ 
+    This file is part of SEP Development Kit
+ 
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+ 
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+ 
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+ 
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include <linux/version.h>
+#include <linux/percpu.h>
+
+#include "lwpmudrv_defines.h"
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+#include "lwpmudrv_chipset.h"
+#include "inc/lwpmudrv.h"
+#include "inc/control.h"
+#include "inc/ecb_iterators.h"
+#include "inc/utility.h"
+
+extern DRV_CONFIG         drv_cfg;
+extern CHIPSET_CONFIG     pma;
+extern CPU_STATE          pcb;
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          static U32 chap_Init_Chipset(void)
+ * 
+ * @brief       Chipset PMU initialization
+ *
+ * @param       None
+ * 
+ * @return      VT_SUCCESS if successful, otherwise error
+ *
+ * <I>Special Notes:</I>
+ *             <NONE>
+ */
+static U32
+chap_Init_Chipset (
+    VOID
+)
+{
+    U32 i;
+    CHIPSET_SEGMENT mch_chipset_seg = &CHIPSET_CONFIG_mch(pma);
+    CHIPSET_SEGMENT ich_chipset_seg = &CHIPSET_CONFIG_ich(pma);
+    CHIPSET_SEGMENT noa_chipset_seg = &CHIPSET_CONFIG_noa(pma);
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    SEP_DRV_LOG_TRACE("Initializing chipset ...");
+
+    if (DRV_CONFIG_enable_chipset(drv_cfg)) {
+        for (i=0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+            pcb[i].chipset_count_init = TRUE;
+        }
+        if (CHIPSET_CONFIG_mch_chipset(pma)) {
+            if (CHIPSET_SEGMENT_virtual_address(mch_chipset_seg) == 0) {
+                // Map the virtual address of the PCI CHAP interface.
+                CHIPSET_SEGMENT_virtual_address(mch_chipset_seg) = (U64) (UIOP) ioremap_nocache(
+                                                      CHIPSET_SEGMENT_physical_address(mch_chipset_seg),
+                                                      CHIPSET_SEGMENT_size(mch_chipset_seg));
+            }
+        }
+
+        if (CHIPSET_CONFIG_ich_chipset(pma)) {
+            if (CHIPSET_SEGMENT_virtual_address(ich_chipset_seg) == 0) {
+                // Map the virtual address of the PCI CHAP interface.
+                CHIPSET_SEGMENT_virtual_address(ich_chipset_seg) = (U64) (UIOP) ioremap_nocache(
+                                                      CHIPSET_SEGMENT_physical_address(ich_chipset_seg),
+                                                      CHIPSET_SEGMENT_size(ich_chipset_seg));
+            }
+        }
+
+        // Here we map the MMIO registers for the Gen X processors.
+        if (CHIPSET_CONFIG_noa_chipset(pma)) {
+            if (CHIPSET_SEGMENT_virtual_address(noa_chipset_seg) == 0) {
+                // Map the virtual address of the PCI CHAP interface.
+                CHIPSET_SEGMENT_virtual_address(noa_chipset_seg) = (U64) (UIOP) ioremap_nocache(
+                                                    CHIPSET_SEGMENT_physical_address(noa_chipset_seg),
+                                                    CHIPSET_SEGMENT_size(noa_chipset_seg));
+            }
+        }
+
+        //
+        // always collect processor events
+        //
+        CHIPSET_CONFIG_processor(pma) = 1;
+    }
+    else {
+        CHIPSET_CONFIG_processor(pma) = 0;
+    }
+    SEP_DRV_LOG_TRACE("Initializing chipset done.");
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return VT_SUCCESS;
+}
+
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          static U32 chap_Start_Chipset(void)
+ * @param       None
+ * @return      VT_SUCCESS if successful, otherwise error
+ * @brief       Start collection on the Chipset PMU
+ *
+ * <I>Special Notes:</I>
+ *             <NONE>
+ */
+static VOID
+chap_Start_Chipset (
+    VOID
+)
+{
+    U32 i;
+    CHAP_INTERFACE  chap;
+    CHIPSET_SEGMENT mch_chipset_seg = &CHIPSET_CONFIG_mch(pma);
+    CHIPSET_SEGMENT ich_chipset_seg = &CHIPSET_CONFIG_ich(pma);
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    //
+    // reset and start chipset counters
+    //
+    SEP_DRV_LOG_TRACE("Starting chipset counters...\n");
+    if (pma) {
+        chap = (CHAP_INTERFACE)(UIOP)CHIPSET_SEGMENT_virtual_address(mch_chipset_seg);
+        if (chap != NULL) {
+            for (i = 0; i < CHIPSET_SEGMENT_total_events(mch_chipset_seg); i++) {
+                CHAP_INTERFACE_command_register(&chap[i]) = 0x00040000; // Reset to zero
+                CHAP_INTERFACE_command_register(&chap[i]) = 0x00010000; // Restart
+            }
+        }
+
+        chap = (CHAP_INTERFACE) (UIOP)CHIPSET_SEGMENT_virtual_address(ich_chipset_seg);
+        if (chap != NULL) {
+            for (i = 0; i < CHIPSET_SEGMENT_total_events(ich_chipset_seg); i++) {
+                CHAP_INTERFACE_command_register(&chap[i]) = 0x00040000; // Reset to zero
+                CHAP_INTERFACE_command_register(&chap[i]) = 0x00010000; // Restart
+            }
+        }
+    }
+
+    SEP_DRV_LOG_TRACE("Starting chipset counters done.\n");
+
+    SEP_DRV_LOG_TRACE_OUT("");
+
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          static U32 chap_Read_Counters(PVOID param)
+ * 
+ * @brief       Read the CHAP counter data
+ *
+ * @param       PVOID param - address of the buffer to write into
+ * 
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ *             <NONE>
+ */
+static VOID
+chap_Read_Counters (
+    PVOID  param
+)
+{
+    U64            *data;
+    CHAP_INTERFACE  chap;
+    U32             mch_cpu;
+    int             i, data_index;
+    U64             tmp_data;
+    U64            *mch_data;
+    U64            *ich_data;
+    U64            *mmio_data;
+    U64            *mmio;
+    U32             this_cpu;
+    CHIPSET_SEGMENT mch_chipset_seg = &CHIPSET_CONFIG_mch(pma);
+    CHIPSET_SEGMENT ich_chipset_seg = &CHIPSET_CONFIG_ich(pma);
+    CHIPSET_SEGMENT noa_chipset_seg = &CHIPSET_CONFIG_noa(pma);
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu   = CONTROL_THIS_CPU();
+    data       = param;
+    data_index = 0;
+
+    // Save the Motherboard time.  This is universal time for this
+    // system.  This is the only 64-bit timer so we save it first so
+    // always aligned on 64-bit boundary that way.
+
+    if (CHIPSET_CONFIG_mch_chipset(pma)) {
+        mch_data = data + data_index;
+        // Save the MCH counters.
+        chap = (CHAP_INTERFACE)(UIOP)CHIPSET_SEGMENT_virtual_address(mch_chipset_seg);
+        for (i = CHIPSET_SEGMENT_start_register(mch_chipset_seg);
+                        i < CHIPSET_SEGMENT_total_events(mch_chipset_seg); i++) {
+            CHAP_INTERFACE_command_register(&chap[i]) = 0x00020000; // Sample
+        }
+
+        // The StartingReadRegister is only used for special event
+        // configs that use CHAP counters to trigger events in other
+        // CHAP counters.  This is an unusual request but useful in
+        // getting the number of lit subspans - implying a count of the
+        // number of triangles.  I am not sure it will be used
+        // elsewhere.  We cannot read some of the counters because it
+        // will invalidate their configuration to trigger other CHAP
+        // counters.  Yuk!
+        data_index += CHIPSET_SEGMENT_start_register(mch_chipset_seg);
+        for (i = CHIPSET_SEGMENT_start_register(mch_chipset_seg);
+                        i < CHIPSET_SEGMENT_total_events(mch_chipset_seg); i++) {
+            data[data_index++] = CHAP_INTERFACE_data_register(&chap[i]);
+        }
+
+        // Initialize the counters on the first interrupt
+        if (pcb[this_cpu].chipset_count_init == TRUE) {
+            for (i = 0; i < CHIPSET_SEGMENT_total_events(mch_chipset_seg); i++) {
+                pcb[this_cpu].last_mch_count[i] = mch_data[i];
+            }
+        }
+
+        // Now compute the delta!
+        // NOTE: Special modification to accomodate Gen 4 work - count
+        // everything since last interrupt - regardless of cpu!  This
+        // way there is only one count of the Gen 4 counters.
+        //
+        mch_cpu = CHIPSET_CONFIG_host_proc_run(pma) ? this_cpu : 0;
+        for (i = 0; i < CHIPSET_SEGMENT_total_events(mch_chipset_seg); i++) {
+            tmp_data = mch_data[i];
+            if (mch_data[i] < pcb[mch_cpu].last_mch_count[i]) {
+                mch_data[i] = mch_data[i] + (U32)(-1) - pcb[mch_cpu].last_mch_count[i];
+            }
+            else {
+                mch_data[i] = mch_data[i] - pcb[mch_cpu].last_mch_count[i];
+            }
+            pcb[mch_cpu].last_mch_count[i] = tmp_data;
+        }
+    }
+
+    if (CHIPSET_CONFIG_ich_chipset(pma)) {
+        // Save the ICH counters.
+        ich_data = data + data_index;
+        chap = (CHAP_INTERFACE)(UIOP)CHIPSET_SEGMENT_virtual_address(ich_chipset_seg);
+        for (i = 0; i < CHIPSET_SEGMENT_total_events(ich_chipset_seg); i++) {
+            CHAP_INTERFACE_command_register(&chap[i]) = 0x00020000; // Sample
+        }
+
+        for (i = 0; i < CHIPSET_SEGMENT_total_events(ich_chipset_seg); i++) {
+            data[data_index++] = CHAP_INTERFACE_data_register(&chap[i]);
+        }
+
+        // Initialize the counters on the first interrupt
+        if (pcb[this_cpu].chipset_count_init == TRUE) {
+            for (i = 0; i < CHIPSET_SEGMENT_total_events(ich_chipset_seg); i++) {
+                pcb[this_cpu].last_ich_count[i] = ich_data[i];
+            }
+        }
+
+        // Now compute the delta!
+        for (i = 0; i < CHIPSET_SEGMENT_total_events(ich_chipset_seg); i++) {
+            tmp_data = ich_data[i];
+            if (ich_data[i] < pcb[this_cpu].last_ich_count[i]) {
+                ich_data[i] = ich_data[i] + (U32)(-1) - pcb[this_cpu].last_ich_count[i];
+            }
+            else {
+                ich_data[i] = ich_data[i] - pcb[this_cpu].last_ich_count[i];
+            }
+            pcb[this_cpu].last_ich_count[i] = tmp_data;
+        }
+    }
+
+    if (CHIPSET_CONFIG_noa_chipset(pma)) {
+        // Save the MMIO counters.
+        mmio_data = data + data_index;
+        mmio      = (U64 *) (UIOP)CHIPSET_SEGMENT_virtual_address(noa_chipset_seg);
+
+        for (i = 0; i < CHIPSET_SEGMENT_total_events(noa_chipset_seg); i++) {
+            data[data_index++] = mmio[i*2 + 2244]; // 64-bit quantity
+        }
+
+        // Initialize the counters on the first interrupt
+        if (pcb[this_cpu].chipset_count_init == TRUE) {
+            for (i = 0; i < CHIPSET_SEGMENT_total_events(noa_chipset_seg); i++) {
+                pcb[this_cpu].last_mmio_count[i] = mmio_data[i];
+            }
+        }
+
+        // Now compute the delta!
+        for (i = 0; i < CHIPSET_SEGMENT_total_events(noa_chipset_seg); i++) {
+            tmp_data = mmio_data[i];
+            if (mmio_data[i] < pcb[this_cpu].last_mmio_count[i]) {
+                mmio_data[i] = mmio_data[i] + (U32)(-1) - pcb[this_cpu].last_mmio_count[i];
+            }
+            else {
+                mmio_data[i] = mmio_data[i] - pcb[this_cpu].last_mmio_count[i];
+            }
+            pcb[this_cpu].last_mmio_count[i] = tmp_data;
+        }
+    }
+
+    pcb[this_cpu].chipset_count_init = FALSE;
+
+    FOR_EACH_DATA_REG(pecb,i) {
+            data[data_index++] = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), (U64)0);
+    } END_FOR_EACH_DATA_REG;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          static VOID chap_Stop_Chipset(void)
+ * 
+ * @brief       Stop the Chipset PMU
+ *
+ * @param       None
+ * 
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ *             <NONE>
+ */
+static VOID
+chap_Stop_Chipset (
+    VOID
+)
+{
+    U32 i;
+    CHAP_INTERFACE  chap;
+    CHIPSET_SEGMENT mch_chipset_seg = &CHIPSET_CONFIG_mch(pma);
+    CHIPSET_SEGMENT ich_chipset_seg = &CHIPSET_CONFIG_ich(pma);
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    //
+    // reset and start chipset counters
+    //
+    SEP_DRV_LOG_TRACE("Stopping chipset counters...");
+    if (pma) {
+        if (CHIPSET_CONFIG_mch_chipset(pma)) {
+            chap = (CHAP_INTERFACE)(UIOP)CHIPSET_SEGMENT_virtual_address(mch_chipset_seg);
+            if (chap != NULL) {
+                for (i = 0; i < CHIPSET_SEGMENT_total_events(mch_chipset_seg); i++) {
+                    CHAP_INTERFACE_command_register(&chap[i]) = 0x00000000; // Stop
+                    CHAP_INTERFACE_command_register(&chap[i]) = 0x00040000; // Reset to Zero
+                }
+            }
+        }
+
+        if (CHIPSET_CONFIG_ich_chipset(pma)) {
+            chap = (CHAP_INTERFACE)(UIOP)CHIPSET_SEGMENT_virtual_address(ich_chipset_seg);
+            if (chap != NULL) {
+                for (i = 0; i < CHIPSET_SEGMENT_total_events(ich_chipset_seg); i++) {
+                    CHAP_INTERFACE_command_register(&chap[i]) = 0x00000000; // Stop
+                    CHAP_INTERFACE_command_register(&chap[i]) = 0x00040000; // Reset to Zero
+                }
+            }
+        }
+
+        if (CHIPSET_CONFIG_mch_chipset(pma) && CHIPSET_SEGMENT_virtual_address(mch_chipset_seg)) {
+            iounmap((void*)(UIOP)CHIPSET_SEGMENT_virtual_address(mch_chipset_seg));
+            CHIPSET_SEGMENT_virtual_address(mch_chipset_seg) = 0;
+        }
+
+        if (CHIPSET_CONFIG_ich_chipset(pma) && CHIPSET_SEGMENT_virtual_address(ich_chipset_seg)) {
+            iounmap((void*)(UIOP)CHIPSET_SEGMENT_virtual_address(ich_chipset_seg));
+            CHIPSET_SEGMENT_virtual_address(ich_chipset_seg) = 0;
+        }
+        CONTROL_Free_Memory(pma);
+        pma = NULL;
+    }
+
+    SEP_DRV_LOG_TRACE("Stopped chipset counters.");
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          static VOID chap_Fini_Chipset(void)
+ * 
+ * @brief       Finish routine on a per-logical-core basis
+ *
+ * @param       None
+ * 
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ *             <NONE>
+ */
+static VOID
+chap_Fini_Chipset (
+    VOID
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+    SEP_DRV_LOG_TRACE_OUT("Empty function.");
+    return;
+}
+
+CS_DISPATCH_NODE  chap_dispatch =
+{
+    chap_Init_Chipset,
+    chap_Start_Chipset,
+    chap_Read_Counters,
+    chap_Stop_Chipset,
+    chap_Fini_Chipset,
+    NULL
+};
diff --git a/drivers/misc/intel/sepdk/sep/control.c b/drivers/misc/intel/sepdk/sep/control.c
new file mode 100644
index 000000000000..3e5a8c5f951c
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/control.c
@@ -0,0 +1,853 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/mm.h>
+#include <linux/mempool.h>
+#include <linux/slab.h>
+#include <linux/vmalloc.h>
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv.h"
+#include "control.h"
+#include "utility.h"
+#include <linux/sched.h>
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 27)
+#define SMP_CALL_FUNCTION(func,ctx,retry,wait)               smp_call_function((func),(ctx),(wait))
+#define SMP_CALL_FUNCTION_SINGLE(cpuid,func,ctx,retry,wait)  smp_call_function_single((cpuid),(func),(ctx),(wait))
+#define ON_EACH_CPU(func,ctx,retry,wait)                     on_each_cpu((func),(ctx),(wait))
+#else
+#define SMP_CALL_FUNCTION(func,ctx,retry,wait)               smp_call_function((func),(ctx),(retry),(wait))
+#define SMP_CALL_FUNCTION_SINGLE(cpuid,func,ctx,retry,wait)  smp_call_function_single((cpuid),(func),(ctx),(retry),(wait))
+#define ON_EACH_CPU(func,ctx,retry,wait)                     on_each_cpu((func),(ctx),(retry),(wait))
+#endif
+
+/*
+ */
+GLOBAL_STATE_NODE  driver_state;
+MSR_DATA           msr_data      = NULL;
+MEM_TRACKER        mem_tr_head   = NULL;   // start of the mem tracker list
+MEM_TRACKER        mem_tr_tail   = NULL;   // end of mem tracker list
+spinlock_t         mem_tr_lock;            // spinlock for mem tracker list
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       VOID CONTROL_Invoke_Cpu (func, ctx, arg)
+ *
+ * @brief    Set up a DPC call and insert it into the queue
+ *
+ * @param    IN cpu_idx  - the core id to dispatch this function to
+ *           IN func     - function to be invoked by the specified core(s)
+ *           IN ctx      - pointer to the parameter block for each function
+ *                         invocation
+ *
+ * @return   None
+ *
+ * <I>Special Notes:</I>
+ *
+ */
+extern VOID
+CONTROL_Invoke_Cpu (
+    int     cpu_idx,
+    VOID    (*func)(PVOID),
+    PVOID   ctx
+)
+{
+    SEP_DRV_LOG_TRACE_IN("CPU: %d, function: %p, ctx: %p.", cpu_idx, func, ctx);
+    SMP_CALL_FUNCTION_SINGLE(cpu_idx, func, ctx, 0, 1);
+    SEP_DRV_LOG_TRACE_OUT("");
+
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn VOID CONTROL_Invoke_Parallel_Service(func, ctx, blocking, exclude)
+ *
+ * @param    func     - function to be invoked by each core in the system
+ * @param    ctx      - pointer to the parameter block for each function invocation
+ * @param    blocking - Wait for invoked function to complete
+ * @param    exclude  - exclude the current core from executing the code
+ *
+ * @returns  None
+ *
+ * @brief    Service routine to handle all kinds of parallel invoke on all CPU calls
+ *
+ * <I>Special Notes:</I>
+ *           Invoke the function provided in parallel in either a blocking or
+ *           non-blocking mode.  The current core may be excluded if desired.
+ *           NOTE - Do not call this function directly from source code.
+ *           Use the aliases CONTROL_Invoke_Parallel(), CONTROL_Invoke_Parallel_NB(),
+ *           or CONTROL_Invoke_Parallel_XS().
+ *
+ */
+extern VOID
+CONTROL_Invoke_Parallel_Service (
+    VOID   (*func)(PVOID),
+    PVOID  ctx,
+    int    blocking,
+    int    exclude
+)
+{
+    SEP_DRV_LOG_TRACE_IN("Fn: %p, ctx: %p, block: %d, excl: %d.", func, ctx, blocking, exclude);
+
+    GLOBAL_STATE_cpu_count(driver_state) = 0;
+    GLOBAL_STATE_dpc_count(driver_state) = 0;
+
+    if (GLOBAL_STATE_num_cpus(driver_state) == 1) {
+        if (!exclude) {
+            func(ctx);
+        }
+        SEP_DRV_LOG_TRACE_OUT("");
+        return;
+    }
+    if (!exclude) {
+        ON_EACH_CPU(func, ctx, 0, blocking);
+        SEP_DRV_LOG_TRACE_OUT("");
+        return;
+    }
+
+    preempt_disable();
+    SMP_CALL_FUNCTION (func, ctx, 0, blocking);
+    preempt_enable();
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn VOID control_Memory_Tracker_Delete_Node(mem_tr)
+ *
+ * @param    IN mem_tr    - memory tracker node to delete
+ *
+ * @returns  None
+ *
+ * @brief    Delete specified node in the memory tracker
+ *
+ * <I>Special Notes:</I>
+ *           Assumes mem_tr_lock is already held while calling this function!
+ */
+static VOID
+control_Memory_Tracker_Delete_Node (
+    MEM_TRACKER mem_tr
+)
+{
+    MEM_TRACKER prev_tr = NULL;
+    MEM_TRACKER next_tr = NULL;
+    U32         size    = 0;
+
+    SEP_DRV_LOG_ALLOC_IN("");
+
+    if (! mem_tr) {
+        SEP_DRV_LOG_ALLOC_OUT("mem_tr is NULL!");
+        return;
+    }
+    size     = MEM_TRACKER_max_size(mem_tr) * sizeof(MEM_EL_NODE);
+    // update the linked list
+    prev_tr = MEM_TRACKER_prev(mem_tr);
+    next_tr = MEM_TRACKER_next(mem_tr);
+    if (prev_tr) {
+        MEM_TRACKER_next(prev_tr) = next_tr;
+    }
+    if (next_tr) {
+        MEM_TRACKER_prev(next_tr) = prev_tr;
+    }
+
+    // free the allocated mem_el array (if any)
+    if (MEM_TRACKER_mem(mem_tr)) {
+        if (MEM_TRACKER_array_vmalloc(mem_tr)) {
+            vfree(MEM_TRACKER_mem(mem_tr));
+        }
+        else {
+            if (size < MAX_KMALLOC_SIZE) {
+                kfree(MEM_TRACKER_mem(mem_tr));
+            }
+            else {
+                free_pages((unsigned long)MEM_TRACKER_mem(mem_tr), get_order(size));
+            }
+        }
+    }
+
+    // free the mem_tracker node
+    if (MEM_TRACKER_node_vmalloc(mem_tr)) {
+        vfree(mem_tr);
+    }
+    else {
+        kfree(mem_tr);
+    }
+    SEP_DRV_LOG_ALLOC_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn VOID control_Memory_Tracker_Create_Node(void)
+ *
+ * @param    None    - size of the memory to allocate
+ *
+ * @returns  OS_SUCCESS if successful, otherwise error
+ *
+ * @brief    Initialize the memory tracker
+ *
+ * <I>Special Notes:</I>
+ *           Assumes mem_tr_lock is already held while calling this function!
+ *
+ *           Since this function can be called within either GFP_KERNEL or
+ *           GFP_ATOMIC contexts, the most restrictive allocation is used
+ *           (viz., GFP_ATOMIC).
+ */
+static U32
+control_Memory_Tracker_Create_Node (
+    void
+)
+{
+    U32         size     = MEM_EL_MAX_ARRAY_SIZE * sizeof(MEM_EL_NODE);
+    PVOID       location = NULL;
+    MEM_TRACKER mem_tr   = NULL;
+
+    SEP_DRV_LOG_ALLOC_IN("");
+
+    // create a mem tracker node
+    mem_tr = (MEM_TRACKER)kmalloc(sizeof(MEM_TRACKER_NODE), GFP_ATOMIC);
+    if (!mem_tr) {
+        mem_tr = (MEM_TRACKER)vmalloc(sizeof(MEM_TRACKER_NODE));
+        if (mem_tr) {
+            MEM_TRACKER_node_vmalloc(mem_tr)  = 1;
+        }
+        else {
+            SEP_DRV_LOG_ERROR_ALLOC_OUT("Failed to allocate mem tracker node.");
+            return OS_FAULT;
+        }
+    }
+    else {
+        MEM_TRACKER_node_vmalloc(mem_tr)  = 0;
+    }
+    SEP_DRV_LOG_TRACE("Node %p, vmalloc %d.", mem_tr, MEM_TRACKER_node_vmalloc(mem_tr));
+
+    // create an initial array of mem_el's inside the mem tracker node
+    MEM_TRACKER_array_vmalloc(mem_tr)  = 0;
+    if (size < MAX_KMALLOC_SIZE) {
+        location = (PVOID)kmalloc(size, GFP_ATOMIC);
+        SEP_DRV_LOG_ALLOC("Allocated small memory (0x%p, %d).", location, (S32) size);
+    }
+    else {
+        location = (PVOID)__get_free_pages(GFP_ATOMIC, get_order(size));
+        SEP_DRV_LOG_ALLOC("Allocated large memory (0x%p, %d).", location, (S32) size);
+    }
+    if (!location) {
+        location = (PVOID)vmalloc(size);
+        if (location) {
+            MEM_TRACKER_array_vmalloc(mem_tr)  = 1;
+            SEP_DRV_LOG_ALLOC("Allocated memory (vmalloc) (0x%p, %d).", location, (S32) size);
+        }
+        else {
+            if (MEM_TRACKER_node_vmalloc(mem_tr)) {
+                 vfree(mem_tr);
+            }
+            else {
+                 kfree(mem_tr);
+            }
+            SEP_DRV_LOG_ERROR_ALLOC_OUT("Failed to allocate mem_el array... deleting node.");
+            return OS_FAULT;
+        }
+    }
+
+    // initialize new mem tracker node
+    MEM_TRACKER_mem(mem_tr)  = location;
+    MEM_TRACKER_prev(mem_tr) = NULL;
+    MEM_TRACKER_next(mem_tr) = NULL;
+
+    // initialize mem_tracker's mem_el array
+    MEM_TRACKER_max_size(mem_tr) = MEM_EL_MAX_ARRAY_SIZE;
+    MEM_TRACKER_elements(mem_tr) = 0;
+    memset(MEM_TRACKER_mem(mem_tr), 0, size);
+
+    // update the linked list
+    if (!mem_tr_head) {
+        mem_tr_head = mem_tr;
+    }
+    else {
+        MEM_TRACKER_prev(mem_tr) = mem_tr_tail;
+        MEM_TRACKER_next(mem_tr_tail) = mem_tr;
+    }
+    mem_tr_tail = mem_tr;
+
+    SEP_DRV_LOG_ALLOC_OUT("Allocated node=0x%p, max_elements=%d, size=%d.",
+                    MEM_TRACKER_mem(mem_tr_tail), MEM_EL_MAX_ARRAY_SIZE, size);
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn VOID control_Memory_Tracker_Add(location, size, vmalloc_flag)
+ *
+ * @param    IN location     - memory location
+ * @param    IN size         - size of the memory to allocate
+ * @param    IN vmalloc_flag - flag that indicates if the allocation was done with vmalloc
+ *
+ * @returns  None
+ *
+ * @brief    Keep track of allocated memory with memory tracker
+ *
+ * <I>Special Notes:</I>
+ *           Starting from first mem_tracker node, the algorithm
+ *           finds the first "hole" in the mem_tracker list and
+ *           tracks the memory allocation there.
+ */
+static U32
+control_Memory_Tracker_Add (
+    PVOID     location,
+    ssize_t   size,
+    DRV_BOOL  vmalloc_flag
+)
+{
+    S32         i, n;
+    U32         status;
+    DRV_BOOL    found;
+    MEM_TRACKER mem_tr;
+
+    SEP_DRV_LOG_ALLOC_IN("Location: %p, size: %u, flag: %u.", location, (U32) size, vmalloc_flag);
+
+    spin_lock(&mem_tr_lock);
+
+    // check if there is space in ANY of mem_tracker's nodes for the memory item
+    mem_tr = mem_tr_head;
+    found = FALSE;
+    status = OS_SUCCESS;
+    i = n = 0;
+    while (mem_tr && (!found)) {
+        if (MEM_TRACKER_elements(mem_tr) < MEM_TRACKER_max_size(mem_tr)) {
+            for (i = 0; i < MEM_TRACKER_max_size(mem_tr); i++) {
+                if (!MEM_TRACKER_mem_address(mem_tr,i)) {
+                    SEP_DRV_LOG_ALLOC("Found index %d of %d available.",
+                                        i,
+                                        MEM_TRACKER_max_size(mem_tr) - 1);
+                    n = i;
+                    found = TRUE;
+                    break;
+                }
+            }
+        }
+        if (!found) {
+            mem_tr = MEM_TRACKER_next(mem_tr);
+        }
+    }
+
+    if (!found) {
+        // extend into (i.e., create new) mem_tracker node ...
+        status = control_Memory_Tracker_Create_Node();
+        if (status != OS_SUCCESS) {
+            SEP_DRV_LOG_ERROR("Unable to create mem tracker node.");
+            goto finish_add;
+        }
+        // use mem tracker tail node and first available entry in mem_el array
+        mem_tr = mem_tr_tail;
+        n = 0;
+    }
+
+    // we now have a location in mem tracker to keep track of the memory item
+    MEM_TRACKER_mem_address(mem_tr,n) = location;
+    MEM_TRACKER_mem_size(mem_tr,n)    = size;
+    MEM_TRACKER_mem_vmalloc(mem_tr,n) = vmalloc_flag;
+    MEM_TRACKER_elements(mem_tr)++;
+    SEP_DRV_LOG_ALLOC("Tracking (0x%p, %d) in node %d of %d.",
+                     location, (S32)size, n, MEM_TRACKER_max_size(mem_tr) - 1);
+
+finish_add:
+    spin_unlock(&mem_tr_lock);
+
+    SEP_DRV_LOG_ALLOC_OUT("Result: %u.", status);
+    return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn VOID CONTROL_Memory_Tracker_Init(void)
+ *
+ * @param    None
+ *
+ * @returns  None
+ *
+ * @brief    Initializes Memory Tracker
+ *
+ * <I>Special Notes:</I>
+ *           This should only be called when the driver is being loaded.
+ */
+extern VOID
+CONTROL_Memory_Tracker_Init (
+    VOID
+)
+{
+    SEP_DRV_LOG_ALLOC_IN("Initializing mem tracker.");
+
+    mem_tr_head = NULL;
+    mem_tr_tail = NULL;
+
+    spin_lock_init(&mem_tr_lock);
+
+    SEP_DRV_LOG_ALLOC_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn VOID CONTROL_Memory_Tracker_Free(void)
+ *
+ * @param    None
+ *
+ * @returns  None
+ *
+ * @brief    Frees memory used by Memory Tracker
+ *
+ * <I>Special Notes:</I>
+ *           This should only be called when the driver is being unloaded.
+ */
+extern VOID
+CONTROL_Memory_Tracker_Free (
+    VOID
+)
+{
+    S32         i;
+    MEM_TRACKER temp;
+
+    SEP_DRV_LOG_ALLOC_IN("Destroying mem tracker.");
+
+    spin_lock(&mem_tr_lock);
+
+    // check for any memory that was not freed, and free it
+    while (mem_tr_head) {
+        if (MEM_TRACKER_elements(mem_tr_head)) {
+            for (i = 0; i < MEM_TRACKER_max_size(mem_tr_head); i++) {
+                if (MEM_TRACKER_mem_address(mem_tr_head,i)) {
+                    SEP_DRV_LOG_WARNING("Index %d of %d, not freed (0x%p, %d) ... freeing now.",
+                                             i,
+                                             MEM_TRACKER_max_size(mem_tr_head)-1,
+                                             MEM_TRACKER_mem_address(mem_tr_head,i),
+                                             MEM_TRACKER_mem_size(mem_tr_head,i));
+                    if (MEM_TRACKER_mem_vmalloc(mem_tr_head,i)) {
+                        vfree(MEM_TRACKER_mem_address(mem_tr_head,i));
+                    }
+                    else {
+                        free_pages((unsigned long)MEM_TRACKER_mem_address(mem_tr_head,i), get_order(MEM_TRACKER_mem_size(mem_tr_head,i)));
+                    }
+                    MEM_TRACKER_mem_address(mem_tr_head,i) = NULL;
+                    MEM_TRACKER_mem_size(mem_tr_head,i)    = 0;
+                    MEM_TRACKER_mem_vmalloc(mem_tr_head,i) = 0;
+                }
+            }
+        }
+        temp = mem_tr_head;
+        mem_tr_head = MEM_TRACKER_next(mem_tr_head);
+        control_Memory_Tracker_Delete_Node(temp);
+    }
+
+    mem_tr_tail = NULL;
+
+    spin_unlock(&mem_tr_lock);
+
+    SEP_DRV_LOG_ALLOC_OUT("Mem tracker destruction complete.");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn VOID CONTROL_Memory_Tracker_Compaction(void)
+ *
+ * @param    None
+ *
+ * @returns  None
+ *
+ * @brief    Compacts the memory allocator if holes are detected
+ *
+ * <I>Special Notes:</I>
+ *           The algorithm compacts mem_tracker nodes such that
+ *           node entries are full starting from mem_tr_head
+ *           up until the first empty node is detected, after
+ *           which nodes up to mem_tr_tail will be empty.
+ *           At end of collection (or at other safe sync point),
+ *           we reclaim/compact space used by mem tracker.
+ */
+extern VOID
+CONTROL_Memory_Tracker_Compaction (
+    void
+)
+{
+    S32         i, j, n, m, c, d;
+    DRV_BOOL    found, overlap;
+    MEM_TRACKER mem_tr1, mem_tr2, empty_tr;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    spin_lock(&mem_tr_lock);
+
+    mem_tr1 = mem_tr_head;
+
+    i = j = n = c = d = 0;
+
+    /*
+     * step1: free up the track node which does not contain any elements.
+     */
+    while (mem_tr1) {
+        SEP_DRV_LOG_ALLOC("Node %p, index %d, elememts %d.", mem_tr1, n, MEM_TRACKER_elements(mem_tr1));
+        if (MEM_TRACKER_elements(mem_tr1)) {
+            mem_tr1 = MEM_TRACKER_next(mem_tr1);
+        }
+        else {
+            empty_tr = mem_tr1;
+            mem_tr1 = MEM_TRACKER_next(mem_tr1);
+            if (empty_tr == mem_tr_head) {
+                mem_tr_head = mem_tr1;
+            }
+            if (empty_tr == mem_tr_tail) {
+                mem_tr_tail = MEM_TRACKER_prev(empty_tr);
+            }
+            control_Memory_Tracker_Delete_Node(empty_tr);
+            d++;
+            SEP_DRV_LOG_ALLOC("Delete node %p.", mem_tr1);
+        }
+    }
+
+    mem_tr1 = mem_tr_head;
+    mem_tr2 = mem_tr_tail;
+
+    /*
+     * there is no need to compact if memory tracker was never used, or only have one track node
+     */
+    overlap = (mem_tr1 == mem_tr2);
+    if (!mem_tr1 || !mem_tr2 || overlap) {
+        goto finish_compact;
+    }
+
+    /*
+     * step2: there are more than 2 track node.
+     *        starting from head node, find an empty element slot in a node
+     *        if there is no empty slot or the node is tail, the compact is done.
+     *        find an element in tail node, and move it to the empty slot fount below.
+     *        if tail node is empty after moving, free it up.
+     *        repeat until only one node.
+     */
+    m = MEM_TRACKER_max_size(mem_tr2) - 1;
+    while (!overlap) {
+        // find an empty node
+        found = FALSE;
+        while (!found && !overlap && mem_tr1) {
+            SEP_DRV_LOG_TRACE("Looking at mem_tr1 0x%p, index=%d, elements %d.", mem_tr1, n, MEM_TRACKER_elements(mem_tr1));
+            if (MEM_TRACKER_elements(mem_tr1) < MEM_TRACKER_max_size(mem_tr1)) {
+                for (i = n; i < MEM_TRACKER_max_size(mem_tr1); i++) {
+                    if (!MEM_TRACKER_mem_address(mem_tr1,i)) {
+                        SEP_DRV_LOG_TRACE("Found index %d of %d empty.",
+                                            i,
+                                            MEM_TRACKER_max_size(mem_tr1)-1);
+                        found = TRUE;
+                        break; // tentative
+                    }
+                }
+            }
+
+            // if no overlap and an empty node was not found, then advance to next node
+            if (!found) {
+                mem_tr1 = MEM_TRACKER_next(mem_tr1);
+                // check for overlap
+                overlap = (mem_tr1==mem_tr2);
+                n = 0;
+            }
+        }
+        // all nodes going in forward direction are full, so exit
+        if (!found || overlap || !mem_tr1) {
+            goto finish_compact;
+        }
+
+        // find a non-empty node
+        found = FALSE;
+        while (!found && !overlap && mem_tr2) {
+            SEP_DRV_LOG_ALLOC("Looking at mem_tr2 0x%p, index=%d, elements %d.", mem_tr2, m, MEM_TRACKER_elements(mem_tr2));
+            if (MEM_TRACKER_elements(mem_tr2)) {
+                for (j = m; j >= 0; j--) {
+                    if (MEM_TRACKER_mem_address(mem_tr2,j)) {
+                        SEP_DRV_LOG_ALLOC("Found index %d of %d non-empty.",
+                                            j,
+                                            MEM_TRACKER_max_size(mem_tr2)-1);
+                        found = TRUE;
+                        // Any reason why we are not 'breaking' here?
+                    }
+                }
+            }
+
+            // if no overlap and no non-empty node was found, then retreat to prev node
+            if (!found) {
+                empty_tr = mem_tr2;  // keep track of empty node
+                mem_tr2 = MEM_TRACKER_prev(mem_tr2);
+                m = MEM_TRACKER_max_size(mem_tr2) - 1;
+                mem_tr_tail = mem_tr2; // keep track of new tail
+                // reclaim empty mem_tracker node
+                control_Memory_Tracker_Delete_Node(empty_tr);
+                // keep track of number of node deletions performed
+                d++;
+                // check for overlap
+                overlap = (mem_tr1==mem_tr2);
+            }
+        }
+        // all nodes going in reverse direction are empty, so exit
+        if (!found || overlap || !mem_tr2 ) {
+            goto finish_compact;
+        }
+
+        // swap empty node with non-empty node so that "holes" get bubbled towards the end of list
+        MEM_TRACKER_mem_address(mem_tr1,i) = MEM_TRACKER_mem_address(mem_tr2,j);
+        MEM_TRACKER_mem_size(mem_tr1,i)    = MEM_TRACKER_mem_size(mem_tr2,j);
+        MEM_TRACKER_mem_vmalloc(mem_tr1,i) = MEM_TRACKER_mem_vmalloc(mem_tr2,j);
+        MEM_TRACKER_elements(mem_tr1)++;
+
+        MEM_TRACKER_mem_address(mem_tr2,j) = NULL;
+        MEM_TRACKER_mem_size(mem_tr2,j)    = 0;
+        MEM_TRACKER_mem_vmalloc(mem_tr2,j) = FALSE;
+        MEM_TRACKER_elements(mem_tr2)--;
+
+        SEP_DRV_LOG_ALLOC("Node <%p,elemts %d,index %d> moved to <%p,elemts %d,index %d>.", mem_tr2, MEM_TRACKER_elements(mem_tr2), j, mem_tr1, MEM_TRACKER_elements(mem_tr1), i);
+
+        // keep track of number of memory compactions performed
+        c++;
+
+        // start new search starting from next element in mem_tr1
+        n = i+1;
+
+        // start new search starting from prev element in mem_tr2
+        m = j-1;
+    }
+
+finish_compact:
+    spin_unlock(&mem_tr_lock);
+
+    SEP_DRV_LOG_FLOW_OUT("Number of elements compacted = %d, nodes deleted = %d.", c, d);
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn PVOID CONTROL_Allocate_Memory(size)
+ *
+ * @param    IN size     - size of the memory to allocate
+ *
+ * @returns  char*       - pointer to the allocated memory block
+ *
+ * @brief    Allocate and zero memory
+ *
+ * <I>Special Notes:</I>
+ *           Allocate memory in the GFP_KERNEL pool.
+ *
+ *           Use this if memory is to be allocated within a context where
+ *           the allocator can block the allocation (e.g., by putting
+ *           the caller to sleep) while it tries to free up memory to
+ *           satisfy the request.  Otherwise, if the allocation must
+ *           occur atomically (e.g., caller cannot sleep), then use
+ *           CONTROL_Allocate_KMemory instead.
+ */
+extern PVOID
+CONTROL_Allocate_Memory (
+    size_t size
+)
+{
+    U32   status;
+    PVOID location = NULL;
+
+    SEP_DRV_LOG_ALLOC_IN("Attempting to allocate %d bytes.", (S32) size);
+
+    if (size <= 0) {
+        SEP_DRV_LOG_WARNING_ALLOC_OUT("Cannot allocate a number of bytes <= 0.");
+        return NULL;
+    }
+
+    // determine whether to use mem_tracker or not
+    if (size < MAX_KMALLOC_SIZE) {
+        location = (PVOID)kmalloc(size, GFP_KERNEL);
+        SEP_DRV_LOG_ALLOC("Allocated small memory (0x%p, %d)", location, (S32) size);
+    }
+    if (!location) {
+        location = (PVOID)vmalloc(size);
+        if (location) {
+            status = control_Memory_Tracker_Add(location, size, TRUE);
+            SEP_DRV_LOG_ALLOC("Allocated large memory (0x%p, %d)", location, (S32) size);
+            if (status != OS_SUCCESS) {
+                // failed to track in mem_tracker, so free up memory and return NULL
+                SEP_DRV_LOG_ERROR("Allocated %db; failed to track w/ MEM_TRACKER. Freeing...", (S32) size);
+                vfree(location);
+                location = NULL;
+            }
+        }
+    }
+
+    if (!location) {
+        SEP_DRV_LOG_ERROR("Failed to allocated %db.", (S32) size);
+    }
+    else {
+        memset(location, 0, size);
+    }
+
+    SEP_DRV_LOG_ALLOC_OUT("Returning %p.", location);
+    return location;
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn PVOID CONTROL_Allocate_KMemory(size)
+ *
+ * @param    IN size     - size of the memory to allocate
+ *
+ * @returns  char*       - pointer to the allocated memory block
+ *
+ * @brief    Allocate and zero memory
+ *
+ * <I>Special Notes:</I>
+ *           Allocate memory in the GFP_ATOMIC pool.
+ *
+ *           Use this if memory is to be allocated within a context where
+ *           the allocator cannot block the allocation (e.g., by putting
+ *           the caller to sleep) as it tries to free up memory to
+ *           satisfy the request.  Examples include interrupt handlers,
+ *           process context code holding locks, etc.
+ */
+extern PVOID
+CONTROL_Allocate_KMemory (
+    size_t size
+)
+{
+    U32   status;
+    PVOID location;
+
+    SEP_DRV_LOG_ALLOC_IN("Attempting to allocate %d bytes.", (S32) size);
+
+    if (size <= 0) {
+        SEP_DRV_LOG_ALLOC_OUT("Cannot allocate a number of bytes <= 0.");
+        return NULL;
+    }
+
+    if (size < MAX_KMALLOC_SIZE) {
+        location = (PVOID)kmalloc(size, GFP_ATOMIC);
+        SEP_DRV_LOG_ALLOC("Allocated small memory (0x%p, %d)", location, (S32) size);
+    }
+    else {
+        location = (PVOID)__get_free_pages(GFP_ATOMIC, get_order(size));
+        if (location) {
+            status = control_Memory_Tracker_Add(location, size, FALSE);
+            SEP_DRV_LOG_ALLOC("Allocated large memory (0x%p, %d)", location, (S32) size);
+            if (status != OS_SUCCESS) {
+                // failed to track in mem_tracker, so free up memory and return NULL
+                SEP_DRV_LOG_ERROR("Allocated %db; failed to track w/ MEM_TRACKER. Freeing...", (S32) size);
+                free_pages((unsigned long)location, get_order(size));
+                location = NULL;
+            }
+        }
+    }
+
+    if (!location) {
+        SEP_DRV_LOG_ERROR("Failed to allocated %db.", (S32) size);
+    }
+    else {
+        memset(location, 0, size);
+    }
+
+    SEP_DRV_LOG_ALLOC_OUT("Returning %p.", location);
+    return location;
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn PVOID CONTROL_Free_Memory(location)
+ *
+ * @param    IN location  - size of the memory to allocate
+ *
+ * @returns  pointer to the allocated memory block
+ *
+ * @brief    Frees the memory block
+ *
+ * <I>Special Notes:</I>
+ *           Does not try to free memory if fed with a NULL pointer
+ *           Expected usage:
+ *               ptr = CONTROL_Free_Memory(ptr);
+ *           Does not do compaction ... can have "holes" in
+ *           mem_tracker list after this operation.
+ */
+extern PVOID
+CONTROL_Free_Memory (
+    PVOID  location
+)
+{
+    S32         i;
+    DRV_BOOL    found;
+    MEM_TRACKER mem_tr;
+
+    SEP_DRV_LOG_ALLOC_IN("Attempting to free %p.", location);
+
+    if (!location) {
+        SEP_DRV_LOG_ALLOC_OUT("Cannot free NULL.");
+        return NULL;
+    }
+
+    spin_lock(&mem_tr_lock);
+
+    // scan through mem_tracker nodes for matching entry (if any)
+    mem_tr = mem_tr_head;
+    found = FALSE;
+    while (mem_tr) {
+        for (i = 0; i < MEM_TRACKER_max_size(mem_tr); i++) {
+            if (location == MEM_TRACKER_mem_address(mem_tr,i)) {
+                SEP_DRV_LOG_ALLOC("Freeing large memory location 0x%p", location);
+                found = TRUE;
+                if (MEM_TRACKER_mem_vmalloc(mem_tr, i)) {
+                    vfree(location);
+                }
+                else {
+                    free_pages((unsigned long)location, get_order(MEM_TRACKER_mem_size(mem_tr,i)));
+                }
+                MEM_TRACKER_mem_address(mem_tr,i) = NULL;
+                MEM_TRACKER_mem_size(mem_tr,i)    = 0;
+                MEM_TRACKER_mem_vmalloc(mem_tr,i) = 0;
+                MEM_TRACKER_elements(mem_tr)--;
+                goto finish_free;
+            }
+        }
+        mem_tr = MEM_TRACKER_next(mem_tr);
+    }
+
+finish_free:
+    spin_unlock(&mem_tr_lock);
+
+    // must have been of smaller than the size limit for mem tracker nodes
+    if (!found) {
+        SEP_DRV_LOG_ALLOC("Freeing small memory location 0x%p", location);
+        kfree(location);
+    }
+
+    SEP_DRV_LOG_ALLOC_OUT("Success. Returning NULL.");
+    return NULL;
+}
diff --git a/drivers/misc/intel/sepdk/sep/core2.c b/drivers/misc/intel/sepdk/sep/core2.c
new file mode 100644
index 000000000000..65830679c60f
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/core2.c
@@ -0,0 +1,1918 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/wait.h>
+#include <linux/fs.h>
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+#include "lwpmudrv.h"
+#include "utility.h"
+#include "control.h"
+#include "output.h"
+#include "core2.h"
+#include "ecb_iterators.h"
+#include "pebs.h"
+#include "apic.h"
+
+#if !defined(DRV_ANDROID)
+#include "jkt_unc_ha.h"
+#include "jkt_unc_qpill.h"
+#include "pci.h"
+#endif
+
+extern EVENT_CONFIG               global_ec;
+extern U64                       *read_counter_info;
+extern LBR                        lbr;
+extern DRV_CONFIG                 drv_cfg;
+extern DEV_CONFIG                 pcfg;
+extern PWR                        pwr;
+extern U64                       *interrupt_counts;
+extern DRV_SETUP_INFO_NODE        req_drv_setup_info;
+extern EMON_BUFFER_DRIVER_HELPER  emon_buffer_driver_helper;
+
+#if !defined(DRV_ANDROID)
+static U32            direct2core_data_saved = 0;
+static U32            bl_bypass_data_saved   = 0;
+#endif
+
+static U32 restore_reg_addr[3];
+
+typedef struct SADDR_S {
+    S64 addr:CORE2_LBR_DATA_BITS;
+} SADDR;
+
+#define SADDR_addr(x)                  (x).addr
+#define MSR_ENERGY_MULTIPLIER           0x606        // Energy Multiplier MSR
+
+#if !defined(DRV_ANDROID)
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void core2_Disable_Direct2core(ECB)
+ *
+ * @param    pecb     ECB of group being scheduled
+ *
+ * @return   None     No return needed
+ *
+ * @brief    program the QPILL and HA register for disabling of direct2core
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+core2_Disable_Direct2core (
+    ECB pecb
+)
+{
+    U32            busno       = 0;
+    U32            dev_idx     = 0;
+    U32            base_idx    = 0;
+    U32            device_id   = 0;
+    U32            value       = 0;
+    U32            vendor_id   = 0;
+    U32 core2_qpill_dev_no[2]  = {8,9};
+    U32            this_cpu;
+
+    SEP_DRV_LOG_TRACE_IN("PECB: %p.", pecb);
+
+    this_cpu = CONTROL_THIS_CPU();
+
+    // Discover the bus # for HA
+    for (busno = 0; busno < MAX_BUSNO; busno++) {
+        value = PCI_Read_U32(busno,
+                             JKTUNC_HA_DEVICE_NO,
+                             JKTUNC_HA_D2C_FUNC_NO,
+                             0);
+        vendor_id = value & VENDOR_ID_MASK;
+        device_id = (value & DEVICE_ID_MASK) >> DEVICE_ID_BITSHIFT;
+
+        if (vendor_id != DRV_IS_PCI_VENDOR_ID_INTEL) {
+            continue;
+        }
+        if (device_id != JKTUNC_HA_D2C_DID) {
+            continue;
+        }
+        value = 0;
+        // now program at the offset
+        value   = PCI_Read_U32(busno,
+                               JKTUNC_HA_DEVICE_NO,
+                               JKTUNC_HA_D2C_FUNC_NO,
+                               JKTUNC_HA_D2C_OFFSET);
+        restore_ha_direct2core[this_cpu][busno]   = 0;
+        restore_ha_direct2core[this_cpu][busno]   = value;
+    }
+    for (busno = 0; busno < MAX_BUSNO; busno++) {
+        value = PCI_Read_U32(busno,
+                             JKTUNC_HA_DEVICE_NO,
+                             JKTUNC_HA_D2C_FUNC_NO,
+                             0);
+        vendor_id = value & VENDOR_ID_MASK;
+        device_id = (value & DEVICE_ID_MASK) >> DEVICE_ID_BITSHIFT;
+
+        if (vendor_id != DRV_IS_PCI_VENDOR_ID_INTEL) {
+            continue;
+        }
+        if (device_id != JKTUNC_HA_D2C_DID) {
+            continue;
+        }
+
+        // now program at the offset
+        value   = PCI_Read_U32(busno,
+                               JKTUNC_HA_DEVICE_NO,
+                               JKTUNC_HA_D2C_FUNC_NO,
+                               JKTUNC_HA_D2C_OFFSET);
+        value  |= value | JKTUNC_HA_D2C_BITMASK;
+        PCI_Write_U32(busno,
+                      JKTUNC_HA_DEVICE_NO,
+                      JKTUNC_HA_D2C_FUNC_NO,
+                      JKTUNC_HA_D2C_OFFSET,
+                      value);
+    }
+
+    // Discover the bus # for QPI
+    for (dev_idx = 0; dev_idx < 2; dev_idx++) {
+        base_idx = dev_idx * MAX_BUSNO;
+        for (busno = 0; busno < MAX_BUSNO; busno++) {
+            value = PCI_Read_U32(busno,
+                                 core2_qpill_dev_no[dev_idx],
+                                 JKTUNC_QPILL_D2C_FUNC_NO,
+                                 0);
+            vendor_id = value & VENDOR_ID_MASK;
+            device_id = (value & DEVICE_ID_MASK) >> DEVICE_ID_BITSHIFT;
+
+            if (vendor_id != DRV_IS_PCI_VENDOR_ID_INTEL) {
+                continue;
+            }
+            if ((device_id != JKTUNC_QPILL0_D2C_DID) &&
+                (device_id != JKTUNC_QPILL1_D2C_DID)) {
+                continue;
+            }
+            // now program at the corresponding offset
+            value   = PCI_Read_U32(busno,
+                                   core2_qpill_dev_no[dev_idx],
+                                   JKTUNC_QPILL_D2C_FUNC_NO,
+                                   JKTUNC_QPILL_D2C_OFFSET);
+            restore_qpi_direct2core[this_cpu][base_idx + busno]   = 0;
+            restore_qpi_direct2core[this_cpu][base_idx + busno]   = value;
+        }
+    }
+    for (dev_idx = 0; dev_idx < 2; dev_idx++) {
+        for (busno = 0; busno < MAX_BUSNO; busno++) {
+            value = PCI_Read_U32(busno,
+                                 core2_qpill_dev_no[dev_idx],
+                                 JKTUNC_QPILL_D2C_FUNC_NO,
+                                 0);
+            vendor_id = value & VENDOR_ID_MASK;
+            device_id = (value & DEVICE_ID_MASK) >> DEVICE_ID_BITSHIFT;
+
+            if (vendor_id != DRV_IS_PCI_VENDOR_ID_INTEL) {
+                continue;
+            }
+            if ((device_id != JKTUNC_QPILL0_D2C_DID) &&
+                (device_id != JKTUNC_QPILL1_D2C_DID)) {
+                continue;
+            }
+            // now program at the corresponding offset
+            value   = PCI_Read_U32(busno,
+                                   core2_qpill_dev_no[dev_idx],
+                                   JKTUNC_QPILL_D2C_FUNC_NO,
+                                   JKTUNC_QPILL_D2C_OFFSET);
+            value  |= value | JKTUNC_QPILL_D2C_BITMASK;
+            PCI_Write_U32(busno,
+                          core2_qpill_dev_no[dev_idx],
+                          JKTUNC_QPILL_D2C_FUNC_NO,
+                          JKTUNC_QPILL_D2C_OFFSET,
+                          value);
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void core2_Disable_BL_Bypass(ECB)
+ *
+ * @param    pecb     ECB of group being scheduled
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Disable the BL Bypass
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+core2_Disable_BL_Bypass (
+    ECB pecb
+)
+{
+    U64            value;
+    U32            this_cpu;
+
+    SEP_DRV_LOG_TRACE_IN("PECB: %p.", pecb);
+
+    this_cpu = CONTROL_THIS_CPU();
+
+    value = SYS_Read_MSR(CORE2UNC_DISABLE_BL_BYPASS_MSR);
+    restore_bl_bypass[this_cpu] = 0;
+    restore_bl_bypass[this_cpu] = value;
+    value |= CORE2UNC_BLBYPASS_BITMASK;
+    SYS_Write_MSR(CORE2UNC_DISABLE_BL_BYPASS_MSR, value);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+#endif
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void core2_Write_PMU(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Initial set up of the PMU registers
+ *
+ * <I>Special Notes</I>
+ *         Initial write of PMU registers.
+ *         Walk through the enties and write the value of the register accordingly.
+ *         Assumption:  For CCCR registers the enable bit is set to value 0.
+ *         When current_group = 0, then this is the first time this routine is called,
+ *         initialize the locks and set up EM tables.
+ */
+static VOID
+core2_Write_PMU (
+    VOID  *param
+)
+{
+    U32            this_cpu;
+    CPU_STATE      pcpu;
+    ECB            pecb;
+    U32            dev_idx;
+    U32            cur_grp;
+    EVENT_CONFIG   ec;
+    DISPATCH       dispatch;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    ec       = LWPMU_DEVICE_ec(&devices[dev_idx]);
+    dispatch = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("No programming for this device in this group.");
+        return;
+    }
+
+    if (CPU_STATE_current_group(pcpu) == 0) {
+        if (EVENT_CONFIG_mode(ec) != EM_DISABLED) {
+            U32            index;
+            U32            st_index;
+            U32            j;
+
+            /* Save all the initialization values away into an array for Event Multiplexing. */
+            for (j = 0; j < EVENT_CONFIG_num_groups(ec); j++) {
+                CPU_STATE_current_group(pcpu) = j;
+                st_index   = CPU_STATE_current_group(pcpu) * EVENT_CONFIG_max_gp_events(ec);
+                FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_GP) {
+                    index = st_index + i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+                    CPU_STATE_em_tables(pcpu)[index] = ECB_entries_reg_value(pecb,i);
+                } END_FOR_EACH_REG_CORE_OPERATION;
+            }
+            /* Reset the current group to the very first one. */
+            CPU_STATE_current_group(pcpu) = this_cpu % EVENT_CONFIG_num_groups(ec);
+        }
+    }
+
+    if (dispatch->hw_errata) {
+        dispatch->hw_errata();
+    }
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_ALL_REG) {
+        /*
+         * Writing the GLOBAL Control register enables the PMU to start counting.
+         * So write 0 into the register to prevent any counting from starting.
+         */
+        if (i == ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)) {
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+            continue;
+        }
+        /*
+         *  PEBS is enabled for this collection session
+         */
+        if (DRV_SETUP_INFO_pebs_accessible(&req_drv_setup_info) &&
+            i == ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS) &&
+            ECB_entries_reg_value(pecb,i)) {
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+            continue;
+        }
+        SYS_Write_MSR(ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i));
+#if defined(MYDEBUG)
+        {
+            U64 val = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+            SEP_DRV_LOG_TRACE("Register 0x%x: wrvalue 0x%llx, rdvalue 0x%llx.",
+                            ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i), val);
+        }
+#endif
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void core2_Disable_PMU(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Zero out the global control register.  This automatically disables the PMU counters.
+ *
+ */
+static VOID
+core2_Disable_PMU (
+    PVOID  param
+)
+{
+    U32         this_cpu;
+    CPU_STATE   pcpu;
+    ECB         pecb;
+    U32         dev_idx;
+    U32         cur_grp;
+    DEV_CONFIG  pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("No programming for this device in this group.");
+        return;
+    }
+
+    if (GET_DRIVER_STATE() != DRV_STATE_RUNNING) {
+        SEP_DRV_LOG_TRACE("Driver state is not RUNNING.");
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), 0LL);
+        if (DEV_CONFIG_pebs_mode(pcfg)) {
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), 0LL);
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void core2_Enable_PMU(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Set the enable bit for all the Control registers
+ *
+ */
+static VOID
+core2_Enable_PMU (
+    PVOID   param
+)
+{
+    /*
+     * Get the value from the event block
+     *   0 == location of the global control reg for this block.
+     *   Generalize this location awareness when possible
+     */
+    U32         this_cpu;
+    CPU_STATE   pcpu;
+    ECB         pecb;
+    U32         dev_idx;
+    U32         cur_grp;
+    DEV_CONFIG  pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("No programming for this device in this group.");
+        return;
+    }
+
+    if (KVM_guest_mode) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX (pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), 0LL);
+    }
+    if (GET_DRIVER_STATE() == DRV_STATE_RUNNING) {
+        APIC_Enable_Pmi();
+        if (CPU_STATE_reset_mask(pcpu)) {
+            SEP_DRV_LOG_TRACE("Overflow reset mask %llx.", CPU_STATE_reset_mask(pcpu));
+            // Reinitialize the global overflow control register
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            CPU_STATE_reset_mask(pcpu) = 0LL;
+        }
+        if (CPU_STATE_group_swap(pcpu)) {
+            CPU_STATE_group_swap(pcpu) = 0;
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            if (DEV_CONFIG_pebs_mode(pcfg)) {
+                SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                              ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            }
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+#if defined(MYDEBUG)
+            {
+                U64 val;
+                val = SYS_Read_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+                SEP_DRV_LOG_TRACE("Write reg 0x%x--- read 0x%llx.",
+                        ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), val);
+            }
+#endif
+        }
+    }
+    SEP_DRV_LOG_TRACE("Reenabled PMU with value 0x%llx.", ECB_entries_reg_value(pecb,0));
+
+    SEP_DRV_LOG_TRACE_OUT("");
+
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void corei7_Enable_PMU_2(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Set the enable bit for all the Control registers
+ *
+ */
+static VOID
+corei7_Enable_PMU_2 (
+    PVOID   param
+)
+{
+    /*
+     * Get the value from the event block
+     *   0 == location of the global control reg for this block.
+     */
+    U32          this_cpu;
+    CPU_STATE    pcpu;
+    ECB          pecb;
+    U64          pebs_val    = 0;
+    U32          dev_idx;
+    U32          cur_grp;
+    DEV_CONFIG   pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu    = CONTROL_THIS_CPU();
+    pcpu        = &pcb[this_cpu];
+    dev_idx     = core_to_dev_map[this_cpu];
+    cur_grp     = CPU_STATE_current_group(pcpu);
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    pcfg        = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("No programming for this device in this group.");
+        return;
+    }
+
+    if (KVM_guest_mode) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX (pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), 0LL);
+    }
+    if (GET_DRIVER_STATE() == DRV_STATE_RUNNING) {
+        APIC_Enable_Pmi();
+        if (CPU_STATE_group_swap(pcpu)) {
+            CPU_STATE_group_swap(pcpu) = 0;
+            if (DEV_CONFIG_pebs_mode(pcfg)) {
+                pebs_val = SYS_Read_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+                if (ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)) != 0) {
+                    SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                                  ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+                }
+                else if (pebs_val != 0) {
+                    SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                                  0LL);
+                }
+            }
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+#if defined(MYDEBUG)
+            SEP_DRV_LOG_TRACE("Reenabled PMU with value 0x%llx.", ECB_entries_reg_value(pecb,0));
+#endif
+        }
+        if (CPU_STATE_reset_mask(pcpu)) {
+#if defined(MYDEBUG)
+            SEP_DRV_LOG_TRACE("Overflow reset mask %llx.", CPU_STATE_reset_mask(pcpu));
+#endif
+            // Reinitialize the global overflow control register
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            CPU_STATE_reset_mask(pcpu) = 0LL;
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn core2_Read_PMU_Data(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read all the data MSR's into a buffer.  Called by the interrupt handler.
+ *
+ */
+static void
+core2_Read_PMU_Data (
+    PVOID   param
+)
+{
+    U32       j;
+    U64      *buffer    = read_counter_info;
+    U32       this_cpu;
+    CPU_STATE pcpu;
+    ECB       pecb;
+    U32       dev_idx;
+    U32       cur_grp;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    preempt_disable();
+    this_cpu  = CONTROL_THIS_CPU();
+    preempt_enable();
+    pcpu      = &pcb[this_cpu];
+    dev_idx   = core_to_dev_map[this_cpu];
+    cur_grp   = CPU_STATE_current_group(pcpu);
+    pecb      = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("No programming for this device in this group.");
+        return;
+    }
+
+    SEP_DRV_LOG_TRACE("PMU control_data 0x%p, buffer 0x%p.", LWPMU_DEVICE_PMU_register_data(&devices[dev_idx]), buffer);
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+
+        j = EMON_BUFFER_CORE_EVENT_OFFSET(EMON_BUFFER_DRIVER_HELPER_core_index_to_thread_offset_map(emon_buffer_driver_helper)[this_cpu],
+                                          ECB_entries_core_event_id(pecb,i));
+
+        buffer[j] = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+        SEP_DRV_LOG_TRACE("j=%u, value=%llu, cpu=%u, event_id=%u", j, buffer[j], this_cpu, ECB_entries_core_event_id(pecb,i));
+
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn core2_Check_Overflow_Errata(pecb, index, overflow_status)
+ *
+ * @param  pecb:            The current event control block
+ * @param  index:           index of the register to process
+ * @param  overflow_status: current overflow mask
+ *
+ * @return Updated Event mask of the overflowed registers.
+ *
+ * @brief  Go through the overflow errata for the architecture and set the mask
+ *
+ * <I>Special Notes</I>
+ *         fixed_counter1 on some architectures gets interfered by
+ *         other event counts.  Overcome this problem by reading the
+ *         counter value and resetting the overflow mask.
+ *
+ */
+static U64
+core2_Check_Overflow_Errata (
+    ECB   pecb,
+    U32   index,
+    U64   overflow_status
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (DRV_CONFIG_num_events(drv_cfg) == 1) {
+        SEP_DRV_LOG_TRACE_OUT("Res: %llu. (num_events = 1)", overflow_status);
+        return overflow_status;
+    }
+    if (ECB_entries_reg_id(pecb, index) == IA32_FIXED_CTR1 &&
+        (overflow_status & 0x200000000LL) == 0LL) {
+        U64 val = SYS_Read_MSR(IA32_FIXED_CTR1);
+        val &= ECB_entries_max_bits(pecb,index);
+        if (val < ECB_entries_reg_value(pecb, index)) {
+            overflow_status |= 0x200000000LL;
+            SEP_DRV_LOG_TRACE("Reset -- clk count %llx, status %llx.", val, overflow_status);
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %llu.", overflow_status);
+    return overflow_status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void core2_Check_Overflow(masks)
+ *
+ * @param    masks    the mask structure to populate
+ *
+ * @return   None     No return needed
+ *
+ * @brief  Called by the data processing method to figure out which registers have overflowed.
+ *
+ */
+static void
+core2_Check_Overflow (
+    DRV_MASKS    masks
+)
+{
+    U32              index;
+    U64              overflow_status     = 0;
+    U32              this_cpu;
+    BUFFER_DESC      bd;
+    CPU_STATE        pcpu;
+    ECB              pecb;
+    U32              dev_idx;
+    U32              cur_grp;
+    DEV_CONFIG       pcfg;
+    DISPATCH         dispatch;
+    U64              overflow_status_clr = 0;
+    DRV_EVENT_MASK_NODE event_flag;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu            = CONTROL_THIS_CPU();
+    bd                  = &cpu_buf[this_cpu];
+    pcpu                = &pcb[this_cpu];
+    dev_idx             = core_to_dev_map[this_cpu];
+    cur_grp             = CPU_STATE_current_group(pcpu);
+    pecb                = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    pcfg                = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    dispatch            = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("No programming for this device in this group.");
+        return;
+    }
+
+    // initialize masks
+    DRV_MASKS_masks_num(masks) = 0;
+
+    overflow_status = SYS_Read_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_STATUS_REG_INDEX, PMU_OPERATION_GLOBAL_STATUS)));
+
+    if (DEV_CONFIG_pebs_mode(pcfg)) {
+        overflow_status = PEBS_Overflowed (this_cpu, overflow_status, 0);
+    }
+    overflow_status_clr = overflow_status;
+
+    if (dispatch->check_overflow_gp_errata) {
+        overflow_status = dispatch->check_overflow_gp_errata(pecb,  &overflow_status_clr);
+    }
+    SEP_DRV_LOG_TRACE("Overflow:  cpu: %d, status 0x%llx.", this_cpu, overflow_status);
+    index                        = 0;
+    BUFFER_DESC_sample_count(bd) = 0;
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+        if (ECB_entries_fixed_reg_get(pecb, i)) {
+            index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_FIXED) + 0x20;
+            if (dispatch->check_overflow_errata) {
+                overflow_status = dispatch->check_overflow_errata(pecb, i, overflow_status);
+            }
+        }
+        else if (ECB_entries_is_gp_reg_get(pecb, i)) {
+            index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+        }
+        else {
+            continue;
+        }
+        if (overflow_status & ((U64)1 << index)) {
+            SEP_DRV_LOG_TRACE("Overflow:  cpu: %d, index %d.", this_cpu, index);
+            SEP_DRV_LOG_TRACE("register 0x%x --- val 0%llx.",
+                            ECB_entries_reg_id(pecb,i),
+                            SYS_Read_MSR(ECB_entries_reg_id(pecb,i)));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i));
+
+            if (DRV_CONFIG_enable_cp_mode(drv_cfg)) {
+                /* Increment the interrupt count. */
+                if (interrupt_counts) {
+                    interrupt_counts[this_cpu * DRV_CONFIG_num_events(drv_cfg) + ECB_entries_event_id_index(pecb,i)] += 1;
+                }
+            }
+
+            DRV_EVENT_MASK_bitFields1(&event_flag) = (U8) 0;
+            if (ECB_entries_fixed_reg_get(pecb, i)) {
+                CPU_STATE_p_state_counting(pcpu) = 1;
+            }
+            if (ECB_entries_precise_get(pecb, i)) {
+                DRV_EVENT_MASK_precise(&event_flag) = 1;
+            }
+            if (ECB_entries_lbr_value_get(pecb, i)) {
+                DRV_EVENT_MASK_lbr_capture(&event_flag) = 1;
+            }
+            if (ECB_entries_uncore_get(pecb, i)) {
+                DRV_EVENT_MASK_uncore_capture(&event_flag) = 1;
+            }
+            if (ECB_entries_branch_evt_get(pecb, i)) {
+                DRV_EVENT_MASK_branch(&event_flag) = 1;
+            }
+
+            if (DRV_MASKS_masks_num(masks) < MAX_OVERFLOW_EVENTS) {
+                DRV_EVENT_MASK_bitFields1(DRV_MASKS_eventmasks(masks) + DRV_MASKS_masks_num(masks)) = DRV_EVENT_MASK_bitFields1(&event_flag);
+                DRV_EVENT_MASK_event_idx(DRV_MASKS_eventmasks(masks) + DRV_MASKS_masks_num(masks)) = ECB_entries_event_id_index(pecb, i);
+                DRV_MASKS_masks_num(masks)++;
+            }
+            else {
+                SEP_DRV_LOG_ERROR("The array for event masks is full.");
+            }
+
+            SEP_DRV_LOG_TRACE("overflow -- 0x%llx, index 0x%llx.", overflow_status, (U64)1 << index);
+            SEP_DRV_LOG_TRACE("slot# %d, reg_id 0x%x, index %d.",
+                            i, ECB_entries_reg_id(pecb, i), index);
+            if (ECB_entries_event_id_index(pecb, i) == CPU_STATE_trigger_event_num(pcpu)) {
+                CPU_STATE_trigger_count(pcpu)--;
+            }
+        }
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+
+    CPU_STATE_reset_mask(pcpu) = overflow_status_clr;
+    // Reinitialize the global overflow control register
+    SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_OVF_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                  overflow_status_clr);
+
+    SEP_DRV_LOG_TRACE("Check Overflow completed %d.", this_cpu);
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn core2_Swap_Group(restart)
+ *
+ * @param    restart    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Perform the mechanics of swapping the event groups for event mux operations
+ *
+ * <I>Special Notes</I>
+ *         Swap function for event multiplexing.
+ *         Freeze the counting.
+ *         Swap the groups.
+ *         Enable the counting.
+ *         Reset the event trigger count
+ *
+ */
+static VOID
+core2_Swap_Group (
+    DRV_BOOL  restart
+)
+{
+    U32            index;
+    U32            next_group;
+    U32            st_index;
+    U32            this_cpu;
+    CPU_STATE      pcpu;
+    U32            dev_idx;
+    U32            cur_grp;
+    DISPATCH       dispatch;
+    EVENT_CONFIG   ec;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu   = CONTROL_THIS_CPU();
+    pcpu       = &pcb[this_cpu];
+    dev_idx    = core_to_dev_map[this_cpu];
+    cur_grp    = CPU_STATE_current_group(pcpu);
+    dispatch   = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    ec         = LWPMU_DEVICE_ec(&devices[dev_idx]);
+
+    st_index   = CPU_STATE_current_group(pcpu) * EVENT_CONFIG_max_gp_events(ec);
+    next_group = (CPU_STATE_current_group(pcpu) + 1);
+    if (next_group >= EVENT_CONFIG_num_groups(ec)) {
+        next_group = 0;
+    }
+
+    SEP_DRV_LOG_TRACE("current group : 0x%x.", CPU_STATE_current_group(pcpu));
+    SEP_DRV_LOG_TRACE("next group : 0x%x.", next_group);
+
+    // Save the counters for the current group
+    if (!DRV_CONFIG_event_based_counts(drv_cfg)) {
+        FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_GP) {
+            index = st_index + i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+            CPU_STATE_em_tables(pcpu)[index] = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+            SEP_DRV_LOG_TRACE("Saved value for reg 0x%x : 0x%llx.",
+                            ECB_entries_reg_id(pecb,i),
+                            CPU_STATE_em_tables(pcpu)[index]);
+        } END_FOR_EACH_REG_CORE_OPERATION;
+    }
+
+    CPU_STATE_current_group(pcpu) = next_group;
+
+    if (dispatch->hw_errata) {
+        dispatch->hw_errata();
+    }
+
+    // First write the GP control registers (eventsel)
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_CTRL_GP)  {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i));
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    if (DRV_CONFIG_event_based_counts(drv_cfg)) {
+        // In EBC mode, reset the counts for all events except for trigger event
+        FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+            if (ECB_entries_event_id_index(pecb, i) != CPU_STATE_trigger_event_num(pcpu)) {
+                SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+            }
+        } END_FOR_EACH_REG_CORE_OPERATION;
+    }
+    else {
+        // Then write the gp count registers
+        st_index = CPU_STATE_current_group(pcpu) * EVENT_CONFIG_max_gp_events(ec);
+        FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_GP) {
+            index = st_index + i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), CPU_STATE_em_tables(pcpu)[index]);
+            SEP_DRV_LOG_TRACE("Restore value for reg 0x%x : 0x%llx.",
+                            ECB_entries_reg_id(pecb,i),
+                            CPU_STATE_em_tables(pcpu)[index]);
+        } END_FOR_EACH_REG_CORE_OPERATION;
+    }
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_OCR) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, i), ECB_entries_reg_value(pecb, i));
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    /*
+     *  reset the em factor when a group is swapped
+     */
+    CPU_STATE_trigger_count(pcpu) = EVENT_CONFIG_em_factor(ec);
+
+    /*
+     * The enable routine needs to rewrite the control registers
+     */
+    CPU_STATE_reset_mask(pcpu) = 0LL;
+    CPU_STATE_group_swap(pcpu) = 1;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn core2_Initialize(params)
+ *
+ * @param    params    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Initialize the PMU setting up for collection
+ *
+ * <I>Special Notes</I>
+ *         Saves the relevant PMU state (minimal set of MSRs required
+ *         to avoid conflicts with other Linux tools, such as Oprofile).
+ *         This function should be called in parallel across all CPUs
+ *         prior to the start of sampling, before PMU state is changed.
+ *
+ */
+static VOID
+core2_Initialize (
+    VOID  *param
+)
+{
+    U32        this_cpu;
+    CPU_STATE  pcpu;
+    U32        dev_idx;
+    DEV_CONFIG pcfg;
+    U32        i        = 0;
+    ECB        pecb     = NULL;
+    U32        cur_grp;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (pcb == NULL) {
+        SEP_DRV_LOG_TRACE_OUT("No programming for this device in this group.");
+        return;
+    }
+
+    pcpu  = &pcb[this_cpu];
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    CPU_STATE_pmu_state(pcpu) = pmu_state + (this_cpu * 3);
+    if (CPU_STATE_pmu_state(pcpu) == NULL) {
+        SEP_DRV_LOG_WARNING_TRACE_OUT("Unable to save PMU state on CPU %d.", this_cpu);
+        return;
+    }
+
+    restore_reg_addr[0] = ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS));
+    restore_reg_addr[1] = ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS));
+    restore_reg_addr[2] = ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, FIXED_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS));
+    // save the original PMU state on this CPU (NOTE: must only be called ONCE per collection)
+    CPU_STATE_pmu_state(pcpu)[0] = SYS_Read_MSR(restore_reg_addr[0]);
+    CPU_STATE_pmu_state(pcpu)[1] = SYS_Read_MSR(restore_reg_addr[1]);
+    CPU_STATE_pmu_state(pcpu)[2] = SYS_Read_MSR(restore_reg_addr[2]);
+
+    if (DRV_CONFIG_ds_area_available(drv_cfg) && DEV_CONFIG_pebs_mode(pcfg)) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), 0LL);
+    }
+
+    SEP_DRV_LOG_TRACE("Saving PMU state on CPU %d:", this_cpu);
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_DEBUG_CTRL)=0x%llx.", CPU_STATE_pmu_state(pcpu)[0]);
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_PERF_GLOBAL_CTRL)=0x%llx.", CPU_STATE_pmu_state(pcpu)[1]);
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_FIXED_CTRL)=0x%llx.", CPU_STATE_pmu_state(pcpu)[2]);
+
+#if !defined(DRV_ANDROID)
+    if (!CPU_STATE_socket_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Not socket master.");
+        return;
+    }
+
+    direct2core_data_saved = 0;
+    bl_bypass_data_saved = 0;
+    cur_grp = CPU_STATE_current_group(pcpu);
+
+    if (restore_ha_direct2core && restore_qpi_direct2core) {
+        for (i = 0; i < GLOBAL_STATE_num_em_groups(driver_state); i++) {
+            pecb  = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[i];
+            if (pecb && (ECB_flags(pecb) & ECB_direct2core_bit)) {
+                core2_Disable_Direct2core(LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp]);
+                direct2core_data_saved = 1;
+                break;
+            }
+        }
+    }
+    if (restore_bl_bypass) {
+        for (i = 0; i < GLOBAL_STATE_num_em_groups(driver_state); i++) {
+            pecb  = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[i];
+            if (pecb && (ECB_flags(pecb) &  ECB_bl_bypass_bit)) {
+                core2_Disable_BL_Bypass(LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp]);
+                bl_bypass_data_saved = 1;
+                break;
+            }
+        }
+    }
+#endif
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn core2_Destroy(params)
+ *
+ * @param    params    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Reset the PMU setting up after collection
+ *
+ * <I>Special Notes</I>
+ *         Restores the previously saved PMU state done in core2_Initialize.
+ *         This function should be called in parallel across all CPUs
+ *         after sampling collection ends/terminates.
+ *
+ */
+static VOID
+core2_Destroy (
+    VOID *param
+)
+{
+    U32        this_cpu;
+    CPU_STATE  pcpu;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (pcb == NULL) {
+        SEP_DRV_LOG_TRACE_OUT("No programming for this device in this group.");
+        return;
+    }
+
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    preempt_enable();
+    pcpu = &pcb[this_cpu];
+
+    if (CPU_STATE_pmu_state(pcpu) == NULL) {
+        SEP_DRV_LOG_WARNING_TRACE_OUT("Unable to restore PMU state on CPU %d.", this_cpu);
+        return;
+    }
+
+    SEP_DRV_LOG_TRACE("Clearing PMU state on CPU %d:", this_cpu);
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_DEBUG_CTRL)=0x0.");
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_PERF_GLOBAL_CTRL)=0x0.");
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_FIXED_CTRL)=0x0.");
+
+    // Tentative code below (trying to avoid race conditions with the NMI watchdog). Should be evaluated in the coming few days. (2018/05/21)
+    SYS_Write_MSR(restore_reg_addr[0], 0);
+    SYS_Write_MSR(restore_reg_addr[1], 0);
+    SYS_Write_MSR(restore_reg_addr[2], 0);
+
+    CPU_STATE_pmu_state(pcpu) = NULL;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*
+ * @fn core2_Read_LBRs(buffer)
+ *
+ * @param   IN buffer - pointer to the buffer to write the data into
+ * @return  Last branch source IP address
+ *
+ * @brief   Read all the LBR registers into the buffer provided and return
+ *
+ */
+static U64
+core2_Read_LBRs (
+    VOID   *buffer
+)
+{
+    U32   i, count = 0;
+    U64  *lbr_buf = NULL;
+    U64   value = 0;
+    U64   tos_ip_addr = 0;
+    U64   tos_ptr = 0;
+    SADDR saddr;
+    U32   this_cpu;
+    U32   dev_idx;
+    LBR   lbr;
+    DEV_CONFIG pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    lbr      = LWPMU_DEVICE_lbr(&devices[dev_idx]);
+
+    if (buffer && DEV_CONFIG_store_lbrs(pcfg)) {
+        lbr_buf = (U64 *)buffer;
+    }
+
+    for (i = 0; i < LBR_num_entries(lbr); i++) {
+        value = SYS_Read_MSR(LBR_entries_reg_id(lbr,i));
+        if (buffer && DEV_CONFIG_store_lbrs(pcfg)) {
+            *lbr_buf = value;
+        }
+        SEP_DRV_LOG_TRACE("core2_Read_LBRs %u, 0x%llx.", i, value);
+        if (i == 0) {
+            tos_ptr = value;
+        }
+        else {
+            if (LBR_entries_etype(lbr, i) == LBR_ENTRY_FROM_IP) { // LBR from register
+                if (tos_ptr == count) {
+                    SADDR_addr(saddr) = value & CORE2_LBR_BITMASK;
+                    tos_ip_addr = (U64) SADDR_addr(saddr); // Add signed extension
+                    SEP_DRV_LOG_TRACE("Tos_ip_addr %llu, 0x%llx.", tos_ptr, value);
+                }
+                count++;
+            }
+        }
+        if (buffer && DEV_CONFIG_store_lbrs(pcfg)) {
+            lbr_buf++;
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %llu.", tos_ip_addr);
+    return tos_ip_addr;
+}
+
+/*
+ * @fn corei7_Read_LBRs(buffer)
+ *
+ * @param   IN buffer - pointer to the buffer to write the data into
+ * @return  Last branch source IP address
+ *
+ * @brief   Read all the LBR registers into the buffer provided and return
+ *
+ */
+static U64
+corei7_Read_LBRs (
+    VOID   *buffer
+)
+{
+    U32   i, count    = 0;
+    U64  *lbr_buf     = NULL;
+    U64   value       = 0;
+    U64   tos_ip_addr = 0;
+    U64   tos_ptr     = 0;
+    SADDR saddr;
+    U32   pairs       = 0;
+    U32   this_cpu;
+    U32   dev_idx;
+    LBR   lbr;
+    DEV_CONFIG pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    lbr      = LWPMU_DEVICE_lbr(&devices[dev_idx]);
+
+    if (buffer && DEV_CONFIG_store_lbrs(pcfg)) {
+        lbr_buf = (U64 *)buffer;
+    }
+
+    if (LBR_num_entries(lbr) > 0) {
+        pairs = (LBR_num_entries(lbr) - 1)/2;
+    }
+    for (i = 0; i < LBR_num_entries(lbr); i++) {
+        value = SYS_Read_MSR(LBR_entries_reg_id(lbr,i));
+        if (buffer && DEV_CONFIG_store_lbrs(pcfg)) {
+            *lbr_buf = value;
+        }
+        if (DEV_CONFIG_collect_callstacks(pcfg)) {
+            if ((LBR_entries_etype(lbr, i) == LBR_ENTRY_FROM_IP && i > tos_ptr+1) ||
+                (LBR_entries_etype(lbr, i) == LBR_ENTRY_TO_IP && i > tos_ptr+pairs+1)) {
+                if (buffer && DEV_CONFIG_store_lbrs(pcfg)) {
+                    *lbr_buf = 0x0ULL;
+                    lbr_buf++;
+                }
+                continue;
+            }
+        }
+        SEP_DRV_LOG_TRACE("I: %u, value: 0x%llx.", i, value);
+        if (i == 0) {
+            tos_ptr = value;
+        }
+        else {
+            if (LBR_entries_etype(lbr, i) == LBR_ENTRY_FROM_IP) { // LBR from register
+                if (tos_ptr == count) {
+                    SADDR_addr(saddr) = value & CORE2_LBR_BITMASK;
+                    tos_ip_addr = (U64) SADDR_addr(saddr); // Add signed extension
+                    SEP_DRV_LOG_TRACE("tos_ip_addr %llu, 0x%llx.", tos_ptr, value);
+                }
+                count++;
+            }
+        }
+        if (buffer && DEV_CONFIG_store_lbrs(pcfg)) {
+            lbr_buf++;
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %llu.", tos_ip_addr);
+    return tos_ip_addr;
+}
+
+static VOID
+core2_Clean_Up (
+    VOID   *param
+)
+{
+#if !defined(DRV_ANDROID)
+    U32            this_cpu;
+    CPU_STATE      pcpu;
+    U32            busno       = 0;
+    U32            dev_idx     = 0;
+    U32            base_idx    = 0;
+    U32            device_id   = 0;
+    U32            value       = 0;
+    U32            vendor_id   = 0;
+    U32 core2_qpill_dev_no[2]  = {8,9};
+#endif
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+#if !defined(DRV_ANDROID)
+    this_cpu    = CONTROL_THIS_CPU();
+    pcpu        = &pcb[this_cpu];
+#endif
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_ALL_REG) {
+        if (ECB_entries_clean_up_get(pecb,i)) {
+            SEP_DRV_LOG_TRACE("clean up set --- RegId --- %x.", ECB_entries_reg_id(pecb,i));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+        }
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+
+#if !defined(DRV_ANDROID)
+    if (!CPU_STATE_socket_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Not socket master.");
+        return;
+    }
+
+    if (restore_ha_direct2core && restore_qpi_direct2core && direct2core_data_saved) {
+        // Discover the bus # for HA
+        for (busno = 0; busno < MAX_BUSNO; busno++) {
+            value = PCI_Read_U32(busno,
+                                 JKTUNC_HA_DEVICE_NO,
+                                 JKTUNC_HA_D2C_FUNC_NO,
+                                 0);
+            vendor_id = value & VENDOR_ID_MASK;
+            device_id = (value & DEVICE_ID_MASK) >> DEVICE_ID_BITSHIFT;
+
+            if (vendor_id != DRV_IS_PCI_VENDOR_ID_INTEL) {
+                continue;
+            }
+            if (device_id != JKTUNC_HA_D2C_DID) {
+                continue;
+            }
+
+            // now program at the offset
+            PCI_Write_U32(busno,
+                          JKTUNC_HA_DEVICE_NO,
+                          JKTUNC_HA_D2C_FUNC_NO,
+                          JKTUNC_HA_D2C_OFFSET,
+                          restore_ha_direct2core[this_cpu][busno]);
+        }
+
+        // Discover the bus # for QPI
+        for (dev_idx = 0; dev_idx < 2; dev_idx++) {
+            base_idx = dev_idx * MAX_BUSNO;
+            for (busno = 0; busno < MAX_BUSNO; busno++) {
+                value = PCI_Read_U32(busno,
+                                     core2_qpill_dev_no[dev_idx],
+                                     JKTUNC_QPILL_D2C_FUNC_NO,
+                                     0);
+                vendor_id = value & VENDOR_ID_MASK;
+                device_id = (value & DEVICE_ID_MASK) >> DEVICE_ID_BITSHIFT;
+
+                if (vendor_id != DRV_IS_PCI_VENDOR_ID_INTEL) {
+                    continue;
+                }
+                if ((device_id != JKTUNC_QPILL0_D2C_DID) &&
+                    (device_id != JKTUNC_QPILL1_D2C_DID)) {
+                    continue;
+                }
+                // now program at the corresponding offset
+                PCI_Write_U32(busno,
+                              core2_qpill_dev_no[dev_idx],
+                              JKTUNC_QPILL_D2C_FUNC_NO,
+                              JKTUNC_QPILL_D2C_OFFSET,
+                              restore_qpi_direct2core[this_cpu][base_idx + busno]);
+            }
+        }
+    }
+    if (restore_bl_bypass && bl_bypass_data_saved) {
+        SYS_Write_MSR(CORE2UNC_DISABLE_BL_BYPASS_MSR, restore_bl_bypass[this_cpu]);
+    }
+#endif
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+static VOID
+corei7_Errata_Fix (
+    void
+)
+{
+    U32        this_cpu = CONTROL_THIS_CPU();
+    CPU_STATE  pcpu     = &pcb[this_cpu];
+    ECB        (pecb)   = NULL;
+    U32        dev_idx, cur_grp;
+    DEV_CONFIG pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu  = CONTROL_THIS_CPU();
+    dev_idx   = core_to_dev_map[this_cpu];
+    pcfg      = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    cur_grp   = CPU_STATE_current_group(pcpu);
+    pcfg      = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    pecb      = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+
+    if (DEV_CONFIG_pebs_mode(pcfg)) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), 0LL);
+    }
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_HW_ERRATA) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i));
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+
+    return;
+}
+
+static VOID
+corei7_Errata_Fix_2 (
+    void
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_HW_ERRATA) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i));
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void core2_Check_Overflow_Htoff_Mode(masks)
+ *
+ * @param    masks    the mask structure to populate
+ *
+ * @return   None     No return needed
+ *
+ * @brief  Called by the data processing method to figure out which registers have overflowed.
+ *
+ */
+static void
+core2_Check_Overflow_Htoff_Mode (
+    DRV_MASKS    masks
+)
+{
+    U32              index;
+    U64              value               = 0;
+    U64              overflow_status     = 0;
+    U32              this_cpu;
+    BUFFER_DESC      bd;
+    CPU_STATE        pcpu;
+    U32              dev_idx;
+    U32              cur_grp;
+    DISPATCH         dispatch;
+    DEV_CONFIG       pcfg;
+    ECB              pecb;
+    U64              overflow_status_clr = 0;
+    DRV_EVENT_MASK_NODE event_flag;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu  = CONTROL_THIS_CPU();
+    bd        = &cpu_buf[this_cpu];
+    pcpu      = &pcb[this_cpu];
+    dev_idx   = core_to_dev_map[this_cpu];
+    cur_grp   = CPU_STATE_current_group(pcpu);
+    dispatch  = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    pcfg      = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    pecb      = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+
+    SEP_DRV_LOG_TRACE("");
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("No programming for this device in this group.");
+        return;
+    }
+
+    // initialize masks
+    DRV_MASKS_masks_num(masks) = 0;
+
+    overflow_status = SYS_Read_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_STATUS_REG_INDEX, PMU_OPERATION_GLOBAL_STATUS)));
+
+    if (DEV_CONFIG_pebs_mode(pcfg)) {
+        overflow_status = PEBS_Overflowed (this_cpu, overflow_status, 0);
+    }
+    overflow_status_clr = overflow_status;
+    SEP_DRV_LOG_TRACE("Overflow:  cpu: %d, status 0x%llx.", this_cpu, overflow_status);
+    index                        = 0;
+    BUFFER_DESC_sample_count(bd) = 0;
+
+    if (dispatch->check_overflow_gp_errata) {
+        overflow_status = dispatch->check_overflow_gp_errata(pecb,  &overflow_status_clr);
+    }
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+        if (ECB_entries_fixed_reg_get(pecb, i)) {
+            index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_FIXED) + 0x20;
+        }
+        else if (ECB_entries_is_gp_reg_get(pecb,i) && ECB_entries_reg_value(pecb,i) != 0) {
+            index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+            if (i >= (ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP) + 4) &&
+                i <= (ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP) + 7)) {
+                value = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+                if (value > 0 && value <= 0x100000000LL) {
+                    overflow_status |= ((U64)1 << index);
+                }
+            }
+        }
+        else {
+            continue;
+        }
+        if (overflow_status & ((U64)1 << index)) {
+            SEP_DRV_LOG_TRACE("Overflow:  cpu: %d, index %d.", this_cpu, index);
+            SEP_DRV_LOG_TRACE("register 0x%x --- val 0%llx.",
+                            ECB_entries_reg_id(pecb,i),
+                            SYS_Read_MSR(ECB_entries_reg_id(pecb,i)));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i));
+
+            if (DRV_CONFIG_enable_cp_mode(drv_cfg)) {
+                /* Increment the interrupt count. */
+                if (interrupt_counts) {
+                    interrupt_counts[this_cpu * DRV_CONFIG_num_events(drv_cfg) + ECB_entries_event_id_index(pecb,i)] += 1;
+                }
+            }
+
+            DRV_EVENT_MASK_bitFields1(&event_flag) = (U8) 0;
+            if (ECB_entries_fixed_reg_get(pecb, i)) {
+                CPU_STATE_p_state_counting(pcpu) = 1;
+            }
+            if (ECB_entries_precise_get(pecb, i)) {
+                DRV_EVENT_MASK_precise(&event_flag) = 1;
+            }
+            if (ECB_entries_lbr_value_get(pecb, i)) {
+                DRV_EVENT_MASK_lbr_capture(&event_flag) = 1;
+            }
+            if (ECB_entries_branch_evt_get(pecb, i)) {
+                DRV_EVENT_MASK_branch(&event_flag) = 1;
+            }
+
+            if (DRV_MASKS_masks_num(masks) < MAX_OVERFLOW_EVENTS) {
+                DRV_EVENT_MASK_bitFields1(DRV_MASKS_eventmasks(masks) + DRV_MASKS_masks_num(masks)) = DRV_EVENT_MASK_bitFields1(&event_flag);
+                DRV_EVENT_MASK_event_idx(DRV_MASKS_eventmasks(masks) + DRV_MASKS_masks_num(masks)) = ECB_entries_event_id_index(pecb, i);
+                DRV_MASKS_masks_num(masks)++;
+            }
+            else {
+                SEP_DRV_LOG_ERROR("The array for event masks is full.");
+            }
+
+            SEP_DRV_LOG_TRACE("overflow -- 0x%llx, index 0x%llx.", overflow_status, (U64)1 << index);
+            SEP_DRV_LOG_TRACE("slot# %d, reg_id 0x%x, index %d.",
+                             i, ECB_entries_reg_id(pecb, i), index);
+            if (ECB_entries_event_id_index(pecb, i) == CPU_STATE_trigger_event_num(pcpu)) {
+                CPU_STATE_trigger_count(pcpu)--;
+            }
+        }
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    CPU_STATE_reset_mask(pcpu) = overflow_status_clr;
+    // Reinitialize the global overflow control register
+    SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_OVF_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                  overflow_status_clr);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void core2_Read_Power(buffer)
+ *
+ * @param    buffer   - pointer to the buffer to write the data into
+ *
+ * @return   None     No return needed
+ *
+ * @brief  Read all the power MSRs into the buffer provided and return.
+ *
+ */
+static VOID
+corei7_Read_Power (
+    VOID   *buffer
+)
+{
+    U32  i;
+    U64 *pwr_buf = (U64 *)buffer;
+    U32  this_cpu;
+    U32  dev_idx;
+    PWR  pwr;
+
+    SEP_DRV_LOG_TRACE_IN("Buffer: %p.", buffer);
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    pwr      = LWPMU_DEVICE_pwr(&devices[dev_idx]);
+
+    for (i = 0; i < PWR_num_entries(pwr); i++) {
+        *pwr_buf = SYS_Read_MSR(PWR_entries_reg_id(pwr,i));
+        pwr_buf++;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn core2_Read_Counts(param, id)
+ *
+ * @param    param      The read thread node to process
+ * @param    id         The event id for the which the sample is generated
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read CPU event based counts for the events with reg value=0 and store into the buffer param;
+ *
+ */
+static VOID
+core2_Read_Counts (
+    PVOID  param,
+    U32    id
+)
+{
+    U64       *data;
+    U32        this_cpu;
+    CPU_STATE  pcpu;
+    U32        dev_idx;
+    DEV_CONFIG pcfg;
+    U32        event_id = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p, id: %u.", param, id);
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (DEV_CONFIG_ebc_group_id_offset(pcfg)) {
+        // Write GroupID
+        data  = (U64 *)((S8*)param + DEV_CONFIG_ebc_group_id_offset(pcfg));
+        *data = CPU_STATE_current_group(pcpu) + 1;
+    }
+
+    FOR_EACH_REG_CORE_OPERATION(pecb,i, PMU_OPERATION_DATA_ALL) {
+        if (ECB_entries_counter_event_offset(pecb,i) == 0) {
+            continue;
+        }
+        data     = (U64 *)((S8*)param + ECB_entries_counter_event_offset(pecb,i));
+        event_id = ECB_entries_event_id_index(pecb,i);
+        if (event_id == id) {
+            *data = ~(ECB_entries_reg_value(pecb,i) - 1) &
+                                           ECB_entries_max_bits(pecb,i);;
+        }
+        else {
+            *data = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+        }
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    if (DRV_CONFIG_enable_p_state(drv_cfg)) {
+        CPU_STATE_p_state_counting(pcpu) = 0;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn corei7_Check_Overflow_Errata(pecb)
+ *
+ * @param pecb:            The current event control block
+ * @param overflow_status: current overflow mask
+ *
+ * @return   Updated Event mask of the overflowed registers.
+ *
+ * @brief    There is a bug where highly correlated precise events do
+ *           not raise an indication on overflows in Core i7 and SNB.
+ */
+static U64
+corei7_Check_Overflow_Errata (
+    ECB   pecb,
+    U64   *overflow_status_clr
+)
+{
+    U64 index = 0, value = 0, overflow_status = 0;
+
+    SEP_DRV_LOG_TRACE_IN("PECB: %p, overflow_status_clr: %p.", pecb, overflow_status_clr);
+
+    overflow_status = *overflow_status_clr;
+
+    if (DRV_CONFIG_num_events(drv_cfg) == 1) {
+        SEP_DRV_LOG_TRACE_OUT("Res = %llu (num_events = 1).", overflow_status);
+        return overflow_status;
+    }
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+        if (ECB_entries_reg_value(pecb, i) == 0) {
+            continue;
+        }
+        if (ECB_entries_is_gp_reg_get(pecb, i)) {
+            index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+            value = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+            if (value > 0LL && value <= 0x100000000LL) {
+                overflow_status      |= ((U64)1 << index);
+                *overflow_status_clr |= ((U64)1 << index);
+                SEP_DRV_LOG_TRACE("Counter 0x%x value 0x%llx.",
+                                ECB_entries_reg_id(pecb,i), value);
+            }
+            continue;
+        }
+        if (ECB_entries_fixed_reg_get(pecb,i)) {
+            index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_FIXED) + 0x20;
+            if (!(overflow_status & ((U64)1 << index))) {
+                value = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+                if (ECB_entries_reg_id(pecb,i) ==
+                    ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, 0, PMU_OPERATION_CHECK_OVERFLOW_GP_ERRATA))) {
+                    if (!(value > 0LL && value <= 0x1000000LL) &&
+                        (*overflow_status_clr & ((U64)1 << index))) {
+                        //Clear it only for overflow_status so that we do not create sample records
+                        //Please do not remove the check for MSR index
+                        overflow_status = overflow_status & ~((U64)1 << index);
+                        continue;
+                    }
+                }
+                if (value > 0LL && value <= 0x100000000LL) {
+                    overflow_status      |= ((U64)1 << index);
+                    *overflow_status_clr |= ((U64)1 << index);
+                    SEP_DRV_LOG_TRACE("counter 0x%x value 0x%llx\n",
+                                    ECB_entries_reg_id(pecb,i), value);
+                }
+            }
+        }
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("Res = %llu.", overflow_status);
+    return overflow_status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U64 corei7_Read_Platform_Info
+ *
+ * @brief       Reads the MSR_PLATFORM_INFO register if present
+ *
+ * @param       void
+ *
+ * @return      value read from the register
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static VOID
+corei7_Platform_Info (
+    PVOID data
+)
+{
+    DRV_PLATFORM_INFO      platform_data               = (DRV_PLATFORM_INFO)data;
+    U64                    value                       = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Data: %p.", data);
+
+    if (!platform_data) {
+        SEP_DRV_LOG_TRACE_OUT("Platform_data is NULL!");
+        return;
+    }
+
+    DRV_PLATFORM_INFO_energy_multiplier(platform_data) = 0;
+
+#define IA32_MSR_PLATFORM_INFO 0xCE
+    value = SYS_Read_MSR(IA32_MSR_PLATFORM_INFO);
+
+    DRV_PLATFORM_INFO_info(platform_data)           = value;
+    DRV_PLATFORM_INFO_ddr_freq_index(platform_data) = 0;
+#undef IA32_MSR_PLATFORM_INFO
+#define IA32_MSR_MISC_ENABLE 0x1A4
+    DRV_PLATFORM_INFO_misc_valid(platform_data)     = 1;
+    value = SYS_Read_MSR(IA32_MSR_MISC_ENABLE);
+    DRV_PLATFORM_INFO_misc_info(platform_data)      = value;
+#undef  IA32_MSR_MISC_ENABLE
+    SEP_DRV_LOG_TRACE("Read from MSR_ENERGY_MULTIPLIER reg is %llu.", SYS_Read_MSR(MSR_ENERGY_MULTIPLIER));
+    DRV_PLATFORM_INFO_energy_multiplier(platform_data) = (U32) (SYS_Read_MSR(MSR_ENERGY_MULTIPLIER) & 0x00001F00) >> 8;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U64 corei7_Platform_Info_Nehalem
+ *
+ * @brief       Reads the MSR_PLATFORM_INFO register if present
+ *
+ * @param       void
+ *
+ * @return      value read from the register
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static VOID
+corei7_Platform_Info_Nehalem (
+    PVOID data
+)
+{
+    DRV_PLATFORM_INFO      platform_data = (DRV_PLATFORM_INFO)data;
+    U64                    value         = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Data: %p.", data);
+
+    if (!platform_data) {
+        SEP_DRV_LOG_TRACE_OUT("Platform_data is NULL!");
+        return;
+    }
+
+#define IA32_MSR_PLATFORM_INFO 0xCE
+    value = SYS_Read_MSR(IA32_MSR_PLATFORM_INFO);
+
+    DRV_PLATFORM_INFO_info(platform_data)           = value;
+    DRV_PLATFORM_INFO_ddr_freq_index(platform_data) = 0;
+#undef IA32_MSR_PLATFORM_INFO
+#define IA32_MSR_MISC_ENABLE 0x1A4
+    DRV_PLATFORM_INFO_misc_valid(platform_data)     = 1;
+    value = SYS_Read_MSR(IA32_MSR_MISC_ENABLE);
+    DRV_PLATFORM_INFO_misc_info(platform_data)      = value;
+#undef  IA32_MSR_MISC_ENABLE
+    DRV_PLATFORM_INFO_energy_multiplier(platform_data) = 0;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*
+ * Initialize the dispatch table
+ */
+DISPATCH_NODE  core2_dispatch =
+{
+    .init                     = core2_Initialize,
+    .fini                     = core2_Destroy,
+    .write                    = core2_Write_PMU,
+    .freeze                   = core2_Disable_PMU,
+    .restart                  = core2_Enable_PMU,
+    .read_data                = core2_Read_PMU_Data,
+    .check_overflow           = core2_Check_Overflow,
+    .swap_group               = core2_Swap_Group,
+    .read_lbrs                = core2_Read_LBRs,
+    .cleanup                  = core2_Clean_Up,
+    .hw_errata                = NULL,
+    .read_power               = NULL,
+    .check_overflow_errata    = core2_Check_Overflow_Errata,
+    .read_counts              = core2_Read_Counts,
+    .check_overflow_gp_errata = NULL,
+    .read_ro                  = NULL,
+    .platform_info            = NULL,
+    .trigger_read             = NULL,
+    .scan_for_uncore          = NULL,
+    .read_metrics             = NULL
+};
+
+DISPATCH_NODE  corei7_dispatch =
+{
+    .init                     = core2_Initialize,
+    .fini                     = core2_Destroy,
+    .write                    = core2_Write_PMU,
+    .freeze                   = core2_Disable_PMU,
+    .restart                  = core2_Enable_PMU,
+    .read_data                = core2_Read_PMU_Data,
+    .check_overflow           = core2_Check_Overflow,
+    .swap_group               = core2_Swap_Group,
+    .read_lbrs                = corei7_Read_LBRs,
+    .cleanup                  = core2_Clean_Up,
+    .hw_errata                = corei7_Errata_Fix,
+    .read_power               = corei7_Read_Power,
+    .check_overflow_errata    = NULL,
+    .read_counts              = core2_Read_Counts,
+    .check_overflow_gp_errata = corei7_Check_Overflow_Errata,
+    .read_ro                  = NULL,
+    .platform_info            = corei7_Platform_Info,
+    .trigger_read             = NULL,
+    .scan_for_uncore          = NULL,
+    .read_metrics             = NULL
+};
+
+DISPATCH_NODE  corei7_dispatch_2 =
+{
+    .init                     = core2_Initialize,
+    .fini                     = core2_Destroy,
+    .write                    = core2_Write_PMU,
+    .freeze                   = core2_Disable_PMU,
+    .restart                  = corei7_Enable_PMU_2,
+    .read_data                = core2_Read_PMU_Data,
+    .check_overflow           = core2_Check_Overflow,
+    .swap_group               = core2_Swap_Group,
+    .read_lbrs                = corei7_Read_LBRs,
+    .cleanup                  = core2_Clean_Up,
+    .hw_errata                = corei7_Errata_Fix_2,
+    .read_power               = corei7_Read_Power,
+    .check_overflow_errata    = NULL,
+    .read_counts              = core2_Read_Counts,
+    .check_overflow_gp_errata = corei7_Check_Overflow_Errata,
+    .read_ro                  = NULL,
+    .platform_info            = corei7_Platform_Info,
+    .trigger_read             = NULL,
+    .scan_for_uncore          = NULL,
+    .read_metrics             = NULL
+};
+
+DISPATCH_NODE  corei7_dispatch_nehalem =
+{
+    .init                     = core2_Initialize,
+    .fini                     = core2_Destroy,
+    .write                    = core2_Write_PMU,
+    .freeze                   = core2_Disable_PMU,
+    .restart                  = core2_Enable_PMU,
+    .read_data                = core2_Read_PMU_Data,
+    .check_overflow           = core2_Check_Overflow,
+    .swap_group               = core2_Swap_Group,
+    .read_lbrs                = corei7_Read_LBRs,
+    .cleanup                  = core2_Clean_Up,
+    .hw_errata                = corei7_Errata_Fix,
+    .read_power               = corei7_Read_Power,
+    .check_overflow_errata    = NULL,
+    .read_counts              = core2_Read_Counts,
+    .check_overflow_gp_errata = corei7_Check_Overflow_Errata,
+    .read_ro                  = NULL,
+    .platform_info            = corei7_Platform_Info_Nehalem,
+    .trigger_read             = NULL,
+    .scan_for_uncore          = NULL,
+    .read_metrics             = NULL
+};
+
+DISPATCH_NODE  corei7_dispatch_htoff_mode =
+{
+    .init                     = core2_Initialize,
+    .fini                     = core2_Destroy,
+    .write                    = core2_Write_PMU,
+    .freeze                   = core2_Disable_PMU,
+    .restart                  = core2_Enable_PMU,
+    .read_data                = core2_Read_PMU_Data,
+    .check_overflow           = core2_Check_Overflow_Htoff_Mode,
+    .swap_group               = core2_Swap_Group,
+    .read_lbrs                = corei7_Read_LBRs,
+    .cleanup                  = core2_Clean_Up,
+    .hw_errata                = corei7_Errata_Fix,
+    .read_power               = corei7_Read_Power,
+    .check_overflow_errata    = NULL,
+    .read_counts              = core2_Read_Counts,
+    .check_overflow_gp_errata = corei7_Check_Overflow_Errata,
+    .read_ro                  = NULL,
+    .platform_info            = corei7_Platform_Info,
+    .trigger_read             = NULL,
+    .scan_for_uncore          = NULL,
+    .read_metrics             = NULL
+};
+
+DISPATCH_NODE  corei7_dispatch_htoff_mode_2 =
+{
+    .init                     = core2_Initialize,
+    .fini                     = core2_Destroy,
+    .write                    = core2_Write_PMU,
+    .freeze                   = core2_Disable_PMU,
+    .restart                  = corei7_Enable_PMU_2,
+    .read_data                = core2_Read_PMU_Data,
+    .check_overflow           = core2_Check_Overflow_Htoff_Mode,
+    .swap_group               = core2_Swap_Group,
+    .read_lbrs                = corei7_Read_LBRs,
+    .cleanup                  = core2_Clean_Up,
+    .hw_errata                = corei7_Errata_Fix_2,
+    .read_power               = corei7_Read_Power,
+    .check_overflow_errata    = NULL,
+    .read_counts              = core2_Read_Counts,
+    .check_overflow_gp_errata = corei7_Check_Overflow_Errata,
+    .read_ro                  = NULL,
+    .platform_info            = corei7_Platform_Info,
+    .trigger_read             = NULL,
+    .scan_for_uncore          = NULL,
+    .read_metrics             = NULL
+};
+
+
diff --git a/drivers/misc/intel/sepdk/sep/cpumon.c b/drivers/misc/intel/sepdk/sep/cpumon.c
new file mode 100644
index 000000000000..a976308e4c74
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/cpumon.c
@@ -0,0 +1,355 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+/*
+ *  CVS_Id="$Id$"
+ */
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/interrupt.h>
+#if defined(DRV_EM64T)
+#include <asm/desc.h>
+#endif
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "apic.h"
+#include "lwpmudrv.h"
+#include "control.h"
+#include "utility.h"
+#include "cpumon.h"
+#include "pmi.h"
+#include "sys_info.h"
+
+#include <linux/ptrace.h>
+#include <asm/nmi.h>
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,2,0))
+#include <linux/notifier.h>
+static int
+cpumon_NMI_Handler (
+    unsigned int cmd,
+    struct pt_regs *regs
+)
+{
+    U32 captured_state = GET_DRIVER_STATE();
+
+    if (DRIVER_STATE_IN(captured_state, STATE_BIT_RUNNING | STATE_BIT_PAUSING | STATE_BIT_PREPARE_STOP | STATE_BIT_TERMINATING)) {
+        if (captured_state != DRV_STATE_TERMINATING) {
+            PMI_Interrupt_Handler(regs);
+        }
+        return NMI_HANDLED;
+    }
+    else {
+        return NMI_DONE;
+    }
+}
+
+#define EBS_NMI_CALLBACK                        cpumon_NMI_Handler
+
+#else
+#include <linux/kdebug.h>
+static int
+cpumon_NMI_Handler (
+    struct notifier_block *self,
+    unsigned long val, void *data
+)
+{
+    struct die_args *args = (struct die_args *)data;
+    U32 captured_state      = GET_DRIVER_STATE();
+
+    if (args) {
+        switch (val) {
+            case DIE_NMI:
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,38))
+            case DIE_NMI_IPI:
+#endif
+                if (DRIVER_STATE_IN(captured_state, STATE_BIT_RUNNING | STATE_BIT_PAUSING | STATE_BIT_PREPARE_STOP | STATE_BIT_TERMINATING)) {
+                    if (captured_state != DRV_STATE_TERMINATING) {
+                        PMI_Interrupt_Handler(args->regs);
+                    }
+                    return NOTIFY_STOP;
+                }
+        }
+    }
+    return NOTIFY_DONE;
+}
+
+static struct notifier_block cpumon_notifier = {
+        .notifier_call = cpumon_NMI_Handler,
+        .next = NULL,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,38))
+        .priority = 2
+#else
+        .priority = NMI_LOCAL_LOW_PRIOR,
+#endif
+};
+#endif
+
+
+static volatile S32   cpuhook_installed = 0;
+
+/*
+ * CPU Monitoring Functionality
+ */
+
+
+/*
+ * General per-processor initialization
+ */
+#if defined(DRV_CPU_HOTPLUG)
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       DRV_BOOL CPUMON_is_Online_Allowed()
+ *
+ * @param    None
+ *
+ * @return   DRV_BOOL TRUE if cpu is allowed to go Online, else FALSE
+ *
+ * @brief    Checks if the cpu is allowed to go online during the
+ * @brief    current driver state
+ *
+ */
+extern DRV_BOOL
+CPUMON_is_Online_Allowed()
+{
+    U32      cur_driver_state;
+    DRV_BOOL is_allowed = FALSE;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    cur_driver_state = GET_DRIVER_STATE();
+
+    switch (cur_driver_state) {
+       case DRV_STATE_IDLE:
+       case DRV_STATE_PAUSED:
+       case DRV_STATE_RUNNING:
+       case DRV_STATE_PAUSING:
+           is_allowed = TRUE;
+           break;
+       default:
+           SEP_DRV_LOG_TRACE("CPU is prohibited to online in driver state %d.", cur_driver_state);
+           break;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", is_allowed);
+    return is_allowed;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       DRV_BOOL CPUMON_is_Offline_Allowed()
+ *
+ * @param    None
+ *
+ * @return   DRV_BOOL TRUE if cpu is allowed to go Offline, else FALSE
+ *
+ * @brief    Checks if the cpu is allowed to go offline during the
+ * @brief    current driver state
+ *
+ */
+extern DRV_BOOL
+CPUMON_is_Offline_Allowed()
+{
+    U32      cur_driver_state;
+    DRV_BOOL is_allowed = FALSE;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    cur_driver_state = GET_DRIVER_STATE();
+
+    switch (cur_driver_state) {
+       case DRV_STATE_PAUSED:
+       case DRV_STATE_RUNNING:
+       case DRV_STATE_PAUSING:
+           is_allowed = TRUE;
+           break;
+       default:
+           SEP_DRV_LOG_TRACE("CPU is prohibited to offline in driver state %d.", cur_driver_state);
+           break;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", is_allowed);
+    return is_allowed;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       VOID CPUMON_Online_Cpu(
+ *               PVOID param)
+ *
+ * @param    PVOID parm
+ *
+ * @return   None
+ *
+ * @brief    Sets a cpu online, initialize APIC on it,
+ * @brief    Build the sys_info for this cpu
+ *
+ */
+extern VOID
+CPUMON_Online_Cpu (
+    PVOID parm
+)
+{
+    U32           this_cpu;
+    CPU_STATE     pcpu;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy parm: %p.", parm);
+
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    preempt_enable();
+    pcpu = &pcb[this_cpu];
+    if (pcpu == NULL) {
+        SEP_DRV_LOG_WARNING_TRACE_OUT("Unable to set CPU %d online!", this_cpu);
+        return;
+    }
+    SEP_DRV_LOG_INIT("Setting CPU %d online, PCPU = %p.", this_cpu, pcpu);
+    CPU_STATE_offlined(pcpu)           = FALSE;
+    CPU_STATE_accept_interrupt(pcpu)   = 1;
+    CPU_STATE_initial_mask(pcpu)       = 1;
+    CPU_STATE_group_swap(pcpu)         = 1;
+    APIC_Init(NULL);
+    APIC_Install_Interrupt_Handler(NULL);
+
+    SYS_INFO_Build_Cpu(NULL);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       VOID CPUMON_Offline_Cpu(
+ *               PVOID param)
+ *
+ * @param    PVOID parm
+ *
+ * @return   None
+ *
+ * @brief    Sets a cpu offline
+ *
+ */
+extern VOID
+CPUMON_Offline_Cpu (
+    PVOID parm
+)
+{
+    U32       cpu_idx;
+    CPU_STATE pcpu;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy parm: %p.", parm);
+
+    cpu_idx = *(U32 *) parm;
+    pcpu    = &pcb[cpu_idx];
+
+    if (pcpu == NULL) {
+        SEP_DRV_LOG_WARNING_TRACE_OUT("Unable to set CPU %d offline.", cpu_idx);
+        return;
+    }
+    SEP_DRV_LOG_INIT("Setting CPU %d offline.", cpu_idx);
+    CPU_STATE_offlined(pcpu) = TRUE;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+#endif
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern void CPUMON_Install_Cpuhooks(void)
+ *
+ * @param    None
+ *
+ * @return   None     No return needed
+ *
+ * @brief  set up the interrupt handler (on a per-processor basis)
+ * @brief  Initialize the APIC in two phases (current CPU, then others)
+ *
+ */
+extern VOID
+CPUMON_Install_Cpuhooks (
+    void
+)
+{
+    S32   me        = 0;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (cpuhook_installed) {
+        SEP_DRV_LOG_WARNING_TRACE_OUT("Cpuhook already installed.");
+        return;
+    }
+
+    CONTROL_Invoke_Parallel(APIC_Init, NULL);
+    CONTROL_Invoke_Parallel(APIC_Install_Interrupt_Handler, (PVOID)(size_t)me);
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,2,0))
+    register_nmi_handler(NMI_LOCAL, EBS_NMI_CALLBACK, 0, "sep_pmi");
+#else
+    register_die_notifier(&cpumon_notifier);
+#endif
+
+    cpuhook_installed = 1;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern void CPUMON_Remove_Cpuhools(void)
+ *
+ * @param    None
+ *
+ * @return   None     No return needed
+ *
+ * @brief  De-Initialize the APIC in phases
+ * @brief  clean up the interrupt handler (on a per-processor basis)
+ *
+ */
+extern VOID
+CPUMON_Remove_Cpuhooks (
+    void
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+    CONTROL_Invoke_Parallel(APIC_Restore_LVTPC, NULL);
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,2,0))
+    unregister_nmi_handler(NMI_LOCAL, "sep_pmi");
+#else
+    unregister_die_notifier(&cpumon_notifier);
+#endif
+
+    cpuhook_installed = 0;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
diff --git a/drivers/misc/intel/sepdk/sep/eventmux.c b/drivers/misc/intel/sepdk/sep/eventmux.c
new file mode 100644
index 000000000000..bc1aa73f621a
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/eventmux.c
@@ -0,0 +1,469 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+ 
+    This file is part of SEP Development Kit
+ 
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+ 
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+ 
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+ 
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/jiffies.h>
+#include <linux/time.h>
+#include <linux/percpu.h>
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+#include "lwpmudrv.h"
+#include "control.h"
+#include "utility.h"
+
+static PVOID     em_tables      = NULL;
+static size_t    em_tables_size = 0;
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID eventmux_Allocate_Groups (
+ *                         VOID  *params
+ *                         )
+ *
+ * @brief       Allocate memory need to support event multiplexing
+ *
+ * @param       params - pointer to a S32 that holds the size of buffer to allocate
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              Allocate the memory needed to save different group counters
+ *              Called via the parallel control mechanism
+ */
+static VOID 
+eventmux_Allocate_Groups (
+    PVOID  params
+)
+{
+    U32        this_cpu;
+    CPU_STATE  cpu_state;
+    U32        dev_idx;
+    EVENT_CONFIG ec;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    preempt_disable();
+    this_cpu  = CONTROL_THIS_CPU();
+    cpu_state = &pcb[this_cpu];
+    dev_idx   = core_to_dev_map[this_cpu];
+    ec        = LWPMU_DEVICE_ec(&devices[dev_idx]);
+    preempt_enable();
+
+    if (EVENT_CONFIG_mode(ec)       == EM_DISABLED ||
+        EVENT_CONFIG_num_groups(ec) == 1) {
+        return;
+    }
+
+    CPU_STATE_em_tables(cpu_state) = em_tables + CPU_STATE_em_table_offset(cpu_state);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID eventmux_Deallocate_Groups (
+ *                         VOID  *params
+ *                         )
+ *
+ * @brief       Free the scratch memory need to support event multiplexing
+ *
+ * @param       params - pointer to NULL
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              Free the memory needed to save different group counters
+ *              Called via the parallel control mechanism
+ */
+static VOID 
+eventmux_Deallocate_Groups (
+    PVOID  params
+)
+{
+    U32        this_cpu;
+    CPU_STATE  cpu_state;
+    U32        dev_idx;
+    EVENT_CONFIG ec;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    preempt_disable();
+    this_cpu  = CONTROL_THIS_CPU();
+    cpu_state = &pcb[this_cpu];
+    dev_idx   = core_to_dev_map[this_cpu];
+    ec        = LWPMU_DEVICE_ec(&devices[dev_idx]);
+    preempt_enable();
+
+    if (EVENT_CONFIG_mode(ec)       == EM_DISABLED ||
+        EVENT_CONFIG_num_groups(ec) == 1) {
+        return;
+    }
+
+    CPU_STATE_em_tables(cpu_state) = NULL;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID eventmux_Timer_Callback_Thread (
+ *                         )
+ *
+ * @brief       Stop all the timer threads and terminate them
+ *
+ * @param       none
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              timer routine - The event multiplexing happens here.
+ */
+static VOID
+eventmux_Timer_Callback_Thread (
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,15,0)
+    struct timer_list *tl
+#else
+    unsigned long arg
+#endif
+)
+{
+    U32        this_cpu;
+    CPU_STATE  pcpu;
+    U32        dev_idx;
+    DISPATCH   dispatch;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,15,0)
+    SEP_DRV_LOG_TRACE_IN("");
+#else
+    SEP_DRV_LOG_TRACE_IN("Arg: %u.", (U32) arg);
+#endif
+
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    dispatch = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    preempt_enable();
+
+    if (CPU_STATE_em_tables(pcpu) == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Em_tables is NULL!");
+        return;
+    }
+
+
+    dispatch->swap_group(TRUE);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,15,0)
+    mod_timer(CPU_STATE_em_timer(pcpu), jiffies + CPU_STATE_em_timer_delay(pcpu));
+#else
+    CPU_STATE_em_timer(pcpu)->expires = jiffies + arg;
+    add_timer(CPU_STATE_em_timer(pcpu));
+#endif
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID eventmux_Prepare_Timer_Threads (
+ *                         VOID
+ *                         )
+ *
+ * @brief       Stop all the timer threads and terminate them
+ *
+ * @param       NONE
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              Set up the timer threads to prepare for event multiplexing.
+ *              Do not start the threads as yet
+ */
+static VOID
+eventmux_Prepare_Timer_Threads (
+                                PVOID arg
+)
+{
+    U32          this_cpu;
+    CPU_STATE    pcpu;
+    U32          dev_idx;
+    EVENT_CONFIG ec;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    // initialize and set up the timer for all cpus
+    // Do not start the timer as yet.
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    ec       = LWPMU_DEVICE_ec(&devices[dev_idx]);
+    preempt_enable();
+
+    if (EVENT_CONFIG_mode(ec) != EM_TIMER_BASED) {
+        return;
+    }
+
+    CPU_STATE_em_timer(pcpu) = (struct timer_list*)CONTROL_Allocate_Memory(sizeof(struct timer_list));
+
+    if (CPU_STATE_em_timer(pcpu) == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Pcpu = NULL!");
+        return;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID eventmux_Cancel_Timers (
+ *                         VOID
+ *                         )
+ *
+ * @brief       Stop all the timer threads and terminate them
+ *
+ * @param       NONE
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              Cancel all the timer threads that have been started
+ */
+static VOID
+eventmux_Cancel_Timers (
+    VOID
+)
+{
+    CPU_STATE    pcpu;
+    S32          i;
+    U32          dev_idx;
+    EVENT_CONFIG ec;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    /*
+     *  Cancel the timer for all active CPUs
+     */
+    for (i=0; i < GLOBAL_STATE_active_cpus(driver_state); i++) {
+        pcpu    = &pcb[i];
+        dev_idx = core_to_dev_map[i];
+        ec      = LWPMU_DEVICE_ec(&devices[dev_idx]);
+        if (EVENT_CONFIG_mode(ec) != EM_TIMER_BASED) {
+            continue;
+        }
+        del_timer_sync(CPU_STATE_em_timer(pcpu));
+        CPU_STATE_em_timer(pcpu) = (struct timer_list*)CONTROL_Free_Memory(CPU_STATE_em_timer(pcpu));
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID eventmux_Start_Timers (
+ *                         long unsigned arg
+ *                         )
+ *
+ * @brief       Start the timer on a single cpu
+ *
+ * @param       delay   interval time in jiffies
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              start the timer on a single cpu
+ *              Call from each cpu to get cpu affinity for Timer_Callback_Thread
+ */
+static VOID
+eventmux_Start_Timers(
+                      PVOID arg
+                      )
+{
+    U32           this_cpu;
+    CPU_STATE     pcpu;
+    U32           dev_idx;
+    EVENT_CONFIG  ec;
+    unsigned long delay;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    ec       = LWPMU_DEVICE_ec(&devices[dev_idx]);
+    preempt_enable();
+
+    if (EVENT_CONFIG_mode(ec) != EM_TIMER_BASED ||
+        EVENT_CONFIG_num_groups(ec) == 1) {
+        return;
+    }
+
+    /*
+     * notice we want to use group 0's time slice for the initial timer
+     */
+    delay = msecs_to_jiffies(EVENT_CONFIG_em_factor(ec));
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,15,0)
+    CPU_STATE_em_timer_delay(pcpu) = delay;
+    timer_setup(CPU_STATE_em_timer(pcpu), eventmux_Timer_Callback_Thread, 0);
+    mod_timer(CPU_STATE_em_timer(pcpu), jiffies + CPU_STATE_em_timer_delay(pcpu));
+#else
+    init_timer(CPU_STATE_em_timer(pcpu));
+    CPU_STATE_em_timer(pcpu)->function = eventmux_Timer_Callback_Thread;
+    CPU_STATE_em_timer(pcpu)->data     = delay;
+    CPU_STATE_em_timer(pcpu)->expires  = jiffies+delay;
+    add_timer(CPU_STATE_em_timer(pcpu));
+#endif
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID EVENTMUX_Start (
+ *                         VOID
+ *                         )
+ *
+ * @brief       Start the timers and enable all the threads
+ *
+ * @param       NONE
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              if event multiplexing has been enabled, set up the time slices and
+ *              start the timer threads for all the timers
+ */
+extern VOID 
+EVENTMUX_Start (
+    VOID
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    /*
+     * Start the timer for all cpus
+     */
+    CONTROL_Invoke_Parallel(eventmux_Start_Timers, NULL);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID EVENTMUX_Initialize (
+ *                         VOID
+ *                         )
+ *
+ * @brief       Initialize the event multiplexing module
+ *
+ * @param       NONE
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              if event multiplexing has been enabled, 
+ *              then allocate the memory needed to save and restore all the counter data
+ *              set up the timers needed, but do not start them
+ */
+extern VOID
+EVENTMUX_Initialize (
+    VOID
+)
+{
+    S32          size_of_vector;
+    S32          cpu_num;
+    CPU_STATE    pcpu;
+    U32          dev_idx;
+    EVENT_CONFIG ec;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    for (cpu_num = 0; cpu_num < GLOBAL_STATE_num_cpus(driver_state); cpu_num++) {
+        pcpu    = &pcb[cpu_num];
+        dev_idx = core_to_dev_map[cpu_num];
+        ec      = LWPMU_DEVICE_ec(&devices[dev_idx]);
+        if (EVENT_CONFIG_mode(ec)       == EM_DISABLED ||
+            EVENT_CONFIG_num_groups(ec) == 1) {
+            continue;
+        }
+        size_of_vector = EVENT_CONFIG_num_groups(ec)    *
+                         EVENT_CONFIG_max_gp_events(ec) *
+                         sizeof(S64);
+        CPU_STATE_em_table_offset(pcpu) = em_tables_size;
+        em_tables_size += size_of_vector;
+    }
+
+    if (em_tables_size) {
+        em_tables = CONTROL_Allocate_Memory(em_tables_size);
+    }
+    CONTROL_Invoke_Parallel(eventmux_Allocate_Groups, NULL);
+    
+    CONTROL_Invoke_Parallel(eventmux_Prepare_Timer_Threads, (VOID *)(size_t)0);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID EVENTMUX_Destroy (
+ *                         VOID
+ *                         )
+ *
+ * @brief       Clean up the event multiplexing threads
+ *
+ * @param       NONE
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              if event multiplexing has been enabled, then stop and cancel all the timers
+ *              free up all the memory that is associated with EM
+ */
+extern VOID
+EVENTMUX_Destroy (
+    VOID
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    eventmux_Cancel_Timers();
+
+    if (em_tables) {
+        em_tables      = CONTROL_Free_Memory(em_tables);
+        em_tables_size = 0;
+    }
+    CONTROL_Invoke_Parallel(eventmux_Deallocate_Groups, (VOID *)(size_t)0);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
diff --git a/drivers/misc/intel/sepdk/sep/gfx.c b/drivers/misc/intel/sepdk/sep/gfx.c
new file mode 100644
index 000000000000..1d632ce731d1
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/gfx.c
@@ -0,0 +1,260 @@
+/****
+    Copyright(C) 2009-2018 Intel Corporation.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include <asm/page.h>
+#include <asm/io.h>
+
+#include "lwpmudrv_defines.h"
+#include "lwpmudrv_types.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_gfx.h"
+#include "rise_errors.h"
+#include "lwpmudrv.h"
+#include "inc/pci.h"
+#include "gfx.h"
+#include "utility.h"
+
+static char            *gfx_virtual_addr    = NULL;
+static SEP_MMIO_NODE    gfx_map;
+static U32              gfx_code            = GFX_CTRL_DISABLE;
+static U32              gfx_counter[GFX_NUM_COUNTERS] = {0, 0, 0, 0, 0, 0, 0, 0, 0};
+static U32              gfx_overflow[GFX_NUM_COUNTERS] = {0, 0, 0, 0, 0, 0, 0, 0, 0};
+
+/*!
+ * @fn     OS_STATUS GFX_Read
+ *
+ * @brief  Reads the counters into the buffer provided for the purpose
+ *
+ * @param  buffer  - buffer to read the counts into
+ *
+ * @return STATUS_SUCCESS if read succeeded, otherwise error
+ *
+ * @note 
+ */
+extern OS_STATUS
+GFX_Read (
+    S8 *buffer
+)
+{
+    U64  *samp  = (U64 *)buffer;
+    U32   i;
+    U32   val;
+    char *reg_addr;
+
+    SEP_DRV_LOG_TRACE_IN("Buffer: %p.", buffer);
+
+    // GFX counting was not specified
+    if (gfx_virtual_addr == NULL || gfx_code == GFX_CTRL_DISABLE) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("OS_INVALID (!gfx_virtual_addr || gfx_code == GFX_CTRL_DISABLE).");
+        return OS_INVALID;
+    }
+
+    // check for sampling buffer
+    if (!samp) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("OS_INVALID (!samp).");
+        return OS_INVALID;
+    }
+
+    // set the GFX register address
+    reg_addr = gfx_virtual_addr + GFX_PERF_REG;
+
+    // for all counters - save the information to the sampling stream
+    for (i = 0; i < GFX_NUM_COUNTERS; i++) {
+        // read the ith GFX event count
+        reg_addr += 4;
+        val = *(U32 *)(reg_addr);
+#if defined(GFX_COMPUTE_DELTAS)
+        // if the current count is bigger than the previous one, then the counter overflowed
+        // so make sure the delta gets adjusted to account for it
+        if (val < gfx_counter[i]) {
+            samp[i] = val + (GFX_CTR_OVF_VAL - gfx_counter[i]);
+        }
+        else {
+            samp[i] = val - gfx_counter[i];
+        }
+#else   // just keep track of raw count for this counter
+        // if the current count is bigger than the previous one, then the counter overflowed
+        if (val < gfx_counter[i]) {
+            gfx_overflow[i]++;
+        }
+        samp[i] = val + gfx_overflow[i]*GFX_CTR_OVF_VAL;
+#endif
+        // save the current count
+        gfx_counter[i] = val;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("OS_SUCCESS.");
+    return OS_SUCCESS;
+}
+
+/*!
+ * @fn     OS_STATUS GFX_Set_Event_Code
+ *
+ * @brief  Programs the Graphics PMU with the right event code
+ *
+ * @param  arg - buffer containing graphics event code
+ *
+ * @return STATUS_SUCCESS if success, otherwise error
+ *
+ * @note 
+ */
+extern OS_STATUS
+GFX_Set_Event_Code (
+    IOCTL_ARGS arg
+)
+{
+    U32        i;
+    char      *reg_addr;
+    U32        reg_value;
+
+    SEP_DRV_LOG_FLOW_IN("Arg: %p.", arg);
+
+    // extract the graphics event code from usermode
+    if (get_user(gfx_code, (int*)arg->buf_usr_to_drv)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("OS_FAULT (Unable to obtain gfx_code from usermode!).");
+        return OS_FAULT;
+    }
+    SEP_DRV_LOG_TRACE("Got gfx_code=0x%x.", gfx_code);
+
+    // memory map the address to GFX counters, if not already done
+    if (gfx_virtual_addr == NULL) {
+        PCI_Map_Memory(&gfx_map, GFX_BASE_ADDRESS + GFX_BASE_NEW_OFFSET, PAGE_SIZE);
+        gfx_virtual_addr = (char*)(UIOP)SEP_MMIO_NODE_virtual_address(&gfx_map);
+    }
+
+    // initialize the GFX counts
+    for (i =  0; i < GFX_NUM_COUNTERS; i++) {
+        gfx_counter[i] = 0;
+        gfx_overflow[i] = 0;  // only used if storing raw counts (i.e., GFX_COMPUTE_DELTAS is undefined)
+    }
+
+    // get current GFX event code
+    if (gfx_virtual_addr == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("OS_INVALID (Invalid gfx_virtual_addr=0x%p!).", gfx_virtual_addr);
+        return OS_INVALID;
+    }
+
+    reg_addr = gfx_virtual_addr + GFX_PERF_REG;
+    reg_value = *(U32 *)(reg_addr);
+    SEP_DRV_LOG_TRACE("Read reg_value=0x%x from reg_addr=0x%p.", reg_value, reg_addr);
+
+    /* Update the GFX counter group */
+    // write the GFX counter group with reset = 1 for all counters
+    reg_value = (gfx_code | GFX_REG_CTR_CTRL);
+    *(U32 *)(reg_addr) = reg_value;
+    SEP_DRV_LOG_TRACE("Wrote reg_value=0x%x to reg_addr=0x%p.", reg_value, reg_addr);
+
+    SEP_DRV_LOG_FLOW_OUT("OS_SUCCESS.");
+    return OS_SUCCESS;
+}
+
+/*!
+ * @fn     OS_STATUS GFX_Start
+ *
+ * @brief  Starts the count of the Graphics PMU
+ *
+ * @param  NONE
+ *
+ * @return OS_SUCCESS if success, otherwise error
+ *
+ * @note 
+ */
+extern OS_STATUS
+GFX_Start (
+    void
+)
+{
+    U32   reg_value;
+    char *reg_addr;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    // GFX counting was not specified
+    if (gfx_virtual_addr == NULL || gfx_code == GFX_CTRL_DISABLE) {
+        SEP_DRV_LOG_ERROR("Invalid gfx_virtual_addr=0x%p or gfx_code=0x%x.", gfx_virtual_addr, gfx_code);
+        SEP_DRV_LOG_TRACE_OUT("OS_INVALID.");
+        return OS_INVALID;
+    }
+
+    // turn on GFX counters as per event code
+    reg_addr = gfx_virtual_addr + GFX_PERF_REG;
+    *(U32 *)(reg_addr) = gfx_code;
+
+    // verify event code was written properly
+    reg_value = *(U32 *)reg_addr;
+    if (reg_value != gfx_code) {
+        SEP_DRV_LOG_ERROR("Got register value 0x%x, expected 0x%x.", reg_value, gfx_code);
+        SEP_DRV_LOG_TRACE_OUT("OS_INVALID.");
+        return OS_INVALID;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("OS_SUCCESS.");
+    return OS_SUCCESS;
+}
+
+/*!
+ * @fn     OS_STATUS GFX_Stop
+ *
+ * @brief  Stops the count of the Graphics PMU
+ *
+ * @param  NONE
+ *
+ * @return OS_SUCCESS if success, otherwise error
+ *
+ * @note 
+ */
+extern OS_STATUS
+GFX_Stop (
+    void
+)
+{
+    char *reg_addr;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    // GFX counting was not specified
+    if (gfx_virtual_addr == NULL || gfx_code == GFX_CTRL_DISABLE) {
+        SEP_DRV_LOG_ERROR("Invalid gfx_virtual_addr=0x%p or gfx_code=0x%x.", gfx_virtual_addr, gfx_code);
+        SEP_DRV_LOG_TRACE_OUT("OS_INVALID.");
+        return OS_INVALID;
+    }
+
+    // turn off GFX counters
+    reg_addr = gfx_virtual_addr + GFX_PERF_REG;
+    *(U32 *)(reg_addr) = GFX_CTRL_DISABLE;
+
+    // unmap the memory mapped virtual address
+    PCI_Unmap_Memory(&gfx_map);
+    gfx_virtual_addr   = NULL;
+
+    // reset the GFX global variables
+    gfx_code           = GFX_CTRL_DISABLE;
+
+    SEP_DRV_LOG_TRACE_OUT("OS_SUCCESS.");
+    return OS_SUCCESS;
+}
diff --git a/drivers/misc/intel/sepdk/sep/gmch.c b/drivers/misc/intel/sepdk/sep/gmch.c
new file mode 100644
index 000000000000..8c8f723a2d09
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/gmch.c
@@ -0,0 +1,515 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include <linux/version.h>
+#include <linux/errno.h>
+#include <linux/fs.h>
+#include <linux/pci.h>
+#include "lwpmudrv_defines.h"
+#include "lwpmudrv_types.h"
+
+#if defined(PCI_HELPERS_API)
+#include <asm/intel_scu_ipc.h>
+#include <asm/intel-mid.h>
+#endif
+
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+#include "lwpmudrv_chipset.h"
+#include "inc/lwpmudrv.h"
+#include "inc/control.h"
+#include "inc/utility.h"
+#include "inc/ecb_iterators.h"
+#include "inc/gmch.h"
+#include "inc/pci.h"
+
+// global variables for determining which register offsets to use
+static U32 gmch_register_read  = 0;     // value=0 indicates invalid read register
+static U32 gmch_register_write = 0;     // value=0 indicates invalid write register
+static U32 number_of_events    = 0;
+
+//global variable for reading GMCH counter values
+static U64              *gmch_current_data = NULL;
+static U64              *gmch_to_read_data = NULL;
+
+// global variable for tracking number of overflows per GMCH counter
+static U32               gmch_overflow[MAX_CHIPSET_COUNTERS];
+static U64               last_gmch_count[MAX_CHIPSET_COUNTERS];
+
+extern DRV_CONFIG        drv_cfg;
+extern CHIPSET_CONFIG    pma;
+extern CPU_STATE         pcb;
+
+/*
+ * @fn        gmch_PCI_Read32(address)
+ *
+ * @brief     Read the 32bit value specified by the address
+ *
+ * @return    the read value
+ *
+ */
+#if defined(PCI_HELPERS_API)
+#define gmch_PCI_Read32   intel_mid_msgbus_read32_raw
+#else
+static U32
+gmch_PCI_Read32 (
+    unsigned long address
+)
+{
+    U32 read_value = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Address: %lx.", address);
+
+    PCI_Write_U32(0, 0, 0, GMCH_MSG_CTRL_REG, (U32)address);
+    read_value = PCI_Read_U32(0, 0, 0, GMCH_MSG_DATA_REG);
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %x.", read_value);
+    return read_value;
+}
+#endif
+
+/*
+ * @fn        gmch_PCI_Write32(address, data)
+ *
+ * @brief     Write the 32bit value into the address specified
+ *
+ * @return    None
+ *
+ */
+#if defined(PCI_HELPERS_API)
+#define gmch_PCI_Write32  intel_mid_msgbus_write32_raw
+#else
+static void
+gmch_PCI_Write32 (
+    unsigned long address,
+    unsigned long data
+)
+{
+    SEP_DRV_LOG_TRACE_IN("Address: %lx, data: %lx.", address, data);
+
+    PCI_Write_U32(0, 0, 0, GMCH_MSG_DATA_REG, data);
+    PCI_Write_U32(0, 0, 0, GMCH_MSG_CTRL_REG, address);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+#endif
+
+/*
+ * @fn        gmch_Check_Enabled()
+ *
+ * @brief     Read GMCH PMON capabilities
+ *
+ * @param     None
+ *
+ * @return    GMCH enable bits
+ *
+ */
+static ULONG
+gmch_Check_Enabled (
+    VOID
+)
+{
+    ULONG enabled_value;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    enabled_value = gmch_PCI_Read32(GMCH_PMON_CAPABILITIES + gmch_register_read);
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %lx.", enabled_value);
+    return enabled_value;
+}
+
+/*
+ * @fn        gmch_Init_Chipset()
+ *
+ * @brief     Initialize GMCH Counters.  See note below.
+ *
+ * @param     None
+ *
+ * @note      This function must be called BEFORE any other function in this file!
+ *
+ * @return    VT_SUCCESS if successful, error otherwise
+ *
+ */
+static U32
+gmch_Init_Chipset (
+    VOID
+)
+{
+    int             i;
+    CHIPSET_SEGMENT cs;
+    CHIPSET_SEGMENT gmch_chipset_seg;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    cs = &CHIPSET_CONFIG_gmch(pma);
+    gmch_chipset_seg = &CHIPSET_CONFIG_gmch(pma);
+
+    // configure the read/write registers offsets according to usermode setting
+    if (cs) {
+        gmch_register_read = CHIPSET_SEGMENT_read_register(cs);
+        gmch_register_write = CHIPSET_SEGMENT_write_register(cs);;
+    }
+    if (gmch_register_read == 0 || gmch_register_write == 0) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("VT_CHIPSET_CONFIG_FAILED (Invalid GMCH read/write registers!).");
+        return VT_CHIPSET_CONFIG_FAILED;
+    }
+
+    number_of_events = CHIPSET_SEGMENT_total_events(gmch_chipset_seg);
+    SEP_DRV_LOG_INIT("Number of chipset events %d.", number_of_events);
+
+    // Allocate memory for reading GMCH counter values + the group id
+    gmch_current_data = CONTROL_Allocate_Memory((number_of_events+1)*sizeof(U64));
+    if (!gmch_current_data) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("OS_NO_MEM (!gmch_current_data).");
+        return OS_NO_MEM;
+    }
+    gmch_to_read_data = CONTROL_Allocate_Memory((number_of_events+1)*sizeof(U64));
+    if (!gmch_to_read_data) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("OS_NO_MEM (!gmch_to_read_data).");
+        return OS_NO_MEM;
+    }
+
+    if (!DRV_CONFIG_enable_chipset(drv_cfg)) {
+        SEP_DRV_LOG_TRACE_OUT("VT_SUCCESS (!DRV_CONFIG_enable_chipset(drv_cfg)).");
+        return VT_SUCCESS;
+    }
+
+    if (!CHIPSET_CONFIG_gmch_chipset(pma)) {
+        SEP_DRV_LOG_TRACE_OUT("VT_SUCCESS (!CHIPSET_CONFIG_gmch_chipset(drv_cfg)).");
+        return VT_SUCCESS;
+    }
+    // initialize the GMCH per-counter overflow numbers
+    for (i = 0; i < MAX_CHIPSET_COUNTERS; i++) {
+        gmch_overflow[i]   = 0;
+        last_gmch_count[i] = 0;
+    }
+
+    // disable fixed and GP counters
+    gmch_PCI_Write32(GMCH_PMON_GLOBAL_CTRL+gmch_register_write, 0x00000000);
+    // clear fixed counter filter
+    gmch_PCI_Write32(GMCH_PMON_FIXED_CTR_CTRL+gmch_register_write, 0x00000000);
+
+    SEP_DRV_LOG_TRACE_OUT("VT_SUCCESS.");
+    return VT_SUCCESS;
+}
+
+/*
+ * @fn        gmch_Start_Counters()
+ *
+ * @brief     Start the GMCH Counters.
+ *
+ * @param     None
+ *
+ * @return    None
+ *
+ */
+static VOID
+gmch_Start_Counters (
+    VOID
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    // reset and start chipset counters
+    if (pma == NULL) {
+        SEP_DRV_LOG_ERROR("gmch_Start_Counters: ERROR pma=NULL.");
+    }
+
+    // enable fixed and GP counters
+    gmch_PCI_Write32(GMCH_PMON_GLOBAL_CTRL+gmch_register_write, 0x0001000F);
+    // enable fixed counter filter
+    gmch_PCI_Write32(GMCH_PMON_FIXED_CTR_CTRL+gmch_register_write, 0x00000001);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*
+ * @fn        gmch_Trigger_Read()
+ *
+ * @brief     Read the GMCH counters through PCI Config space
+ *
+ * @return    None
+ *
+ */
+static VOID
+gmch_Trigger_Read (
+    VOID
+)
+{
+    U64            *data;
+    int             i, data_index;
+    U64             val;
+    U64            *gmch_data;
+    U32             counter_data_low;
+    U32             counter_data_high;
+    U64             counter_data;
+    U64             cmd_register_low_read;
+    U64             cmd_register_high_read;
+    U32             gp_counter_index    = 0;
+    U64             overflow;
+    U32             cur_driver_state;
+
+    CHIPSET_SEGMENT gmch_chipset_seg;
+    CHIPSET_EVENT   chipset_events;
+    U64             *temp;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    cur_driver_state = GET_DRIVER_STATE();
+
+    if (!IS_COLLECTING_STATE(cur_driver_state))  {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Invalid driver state!");
+        return;
+    }
+
+    if (pma == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("pma is NULL!");
+        return;
+    }
+
+    if (gmch_current_data == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("gmch_current_data is NULL!");
+        return;
+    }
+
+    if (CHIPSET_CONFIG_gmch_chipset(pma) == 0) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("CHIPSET_CONFIG_gmch_chipset(pma) is NULL!");
+        return;
+    }
+
+    data       = gmch_current_data;
+    data_index = 0;
+
+    preempt_disable();
+    SYS_Local_Irq_Disable();
+    gmch_chipset_seg    = &CHIPSET_CONFIG_gmch(pma);
+    chipset_events      = CHIPSET_SEGMENT_events(gmch_chipset_seg);
+
+    // Write GroupID
+    data[data_index] = 1;
+    // Increment the data index as the event id starts from zero
+    data_index++;
+
+    // GMCH data will be written as gmch_data[0], gmch_data[1], ...
+    gmch_data = data + data_index;
+
+    // read the GMCH counters and add them into the sample record
+
+    // iterate through GMCH counters that were configured to collect on the events
+    for (i = 0; i < CHIPSET_SEGMENT_total_events(gmch_chipset_seg); i++) {
+        U32 event_id = CHIPSET_EVENT_event_id(&chipset_events[i]);
+        // read count for fixed GMCH counter event
+        if (event_id == 0) {
+            cmd_register_low_read  = GMCH_PMON_FIXED_CTR0 + gmch_register_read;
+            data[data_index++]     = (U64)gmch_PCI_Read32(cmd_register_low_read);
+            overflow               = GMCH_PMON_FIXED_CTR_OVF_VAL;
+        }
+        else {
+            // read count for general GMCH counter event
+            switch (gp_counter_index) {
+                case 0:
+                default:
+                    cmd_register_low_read  = GMCH_PMON_GP_CTR0_L + gmch_register_read;
+                    cmd_register_high_read = GMCH_PMON_GP_CTR0_H + gmch_register_read;
+                    break;
+
+                case 1:
+                    cmd_register_low_read  = GMCH_PMON_GP_CTR1_L + gmch_register_read;
+                    cmd_register_high_read = GMCH_PMON_GP_CTR1_H + gmch_register_read;
+                    break;
+
+                case 2:
+                    cmd_register_low_read  = GMCH_PMON_GP_CTR2_L + gmch_register_read;
+                    cmd_register_high_read = GMCH_PMON_GP_CTR2_H + gmch_register_read;
+                    break;
+
+                case 3:
+                    cmd_register_low_read  = GMCH_PMON_GP_CTR3_L + gmch_register_read;
+                    cmd_register_high_read = GMCH_PMON_GP_CTR3_H + gmch_register_read;
+                    break;
+            }
+            counter_data_low   = gmch_PCI_Read32(cmd_register_low_read);
+            counter_data_high  = gmch_PCI_Read32(cmd_register_high_read);
+            counter_data       = (U64)counter_data_high;
+            data[data_index++] = (counter_data << 32) + counter_data_low;
+            overflow           = GMCH_PMON_GP_CTR_OVF_VAL;
+            gp_counter_index++;
+        }
+
+        /* Compute the running count of the event. */
+        gmch_data[i] &= overflow;
+        val           = gmch_data[i];
+        if (gmch_data[i] < last_gmch_count[i]) {
+            gmch_overflow[i]++;
+        }
+        gmch_data[i]       = gmch_data[i] + gmch_overflow[i]*overflow;
+        last_gmch_count[i] = val;
+    }
+
+    temp              = gmch_to_read_data;
+    gmch_to_read_data = gmch_current_data;
+    gmch_current_data = temp;
+    SYS_Local_Irq_Enable();
+    preempt_enable();
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*
+ * @fn        gmch_Read_Counters()
+ *
+ * @brief     Copy the GMCH data to the sampling data stream.
+ *
+ * @param     param - pointer to data stream where samples are to be written
+ *
+ * @return    None
+ *
+ */
+static VOID
+gmch_Read_Counters (
+    PVOID  param
+)
+{
+    U64            *data;
+    int             i;
+    U32             cur_driver_state;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    cur_driver_state = GET_DRIVER_STATE();
+
+    if (!IS_COLLECTING_STATE(cur_driver_state))  {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Invalid driver state!");
+        return;
+    }
+
+    if (pma == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("pma is NULL!");
+        return;
+    }
+
+    if (param == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("param is NULL!");
+        return;
+    }
+
+    if (gmch_to_read_data == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("gmch_to_read_data is NULL!");
+        return;
+    }
+
+    /*
+     * Account for the group id that is placed at the start of the chipset array.
+     * The number of data elements to be transferred is number_of_events + 1.
+     */
+    data = param;
+    for (i = 0; i < number_of_events+1; i++) {
+         data[i] = gmch_to_read_data[i];
+         SEP_DRV_LOG_TRACE("Interrupt gmch read counters data %d is: 0x%llx.", i, data[i]);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*
+ * @fn        gmch_Stop_Counters()
+ *
+ * @brief     Stop the GMCH counters
+ *
+ * @param     None
+ *
+ * @return    None
+ *
+ */
+static VOID
+gmch_Stop_Counters (
+    VOID
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    // stop and reset the chipset counters
+    number_of_events = 0;
+    if (pma == NULL) {
+        SEP_DRV_LOG_ERROR("gmch_Stop_Counters: pma=NULL.");
+    }
+
+    // disable fixed and GP counters
+    gmch_PCI_Write32(GMCH_PMON_GLOBAL_CTRL+gmch_register_write, 0x00000000);
+    gmch_PCI_Write32(GMCH_PMON_FIXED_CTR_CTRL+gmch_register_write, 0x00000000);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*
+ * @fn        gmch_Fini_Chipset()
+ *
+ * @brief     Reset GMCH to state where it can be used again.  Called at cleanup phase.
+ *
+ * @param     None
+ *
+ * @return    None
+ *
+ */
+static VOID
+gmch_Fini_Chipset (
+    VOID
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (!gmch_Check_Enabled()) {
+        SEP_DRV_LOG_WARNING("GMCH is not enabled!");
+    }
+
+    gmch_current_data = CONTROL_Free_Memory(gmch_current_data);
+    gmch_to_read_data = CONTROL_Free_Memory(gmch_to_read_data);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+//
+// Initialize the GMCH chipset dispatch table
+//
+CS_DISPATCH_NODE gmch_dispatch =
+{
+    gmch_Init_Chipset,
+    gmch_Start_Counters,
+    gmch_Read_Counters,
+    gmch_Stop_Counters,
+    gmch_Fini_Chipset,
+    gmch_Trigger_Read
+};
diff --git a/drivers/misc/intel/sepdk/sep/linuxos.c b/drivers/misc/intel/sepdk/sep/linuxos.c
new file mode 100644
index 000000000000..cd6aa3a31886
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/linuxos.c
@@ -0,0 +1,1485 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+
+#include <linux/module.h>
+#include <linux/notifier.h>
+#include <linux/profile.h>
+#include <linux/sched.h>
+#include <linux/mm.h>
+#include <linux/delay.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,11,0)
+#include <linux/sched/mm.h>
+#include <linux/sched/signal.h>
+#else
+#include <linux/sched.h>
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,10,0)
+#include <linux/cpuhotplug.h>
+#endif
+#include <linux/fs.h>
+#include <linux/cpu.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,28)
+#include <trace/events/sched.h>
+#endif
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+#include "inc/lwpmudrv.h"
+#include "lwpmudrv_ioctl.h"
+#include "inc/control.h"
+#include "inc/utility.h"
+#include "inc/cpumon.h"
+#include "inc/output.h"
+#include "inc/pebs.h"
+
+#include "inc/linuxos.h"
+#include "inc/apic.h"
+
+extern DRV_BOOL       multi_pebs_enabled;
+extern uid_t          uid;
+extern volatile pid_t control_pid;
+static volatile S32   hooks_installed = 0;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,15,0)
+static struct tracepoint *tp_sched_switch = NULL;
+#endif
+
+#define  HOOK_FREE           0
+#define  HOOK_UNINSTALL     -10000
+static atomic_t hook_state = ATOMIC_INIT(HOOK_UNINSTALL);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,10,0) && defined(DRV_CPU_HOTPLUG)
+static enum cpuhp_state      cpuhp_sepdrv_state;
+#endif
+extern wait_queue_head_t     wait_exit;
+
+static PVOID local_tasklist_lock     = NULL;
+
+extern int
+LWPMUDRV_Abnormal_Terminate(void);
+
+#define MY_TASK  PROFILE_TASK_EXIT
+#define MY_UNMAP PROFILE_MUNMAP
+#ifdef CONFIG_X86_64
+#define MR_SEG_NUM        0
+#else
+#define MR_SEG_NUM        2
+#endif
+
+#if !defined(KERNEL_IMAGE_SIZE)
+#define KERNEL_IMAGE_SIZE (512 * 1024 * 1024)
+#endif
+
+#if defined(DRV_IA32)
+static U16
+linuxos_Get_Exec_Mode (
+    struct task_struct *p
+)
+{
+    return ((unsigned short) MODE_32BIT);
+}
+#endif
+
+#if defined(DRV_EM64T)
+static U16
+linuxos_Get_Exec_Mode (
+    struct task_struct *p
+)
+{
+    SEP_DRV_LOG_TRACE_IN("P: %p.", p);
+
+    if (!p) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("MODE_UNKNOWN (p is NULL!).");
+        return MODE_UNKNOWN;
+    }
+
+    if (test_tsk_thread_flag(p,TIF_IA32)) {
+        SEP_DRV_LOG_TRACE_OUT("Res: %u (test_tsk_thread_flag TIF_IA32).", (U16) (unsigned short) MODE_32BIT);
+        return ((unsigned short) MODE_32BIT);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", (U16) (unsigned short) MODE_64BIT);
+    return ((unsigned short) MODE_64BIT);
+}
+#endif
+
+static S32
+linuxos_Load_Image_Notify_Routine (
+    char           *name,
+    U64             base,
+    U32             size,
+    U64             page_offset,
+    U32             pid,
+    U32             parent_pid,
+    U32             options,
+    unsigned short  mode,
+    S32             load_event,
+    U32             segment_num,
+    U32             kernel_modules
+)
+{
+    char          *raw_path;
+    ModuleRecord  *mra;
+    char           buf[sizeof(ModuleRecord) + MAXNAMELEN + 32];
+    U64            tsc_read;
+    S32            local_load_event = (load_event==-1) ? 0 : load_event;
+    U64            page_offset_shift;
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_IN(load_event == 1, "Name: '%s', pid: %d.", name, pid);
+
+    mra = (ModuleRecord *) buf;
+    memset(mra, '\0', sizeof(buf));
+    raw_path = (char*) mra + sizeof(ModuleRecord);
+
+    page_offset_shift                              = page_offset << PAGE_SHIFT;
+    MR_page_offset_Set(mra, page_offset_shift);
+    MODULE_RECORD_segment_type(mra)                = mode;
+    MODULE_RECORD_load_addr64(mra)                 = (U64)(size_t)base;
+    MODULE_RECORD_length64(mra)                    = size;
+    MODULE_RECORD_tsc_used(mra)                    = 1;
+    MODULE_RECORD_first_module_rec_in_process(mra) = options & LOPTS_1ST_MODREC;
+    MODULE_RECORD_segment_number(mra)              = segment_num;
+    MODULE_RECORD_exe(mra)                         = (LOPTS_EXE & options) ? 1 : 0;
+    MODULE_RECORD_global_module_tb5(mra)           = (options & LOPTS_GLOBAL_MODULE) ? 1 : 0;
+    MODULE_RECORD_global_module(mra)               = (options & LOPTS_GLOBAL_MODULE) ? 1 : 0;
+    MODULE_RECORD_processed(mra)                   = 0;
+    MODULE_RECORD_parent_pid(mra)                  = parent_pid;
+    MODULE_RECORD_osid(mra)                        = OS_ID_NATIVE;
+    MODULE_RECORD_pid_rec_index(mra)               = pid;
+
+    if (kernel_modules) {
+        MODULE_RECORD_tsc(mra)                     = 0;
+        MR_unloadTscSet(mra, 0xffffffffffffffffLL);
+    }
+    else {
+        UTILITY_Read_TSC(&tsc_read);
+        preempt_disable();
+        tsc_read -= TSC_SKEW(CONTROL_THIS_CPU());
+        preempt_enable();
+
+        if (local_load_event) {
+            MR_unloadTscSet(mra, tsc_read);
+        }
+        else {
+            MR_unloadTscSet(mra, (U64)(-1));
+        }
+    }
+
+    MODULE_RECORD_pid_rec_index_raw(mra) = 1; // raw pid
+#if defined(DEBUG)
+    if (total_loads_init) {
+        SEP_DRV_LOG_NOTIFICATION_TRACE(load_event == 1, "Setting pid_rec_index_raw pid 0x%x %s.",
+                         pid, name);
+    }
+#endif
+
+    strncpy(raw_path, name, MAXNAMELEN);
+    raw_path[MAXNAMELEN]              = 0;
+    MODULE_RECORD_path_length(mra)    =  (U16) strlen(raw_path) + 1;
+    MODULE_RECORD_rec_length(mra)     =  (U16) ALIGN_8(sizeof (ModuleRecord) +
+                                                       MODULE_RECORD_path_length(mra));
+
+#if defined(DRV_IA32)
+    MODULE_RECORD_selector(mra)       = (pid==0) ? __KERNEL_CS : __USER_CS;
+#endif
+#if defined(DRV_EM64T)
+    if (mode == MODE_64BIT) {
+        MODULE_RECORD_selector(mra)   = (pid==0) ? __KERNEL_CS : __USER_CS;
+    }
+    else if (mode == MODE_32BIT) {
+        MODULE_RECORD_selector(mra)   = (pid==0) ? __KERNEL32_CS : __USER32_CS;
+    }
+#endif
+
+    OUTPUT_Module_Fill((PVOID)mra, MODULE_RECORD_rec_length(mra), load_event == 1);
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_OUT(load_event == 1, "OS_SUCCESS");
+    return OS_SUCCESS;
+}
+
+#ifdef DRV_MM_EXE_FILE_PRESENT
+static DRV_BOOL
+linuxos_Equal_VM_Exe_File (
+    struct vm_area_struct *vma
+)
+{
+    S8        name_vm_file[MAXNAMELEN];
+    S8        name_exe_file[MAXNAMELEN];
+    S8       *pname_vm_file = NULL;
+    S8       *pname_exe_file = NULL;
+    DRV_BOOL  res;
+
+    SEP_DRV_LOG_TRACE_IN("FMA: %p.", vma);
+
+    if (vma == NULL) {
+        SEP_DRV_LOG_TRACE_OUT("FALSE (!vma).");
+        return FALSE;
+    }
+
+    if (vma->vm_file == NULL) {
+        SEP_DRV_LOG_TRACE_OUT("FALSE (!vma->vm_file).");
+        return FALSE;
+    }
+
+    if (vma->vm_mm->exe_file == NULL) {
+        SEP_DRV_LOG_TRACE_OUT("FALSE (!vma->vm_mm->exe_file).");
+        return FALSE;
+    }
+
+    pname_vm_file = D_PATH(vma->vm_file, name_vm_file, MAXNAMELEN);
+    pname_exe_file = D_PATH(vma->vm_mm->exe_file, name_exe_file, MAXNAMELEN);
+    res = strcmp (pname_vm_file, pname_exe_file) == 0;
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", res);
+    return res;
+}
+#endif
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          linuxos_Map_Kernel_Modules (void)
+ *
+ * @brief       Obtain kernel module details from modules list
+ *              and map the details to the module record.
+ *
+ * @return      S32       VT_SUCCESS on success
+ */
+static S32 linuxos_Map_Kernel_Modules (void)
+{
+    struct module     *current_module;
+    struct list_head  *modules;
+    U16                exec_mode = MODE_UNKNOWN;
+    unsigned long long addr;
+    unsigned long long size;
+#if defined(CONFIG_RANDOMIZE_BASE)
+    unsigned long      dyn_addr = 0;
+#endif
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    mutex_lock(&module_mutex);
+
+#if defined(DRV_EM64T)
+    addr      = (unsigned long) __START_KERNEL_map;
+    exec_mode = MODE_64BIT;
+#elif defined(DRV_IA32)
+    addr      = (unsigned long) PAGE_OFFSET;
+    exec_mode = MODE_32BIT;
+#endif
+
+    SEP_DRV_LOG_TRACE("     kernel module            address           size");
+    SEP_DRV_LOG_TRACE("  -------------------    ------------------    -------");
+
+    addr += (CONFIG_PHYSICAL_START + (CONFIG_PHYSICAL_ALIGN - 1)) & ~(CONFIG_PHYSICAL_ALIGN - 1);
+    size = (unsigned long) KERNEL_IMAGE_SIZE -
+           ((CONFIG_PHYSICAL_START + (CONFIG_PHYSICAL_ALIGN - 1)) & ~(CONFIG_PHYSICAL_ALIGN - 1)) - 1;
+
+#if defined(CONFIG_RANDOMIZE_BASE)
+    if (!dyn_addr) {
+        dyn_addr = (unsigned long)UTILITY_Find_Symbol("_text");
+	if (!dyn_addr) {
+            dyn_addr = (unsigned long)UTILITY_Find_Symbol("_stext");
+        }
+
+	if (dyn_addr && dyn_addr > addr) {
+            dyn_addr &= ~(PAGE_SIZE - 1);
+            size -= (dyn_addr - addr);
+            addr = dyn_addr;
+        } else {
+            SEP_DRV_LOG_WARNING_TRACE_OUT("Could not find the kernel start address!");
+        }
+    }
+#endif
+
+    linuxos_Load_Image_Notify_Routine("vmlinux",
+                                      addr,
+                                      size,
+                                      0,
+                                      0,
+                                      0,
+                                      LOPTS_1ST_MODREC | LOPTS_GLOBAL_MODULE | LOPTS_EXE,
+                                      exec_mode,
+                                      -1,
+                                      MR_SEG_NUM,
+                                      1);
+    SEP_DRV_LOG_TRACE("kmodule: %20s    0x%llx    0x%llx.", "vmlinux", addr, size);
+
+    for (modules = THIS_MODULE->list.prev; (unsigned long) modules > MODULES_VADDR;
+         modules = modules->prev);
+    list_for_each_entry(current_module, modules, list) {
+        char *name   = current_module->name;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,5,0) || defined(SEP_CONFIG_MODULE_LAYOUT)
+        addr = (unsigned long) current_module->core_layout.base;
+        size = current_module->core_layout.size;
+#else
+        addr = (unsigned long) current_module->module_core;
+        size = current_module->core_size;
+#endif
+
+        if (module_is_live(current_module)) {
+            SEP_DRV_LOG_TRACE("kmodule: %20s    0x%llx    0x%llx.", name, addr, size);
+            linuxos_Load_Image_Notify_Routine(name,
+                                              addr,
+                                              size,
+                                              0,
+                                              0,
+                                              0,
+                                              LOPTS_GLOBAL_MODULE,
+                                              exec_mode,
+                                              -1,
+                                              0,
+                                              1);
+        }
+    }
+
+    mutex_unlock(&module_mutex);
+
+    SEP_DRV_LOG_TRACE_OUT("OS_SUCCESS");
+    return OS_SUCCESS;
+}
+
+//
+// Register the module for a process.  The task_struct and mm
+// should be locked if necessary to make sure they don't change while we're
+// iterating...
+// Used as a service routine
+//
+static S32
+linuxos_VMA_For_Process (
+    struct task_struct    *p,
+    struct vm_area_struct *vma,
+    S32                    load_event,
+    U32                   *first
+)
+{
+    U32  options = 0;
+    S8   name[MAXNAMELEN];
+    S8  *pname = NULL;
+    U32  ppid  = 0;
+    U16  exec_mode;
+    U64 page_offset = 0;
+
+#if defined(DRV_ANDROID)
+    char andr_app[TASK_COMM_LEN];
+#endif
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_IN(load_event == 1, "P = %p, vma = %p, load_event: %d, first: %p.", p, vma, load_event, first);
+
+    if (p == NULL) {
+        SEP_DRV_LOG_NOTIFICATION_ERROR(load_event == 1, "Skipped p=NULL.");
+        SEP_DRV_LOG_NOTIFICATION_TRACE_OUT(load_event == 1, "OS_SUCCESS (!p).");
+        return OS_SUCCESS;
+    }
+
+    if (vma->vm_file) pname = D_PATH(vma->vm_file, name, MAXNAMELEN);
+
+    page_offset = vma->vm_pgoff;
+
+    if (!IS_ERR(pname) && pname != NULL) {
+        SEP_DRV_LOG_NOTIFICATION_TRACE(load_event == 1, "enum: %s, %d, %lx, %lx %llu.",
+                         pname, p->pid, vma->vm_start, (vma->vm_end - vma->vm_start), page_offset);
+
+        // if the VM_EXECUTABLE flag is set then this is the module
+        // that is being used to name the module
+        if (DRV_VM_MOD_EXECUTABLE(vma)) {
+            options |= LOPTS_EXE;
+#if defined(DRV_ANDROID)
+            if(!strcmp(pname, "/system/bin/app_process") ||
+               !strcmp(pname, "/system/bin/app_process32") ||
+               !strcmp(pname, "/system/bin/app_process64")) {
+                memset(andr_app, '\0', TASK_COMM_LEN);
+                strncpy(andr_app, p->comm, TASK_COMM_LEN);
+                pname = andr_app;
+            }
+#endif
+        }
+        // mark the first of the bunch...
+        if (*first == 1) {
+            options |= LOPTS_1ST_MODREC;
+            *first = 0;
+        }
+    }
+#if defined(DRV_ALLOW_VDSO)
+    else if (vma->vm_mm &&
+             vma->vm_start == (long)vma->vm_mm->context.vdso) {
+        pname = "[vdso]";
+    }
+#endif
+#if defined(DRV_ALLOW_SYSCALL)
+    else if (vma->vm_start == VSYSCALL_START) {
+        pname = "[vsyscall]";
+    }
+#endif
+
+    if (pname != NULL) {
+        options = 0;
+        if (DRV_VM_MOD_EXECUTABLE(vma)) {
+            options |= LOPTS_EXE;
+        }
+
+        if (p && p->parent) {
+            ppid = p->parent->tgid;
+        }
+        exec_mode = linuxos_Get_Exec_Mode(p);
+        // record this module
+        linuxos_Load_Image_Notify_Routine(pname,
+                                          vma->vm_start,
+                                          (vma->vm_end - vma->vm_start),
+                                          page_offset,
+                                          p->pid,
+                                          ppid,
+                                          options,
+                                          exec_mode,
+                                          load_event,
+                                          1,
+                                          0);
+    }
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_OUT(load_event == 1, "OS_SUCCESS.");
+    return OS_SUCCESS;
+}
+
+//
+// Common loop to enumerate all modules for a process.  The task_struct and mm
+// should be locked if necessary to make sure they don't change while we're
+// iterating...
+//
+static S32
+linuxos_Enum_Modules_For_Process (
+    struct task_struct *p,
+    struct mm_struct   *mm,
+    S32                 load_event
+)
+{
+    struct vm_area_struct *mmap;
+    U32                    first = 1;
+
+#if defined(SECURE_SEP)
+    uid_t                  l_uid;
+#endif
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_IN(load_event == 1, "P: %p, mm: %p, load_event: %d.", p, mm, load_event);
+
+#if defined(SECURE_SEP)
+    l_uid = DRV_GET_UID(p);
+    /*
+     * Check for:  same uid, or root uid
+     */
+    if (l_uid != uid && l_uid != 0) {
+        SEP_DRV_LOG_NOTIFICATION_TRACE_OUT(load_event == 1, "OS_SUCCESS (secure_sep && l_uid != uid && l_uid != 0).");
+        return OS_SUCCESS;
+    }
+#endif
+    for (mmap = mm->mmap; mmap; mmap = mmap->vm_next) {
+        /* We have 3 distinct conditions here.
+         * 1) Is the page executable?
+         * 2) Is is a part of the vdso area?
+         * 3) Is it the vsyscall area?
+         */
+        if (((mmap->vm_flags & VM_EXEC) &&
+              mmap->vm_file             &&
+              mmap->vm_file->DRV_F_DENTRY)
+#if defined(DRV_ALLOW_VDSO)
+             ||
+             (mmap->vm_mm          &&
+              mmap->vm_start == (long)mmap->vm_mm->context.vdso)
+#endif
+#if defined(DRV_ALLOW_VSYSCALL)
+             ||
+             (mmap->vm_start == VSYSCALL_START)
+#endif
+             ) {
+
+            linuxos_VMA_For_Process(p,
+                                    mmap,
+                                    load_event,
+                                    &first);
+        }
+    }
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_OUT(load_event == 1, "OS_SUCCESS");
+    return OS_SUCCESS;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          static int linuxos_Exec_Unmap_Notify(
+ *                  struct notifier_block  *self,
+ *                  unsigned long           val,
+ *                  VOID                   *data)
+ *
+ * @brief       this function is called whenever a task exits
+ *
+ * @param       self IN  - not used
+ *              val  IN  - not used
+ *              data IN  - this is cast in the mm_struct of the task that is call unmap
+ *
+ * @return      none
+ *
+ * <I>Special Notes:</I>
+ *
+ * This notification is called from do_munmap(mm/mmap.c). This is called when ever
+ * a module is loaded or unloaded. It looks like it is called right after a module is
+ * loaded or before its unloaded (if using dlopen,dlclose).
+ * However it is not called when a process is exiting instead exit_mmap is called
+ * (resulting in an EXIT_MMAP notification).
+ */
+static int
+linuxos_Exec_Unmap_Notify (
+    struct notifier_block *self,
+    unsigned long          val,
+    PVOID                  data
+)
+{
+    struct mm_struct      *mm;
+    struct vm_area_struct *mmap  = NULL;
+    U32                    first = 1;
+    U32                    cur_driver_state;
+
+#if defined(SECURE_SEP)
+    uid_t                  l_uid;
+#endif
+
+    SEP_DRV_LOG_NOTIFICATION_IN("Self: %p, val: %lu, data: %p.", self, val, data);
+    SEP_DRV_LOG_NOTIFICATION_TRACE(SEP_IN_NOTIFICATION, "enter: unmap: hook_state %d.", atomic_read(&hook_state));
+
+    cur_driver_state = GET_DRIVER_STATE();
+
+#if defined(SECURE_SEP)
+    l_uid = DRV_GET_UID(current);
+    /*
+     * Check for:  same uid, or root uid
+     */
+    if (l_uid != uid && l_uid != 0) {
+        SEP_DRV_LOG_NOTIFICATION_OUT("Returns 0 (secure_sep && l_uid != uid && l_uid != 0).");
+        return 0;
+    }
+#endif
+
+    if (!IS_COLLECTING_STATE(cur_driver_state)) {
+        SEP_DRV_LOG_NOTIFICATION_OUT("Early exit (driver state).");
+        return 0;
+    }
+    if (!atomic_add_negative(1, &hook_state)) {
+        SEP_DRV_LOG_NOTIFICATION_TRACE(SEP_IN_NOTIFICATION, "unmap: hook_state %d.", atomic_read(&hook_state));
+        mm = get_task_mm(current);
+        if (mm) {
+            UTILITY_down_read_mm(mm);
+            mmap = FIND_VMA (mm, data);
+            if (mmap               &&
+                mmap->vm_file      &&
+                (mmap->vm_flags & VM_EXEC)) {
+
+                linuxos_VMA_For_Process(current, mmap, TRUE, &first);
+            }
+            UTILITY_up_read_mm(mm);
+            mmput(mm);
+        }
+    }
+    atomic_dec(&hook_state);
+    SEP_DRV_LOG_NOTIFICATION_TRACE(SEP_IN_NOTIFICATION, "exit: unmap done: hook_state %d.", atomic_read(&hook_state));
+
+    SEP_DRV_LOG_NOTIFICATION_OUT("Returns 0.");
+    return 0;
+}
+
+#if defined(DRV_CPU_HOTPLUG)
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       VOID linuxos_Handle_Online_cpu(
+ *               PVOID param)
+ *
+ * @param    PVOID param
+ *
+ * @return   None
+ *
+ * @brief    Callback function to set the cpu online
+ * @brief    and begin collection on it
+ */
+static VOID
+linuxos_Handle_Online_cpu(PVOID param)
+{
+    U32          this_cpu;
+    U32          dev_idx;
+    DISPATCH     dispatch;
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_IN(SEP_IN_NOTIFICATION, "Dummy param: %p.", param);
+
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    dispatch = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    preempt_enable();
+    CPUMON_Online_Cpu((PVOID)&this_cpu);
+    if (CPU_STATE_pmu_state(&pcb[this_cpu]) == NULL) {
+        if (dispatch && dispatch->init) {
+            dispatch->init(NULL);
+        }
+    }
+    if (dispatch && dispatch->write) {
+        dispatch->write(NULL);
+    }
+    CPU_STATE_group_swap(&pcb[this_cpu]) = 1;
+    if (GET_DRIVER_STATE() == DRV_STATE_RUNNING) { // possible race conditions with notifications. cleanup should wait until all notifications are done, and new notifications should not proceed
+        if (dispatch && dispatch->restart) {
+            dispatch->restart(NULL);
+        }
+    }
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_OUT(SEP_IN_NOTIFICATION, "");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       VOID linuxos_Handle_Offline_cpu(
+ *               PVOID param)
+ *
+ * @param    PVOID param
+ *
+ * @return   None
+ *
+ * @brief    Callback function to set the cpu offline
+ * @brief    and stop collection on it
+ */
+static VOID
+linuxos_Handle_Offline_cpu(PVOID param)
+{
+    U32 this_cpu;
+    U32 apic_lvterr;
+    U32 dev_idx;
+    DISPATCH dispatch;
+    SEP_DRV_LOG_NOTIFICATION_TRACE_IN(SEP_IN_NOTIFICATION, "Dummy param: %p.", param);
+
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    dispatch = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    preempt_enable();
+    CPUMON_Offline_Cpu((PVOID)&this_cpu);
+    if (dispatch && dispatch->freeze) {
+        dispatch->freeze(NULL);
+    }
+    apic_lvterr = apic_read(APIC_LVTERR);
+    apic_write(APIC_LVTERR, apic_lvterr | APIC_LVT_MASKED);
+    APIC_Restore_LVTPC(NULL);
+    apic_write(APIC_LVTERR, apic_lvterr);
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_OUT(SEP_IN_NOTIFICATION, "");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       int linuxos_online_cpu(
+ *               unsigned int cpu)
+ *
+ * @param    unsigned int cpu
+ *
+ * @return   None
+ *
+ * @brief    Invokes appropriate call back function when CPU is online
+ */
+int linuxos_online_cpu(unsigned int cpu) {
+    SEP_DRV_LOG_NOTIFICATION_IN("Cpu %d coming online.", cpu);
+
+    if (CPUMON_is_Online_Allowed()) {
+        CONTROL_Invoke_Cpu(cpu, linuxos_Handle_Online_cpu, NULL);
+        SEP_DRV_LOG_NOTIFICATION_OUT("Cpu %d came online.", cpu);
+        return 0;
+    }
+    else {
+        SEP_DRV_LOG_WARNING_NOTIFICATION_OUT("Cpu %d is not allowed to come online!", cpu);
+        return 0;
+    }
+}
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       int linuxos_offline_cpu(
+ *               unsigned int cpu)
+ *
+ * @param    unsigned int cpu
+ *
+ * @return   None
+ *
+ * @brief    Invokes appropriate call back function when CPU is offline
+ */
+int linuxos_offline_cpu(unsigned int cpu) {
+    SEP_DRV_LOG_NOTIFICATION_IN("Cpu %d going offline.", cpu);
+
+    if (CPUMON_is_Offline_Allowed()) {
+        CONTROL_Invoke_Cpu(cpu, linuxos_Handle_Offline_cpu, NULL);
+        SEP_DRV_LOG_NOTIFICATION_OUT("Cpu %d went offline.", cpu);
+        return 0;
+    }
+    else {
+        SEP_DRV_LOG_WARNING_NOTIFICATION_OUT("Cpu %d is not allowed to go offline!", cpu);
+        return 0;
+    }
+}
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4,10,0)
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       OS_STATUS linuxos_Hotplug_Notifier(
+ *               struct notifier_block *block, unsigned long action, void *pcpu)
+ *
+ * @param    struct notifier_block *block - notifier block
+ *           unsigned long action - notifier action
+ *           void *pcpu - per cpu pcb
+ *
+ * @return   NOTIFY_OK, if successful
+ *
+ * @brief    Hotplug Notifier function that handles various cpu states
+ * @brief    and invokes respective callback functions
+ */
+static OS_STATUS
+linuxos_Hotplug_Notifier(
+    struct        notifier_block *block,
+    unsigned long action,
+    void          *pcpu
+)
+{
+    U32 cpu = (unsigned int)(unsigned long)pcpu;
+
+    SEP_DRV_LOG_NOTIFICATION_IN("Cpu: %u, action: %u.", cpu, action);  // nb: will overcount number of pending notifications
+                                                                // when using this routine
+
+    switch (action & ~CPU_TASKS_FROZEN) {
+        case CPU_DOWN_FAILED:
+            SEP_DRV_LOG_ERROR("SEP cpu %d offline failed!", cpu);
+        case CPU_ONLINE:
+            linuxos_online_cpu(cpu);
+            break;
+        case CPU_DOWN_PREPARE:
+            linuxos_offline_cpu(cpu);
+            break;
+        default:
+            SEP_DRV_LOG_WARNING("DEFAULT: cpu %d unhandled action value is %d.", cpu, action);
+            break;
+    }
+
+    SEP_DRV_LOG_NOTIFICATION_OUT("");
+    return NOTIFY_OK;
+}
+
+static struct notifier_block cpu_hotplug_notifier = {
+    .notifier_call = &linuxos_Hotplug_Notifier,
+};
+#endif
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       VOID LINUXOS_Register_Hotplug(
+ *               VOID)
+ *
+ * @param    None
+ *
+ * @return   None
+ *
+ * @brief    Registers the Hotplug Notifier
+ */
+extern VOID
+LINUXOS_Register_Hotplug( VOID )
+{
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,10,0)
+    S32    err;
+
+    SEP_DRV_LOG_INIT_IN("Kernel version >= 4.10.0: using direct notifications.");
+
+    err = cpuhp_setup_state_nocalls(CPUHP_AP_ONLINE_DYN, "ia64/sep5:online",
+                                linuxos_online_cpu, linuxos_offline_cpu);
+    cpuhp_sepdrv_state = err;
+#else
+    SEP_DRV_LOG_INIT_IN("Kernel version < 4.10.0: using notification hub.");
+    register_cpu_notifier(&cpu_hotplug_notifier);
+#endif
+    SEP_DRV_LOG_INIT_OUT("Hotplug notifier registered.");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       VOID LINUXOS_Unregister_Hotplug(
+ *               VOID)
+ *
+ * @param    None
+ *
+ * @return   None
+ *
+ * @brief    Unregisters the Hotplug Notifier
+ */
+extern VOID
+LINUXOS_Unregister_Hotplug( VOID )
+{
+    SEP_DRV_LOG_INIT_IN("Unregistering hotplug notifier.");
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,10,0)
+    cpuhp_remove_state_nocalls(cpuhp_sepdrv_state);
+#else
+    unregister_cpu_notifier(&cpu_hotplug_notifier);
+#endif
+    SEP_DRV_LOG_INIT_OUT("Hotplug notifier unregistered.");
+}
+#endif
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          OS_STATUS LINUXOS_Enum_Process_Modules(DRV_BOOL at_end)
+ *
+ * @brief       gather all the process modules that are present.
+ *
+ * @param       at_end - the collection happens at the end of the sampling run
+ *
+ * @return      OS_SUCCESS
+ *
+ * <I>Special Notes:</I>
+ *              This routine gathers all the process modules that are present
+ *              in the system at this time.  If at_end is set to be TRUE, then
+ *              act as if all the modules are being unloaded.
+ *
+ */
+extern OS_STATUS
+LINUXOS_Enum_Process_Modules (
+    DRV_BOOL  at_end
+)
+{
+    int                 n = 0;
+    struct task_struct *p;
+
+    SEP_DRV_LOG_TRACE_IN("At_end: %u.", at_end);
+    SEP_DRV_LOG_TRACE("Begin tasks.");
+
+    if (GET_DRIVER_STATE() == DRV_STATE_TERMINATING) {
+        SEP_DRV_LOG_TRACE_OUT("OS_SUCCESS (TERMINATING).");
+        return OS_SUCCESS;
+    }
+
+    if (!local_tasklist_lock) {
+        local_tasklist_lock = (PVOID)(UIOP)UTILITY_Find_Symbol("tasklist_lock");
+        if (!local_tasklist_lock) {
+            SEP_DRV_LOG_WARNING("Could not find tasklist_lock.");
+        }
+    }
+
+    // In some machines the tasklist_lock symbol does not exist.
+    // For temporary solution we skip the lock if there is no tasklist_lock
+    if (local_tasklist_lock) {
+#if defined(DEFINE_QRWLOCK)         // assuming that if DEFINE_QRWLOCK is defined, then tasklist_lock was defined using it
+        qread_lock(local_tasklist_lock);
+#else
+        read_lock(local_tasklist_lock);
+#endif
+    }
+
+    FOR_EACH_TASK(p) {
+        struct mm_struct *mm;
+
+        SEP_DRV_LOG_TRACE("Looking at task %d.", n);
+        /*
+         *  Call driver notification routine for each module
+         *  that is mapped into the process created by the fork
+         */
+
+        if (p == NULL) {
+            SEP_DRV_LOG_TRACE("Skipped (p=NULL).");
+            continue;
+        }
+
+        p->comm[TASK_COMM_LEN - 1] = 0; // making sure there is a trailing 0
+        mm = get_task_mm(p);
+
+        if (!mm) {
+            SEP_DRV_LOG_TRACE("Skipped (p->mm=NULL). P=0x%p, pid=%d, p->comm=%s.", p, p->pid, p->comm);
+            linuxos_Load_Image_Notify_Routine(p->comm,
+                                              0,
+                                              0,
+                                              0,
+                                              p->pid,
+                                              (p->parent) ? p->parent->tgid : 0,
+                                              LOPTS_EXE | LOPTS_1ST_MODREC,
+                                              linuxos_Get_Exec_Mode(p),
+                                              2, // '2' to trigger 'if (load_event)' conditions, but still be distinguishable from actual load events
+                                              1,
+                                              0);
+            continue;
+        }
+
+        UTILITY_down_read_mm(mm);
+        linuxos_Enum_Modules_For_Process(p, mm, at_end?-1:0);
+        UTILITY_up_read_mm(mm);
+        mmput(mm);
+        n++;
+    }
+
+    if (local_tasklist_lock) {
+#if defined(DEFINE_QRWLOCK)
+        qread_unlock(local_tasklist_lock);
+#else
+        read_unlock(local_tasklist_lock);
+#endif
+    }
+
+    SEP_DRV_LOG_TRACE("Enum_Process_Modules done with %d tasks.", n);
+
+    SEP_DRV_LOG_TRACE_OUT("OS_SUCCESS.");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          static int linuxos_Exit_Task_Notify(struct notifier_block * self,
+ *                  unsigned long val, PVOID data)
+ * @brief       this function is called whenever a task exits
+ *
+ * @param       self IN  - not used
+ *              val IN  - not used
+ *              data IN  - this is cast into the task_struct of the exiting task
+ *
+ * @return      none
+ *
+ * <I>Special Notes:</I>
+ * this function is called whenever a task exits.  It is called right before
+ * the virtual memory areas are freed.  We just enumerate through all the modules
+ * of the task and set the unload sample count and the load event flag to 1 to
+ * indicate this is a module unload
+ */
+static int
+linuxos_Exit_Task_Notify (
+    struct notifier_block *self,
+    unsigned long          val,
+    PVOID                  data
+)
+{
+    struct task_struct *p      = (struct task_struct *)data;
+    int                 status = OS_SUCCESS;
+    U32                 cur_driver_state;
+    struct mm_struct   *mm;
+
+    SEP_DRV_LOG_NOTIFICATION_IN("Self: %p, val: %lu, data: %p.", self, val, data);
+
+    cur_driver_state = GET_DRIVER_STATE();
+
+    if (cur_driver_state == DRV_STATE_UNINITIALIZED || cur_driver_state == DRV_STATE_TERMINATING) {
+        SEP_DRV_LOG_NOTIFICATION_OUT("Early exit (driver state).");
+        return status;
+    }
+    SEP_DRV_LOG_TRACE("Pid = %d tgid = %d.", p->pid, p->tgid);
+    if (p->pid == control_pid) {
+        SEP_DRV_LOG_NOTIFICATION_TRACE(SEP_IN_NOTIFICATION, "The collector task has been terminated via an uncatchable signal.");
+        SEP_DRV_LOG_NOTIFICATION_WARNING(SEP_IN_NOTIFICATION, "Sep was killed!");
+        CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+        wake_up_interruptible(&wait_exit);
+
+        SEP_DRV_LOG_NOTIFICATION_OUT("Res = %u (pid == control_pid).", status);
+        return status;
+    }
+
+    if (cur_driver_state != DRV_STATE_IDLE && !IS_COLLECTING_STATE(cur_driver_state)) {
+        SEP_DRV_LOG_NOTIFICATION_OUT("Res = %u (stopping collection).", status);
+        return status;
+    }
+
+    mm = get_task_mm(p);
+    if (!mm) {
+        SEP_DRV_LOG_NOTIFICATION_OUT("Res = %u (!p->mm).", status);
+        return status;
+    }
+    UTILITY_down_read_mm(mm);
+    if (GET_DRIVER_STATE() != DRV_STATE_TERMINATING) {
+        if (!atomic_add_negative(1, &hook_state)) {
+            linuxos_Enum_Modules_For_Process(p, mm, 1);
+        }
+        atomic_dec(&hook_state);
+    }
+    UTILITY_up_read_mm(mm);
+    mmput(mm);
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE(SEP_IN_NOTIFICATION, "Hook_state %d.", atomic_read(&hook_state));
+
+    SEP_DRV_LOG_NOTIFICATION_OUT("Res = %u.", status);
+    return status;
+}
+
+
+/*
+ *  The notifier block.  All the static entries have been defined at this point
+ */
+static struct notifier_block linuxos_exec_unmap_nb = {
+    .notifier_call = linuxos_Exec_Unmap_Notify,
+};
+
+static struct notifier_block linuxos_exit_task_nb = {
+    .notifier_call = linuxos_Exit_Task_Notify,
+};
+
+#if defined(CONFIG_TRACEPOINTS)
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          void capture_sched_switch(VOID *)
+ * @brief       capture current pid/tid on all cpus
+ *
+ * @param       p IN - not used
+ *
+ * @return      none
+ *
+ * <I>Special Notes:</I>
+ *
+ * None
+ */
+static void
+capture_sched_switch(void * p)
+{
+    U32                 this_cpu;
+    BUFFER_DESC         bd;
+    SIDEBAND_INFO       sideband_info;
+    U64                 tsc;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    UTILITY_Read_TSC(&tsc);
+
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    preempt_enable();
+
+    bd = &cpu_sideband_buf[this_cpu];
+    if (bd == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Bd is NULL!");
+        return;
+    }
+
+    sideband_info = (SIDEBAND_INFO)OUTPUT_Reserve_Buffer_Space(bd, sizeof(SIDEBAND_INFO_NODE), FALSE, !SEP_IN_NOTIFICATION);
+    if (sideband_info == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Sideband_info is NULL!");
+        return;
+    }
+
+    SIDEBAND_INFO_pid(sideband_info)      = current->tgid;
+    SIDEBAND_INFO_tid(sideband_info)      = current->pid;
+    SIDEBAND_INFO_tsc(sideband_info)      = tsc;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,28)
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          void record_pebs_process_info(...)
+ * @brief       record all sched switch pid/tid info
+ *
+ * @param       ignore IN - not used
+ *              from   IN
+ *              to     IN
+ *
+ * @return      none
+ *
+ * <I>Special Notes:</I>
+ *
+ * None
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+static void
+record_pebs_process_info(void *ignore, bool preempt, struct task_struct *from, struct task_struct *to)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,35)
+static void
+record_pebs_process_info(void *ignore, struct task_struct *from, struct task_struct *to)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,28)
+static void
+record_pebs_process_info(struct rq *ignore, struct task_struct *from, struct task_struct *to)
+#endif
+{
+    U32                 this_cpu;
+    BUFFER_DESC         bd;
+    SIDEBAND_INFO       sideband_info;
+    U64                 tsc;
+    U32                 cur_driver_state;
+
+    SEP_DRV_LOG_NOTIFICATION_IN("From: %p, to: %p.", from, to);
+
+    cur_driver_state = GET_DRIVER_STATE();
+
+    if (cur_driver_state != DRV_STATE_IDLE && !IS_COLLECTING_STATE(cur_driver_state)) {
+        SEP_DRV_LOG_NOTIFICATION_OUT("Early exit (driver state).");
+        return;
+    }
+
+    UTILITY_Read_TSC(&tsc);
+
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    preempt_enable();
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE(SEP_IN_NOTIFICATION, "[OUT<%d:%d:%s>-IN<%d:%d:%s>].",
+                     from->tgid, from->pid, from->comm, to->tgid, to->pid, to->comm);
+
+    bd = &cpu_sideband_buf[this_cpu];
+    if (bd == NULL) {
+        SEP_DRV_LOG_NOTIFICATION_OUT("Early exit (!bd).");
+        return;
+    }
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)) && (LINUX_VERSION_CODE < KERNEL_VERSION(4,14,0))
+    sideband_info = (SIDEBAND_INFO)OUTPUT_Reserve_Buffer_Space(bd, sizeof(SIDEBAND_INFO_NODE), TRUE, SEP_IN_NOTIFICATION);
+#else
+    sideband_info = (SIDEBAND_INFO)OUTPUT_Reserve_Buffer_Space(bd, sizeof(SIDEBAND_INFO_NODE), FALSE, SEP_IN_NOTIFICATION);
+#endif
+
+    if (sideband_info == NULL) {
+        SEP_DRV_LOG_NOTIFICATION_OUT("Early exit (!sideband_info).");
+        return;
+    }
+
+    SIDEBAND_INFO_pid(sideband_info)      = to->tgid;
+    SIDEBAND_INFO_tid(sideband_info)      = to->pid;
+    SIDEBAND_INFO_tsc(sideband_info)      = tsc;
+
+    SEP_DRV_LOG_NOTIFICATION_OUT("");
+}
+#endif
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,15,0)
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          void find_sched_switch_tracepoint
+ * @brief       find trace poing for sched_switch
+ *
+ * @param       tp    pass in by system
+ *              param pointer of trace point
+ *
+ * @return      none
+ *
+ * <I>Special Notes:</I>
+ *
+ * None
+ */
+static void
+find_sched_switch_tracepoint
+(
+    struct tracepoint *tp,
+    VOID * param
+)
+{
+    struct tracepoint ** ptp = (struct tracepoint **)param;
+
+    SEP_DRV_LOG_TRACE_IN("Tp: %p, param: %p.", tp, param);
+
+    if (tp && ptp) {
+        SEP_DRV_LOG_TRACE("trace point name: %s.", tp->name);
+        if (!strcmp(tp->name, "sched_switch")) {
+            SEP_DRV_LOG_TRACE("Found trace point for sched_switch.");
+            *ptp = tp;
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+#endif
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          int install_sched_switch_callback(VOID)
+ * @brief       registers sched_switch callbacks for PEBS sideband
+ *
+ * @param       none
+ *
+ * @return      0 success else error number
+ *
+ * <I>Special Notes:</I>
+ *
+ * None
+ */
+static int
+install_sched_switch_callback(
+    VOID
+)
+{
+    int err = 0;
+
+    SEP_DRV_LOG_TRACE_IN("");
+    SEP_DRV_LOG_INIT("Installing PEBS linux OS Hooks.");
+
+#if defined(CONFIG_TRACEPOINTS)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,15,0)
+    if (!tp_sched_switch) {
+        for_each_kernel_tracepoint(&find_sched_switch_tracepoint, &tp_sched_switch);
+    }
+    if (!tp_sched_switch) {
+        err = -EIO;
+        SEP_DRV_LOG_INIT("Please check Linux is built w/ CONFIG_CONTEXT_SWITCH_TRACER.");
+    }
+    else {
+        err = tracepoint_probe_register(tp_sched_switch, (void *)record_pebs_process_info, NULL);
+    }
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,35)
+    err = register_trace_sched_switch(record_pebs_process_info, NULL);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,28)
+    err = register_trace_sched_switch(record_pebs_process_info);
+#else
+    SEP_DRV_LOG_INIT("Please use Linux kernel version >= 2.6.28 to use multiple pebs.");
+    err = -1;
+#endif
+    CONTROL_Invoke_Parallel(capture_sched_switch, NULL);
+#endif
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %d.", err);
+    return err;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID LINUXOS_Install_Hooks(VOID)
+ * @brief       registers the profiling callbacks
+ *
+ * @param       none
+ *
+ * @return      none
+ *
+ * <I>Special Notes:</I>
+ *
+ * None
+ */
+extern VOID
+LINUXOS_Install_Hooks (
+    VOID
+)
+{
+    int err = 0;
+    int err2 = 0;
+
+    SEP_DRV_LOG_INIT_IN("Installing Linux OS Hooks.");
+
+    if (hooks_installed == 1) {
+        SEP_DRV_LOG_INIT_OUT("The OS Hooks are already installed.");
+        return;
+    }
+
+    linuxos_Map_Kernel_Modules();
+
+    err = profile_event_register(MY_UNMAP, &linuxos_exec_unmap_nb);
+    err2= profile_event_register(MY_TASK,  &linuxos_exit_task_nb);
+    if (err || err2) {
+        if (err == OS_NO_SYSCALL) {
+            SEP_DRV_LOG_WARNING("This kernel does not implement kernel profiling hooks...");
+            SEP_DRV_LOG_WARNING("...task termination and image unloads will not be tracked...");
+            SEP_DRV_LOG_WARNING("...during sampling session!");
+        }
+    }
+
+    if (multi_pebs_enabled) {
+        err = install_sched_switch_callback();
+        if (err) {
+            SEP_DRV_LOG_WARNING("Failed to install sched_switch callback for multiple pebs.");
+        }
+    }
+
+    hooks_installed = 1;
+    atomic_set(&hook_state, HOOK_FREE);
+
+    SEP_DRV_LOG_INIT_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          int uninstall_sched_switch_callback(VOID)
+ * @brief       unregisters sched_switch callbacks for PEBS sideband
+ *
+ * @param       none
+ *
+ * @return      0 success else error number
+ *
+ * <I>Special Notes:</I>
+ *
+ * None
+ */
+static int
+uninstall_sched_switch_callback(
+    VOID
+)
+{
+    int err = 0;
+
+    SEP_DRV_LOG_TRACE_IN("");
+    SEP_DRV_LOG_INIT("Uninstalling PEBS Linux OS Hooks.");
+
+#if defined(CONFIG_TRACEPOINTS)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,15,0)
+    if (!tp_sched_switch) {
+        err = -EIO;
+        SEP_DRV_LOG_INIT("Please check Linux is built w/ CONFIG_CONTEXT_SWITCH_TRACER.");
+    }
+    else {
+        err = tracepoint_probe_unregister(tp_sched_switch, (void *)record_pebs_process_info, NULL);
+    }
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,35)
+    err = unregister_trace_sched_switch(record_pebs_process_info, NULL);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,28)
+    err = unregister_trace_sched_switch(record_pebs_process_info);
+#else
+    SEP_DRV_LOG_INIT("Please use Linux kernel version >= 2.6.28 to use multiple pebs.");
+    err = -1;
+#endif
+    CONTROL_Invoke_Parallel(capture_sched_switch, NULL);
+#endif
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %d.", err);
+    return err;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID LINUXOS_Uninstall_Hooks(VOID)
+ * @brief       unregisters the profiling callbacks
+ *
+ * @param       none
+ *
+ * @return
+ *
+ * <I>Special Notes:</I>
+ *
+ * None
+ */
+extern VOID
+LINUXOS_Uninstall_Hooks (
+    VOID
+)
+{
+    int err    = 0;
+    int value  = 0;
+    int tries  = 10;
+
+    SEP_DRV_LOG_INIT_IN("Uninstalling Linux OS Hooks.");
+
+    if (hooks_installed == 0) {
+        SEP_DRV_LOG_INIT_OUT("Hooks are not installed!");
+        return;
+    }
+
+    hooks_installed = 0;
+    profile_event_unregister(MY_UNMAP, &linuxos_exec_unmap_nb);
+    profile_event_unregister(MY_TASK,  &linuxos_exit_task_nb);
+
+    if (multi_pebs_enabled) {
+        err = uninstall_sched_switch_callback();
+        if (err) {
+            SEP_DRV_LOG_WARNING("Failed to uninstall sched_switch callback for multiple pebs.");
+        }
+    }
+
+    value = atomic_cmpxchg(&hook_state, HOOK_FREE, HOOK_UNINSTALL);
+    if ((value == HOOK_FREE) || (value == HOOK_UNINSTALL)) {  // already in free or uninstall state
+        SEP_DRV_LOG_INIT_OUT("Uninstall hook done (already in state %d).", value);
+        return;
+    }
+    atomic_add(HOOK_UNINSTALL, &hook_state);
+    while (tries) {
+        SYS_IO_Delay();
+        SYS_IO_Delay();
+        value = atomic_read(&hook_state);
+        if (value == HOOK_UNINSTALL) {
+            break;
+        }
+        tries--;
+    }
+
+    SEP_DRV_LOG_INIT_OUT("Done -- state %d, tries %d.", value, tries);
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          DRV_BOOL LINUXOS_Check_KVM_Guest_Process()
+ *
+ * @brief       check the presence of kvm guest process
+ *
+ * @param       none
+ *
+ * @return      TRUE if the kvm guest process is running, FALSE if not
+ */
+extern DRV_BOOL
+LINUXOS_Check_KVM_Guest_Process (
+    VOID
+)
+{
+    struct task_struct *p;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (!local_tasklist_lock) {
+        local_tasklist_lock = (PVOID)(UIOP)UTILITY_Find_Symbol("tasklist_lock");
+        if (!local_tasklist_lock) {
+            SEP_DRV_LOG_WARNING("Could not find tasklist_lock.");
+        }
+    }
+
+    // In some machines the tasklist_lock symbol does not exist.
+    // For temporary solution we skip the lock if there is no tasklist_lock
+    if (local_tasklist_lock) {
+#if defined(DEFINE_QRWLOCK)
+        qread_lock(local_tasklist_lock);
+#else
+        read_lock(local_tasklist_lock);
+#endif
+    }
+
+    FOR_EACH_TASK(p) {
+        if (p == NULL) {
+            continue;
+        }
+
+        p->comm[TASK_COMM_LEN - 1] = 0; // making sure there is a trailing 0
+
+        if (!strncmp(p->comm, "qemu-kvm", 8)) {
+
+            if (local_tasklist_lock) {
+#if defined(DEFINE_QRWLOCK)
+                qread_unlock(local_tasklist_lock);
+#else
+                read_unlock(local_tasklist_lock);
+#endif
+            }
+
+            SEP_DRV_LOG_INIT_TRACE_OUT("TRUE (found qemu-kvm!).");
+            return TRUE;
+        }
+    }
+
+    if (local_tasklist_lock) {
+#if defined(DEFINE_QRWLOCK)
+        qread_unlock(local_tasklist_lock);
+#else
+        read_unlock(local_tasklist_lock);
+#endif
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("FALSE");
+    return FALSE;
+}
diff --git a/drivers/misc/intel/sepdk/sep/lwpmudrv.c b/drivers/misc/intel/sepdk/sep/lwpmudrv.c
new file mode 100644
index 000000000000..5c8f17161dcd
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/lwpmudrv.c
@@ -0,0 +1,6753 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit.
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+
+
+
+
+#include "lwpmudrv_defines.h"
+#include "lwpmudrv_version.h"
+
+#include <linux/version.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/fs.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <asm/page.h>
+#include <linux/cdev.h>
+#include <linux/proc_fs.h>
+#include <linux/fcntl.h>
+#include <linux/device.h>
+#include <linux/ptrace.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,11,0)
+#include <linux/sched/clock.h>
+#else
+#include <linux/sched.h>
+#endif
+#include <linux/syscalls.h>
+#include <asm/unistd.h>
+#include <linux/compat.h>
+#include <linux/vmalloc.h>
+#include <linux/kthread.h>
+#if defined(CONFIG_HYPERVISOR_GUEST)
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,34)
+#include <asm/hypervisor.h>
+#endif
+#endif
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,32)
+#include <xen/xen.h>
+#endif
+
+#if defined(CONFIG_XEN_HAVE_VPMU)
+#include <asm/xen/hypercall.h>
+#include <asm/xen/page.h>
+#include <xen/interface/xenpmu.h>
+#endif
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_ioctl.h"
+#include "lwpmudrv_struct.h"
+#include "inc/ecb_iterators.h"
+#include "inc/unc_common.h"
+
+#if defined(BUILD_GFX)
+#include "gfx.h"
+#endif
+
+#if defined(BUILD_CHIPSET)
+#include "lwpmudrv_chipset.h"
+#endif
+#include "pci.h"
+
+#include "apic.h"
+#include "cpumon.h"
+#include "lwpmudrv.h"
+#include "utility.h"
+#include "control.h"
+#include "core2.h"
+#include "pmi.h"
+
+#include "output.h"
+#include "linuxos.h"
+#include "sys_info.h"
+#include "eventmux.h"
+#include "pebs.h"
+
+
+MODULE_AUTHOR("Copyright(C) 2007-2018 Intel Corporation");
+MODULE_VERSION(SEP_NAME"_"SEP_VERSION_STR);
+MODULE_LICENSE("Dual BSD/GPL");
+
+struct task_struct *abnormal_handler = NULL;
+
+typedef struct LWPMU_DEV_NODE_S  LWPMU_DEV_NODE;
+typedef        LWPMU_DEV_NODE   *LWPMU_DEV;
+
+struct LWPMU_DEV_NODE_S {
+  long              buffer;
+  struct semaphore  sem;
+  struct cdev       cdev;
+};
+
+#define LWPMU_DEV_buffer(dev)      (dev)->buffer
+#define LWPMU_DEV_sem(dev)         (dev)->sem
+#define LWPMU_DEV_cdev(dev)        (dev)->cdev
+
+/* Global variables of the driver */
+SEP_VERSION_NODE           drv_version;
+U64                       *read_counter_info         = NULL;
+U64                       *prev_counter_data         = NULL;
+U64                        prev_counter_size         = 0;
+VOID                     **desc_data                 = NULL;
+U64                        total_ram                 = 0;
+U32                        output_buffer_size        = OUTPUT_LARGE_BUFFER;
+U32                        saved_buffer_size         = 0;
+static  S32                desc_count                = 0;
+uid_t                      uid                       = 0;
+DRV_CONFIG                 drv_cfg                   = NULL;
+DEV_CONFIG                 cur_pcfg                  = NULL;
+volatile pid_t             control_pid               = 0;
+U64                       *interrupt_counts          = NULL;
+LWPMU_DEV                  lwpmu_control             = NULL;
+LWPMU_DEV                  lwmod_control             = NULL;
+LWPMU_DEV                  lwsamp_control            = NULL;
+LWPMU_DEV                  lwsampunc_control         = NULL;
+LWPMU_DEV                  lwsideband_control        = NULL;
+EMON_BUFFER_DRIVER_HELPER  emon_buffer_driver_helper = NULL;
+
+/* needed for multiple devices (core/uncore) */
+U32                     num_devices            = 0;
+U32                     num_core_devs          = 0;
+U32                     cur_device             = 0;
+LWPMU_DEVICE            devices                = NULL;
+static U32              uncore_em_factor       = 0;
+unsigned long           unc_timer_interval     = 0;
+struct timer_list      *unc_read_timer         = 0;
+S32                     max_groups_unc         = 0;
+DRV_BOOL                multi_pebs_enabled     = FALSE;
+DRV_BOOL                unc_buf_init           = FALSE;
+DRV_BOOL                NMI_mode               = TRUE;
+DRV_BOOL                KVM_guest_mode         = FALSE;
+DRV_SETUP_INFO_NODE     req_drv_setup_info;
+
+#define UNCORE_EM_GROUP_SWAP_FACTOR   100
+#define PMU_DEVICES                   2   // pmu, mod
+
+extern U32 *cpu_built_sysinfo;
+
+#define DRV_DEVICE_DELIMITER          "!"
+
+#if defined(DRV_USE_UNLOCKED_IOCTL)
+static   struct mutex   ioctl_lock;
+#endif
+
+
+#if defined(BUILD_CHIPSET)
+CHIPSET_CONFIG          pma               = NULL;
+CS_DISPATCH             cs_dispatch       = NULL;
+#endif
+static S8              *cpu_mask_bits     = NULL;
+
+/*
+ *  Global data: Buffer control structure
+ */
+BUFFER_DESC      cpu_buf    = NULL;
+BUFFER_DESC      unc_buf    = NULL;
+BUFFER_DESC      module_buf = NULL;
+BUFFER_DESC      cpu_sideband_buf    = NULL;
+
+static dev_t     lwpmu_DevNum;  /* the major and minor parts for SEP3 base */
+static dev_t     lwsamp_DevNum; /* the major and minor parts for SEP3 percpu */
+static dev_t     lwsampunc_DevNum; /* the major and minor parts for SEP3 per package */
+static dev_t     lwsideband_DevNum;
+
+static struct class     *pmu_class   = NULL;
+
+extern volatile int      config_done;
+
+CPU_STATE          pcb                        = NULL;
+size_t             pcb_size                   = 0;
+U32               *core_to_package_map        = NULL;
+U32               *core_to_phys_core_map      = NULL;
+U32               *core_to_thread_map         = NULL;
+U32               *core_to_dev_map            = NULL;
+U32                threads_per_core           = 1;
+U32                num_packages               = 0;
+U64               *pmu_state                  = NULL;
+U64               *cpu_tsc                    = NULL;
+U64               *prev_cpu_tsc               = NULL;
+U64               *diff_cpu_tsc               = NULL;
+U64               *restore_bl_bypass          = NULL;
+U32               **restore_ha_direct2core    = NULL;
+U32               **restore_qpi_direct2core   = NULL;
+U32               *occupied_core_ids          = NULL;
+UNCORE_TOPOLOGY_INFO_NODE                   uncore_topology;
+PLATFORM_TOPOLOGY_PROG_NODE                 platform_topology_prog_node;
+static PLATFORM_TOPOLOGY_PROG_NODE          req_platform_topology_prog_node;
+
+static U8              *prev_set_CR4            = 0;
+wait_queue_head_t       wait_exit;
+
+extern OS_STATUS SOCPERF_Switch_Group3 (void);
+
+#if !defined(DRV_USE_UNLOCKED_IOCTL)
+#define MUTEX_INIT(lock)
+#define MUTEX_LOCK(lock)
+#define MUTEX_UNLOCK(lock)
+#else
+#define MUTEX_INIT(lock)     mutex_init(&(lock));
+#define MUTEX_LOCK(lock)     mutex_lock(&(lock))
+#define MUTEX_UNLOCK(lock)   mutex_unlock(&(lock))
+#endif
+
+#if defined(CONFIG_XEN_HAVE_VPMU)
+typedef struct xen_pmu_params   xen_pmu_params_t;
+typedef struct xen_pmu_data     xen_pmu_data_t;
+
+DEFINE_PER_CPU(xen_pmu_data_t *, xenpmu_shared);
+#endif
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  void lwpmudrv_PWR_Info(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief Make a copy of the Power control information that has been passed in.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_PWR_Info (
+    IOCTL_ARGS    arg
+)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+    if (DEV_CONFIG_power_capture(cur_pcfg) == FALSE) {
+        SEP_DRV_LOG_WARNING_FLOW_OUT("'Success' (Power capture is disabled!).");
+        return OS_SUCCESS;
+    }
+
+    // make sure size of incoming arg is correct
+    if ((arg->len_usr_to_drv != sizeof(PWR_NODE))  || (arg->buf_usr_to_drv == NULL)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("OS_FAULT (PWR capture has not been configured!).");
+        return OS_FAULT;
+    }
+
+    //
+    // First things first: Make a copy of the data for global use.
+    //
+    LWPMU_DEVICE_pwr(&devices[cur_device]) = CONTROL_Allocate_Memory((int)arg->len_usr_to_drv);
+    if (!LWPMU_DEVICE_pwr(&devices[cur_device])) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure!");
+        return OS_NO_MEM;
+    }
+
+    if (copy_from_user(LWPMU_DEVICE_pwr(&devices[cur_device]), arg->buf_usr_to_drv, arg->len_usr_to_drv)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure!");
+        return OS_FAULT;
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/*
+ * @fn void lwpmudrv_Allocate_Restore_Buffer
+ *
+ * @param
+ *
+ * @return   OS_STATUS
+ *
+ * @brief    allocate buffer space to save/restore the data (for JKT, QPILL and HA register) before collection
+ */
+static OS_STATUS
+lwpmudrv_Allocate_Restore_Buffer (
+    VOID
+)
+{
+    int i = 0;
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (!restore_ha_direct2core) {
+        restore_ha_direct2core  = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state) * sizeof(U32 *));
+        if (!restore_ha_direct2core) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("Memory allocation failure for restore_ha_direct2core!");
+            return OS_NO_MEM;
+        }
+        for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+            restore_ha_direct2core[i] = CONTROL_Allocate_Memory(MAX_BUSNO * sizeof(U32));
+        }
+    }
+    if (!restore_qpi_direct2core) {
+        restore_qpi_direct2core = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state) * sizeof(U32 *));
+        if (!restore_qpi_direct2core) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("Memory allocation failure for restore_qpi_direct2core!");
+            return OS_NO_MEM;
+        }
+        for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+            restore_qpi_direct2core[i] = CONTROL_Allocate_Memory(2 * MAX_BUSNO * sizeof(U32));
+        }
+    }
+    if (!restore_bl_bypass) {
+        restore_bl_bypass  = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state) * sizeof(U64));
+        if (!restore_bl_bypass) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("Memory allocation failure for restore_bl_bypass!");
+            return OS_NO_MEM;
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/*
+ * @fn void lwpmudrv_Allocate_Uncore_Buffer
+ *
+ * @param
+ *
+ * @return   OS_STATUS
+ *
+ * @brief    allocate buffer space for writing/reading uncore data
+ */
+static OS_STATUS
+lwpmudrv_Allocate_Uncore_Buffer (
+    VOID
+)
+{
+    U32  i, j, k, l;
+    U32  max_entries = 0;
+    U32  num_entries;
+    ECB  ecb;
+
+    SEP_DRV_LOG_TRACE_IN(""); // this function is not checking memory allocations properly
+
+    for (i = num_core_devs; i < num_devices; i++) {
+        if (!LWPMU_DEVICE_pcfg(&devices[i])) {
+            continue;
+        }
+        LWPMU_DEVICE_acc_value(&devices[i]) = CONTROL_Allocate_Memory(num_packages * sizeof(U64 **));
+        LWPMU_DEVICE_prev_value(&devices[i]) = CONTROL_Allocate_Memory(num_packages * sizeof(U64 *));
+        for (j = 0; j < num_packages; j++) {
+            // Allocate memory and zero out accumulator array (one per group)
+            LWPMU_DEVICE_acc_value(&devices[i])[j] = CONTROL_Allocate_Memory(LWPMU_DEVICE_em_groups_count(&devices[i]) * sizeof(U64 *));
+            for (k = 0; k < LWPMU_DEVICE_em_groups_count(&devices[i]); k++) {
+                ecb = LWPMU_DEVICE_PMU_register_data(&devices[i])[k];
+                num_entries = ECB_num_events(ecb) * LWPMU_DEVICE_num_units(&devices[i]);
+                LWPMU_DEVICE_acc_value(&devices[i])[j][k] = CONTROL_Allocate_Memory(num_entries * sizeof(U64));
+                for (l = 0; l < num_entries; l++) {
+                    LWPMU_DEVICE_acc_value(&devices[i])[j][k][l] = 0LL;
+                }
+                if (max_entries < num_entries) {
+                    max_entries = num_entries;
+                }
+            }
+            // Allocate memory and zero out prev_value array (one across groups)
+            LWPMU_DEVICE_prev_value(&devices[i])[j] = CONTROL_Allocate_Memory(max_entries * sizeof(U64));
+            for (k = 0; k < max_entries; k++) {
+                LWPMU_DEVICE_prev_value(&devices[i])[j][k] = 0LL;
+            }
+        }
+        max_entries = 0;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/*
+ * @fn void lwpmudrv_Free_Uncore_Buffer
+ *
+ * @param
+ *
+ * @return   OS_STATUS
+ *
+ * @brief    Free uncore data buffers
+ */
+static OS_STATUS
+lwpmudrv_Free_Uncore_Buffer (
+    U32  i
+)
+{
+    U32  j, k;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (LWPMU_DEVICE_prev_value(&devices[i])) {
+        for (j = 0; j < num_packages; j++) {
+            LWPMU_DEVICE_prev_value(&devices[i])[j] = CONTROL_Free_Memory(LWPMU_DEVICE_prev_value(&devices[i])[j]);
+        }
+        LWPMU_DEVICE_prev_value(&devices[i]) = CONTROL_Free_Memory(LWPMU_DEVICE_prev_value(&devices[i]));
+    }
+    if (LWPMU_DEVICE_acc_value(&devices[i])) {
+        for (j = 0; j < num_packages; j++) {
+            if (LWPMU_DEVICE_acc_value(&devices[i])[j]) {
+                for (k = 0; k < LWPMU_DEVICE_em_groups_count(&devices[i]); k++) {
+                    LWPMU_DEVICE_acc_value(&devices[i])[j][k] = CONTROL_Free_Memory(LWPMU_DEVICE_acc_value(&devices[i])[j][k]);
+                }
+                LWPMU_DEVICE_acc_value(&devices[i])[j] = CONTROL_Free_Memory(LWPMU_DEVICE_acc_value(&devices[i])[j]);
+            }
+        }
+        LWPMU_DEVICE_acc_value(&devices[i]) = CONTROL_Free_Memory(LWPMU_DEVICE_acc_value(&devices[i]));
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/*
+ * @fn void lwpmudrv_Free_Restore_Buffer
+ *
+ * @param
+ *
+ * @return   OS_STATUS
+ *
+ * @brief    allocate buffer space to save/restore the data (for JKT, QPILL and HA register) before collection
+ */
+static OS_STATUS
+lwpmudrv_Free_Restore_Buffer (
+    VOID
+)
+{
+    U32  i = 0;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (restore_ha_direct2core) {
+        for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+              restore_ha_direct2core[i]= CONTROL_Free_Memory(restore_ha_direct2core[i]);
+        }
+        restore_ha_direct2core = CONTROL_Free_Memory(restore_ha_direct2core);
+    }
+    if (restore_qpi_direct2core) {
+         for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+              restore_qpi_direct2core[i]= CONTROL_Free_Memory(restore_qpi_direct2core[i]);
+        }
+        restore_qpi_direct2core = CONTROL_Free_Memory(restore_qpi_direct2core);
+    }
+    if (restore_bl_bypass) {
+        restore_bl_bypass = CONTROL_Free_Memory(restore_bl_bypass);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Success");
+    return OS_SUCCESS;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Initialize_State(void)
+ *
+ * @param none
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Allocates the memory needed at load time.  Initializes all the
+ * @brief  necessary state variables with the default values.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Initialize_State (
+    VOID
+)
+{
+    S32 i, max_cpu_id = 0;
+
+    SEP_DRV_LOG_INIT_IN("");
+
+    for_each_possible_cpu(i) {
+        if (cpu_present(i)) {
+            if (i > max_cpu_id) {
+                max_cpu_id = i;
+            }
+        }
+    }
+    max_cpu_id++;
+
+    /*
+     *  Machine Initializations
+     *  Abstract this information away into a separate entry point
+     *
+     *  Question:  Should we allow for the use of Hot-cpu
+     *    add/subtract functionality while the driver is executing?
+     */
+    if (max_cpu_id > num_present_cpus()) {
+        GLOBAL_STATE_num_cpus(driver_state)      = max_cpu_id;
+    }
+    else {
+        GLOBAL_STATE_num_cpus(driver_state)      = num_present_cpus();
+    }
+    GLOBAL_STATE_active_cpus(driver_state)       = num_online_cpus();
+    GLOBAL_STATE_cpu_count(driver_state)         = 0;
+    GLOBAL_STATE_dpc_count(driver_state)         = 0;
+    GLOBAL_STATE_num_em_groups(driver_state)     = 0;
+    CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_UNINITIALIZED);
+
+    SEP_DRV_LOG_INIT_OUT("Success: num_cpus=%d, active_cpus=%d.",
+                    GLOBAL_STATE_num_cpus(driver_state),
+                    GLOBAL_STATE_active_cpus(driver_state));
+    return OS_SUCCESS;
+}
+
+
+#if !defined(CONFIG_PREEMPT_COUNT)
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static void lwpmudrv_Fill_TSC_Info (PVOID param)
+ *
+ * @param param - pointer the buffer to fill in.
+ *
+ * @return none
+ *
+ * @brief  Read the TSC and write into the correct array slot.
+ *
+ * <I>Special Notes</I>
+ */
+atomic_t read_now;
+static wait_queue_head_t read_tsc_now;
+static VOID
+lwpmudrv_Fill_TSC_Info (
+    PVOID   param
+)
+{
+    U32 this_cpu;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    preempt_enable();
+    //
+    // Wait until all CPU's are ready to proceed
+    // This will serve as a synchronization point to compute tsc skews.
+    //
+
+    if (atomic_read(&read_now) >= 1) {
+        if (atomic_dec_and_test(&read_now) == FALSE) {
+            wait_event_interruptible(read_tsc_now, (atomic_read(&read_now) >= 1));
+        }
+    }
+    else {
+        wake_up_interruptible_all(&read_tsc_now);
+    }
+    UTILITY_Read_TSC(&cpu_tsc[this_cpu]);
+    SEP_DRV_LOG_TRACE("This cpu %d --- tsc --- 0x%llx.",
+                    this_cpu, cpu_tsc[this_cpu]);
+
+    SEP_DRV_LOG_TRACE_OUT("Success");
+    return;
+}
+#endif
+
+
+/*********************************************************************
+ *  Internal Driver functions
+ *     Should be called only from the lwpmudrv_DeviceControl routine
+ *********************************************************************/
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static void lwpmudrv_Dump_Tracer(const char *)
+ *
+ * @param Name of the tracer
+ *
+ * @return void
+ *
+ * @brief  Function that handles the generation of markers into the ftrace stream
+ *
+ * <I>Special Notes</I>
+ */
+static void
+lwpmudrv_Dump_Tracer (
+    const char    *name,
+    U64            tsc
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+    if (tsc == 0) {
+        preempt_disable();
+        UTILITY_Read_TSC(&tsc);
+        tsc -= TSC_SKEW(CONTROL_THIS_CPU());
+        preempt_enable();
+    }
+    SEP_DRV_LOG_TRACE_OUT("Success");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Version(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Local function that handles the LWPMU_IOCTL_VERSION call.
+ * @brief  Returns the version number of the kernel mode sampling.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Version (
+    IOCTL_ARGS   arg
+)
+{
+    OS_STATUS status;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    // Check if enough space is provided for collecting the data
+    if ((arg->len_drv_to_usr != sizeof(U32))  || (arg->buf_drv_to_usr == NULL)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments.");
+        return OS_FAULT;
+    }
+
+    status = put_user(SEP_VERSION_NODE_sep_version(&drv_version), (U32 *)arg->buf_drv_to_usr);
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d", status);
+    return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Reserve(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief
+ * @brief  Local function that handles the LWPMU_IOCTL_RESERVE call.
+ * @brief  Sets the state to RESERVED if possible.  Returns BUSY if unable
+ * @brief  to reserve the PMU.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Reserve (
+    IOCTL_ARGS    arg
+)
+{
+    OS_STATUS  status = OS_SUCCESS;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    // Check if enough space is provided for collecting the data
+    if ((arg->len_drv_to_usr != sizeof(S32))  || (arg->buf_drv_to_usr == NULL)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments.");
+        return OS_FAULT;
+    }
+
+    status = put_user(!CHANGE_DRIVER_STATE(STATE_BIT_UNINITIALIZED, DRV_STATE_RESERVED), (int*)arg->buf_drv_to_usr);
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d", status);
+    return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Finish_Op(void)
+ *
+ * @param - none
+ *
+ * @return OS_STATUS
+ *
+ * @brief Finalize PMU after collection
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Finish_Op (
+    PVOID param
+)
+{
+    U32      this_cpu   = CONTROL_THIS_CPU();
+    U32      dev_idx    = core_to_dev_map[this_cpu];
+    DISPATCH dispatch   = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (dispatch != NULL && dispatch->fini != NULL) {
+        dispatch->fini(&dev_idx);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static VOID lwpmudrv_Clean_Up(DRV_BOOL)
+ *
+ * @param  DRV_BOOL finish - Flag to call finish
+ *
+ * @return VOID
+ *
+ * @brief  Cleans up the memory allocation.
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Clean_Up (
+    DRV_BOOL finish
+)
+{
+    U32  i;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (DRV_CONFIG_use_pcl(drv_cfg) == TRUE) {
+        drv_cfg = CONTROL_Free_Memory(drv_cfg);
+        goto signal_end;
+    }
+
+    if (devices) {
+        U32           id;
+        U32           num_groups   = 0;
+        EVENT_CONFIG  ec;
+        DISPATCH      dispatch_unc = NULL;
+
+        for (id = 0; id < num_devices; id++) {
+            if (LWPMU_DEVICE_pcfg(&devices[id])) {
+                if (LWPMU_DEVICE_device_type(&devices[id]) == DEVICE_INFO_UNCORE) {
+                    dispatch_unc = LWPMU_DEVICE_dispatch(&devices[id]);
+                    if (dispatch_unc && dispatch_unc->fini) {
+                        SEP_DRV_LOG_TRACE("LWP: calling UNC Init.");
+                        dispatch_unc->fini((PVOID *)&id);
+                    }
+                    lwpmudrv_Free_Uncore_Buffer(id);
+                }
+                else if (finish) {
+                    CONTROL_Invoke_Parallel(lwpmudrv_Finish_Op, NULL);
+                }
+            }
+
+            if (LWPMU_DEVICE_PMU_register_data(&devices[id])) {
+                ec =  LWPMU_DEVICE_ec(&devices[id]);
+                if (LWPMU_DEVICE_device_type(&devices[id]) == DEVICE_INFO_CORE) {
+                    num_groups = EVENT_CONFIG_num_groups(ec);
+                }
+                else {
+                    num_groups = EVENT_CONFIG_num_groups_unc(ec);
+                }
+                for (i = 0; i < num_groups; i++) {
+                    LWPMU_DEVICE_PMU_register_data(&devices[id])[i] = CONTROL_Free_Memory(LWPMU_DEVICE_PMU_register_data(&devices[id])[i]);
+                }
+                LWPMU_DEVICE_PMU_register_data(&devices[id]) = CONTROL_Free_Memory(LWPMU_DEVICE_PMU_register_data(&devices[id]));
+            }
+            LWPMU_DEVICE_pcfg(&devices[id]) = CONTROL_Free_Memory(LWPMU_DEVICE_pcfg(&devices[id]));
+            LWPMU_DEVICE_ec(&devices[id])   = CONTROL_Free_Memory(LWPMU_DEVICE_ec(&devices[id]));
+            if (LWPMU_DEVICE_lbr(&devices[id])) {
+                LWPMU_DEVICE_lbr(&devices[id])  = CONTROL_Free_Memory(LWPMU_DEVICE_lbr(&devices[id]));
+            }
+            if (LWPMU_DEVICE_pwr(&devices[id])) {
+                LWPMU_DEVICE_pwr(&devices[id])  = CONTROL_Free_Memory(LWPMU_DEVICE_pwr(&devices[id]));
+            }
+            if (LWPMU_DEVICE_cur_group(&devices[id])) {
+                LWPMU_DEVICE_cur_group(&devices[id])  = CONTROL_Free_Memory(LWPMU_DEVICE_cur_group(&devices[id]));
+            }
+        }
+        devices = CONTROL_Free_Memory(devices);
+    }
+
+    if (desc_data) {
+        for (i = 0; i < GLOBAL_STATE_num_descriptors(driver_state); i++) {
+            desc_data[i] = CONTROL_Free_Memory(desc_data[i]);
+        }
+        desc_data = CONTROL_Free_Memory(desc_data);
+    }
+
+    if (restore_bl_bypass) {
+        restore_bl_bypass = CONTROL_Free_Memory(restore_bl_bypass);
+    }
+
+    if (restore_qpi_direct2core) {
+        for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+              restore_qpi_direct2core[i]= CONTROL_Free_Memory(restore_qpi_direct2core[i]);
+        }
+        restore_qpi_direct2core = CONTROL_Free_Memory(restore_qpi_direct2core);
+    }
+
+    if (restore_ha_direct2core) {
+        for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+              restore_ha_direct2core[i]= CONTROL_Free_Memory(restore_ha_direct2core[i]);
+        }
+        restore_ha_direct2core = CONTROL_Free_Memory(restore_ha_direct2core);
+    }
+
+    drv_cfg                 = CONTROL_Free_Memory(drv_cfg);
+    pmu_state               = CONTROL_Free_Memory(pmu_state);
+    cpu_mask_bits           = CONTROL_Free_Memory(cpu_mask_bits);
+    core_to_dev_map         = CONTROL_Free_Memory(core_to_dev_map);
+#if defined(BUILD_CHIPSET)
+    pma                     = CONTROL_Free_Memory(pma);
+#endif
+
+signal_end:
+    GLOBAL_STATE_num_em_groups(driver_state)   = 0;
+    GLOBAL_STATE_num_descriptors(driver_state) = 0;
+    num_devices                                = 0;
+    num_core_devs                              = 0;
+    max_groups_unc                             = 0;
+    control_pid                                = 0;
+    unc_buf_init                               = FALSE;
+
+    OUTPUT_Cleanup();
+    memset(pcb, 0, pcb_size);
+
+    SEP_DRV_LOG_FLOW_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static NTSTATUS lwpmudrv_Initialize_Driver (PVOID buf_usr_to_drv, size_t len_usr_to_drv)
+ *
+ * @param  buf_usr_to_drv   - pointer to the input buffer
+ * @param  len_usr_to_drv   - size of the input buffer
+ *
+ * @return NTSTATUS
+ *
+ * @brief  Local function that handles the LWPMU_IOCTL_INIT_DRIVER call.
+ * @brief  Sets up the interrupt handler.
+ * @brief  Set up the output buffers/files needed to make the driver
+ * @brief  operational.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Initialize_Driver (
+    PVOID         buf_usr_to_drv,
+    size_t        len_usr_to_drv
+)
+{
+    S32        cpu_num;
+    int        status    = OS_SUCCESS;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments.");
+        return OS_FAULT;
+    }
+
+    if (!CHANGE_DRIVER_STATE(STATE_BIT_RESERVED, DRV_STATE_IDLE)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Unexpected driver state!");
+        return OS_FAULT;
+    }
+
+    interrupt_counts = NULL;
+    pmu_state        = NULL;
+
+    drv_cfg = CONTROL_Allocate_Memory(len_usr_to_drv);
+    if (!drv_cfg) {
+        status = OS_NO_MEM;
+        SEP_DRV_LOG_ERROR("Memory allocation failure for drv_cfg!");
+        goto clean_return;
+    }
+
+    if (copy_from_user(drv_cfg, buf_usr_to_drv, len_usr_to_drv)) {
+        SEP_DRV_LOG_ERROR("Memory copy failure for drv_cfg!");
+        status = OS_FAULT;
+        goto clean_return;
+    }
+
+    if (DRV_CONFIG_enable_cp_mode(drv_cfg)) {
+#if (defined(DRV_EM64T))
+        if (output_buffer_size == OUTPUT_LARGE_BUFFER) {
+            output_buffer_size = OUTPUT_CP_BUFFER;
+        }
+#endif
+        interrupt_counts = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state) *
+                                                   DRV_CONFIG_num_events(drv_cfg) *
+                                                   sizeof(U64));
+        if (interrupt_counts == NULL) {
+            SEP_DRV_LOG_ERROR("Memory allocation failure for interrupt_counts!");
+            status = OS_NO_MEM;
+            goto clean_return;
+        }
+    }
+    else if(output_buffer_size == OUTPUT_CP_BUFFER) {
+        output_buffer_size = OUTPUT_LARGE_BUFFER;
+    }
+
+    if (DRV_CONFIG_use_pcl(drv_cfg) == TRUE) {
+        SEP_DRV_LOG_FLOW_OUT("Success, using PCL.");
+        return OS_SUCCESS;
+    }
+
+    pmu_state = CONTROL_Allocate_KMemory(GLOBAL_STATE_num_cpus(driver_state)*sizeof(U64)*3);
+    if (!pmu_state) {
+        SEP_DRV_LOG_ERROR("Memory allocation failure for pmu_state!");
+        status = OS_NO_MEM;
+        goto clean_return;
+    }
+    uncore_em_factor = 0;
+    for (cpu_num = 0; cpu_num < GLOBAL_STATE_num_cpus(driver_state); cpu_num++) {
+        CPU_STATE_accept_interrupt(&pcb[cpu_num])   = 1;
+        CPU_STATE_initial_mask(&pcb[cpu_num])       = 1;
+        CPU_STATE_group_swap(&pcb[cpu_num])         = 1;
+        CPU_STATE_reset_mask(&pcb[cpu_num])         = 0;
+        CPU_STATE_num_samples(&pcb[cpu_num])        = 0;
+        CPU_STATE_last_p_state_valid(&pcb[cpu_num]) = FALSE;
+#if defined (DRV_CPU_HOTPLUG)
+        CPU_STATE_offlined(&pcb[cpu_num])           = TRUE;
+#else
+        CPU_STATE_offlined(&pcb[cpu_num])           = FALSE;
+#endif
+        CPU_STATE_nmi_handled(&pcb[cpu_num])        = 0;
+    }
+
+    DRV_CONFIG_seed_name(drv_cfg)     = NULL;
+    DRV_CONFIG_seed_name_len(drv_cfg) = 0;
+
+    SEP_DRV_LOG_TRACE("Config : size = %d.", DRV_CONFIG_size(drv_cfg));
+    SEP_DRV_LOG_TRACE("Config : counting_mode = %d.", DRV_CONFIG_counting_mode(drv_cfg));
+
+    control_pid = current->pid;
+    SEP_DRV_LOG_TRACE("Control PID = %d.", control_pid);
+
+    if (core_to_dev_map == NULL) {
+        core_to_dev_map = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state) * sizeof(U32));
+    }
+
+    if (DRV_CONFIG_counting_mode(drv_cfg) == FALSE) {
+        if (cpu_buf == NULL) {
+            cpu_buf = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state)*sizeof(BUFFER_DESC_NODE));
+            if (!cpu_buf) {
+                SEP_DRV_LOG_ERROR("Memory allocation failure for cpu_buf!");
+                status = OS_NO_MEM;
+                goto clean_return;
+            }
+        }
+
+        if (module_buf == NULL) {
+            module_buf = CONTROL_Allocate_Memory(sizeof(BUFFER_DESC_NODE));
+            if (!module_buf) {
+                status = OS_NO_MEM;
+                goto clean_return;
+            }
+        }
+
+#if defined(CONFIG_TRACEPOINTS)
+        multi_pebs_enabled = (DRV_CONFIG_multi_pebs_enabled(drv_cfg) &&
+                              (DRV_SETUP_INFO_page_table_isolation(&req_drv_setup_info) == DRV_SETUP_INFO_PTI_DISABLED));
+#endif
+        if (multi_pebs_enabled) {
+            if (cpu_sideband_buf == NULL) {
+                cpu_sideband_buf = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state)*sizeof(BUFFER_DESC_NODE));
+                if (!cpu_sideband_buf) {
+                    SEP_DRV_LOG_ERROR("Memory allocation failure for cpu_sideband_buf!");
+                    status = OS_NO_MEM;
+                    goto clean_return;
+                }
+            }
+        }
+
+        /*
+         * Allocate the output and control buffers for each CPU in the system
+         * Allocate and set up the temp output files for each CPU in the system
+         * Allocate and set up the temp outout file for detailing the Modules in the system
+         */
+        status = OUTPUT_Initialize();
+        if (status != OS_SUCCESS) {
+            SEP_DRV_LOG_ERROR("OUTPUT_Initialize failed!");
+            goto clean_return;
+        }
+
+        /*
+         * Program the APIC and set up the interrupt handler
+         */
+        CPUMON_Install_Cpuhooks();
+        SEP_DRV_LOG_TRACE("Finished Installing cpu hooks.");
+#if defined(DRV_CPU_HOTPLUG)
+        for (cpu_num = 0; cpu_num < GLOBAL_STATE_num_cpus(driver_state); cpu_num++) {
+            if (cpu_built_sysinfo && cpu_built_sysinfo[cpu_num] == 0) {
+                cpu_tsc[cpu_num] = cpu_tsc[0];
+                CONTROL_Invoke_Cpu(cpu_num, SYS_INFO_Build_Cpu, NULL);
+            }
+        }
+#endif
+
+#if defined(DRV_EM64T)
+        SYS_Get_GDT_Base((PVOID*)&gdt_desc);
+#endif
+        SEP_DRV_LOG_TRACE("About to install module notification.");
+        LINUXOS_Install_Hooks();
+    }
+
+clean_return:
+    if (status != OS_SUCCESS) {
+        drv_cfg          = CONTROL_Free_Memory(drv_cfg);
+        interrupt_counts = CONTROL_Free_Memory(interrupt_counts);
+        pmu_state        = CONTROL_Free_Memory(pmu_state);
+        CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d.", status);
+    return status;
+}
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Initialize (PVOID buf_usr_to_drv, size_t len_usr_to_drv)
+ *
+ * @param  buf_usr_to_drv  - pointer to the input buffer
+ * @param  len_usr_to_drv  - size of the input buffer
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Local function that handles the LWPMU_IOCTL_INIT call.
+ * @brief  Sets up the interrupt handler.
+ * @brief  Set up the output buffers/files needed to make the driver
+ * @brief  operational.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Initialize (
+    PVOID         buf_usr_to_drv,
+    size_t        len_usr_to_drv
+)
+{
+    int   status    = OS_SUCCESS;
+    S32   cpu_num;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments.");
+        return OS_FAULT;
+    }
+
+    if (cur_device >= num_devices) {
+        CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("No more devices to allocate! Wrong lwpmudrv_Init_Num_Devices.");
+        return OS_FAULT;
+    }
+
+    /*
+     *   Program State Initializations
+     */
+    LWPMU_DEVICE_pcfg(&devices[cur_device]) = CONTROL_Allocate_Memory(len_usr_to_drv);
+    if (!LWPMU_DEVICE_pcfg(&devices[cur_device])) {
+        status = OS_NO_MEM;
+        SEP_DRV_LOG_ERROR("Memory allocation failure for pcfg!");
+        goto clean_return;
+    }
+
+    if (copy_from_user(LWPMU_DEVICE_pcfg(&devices[cur_device]), buf_usr_to_drv, len_usr_to_drv)) {
+        SEP_DRV_LOG_ERROR("Memory copy failure for pcfg!");
+        status = OS_FAULT;
+        goto clean_return;
+    }
+    cur_pcfg = (DEV_CONFIG)LWPMU_DEVICE_pcfg(&devices[cur_device]);
+
+    if (DRV_CONFIG_use_pcl(drv_cfg) == TRUE) {
+        SEP_DRV_LOG_FLOW_OUT("Success, using PCL.");
+        return OS_SUCCESS;
+    }
+
+    LWPMU_DEVICE_dispatch(&devices[cur_device]) = UTILITY_Configure_CPU(DEV_CONFIG_dispatch_id(cur_pcfg));
+    if (LWPMU_DEVICE_dispatch(&devices[cur_device]) == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Dispatch pointer is NULL!");
+        status = OS_INVALID;
+        goto clean_return;
+    }
+
+    if (DRV_CONFIG_counting_mode(drv_cfg) == FALSE) {
+        status = PEBS_Initialize(cur_device);
+        if (status != OS_SUCCESS) {
+            SEP_DRV_LOG_ERROR("PEBS_Initialize failed!");
+            goto clean_return;
+        }
+    }
+
+    /* Create core to device ID map */
+    for (cpu_num = 0; cpu_num < GLOBAL_STATE_num_cpus(driver_state); cpu_num++) {
+        if (CPU_STATE_core_type(&pcb[cpu_num]) == DEV_CONFIG_core_type(cur_pcfg)) {
+            core_to_dev_map[cpu_num] = cur_device;
+        }
+    }
+    num_core_devs++; //New core device
+    LWPMU_DEVICE_device_type(&devices[cur_device]) = DEVICE_INFO_CORE;
+
+clean_return:
+    if (status != OS_SUCCESS) {
+        // release all memory allocated in this function:
+        lwpmudrv_Clean_Up(FALSE);
+        PEBS_Destroy();
+        CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d.", status);
+    return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Initialize_Num_Devices(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief
+ * @brief  Local function that handles the LWPMU_IOCTL_INIT_NUM_DEV call.
+ * @brief  Init # uncore devices.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Initialize_Num_Devices (
+    IOCTL_ARGS arg
+)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+
+    // Check if enough space is provided for collecting the data
+    if ((arg->len_usr_to_drv != sizeof(U32))  || (arg->buf_usr_to_drv == NULL)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments.");
+        return OS_FAULT;
+    }
+
+    if (copy_from_user(&num_devices, arg->buf_usr_to_drv, arg->len_usr_to_drv)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure");
+        return OS_FAULT;
+    }
+    /*
+     *   Allocate memory for number of devices
+     */
+    if (num_devices != 0) {
+        devices = CONTROL_Allocate_Memory(num_devices * sizeof(LWPMU_DEVICE_NODE));
+        if (!devices) {
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Unable to allocate memory for devices!");
+            return OS_NO_MEM;
+        }
+    }
+    cur_device = 0;
+
+    SEP_DRV_LOG_FLOW_OUT("Success: num_devices=%d, devices=0x%p.", num_devices, devices);
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Initialize_UNC(PVOID buf_usr_to_drv, U32 len_usr_to_drv)
+ *
+ * @param  buf_usr_to_drv   - pointer to the input buffer
+ * @param  len_usr_to_drv   - size of the input buffer
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Local function that handles the LWPMU_IOCTL_INIT call.
+ * @brief  Sets up the interrupt handler.
+ * @brief  Set up the output buffers/files needed to make the driver
+ * @brief  operational.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Initialize_UNC (
+    PVOID         buf_usr_to_drv,
+    U32           len_usr_to_drv
+)
+{
+    DEV_UNC_CONFIG  pcfg_unc;
+    U32             i;
+    int             status = OS_SUCCESS;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: current state is not IDLE.");
+        return OS_IN_PROGRESS;
+    }
+
+    if (!devices) {
+        CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("No devices allocated!");
+        return OS_INVALID;
+    }
+
+    /*
+     *   Program State Initializations:
+     *   Foreach device, copy over pcfg and configure dispatch table
+     */
+    if (cur_device >= num_devices) {
+        CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("No more devices to allocate! Wrong lwpmudrv_Init_Num_Devices.");
+        return OS_FAULT;
+    }
+    if (buf_usr_to_drv == NULL) {
+        CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments.");
+        return OS_FAULT;
+    }
+    if (len_usr_to_drv != sizeof(DEV_UNC_CONFIG_NODE)) {
+        CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Got len_usr_to_drv=%d, expecting size=%d", len_usr_to_drv, (int)sizeof(DEV_UNC_CONFIG_NODE));
+        return OS_FAULT;
+    }
+    // allocate memory
+    LWPMU_DEVICE_pcfg(&devices[cur_device]) = CONTROL_Allocate_Memory(sizeof(DEV_UNC_CONFIG_NODE));
+    // copy over pcfg
+    if (copy_from_user(LWPMU_DEVICE_pcfg(&devices[cur_device]), buf_usr_to_drv, len_usr_to_drv)) {
+        CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Failed to copy from user!");
+        return OS_FAULT;
+    }
+    // configure dispatch from dispatch_id
+    pcfg_unc = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(&devices[cur_device]);
+    if (!pcfg_unc) {
+        CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid pcfg_unc.");
+        return OS_INVALID;
+    }
+
+    LWPMU_DEVICE_dispatch(&devices[cur_device]) = UTILITY_Configure_CPU(DEV_UNC_CONFIG_dispatch_id(pcfg_unc));
+    if (LWPMU_DEVICE_dispatch(&devices[cur_device]) == NULL) {
+        CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Unable to configure CPU!");
+        return OS_FAULT;
+    }
+
+    LWPMU_DEVICE_cur_group(&devices[cur_device]) = CONTROL_Allocate_Memory(num_packages * sizeof(S32));
+    if (LWPMU_DEVICE_cur_group(&devices[cur_device]) == NULL) {
+        CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Cur_grp allocation failed for device %u!", cur_device);
+        return OS_NO_MEM;
+    }
+    for (i = 0; i < num_packages; i++) {
+        LWPMU_DEVICE_cur_group(&devices[cur_device])[i] = 0;
+    }
+
+    LWPMU_DEVICE_em_groups_count(&devices[cur_device]) = 0;
+    LWPMU_DEVICE_num_units(&devices[cur_device])       = 0;
+    LWPMU_DEVICE_device_type(&devices[cur_device])     = DEVICE_INFO_UNCORE;
+
+    if (DRV_CONFIG_counting_mode(drv_cfg) == FALSE) {
+        if (unc_buf == NULL) {
+            unc_buf = CONTROL_Allocate_Memory(num_packages*sizeof(BUFFER_DESC_NODE));
+            if (!unc_buf) {
+                CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+                SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure.");
+                return OS_NO_MEM;
+            }
+        }
+
+        if (!unc_buf_init) {
+            status = OUTPUT_Initialize_UNC();
+            if (status != OS_SUCCESS) {
+                CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+                SEP_DRV_LOG_ERROR_FLOW_OUT("OUTPUT_Initialize failed!");
+                return status;
+            }
+            unc_buf_init = TRUE;
+        }
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("unc dispatch id = %d.", DEV_UNC_CONFIG_dispatch_id(pcfg_unc));
+
+    return OS_SUCCESS;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Terminate(void)
+ *
+ * @param  none
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Local function that handles the DRV_OPERATION_TERMINATE call.
+ * @brief  Cleans up the interrupt handler and resets the PMU state.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Terminate (
+    VOID
+)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (GET_DRIVER_STATE() == DRV_STATE_UNINITIALIZED) {
+        SEP_DRV_LOG_FLOW_OUT("Success (already uninitialized).");
+        return OS_SUCCESS;
+    }
+
+    if (!CHANGE_DRIVER_STATE(STATE_BIT_STOPPED | STATE_BIT_TERMINATING, DRV_STATE_UNINITIALIZED)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Unexpected state!");
+        return OS_FAULT;
+    }
+
+    if (drv_cfg && DRV_CONFIG_counting_mode(drv_cfg) == FALSE) {
+        LINUXOS_Uninstall_Hooks();
+    }
+
+    lwpmudrv_Clean_Up(TRUE);
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static void lwpmudrv_Switch_To_Next_Group(param)
+ *
+ * @param  none
+ *
+ * @return none
+ *
+ * @brief  Switch to the next event group for both core and uncore.
+ * @brief  This function assumes an active collection is frozen
+ * @brief  or no collection is active.
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Switch_To_Next_Group (
+    VOID
+)
+{
+    S32            cpuid;
+    U32            i, j;
+    CPU_STATE      pcpu;
+    EVENT_CONFIG   ec;
+    DEV_UNC_CONFIG pcfg_unc;
+    DISPATCH       dispatch_unc;
+    ECB            pecb_unc      = NULL;
+    U32            cur_grp       = 0;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    for (cpuid = 0; cpuid < GLOBAL_STATE_num_cpus(driver_state); cpuid++) {
+        pcpu     = &pcb[cpuid];
+        ec       = (EVENT_CONFIG)LWPMU_DEVICE_ec(&devices[core_to_dev_map[cpuid]]);
+        CPU_STATE_current_group(pcpu)++;
+        // make the event group list circular
+        CPU_STATE_current_group(pcpu) %= EVENT_CONFIG_num_groups(ec);
+    }
+
+    if (num_devices) {
+        for (i = num_core_devs; i < num_devices; i++) {
+            pcfg_unc     = LWPMU_DEVICE_pcfg(&devices[i]);
+            dispatch_unc = LWPMU_DEVICE_dispatch(&devices[i]);
+            if (LWPMU_DEVICE_em_groups_count(&devices[i]) > 1) {
+                if (pcb && pcfg_unc && dispatch_unc && DRV_CONFIG_emon_mode(drv_cfg)) {
+                    for (j = 0; j < num_packages; j++) {
+                        cur_grp      = LWPMU_DEVICE_cur_group(&devices[i])[j];
+                        pecb_unc     = LWPMU_DEVICE_PMU_register_data(&devices[i])[cur_grp];
+                        LWPMU_DEVICE_cur_group(&devices[i])[j]++;
+                        if (CPU_STATE_current_group(&pcb[0]) == 0) {
+                            LWPMU_DEVICE_cur_group(&devices[i])[j] = 0;
+                        }
+                        LWPMU_DEVICE_cur_group(&devices[i])[j] %= LWPMU_DEVICE_em_groups_count(&devices[i]);
+                    }
+                    SEP_DRV_LOG_TRACE("Swap Group to %d for device %d.",
+                                    cur_grp,
+                                    i);
+                    if (pecb_unc && ECB_device_type(pecb_unc) == DEVICE_UNC_SOCPERF) {
+                        SOCPERF_Switch_Group3();
+                    }
+                }
+            }
+        }
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwmpudrv_Get_Driver_State(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Local function that handles the LWPMU_IOCTL_GET_Driver_State call.
+ * @brief  Returns the current driver state.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Get_Driver_State (
+    IOCTL_ARGS    arg
+)
+{
+    OS_STATUS  status = OS_SUCCESS;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    // Check if enough space is provided for collecting the data
+    if ((arg->len_drv_to_usr != sizeof(U32)) || (arg->buf_drv_to_usr == NULL)) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Invalid arguments!");
+        return OS_FAULT;
+    }
+
+    status = put_user(GET_DRIVER_STATE(), (U32*)arg->buf_drv_to_usr);
+
+    SEP_DRV_LOG_TRACE_OUT("Return value: %d.", status);
+    return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Pause_Uncore(void)
+ *
+ * @param - 1 if switching group, 0 otherwise
+ *
+ * @return OS_STATUS
+ *
+ * @brief Pause the uncore collection
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Pause_Uncore (
+    PVOID param
+)
+{
+    U32 i;
+    U32 switch_grp;
+    DEV_UNC_CONFIG pcfg_unc = NULL;
+    DISPATCH   dispatch_unc = NULL;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    switch_grp = *((U32*)param);
+
+    for (i = num_core_devs; i < num_devices; i++) {
+         pcfg_unc = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(&devices[i]);
+         dispatch_unc = LWPMU_DEVICE_dispatch(&devices[i]);
+
+         if (pcfg_unc                                &&
+             dispatch_unc                            &&
+             dispatch_unc->freeze) {
+                SEP_DRV_LOG_TRACE("LWP: calling UNC Pause.");
+                if (switch_grp) {
+                    if (LWPMU_DEVICE_em_groups_count(&devices[i]) > 1) {
+                        dispatch_unc->freeze(&i);
+                    }
+                }
+                else {
+                    dispatch_unc->freeze(&i);
+                }
+         }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Pause_Op(void)
+ *
+ * @param - none
+ *
+ * @return OS_STATUS
+ *
+ * @brief Pause the core/uncore collection
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Pause_Op (
+    PVOID param
+)
+{
+    U32      this_cpu   = CONTROL_THIS_CPU();
+    U32      dev_idx    = core_to_dev_map[this_cpu];
+    DISPATCH dispatch   = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    U32      switch_grp = 0;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (dispatch != NULL && dispatch->freeze != NULL &&
+        DRV_CONFIG_use_pcl(drv_cfg) == FALSE) {
+        dispatch->freeze(param);
+    }
+
+    lwpmudrv_Pause_Uncore((PVOID)&switch_grp);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Pause(void)
+ *
+ * @param - none
+ *
+ * @return OS_STATUS
+ *
+ * @brief Pause the collection
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Pause (
+    VOID
+)
+{
+    int  i;
+    int  done = FALSE;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (!pcb || !drv_cfg) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Pcb or drv_cfg pointer is NULL!");
+        return OS_INVALID;
+    }
+
+    if (CHANGE_DRIVER_STATE(STATE_BIT_RUNNING, DRV_STATE_PAUSING)) {
+        if (DRV_CONFIG_use_pcl(drv_cfg) == FALSE) {
+            for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+                CPU_STATE_accept_interrupt(&pcb[i]) = 0;
+            }
+            while (!done) {
+                done = TRUE;
+                for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+                    if (atomic_read(&CPU_STATE_in_interrupt(&pcb[i]))) {
+                        done = FALSE;
+                    }
+                }
+            }
+        }
+        CONTROL_Invoke_Parallel(lwpmudrv_Pause_Op, NULL);
+        /*
+         * This means that the PAUSE state has been reached.
+         */
+        CHANGE_DRIVER_STATE(STATE_BIT_PAUSING, DRV_STATE_PAUSED);
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Resume_Uncore(void)
+ *
+ * @param - 1 if switching group, 0 otherwise
+ *
+ * @return OS_STATUS
+ *
+ * @brief Resume the uncore collection
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Resume_Uncore (
+    PVOID param
+)
+{
+    U32 i;
+    U32 switch_grp;
+    DEV_UNC_CONFIG pcfg_unc = NULL;
+    DISPATCH   dispatch_unc = NULL;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    switch_grp = *((U32*)param);
+
+    for (i = num_core_devs; i < num_devices; i++) {
+         pcfg_unc = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(&devices[i]);
+         dispatch_unc = LWPMU_DEVICE_dispatch(&devices[i]);
+
+         if (pcfg_unc                                &&
+             dispatch_unc                            &&
+             dispatch_unc->restart) {
+                SEP_DRV_LOG_TRACE("LWP: calling UNC Resume.");
+                if (switch_grp) {
+                    if (LWPMU_DEVICE_em_groups_count(&devices[i]) > 1) {
+                        dispatch_unc->restart(&i);
+                    }
+                }
+                else {
+                    dispatch_unc->restart(&i);
+                }
+         }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Resume_Op(void)
+ *
+ * @param - none
+ *
+ * @return OS_STATUS
+ *
+ * @brief Resume the core/uncore collection
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Resume_Op (
+    PVOID param
+)
+{
+    U32      this_cpu   = CONTROL_THIS_CPU();
+    U32      dev_idx    = core_to_dev_map[this_cpu];
+    DISPATCH dispatch   = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    U32      switch_grp = 0;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (dispatch != NULL && dispatch->restart != NULL &&
+        DRV_CONFIG_use_pcl(drv_cfg) == FALSE) {
+        dispatch->restart((VOID *)(size_t)0);
+    }
+
+    lwpmudrv_Resume_Uncore((PVOID)&switch_grp);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Resume(void)
+ *
+ * @param - none
+ *
+ * @return OS_STATUS
+ *
+ * @brief Resume the collection
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Resume (
+    VOID
+)
+{
+    int        i;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (!pcb || !drv_cfg) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Pcb or drv_cfg pointer is NULL!");
+        return OS_INVALID;
+    }
+
+    /*
+     * If we are in the process of pausing sampling, wait until the pause has been
+     * completed.  Then start the Resume process.
+     */
+    while (GET_DRIVER_STATE() == DRV_STATE_PAUSING) {
+        /*
+         *  This delay probably needs to be expanded a little bit more for large systems.
+         *  For now, it is probably sufficient.
+         */
+        SYS_IO_Delay();
+        SYS_IO_Delay();
+    }
+
+    if (CHANGE_DRIVER_STATE(STATE_BIT_PAUSED, DRV_STATE_RUNNING)) {
+        for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+            if (cpu_mask_bits) {
+                CPU_STATE_accept_interrupt(&pcb[i]) = cpu_mask_bits[i] ? 1 : 0;
+                CPU_STATE_group_swap(&pcb[i])       = 1;
+            }
+            else {
+                CPU_STATE_accept_interrupt(&pcb[i]) = 1;
+                CPU_STATE_group_swap(&pcb[i])       = 1;
+            }
+        }
+        CONTROL_Invoke_Parallel(lwpmudrv_Resume_Op, NULL);
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Write_Uncore(void)
+ *
+ * @param - 1 if switching group, 0 otherwise
+ *
+ * @return OS_STATUS
+ *
+ * @brief Program the uncore collection
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Write_Uncore (
+    PVOID param
+)
+{
+    U32        i;
+    U32        switch_grp;
+    DEV_UNC_CONFIG pcfg_unc = NULL;
+    DISPATCH   dispatch_unc = NULL;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    switch_grp = *((U32*)param);
+
+    for (i = num_core_devs; i < num_devices; i++) {
+         pcfg_unc = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(&devices[i]);
+         dispatch_unc = LWPMU_DEVICE_dispatch(&devices[i]);
+
+         if (pcfg_unc && dispatch_unc && dispatch_unc->write) {
+                SEP_DRV_LOG_TRACE("LWP: calling UNC Write.");
+                if (switch_grp) {
+                    if (LWPMU_DEVICE_em_groups_count(&devices[i]) > 1) {
+                        dispatch_unc->write(&i);
+                    }
+                }
+                else {
+                    dispatch_unc->write(&i);
+                }
+         }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Write_Op(void)
+ *
+ * @param - Do operation for Core only
+ *
+ * @return OS_STATUS
+ *
+ * @brief Program the core/uncore collection
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Write_Op (
+    PVOID param
+)
+{
+    U32      this_cpu   = CONTROL_THIS_CPU();
+    U32      dev_idx    = core_to_dev_map[this_cpu];
+    DISPATCH dispatch   = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    U32      switch_grp = 0;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (dispatch != NULL && dispatch->write != NULL) {
+        dispatch->write((VOID *)(size_t)0);
+    }
+
+    if (param == NULL) {
+        lwpmudrv_Write_Uncore((PVOID)&switch_grp);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Switch_Group(void)
+ *
+ * @param none
+ *
+ * @return OS_STATUS
+ *
+ * @brief Switch the current group that is being collected.
+ *
+ * <I>Special Notes</I>
+ *     This routine is called from the user mode code to handle the multiple group
+ *     situation.  4 distinct steps are taken:
+ *     Step 1: Pause the sampling
+ *     Step 2: Increment the current group count
+ *     Step 3: Write the new group to the PMU
+ *     Step 4: Resume sampling
+ */
+static OS_STATUS
+lwpmudrv_Switch_Group (
+    VOID
+)
+{
+    S32            idx;
+    CPU_STATE      pcpu;
+    EVENT_CONFIG   ec;
+    OS_STATUS      status        = OS_SUCCESS;
+    U32            current_state = GET_DRIVER_STATE();
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (!pcb || !drv_cfg) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Pcb or drv_cfg pointer is NULL!");
+        return OS_INVALID;
+    }
+
+    if (current_state != DRV_STATE_RUNNING &&
+        current_state != DRV_STATE_PAUSED) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Return value: %d (invalid driver state!).", status);
+        return status;
+    }
+
+    status = lwpmudrv_Pause();
+
+    for (idx = 0; idx < GLOBAL_STATE_num_cpus(driver_state); idx++) {
+        pcpu = &pcb[idx];
+        ec   = (EVENT_CONFIG)LWPMU_DEVICE_ec(&devices[core_to_dev_map[idx]]);
+        CPU_STATE_current_group(pcpu)++;
+        // make the event group list circular
+        CPU_STATE_current_group(pcpu) %= EVENT_CONFIG_num_groups(ec);
+    }
+    CONTROL_Invoke_Parallel(lwpmudrv_Write_Op, (VOID *)(size_t)CONTROL_THIS_CPU());
+    if (drv_cfg && DRV_CONFIG_start_paused(drv_cfg) == FALSE) {
+        lwpmudrv_Resume();
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d", status);
+    return status;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Trigger_Read_Op(void)
+ *
+ * @param - none
+ *
+ * @return OS_STATUS
+ *
+ * @brief Read uncore data
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Trigger_Read_Op (
+    PVOID param
+)
+{
+    DEV_UNC_CONFIG        pcfg_unc     = NULL;
+    DISPATCH              dispatch_unc = NULL;
+    U32                   this_cpu;
+    CPU_STATE             pcpu;
+    U32                   package_num;
+    U64                   tsc;
+    BUFFER_DESC           bd;
+    EVENT_DESC            evt_desc;
+    U32                   cur_grp;
+    ECB                   pecb;
+    U32                   sample_size  = 0;
+    U32                   offset       = 0;
+    PVOID                 buf;
+    UncoreSampleRecordPC *psamp;
+    U32                   i;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu         = CONTROL_THIS_CPU();
+    pcpu             = &pcb[this_cpu];
+    package_num      = core_to_package_map[this_cpu];
+
+    if (!DRIVER_STATE_IN(GET_DRIVER_STATE(), STATE_BIT_RUNNING | STATE_BIT_PAUSED)) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("State is not RUNNING or PAUSED!");
+        return;
+    }
+
+    if (!CPU_STATE_socket_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Not socket master.");
+        return;
+    }
+
+    UTILITY_Read_TSC(&tsc);
+    bd = &unc_buf[package_num];
+
+    for (i = num_core_devs; i < num_devices; i++) {
+        pcfg_unc = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(&devices[i]);
+        if (pcfg_unc) {
+            cur_grp = LWPMU_DEVICE_cur_group(&devices[i])[package_num];
+            pecb = LWPMU_DEVICE_PMU_register_data(&devices[i])[cur_grp];
+            evt_desc = desc_data[ECB_descriptor_id(pecb)];
+            sample_size += EVENT_DESC_sample_size(evt_desc);
+        }
+    }
+
+    buf = OUTPUT_Reserve_Buffer_Space(bd, sample_size, FALSE, !SEP_IN_NOTIFICATION);
+
+    if (buf) {
+        for (i = num_core_devs; i < num_devices; i++) {
+            pcfg_unc = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(&devices[i]);
+            dispatch_unc = LWPMU_DEVICE_dispatch(&devices[i]);
+            if (pcfg_unc && dispatch_unc && dispatch_unc->trigger_read) {
+                cur_grp = LWPMU_DEVICE_cur_group(&devices[i])[package_num];
+                pecb = LWPMU_DEVICE_PMU_register_data(&devices[i])[cur_grp];
+                evt_desc = desc_data[ECB_descriptor_id(pecb)];
+
+                psamp = (UncoreSampleRecordPC *)(((S8 *)buf) + offset);
+                UNCORE_SAMPLE_RECORD_descriptor_id(psamp)  = ECB_descriptor_id(pecb);
+                UNCORE_SAMPLE_RECORD_tsc(psamp)            = tsc;
+                UNCORE_SAMPLE_RECORD_uncore_valid(psamp)   = 1;
+                UNCORE_SAMPLE_RECORD_cpu_num(psamp)        = (U16)this_cpu;
+                UNCORE_SAMPLE_RECORD_pkg_num(psamp)        = (U16)package_num;
+
+                dispatch_unc->trigger_read(psamp, i);
+                offset += EVENT_DESC_sample_size(evt_desc);
+            }
+        }
+    }
+    else {
+        SEP_DRV_LOG_WARNING("Buffer space reservation failed; some samples will be dropped.");
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Uncore_Switch_Group(void)
+ *
+ * @param none
+ *
+ * @return OS_STATUS
+ *
+ * @brief Switch the current group that is being collected.
+ *
+ * <I>Special Notes</I>
+ *     This routine is called from the user mode code to handle the multiple group
+ *     situation.  4 distinct steps are taken:
+ *     Step 1: Pause the sampling
+ *     Step 2: Increment the current group count
+ *     Step 3: Write the new group to the PMU
+ *     Step 4: Resume sampling
+ */
+static OS_STATUS
+lwpmudrv_Uncore_Switch_Group (
+    VOID
+)
+{
+    OS_STATUS      status        = OS_SUCCESS;
+    U32            current_state = GET_DRIVER_STATE();
+    U32            i             = 0;
+    U32            j, k;
+    DEV_UNC_CONFIG pcfg_unc;
+    DISPATCH       dispatch_unc;
+    ECB            ecb_unc;
+    U32            cur_grp;
+    U32            num_units;
+    U32            switch_grp    = 1;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (!devices || !drv_cfg) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Devices or drv_cfg pointer is NULL!");
+        return OS_INVALID;
+    }
+
+    if (current_state != DRV_STATE_RUNNING &&
+        current_state != DRV_STATE_PAUSED) {
+        SEP_DRV_LOG_FLOW_OUT("Driver state is not RUNNING or PAUSED!");
+        return OS_INVALID;
+    }
+
+    if (max_groups_unc > 1) {
+        CONTROL_Invoke_Parallel(lwpmudrv_Pause_Uncore, (PVOID)&switch_grp);
+        for(i = num_core_devs; i < num_devices; i++) {
+            pcfg_unc     = LWPMU_DEVICE_pcfg(&devices[i]);
+            dispatch_unc = LWPMU_DEVICE_dispatch(&devices[i]);
+            num_units    = LWPMU_DEVICE_num_units(&devices[i]);
+            if (!pcfg_unc || !dispatch_unc) {
+                continue;
+            }
+            if (LWPMU_DEVICE_em_groups_count(&devices[i]) > 1) {
+                for (j = 0; j < num_packages; j++) {
+                    cur_grp = LWPMU_DEVICE_cur_group(&devices[i])[j];
+                    ecb_unc = LWPMU_DEVICE_PMU_register_data(&devices[i])[cur_grp];
+                    // Switch group
+                    LWPMU_DEVICE_cur_group(&devices[i])[j]++;
+                    LWPMU_DEVICE_cur_group(&devices[i])[j] %= LWPMU_DEVICE_em_groups_count(&devices[i]);
+                    if (ecb_unc && (ECB_device_type(ecb_unc) == DEVICE_UNC_SOCPERF) && (j == 0)) {
+                        SOCPERF_Switch_Group3();
+                    }
+                    // Post group switch
+                    cur_grp = LWPMU_DEVICE_cur_group(&devices[i])[j];
+                    ecb_unc = LWPMU_DEVICE_PMU_register_data(&devices[i])[cur_grp];
+                    for (k = 0; k < (ECB_num_events(ecb_unc)*num_units); k++) {
+                        LWPMU_DEVICE_prev_value(&devices[i])[j][k] = 0LL;  //zero out prev_value for new collection
+                    }
+                }
+            }
+        }
+        CONTROL_Invoke_Parallel(lwpmudrv_Write_Uncore, (PVOID)&switch_grp);
+        CONTROL_Invoke_Parallel(lwpmudrv_Resume_Uncore, (PVOID)&switch_grp);
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d", status);
+    return status;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static VOID lwpmudrv_Trigger_Read(void)
+ *
+ * @param - none
+ *
+ * @return - OS_STATUS
+ *
+ * @brief Read the Counter Data.
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Trigger_Read (
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,15,0)
+    struct timer_list *tl
+#else
+    unsigned long arg
+#endif
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_RUNNING) {
+        SEP_DRV_LOG_TRACE_OUT("Success: driver state is not RUNNING");
+        return;
+    }
+#if defined(BUILD_CHIPSET)
+    if (cs_dispatch && cs_dispatch->Trigger_Read) {
+        cs_dispatch->Trigger_Read();
+    }
+#endif
+
+    if (drv_cfg && DRV_CONFIG_use_pcl(drv_cfg) == TRUE) {
+        SEP_DRV_LOG_TRACE_OUT("Success: Using PCL");
+        return;
+    }
+
+    CONTROL_Invoke_Parallel(lwpmudrv_Trigger_Read_Op, NULL);
+
+    uncore_em_factor++;
+    if (uncore_em_factor == DRV_CONFIG_unc_em_factor(drv_cfg)) {
+        SEP_DRV_LOG_TRACE("Switching Uncore Group...");
+        lwpmudrv_Uncore_Switch_Group();
+        uncore_em_factor = 0;
+    }
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,15,0)
+    mod_timer(unc_read_timer, jiffies + unc_timer_interval);
+#else
+    unc_read_timer->expires = jiffies + unc_timer_interval;
+    add_timer(unc_read_timer);
+#endif
+
+    SEP_DRV_LOG_TRACE_OUT("Success.");
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static void lwmudrv_Read_Specific_TSC (PVOID param)
+ *
+ * @param param - pointer to the result
+ *
+ * @return none
+ *
+ * @brief  Read the tsc value in the current processor and
+ * @brief  write the result into param.
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Read_Specific_TSC (
+    PVOID  param
+)
+{
+    U32 this_cpu;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    if (this_cpu == 0) {
+        UTILITY_Read_TSC((U64*)param);
+    }
+    preempt_enable();
+
+    SEP_DRV_LOG_TRACE_OUT("");
+
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID lwpmudrv_Uncore_Stop_Timer (void)
+ *
+ * @brief       Stop the uncore read timer
+ *
+ * @param       none
+ *
+ * @return      none
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+lwpmudrv_Uncore_Stop_Timer (
+    VOID
+)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (unc_read_timer == NULL) {
+        return;
+    }
+
+    del_timer_sync(unc_read_timer);
+    unc_read_timer = CONTROL_Free_Memory(unc_read_timer);
+
+    SEP_DRV_LOG_FLOW_OUT("");
+
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          OS_STATUS lwpmudrv_Uncore_Start_Timer (void)
+ *
+ * @brief       Start the uncore read timer
+ *
+ * @param       none
+ *
+ * @return      OS_STATUS
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+lwpmudrv_Uncore_Start_Timer (
+    VOID
+)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+
+    unc_timer_interval = msecs_to_jiffies(DRV_CONFIG_unc_timer_interval(drv_cfg));
+    unc_read_timer = CONTROL_Allocate_Memory(sizeof(struct timer_list));
+    if (unc_read_timer == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for unc_read_timer!");
+        return;
+    }
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,15,0)
+    timer_setup(unc_read_timer, lwpmudrv_Trigger_Read, 0);
+    mod_timer(unc_read_timer, jiffies + unc_timer_interval);
+#else
+    init_timer(unc_read_timer);
+    unc_read_timer->function = lwpmudrv_Trigger_Read;
+    unc_read_timer->expires  = jiffies + unc_timer_interval;
+    add_timer(unc_read_timer);
+#endif
+
+    SEP_DRV_LOG_FLOW_OUT("");
+
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Init_Op(void)
+ *
+ * @param - none
+ *
+ * @return OS_STATUS
+ *
+ * @brief Initialize PMU before collection
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Init_Op (
+    PVOID param
+)
+{
+    U32      this_cpu   = CONTROL_THIS_CPU();
+    U32      dev_idx    = core_to_dev_map[this_cpu];
+    DISPATCH dispatch   = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (dispatch != NULL && dispatch->init != NULL) {
+        dispatch->init(&dev_idx);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Init_PMU(void)
+ *
+ * @param - none
+ *
+ * @return - OS_STATUS
+ *
+ * @brief Initialize the PMU and the driver state in preparation for data collection.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Init_PMU (
+    IOCTL_ARGS args
+)
+{
+    DEV_UNC_CONFIG pcfg_unc = NULL;
+    DISPATCH       dispatch_unc = NULL;
+    EVENT_CONFIG   ec;
+    U32            i;
+    U32            emon_buffer_size = 0;
+    OS_STATUS      status = OS_SUCCESS;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (args->len_usr_to_drv == 0 || args->buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments.");
+        return OS_INVALID;
+    }
+
+    if (copy_from_user(&emon_buffer_size, args->buf_usr_to_drv, sizeof(U32))) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure");
+        return OS_FAULT;
+    }
+    prev_counter_size     = emon_buffer_size;
+
+    if (!drv_cfg) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("drv_cfg not set!");
+        return OS_FAULT;
+    }
+    if (DRV_CONFIG_use_pcl(drv_cfg) == TRUE) {
+        SEP_DRV_LOG_FLOW_OUT("Success: using PCL.");
+        return OS_SUCCESS;
+    }
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Discarded: driver state is not IDLE!");
+        return OS_IN_PROGRESS;
+    }
+
+    for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+        ec = (EVENT_CONFIG)LWPMU_DEVICE_ec(&devices[core_to_dev_map[i]]);
+        CPU_STATE_trigger_count(&pcb[i])     = EVENT_CONFIG_em_factor(ec);
+        CPU_STATE_trigger_event_num(&pcb[i]) = EVENT_CONFIG_em_event_num(ec);
+    }
+
+    // set cur_device's total groups to max groups of all devices
+    max_groups_unc = 0;
+    for (i = num_core_devs; i < num_devices; i++) {
+        if (max_groups_unc < LWPMU_DEVICE_em_groups_count(&devices[i])) {
+            max_groups_unc = LWPMU_DEVICE_em_groups_count(&devices[i]);
+        }
+    }
+    // now go back and up total groups for all devices
+    if (DRV_CONFIG_emon_mode(drv_cfg) == TRUE) {
+        for (i = num_core_devs; i < num_devices; i++) {
+            if (LWPMU_DEVICE_em_groups_count(&devices[i]) < max_groups_unc) {
+                LWPMU_DEVICE_em_groups_count(&devices[i]) = max_groups_unc;
+            }
+        }
+    }
+
+    // allocate save/restore space before program the PMU
+    lwpmudrv_Allocate_Restore_Buffer();
+
+    // allocate uncore read buffers for SEP
+    if (unc_buf_init && !DRV_CONFIG_emon_mode(drv_cfg)) {
+        lwpmudrv_Allocate_Uncore_Buffer();
+    }
+
+    // must be done after pcb is created and before PMU is first written to
+    CONTROL_Invoke_Parallel(lwpmudrv_Init_Op, NULL);
+
+    for (i = num_core_devs; i < num_devices; i++) {
+        pcfg_unc     = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(&devices[i]);
+        dispatch_unc = LWPMU_DEVICE_dispatch(&devices[i]);
+        if (pcfg_unc && dispatch_unc && dispatch_unc->init) {
+            dispatch_unc->init((VOID *)&i);
+        }
+    }
+
+    // Allocate PEBS buffers
+    if (DRV_CONFIG_counting_mode(drv_cfg) == FALSE) {
+        PEBS_Allocate();
+    }
+
+    //
+    // Transfer the data into the PMU registers
+    //
+    CONTROL_Invoke_Parallel(lwpmudrv_Write_Op, NULL);
+
+    SEP_DRV_LOG_TRACE("IOCTL_Init_PMU - finished initial Write.");
+
+    if (DRV_CONFIG_counting_mode(drv_cfg) == TRUE || DRV_CONFIG_emon_mode(drv_cfg) == TRUE) {
+        if (!read_counter_info) {
+            read_counter_info = CONTROL_Allocate_Memory(emon_buffer_size);
+            if (!read_counter_info) {
+                SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure!");
+                return OS_NO_MEM;
+            }
+        }
+        if (!prev_counter_data) {
+            prev_counter_data = CONTROL_Allocate_Memory(emon_buffer_size);
+            if (!prev_counter_data) {
+                read_counter_info = CONTROL_Free_Memory(read_counter_info);
+                SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure!");
+                return OS_NO_MEM;
+            }
+        }
+        if (!emon_buffer_driver_helper) {
+            // allocate size = size of EMON_BUFFER_DRIVER_HELPER_NODE + the number of entries in core_index_to_thread_offset_map, which is num of cpu
+            emon_buffer_driver_helper = CONTROL_Allocate_Memory(sizeof(EMON_BUFFER_DRIVER_HELPER_NODE) + sizeof(U32) * GLOBAL_STATE_num_cpus(driver_state));
+            if (!emon_buffer_driver_helper) {
+                SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure!");
+                return OS_NO_MEM;
+            }
+        }
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d", status);
+    return status;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static void lwpmudrv_Read_MSR(pvoid param)
+ *
+ * @param param - pointer to the buffer to store the MSR counts
+ *
+ * @return none
+ *
+ * @brief
+ * @brief  Read the U64 value at address in buf_drv_to_usr and
+ * @brief  write the result into buf_usr_to_drv.
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Read_MSR (
+    PVOID param
+)
+{
+    U32       this_cpu;
+    MSR_DATA  this_node;
+    S64       reg_num;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    preempt_disable();
+    this_cpu  = CONTROL_THIS_CPU();
+    this_node = &msr_data[this_cpu];
+    reg_num = MSR_DATA_addr(this_node);
+
+    if (reg_num == 0) {
+        preempt_enable();
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Error: tried to read MSR 0");
+        return;
+    }
+
+    MSR_DATA_value(this_node) = (U64)SYS_Read_MSR((U32)MSR_DATA_addr(this_node));
+    preempt_enable();
+
+    SEP_DRV_LOG_TRACE_OUT("");
+
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Read_MSR_All_Cores(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Read the U64 value at address into buf_drv_to_usr and write
+ * @brief  the result into buf_usr_to_drv.
+ * @brief  Returns OS_SUCCESS if the read across all cores succeed,
+ * @brief  otherwise OS_FAULT.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Read_MSR_All_Cores (
+    IOCTL_ARGS    arg
+)
+{
+    U64            *val;
+    S32             reg_num;
+    S32             i;
+    MSR_DATA        node;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if ((arg->len_usr_to_drv != sizeof(U32))  || (arg->buf_usr_to_drv == NULL) || (arg->buf_drv_to_usr == NULL)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments!");
+        return OS_FAULT;
+    }
+
+    val     = (U64 *)arg->buf_drv_to_usr;
+    if (val == NULL)  {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("NULL buf_usr_to_drv!");
+        return OS_FAULT;
+    }
+
+    if (copy_from_user(&reg_num, arg->buf_usr_to_drv, sizeof(U32))) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure!");
+        return OS_FAULT;
+    }
+
+    msr_data = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state)*sizeof(MSR_DATA_NODE));
+    if (!msr_data) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure!");
+        return OS_NO_MEM;
+    }
+
+    for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+        node                = &msr_data[i];
+        MSR_DATA_addr(node) = reg_num;
+    }
+
+    CONTROL_Invoke_Parallel(lwpmudrv_Read_MSR, (VOID *)(size_t)0);
+
+    /* copy values to arg array? */
+    if (arg->len_drv_to_usr < GLOBAL_STATE_num_cpus(driver_state)) {
+        msr_data = CONTROL_Free_Memory(msr_data);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Not enough memory allocated in output buffer!");
+        return OS_FAULT;
+    }
+    for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+        node = &msr_data[i];
+        if (copy_to_user(&val[i], (U64*)&MSR_DATA_value(node), sizeof(U64))) {
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure!");
+            return OS_FAULT;
+        }
+    }
+
+    msr_data = CONTROL_Free_Memory(msr_data);
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static void lwpmudrv_Write_MSR(pvoid iaram)
+ *
+ * @param param - pointer to array containing the MSR address and the value to be written
+ *
+ * @return none
+ *
+ * @brief
+ * @brief  Read the U64 value at address in buf_drv_to_usr and
+ * @brief  write the result into buf_usr_to_drv.
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Write_MSR (
+    PVOID param
+)
+{
+    U32       this_cpu;
+    MSR_DATA  this_node;
+    U32       reg_num;
+    U64       val;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    preempt_disable();
+    this_cpu  = CONTROL_THIS_CPU();
+    this_node = &msr_data[this_cpu];
+    reg_num   = (U32)MSR_DATA_addr(this_node);
+    val       = (U64)MSR_DATA_value(this_node);
+    // don't attempt to write MSR 0
+    if (reg_num == 0) {
+        preempt_enable();
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Error: tried to write MSR 0!");
+        return;
+    }
+
+    SYS_Write_MSR(reg_num, val);
+    preempt_enable();
+
+    SEP_DRV_LOG_TRACE_OUT("");
+
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Write_MSR_All_Cores(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Read the U64 value at address into buf_usr_to_drv and write
+ * @brief  the result into buf_usr_to_drv.
+ * @brief  Returns OS_SUCCESS if the write across all cores succeed,
+ * @brief  otherwise OS_FAULT.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Write_MSR_All_Cores (
+    IOCTL_ARGS    arg
+)
+{
+    EVENT_REG_NODE  buf;
+    EVENT_REG       buf_usr_to_drv = &buf;
+    U32             reg_num;
+    U64             val;
+    S32             i;
+    MSR_DATA        node;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (arg->len_usr_to_drv < sizeof(EVENT_REG_NODE) || arg->buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments!");
+        return OS_FAULT;
+    }
+
+    if (copy_from_user(buf_usr_to_drv, arg->buf_usr_to_drv, sizeof(EVENT_REG_NODE))) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure!");
+        return OS_FAULT;
+    }
+    reg_num = (U32)EVENT_REG_reg_id(buf_usr_to_drv,0);
+    val     = (U64)EVENT_REG_reg_value(buf_usr_to_drv,0);
+
+    msr_data = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state)*sizeof(MSR_DATA_NODE));
+    if (!msr_data) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure");
+        return OS_NO_MEM;
+    }
+
+    for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+        node                 = &msr_data[i];
+        MSR_DATA_addr(node)  = reg_num;
+        MSR_DATA_value(node) = val;
+    }
+
+    CONTROL_Invoke_Parallel(lwpmudrv_Write_MSR, (VOID *)(size_t)0);
+
+    msr_data = CONTROL_Free_Memory(msr_data);
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static void lwpmudrv_Read_Data_Op(PVOID param)
+ *
+ * @param param   - dummy
+ *
+ * @return void
+ *
+ * @brief  Read all the core/uncore data counters at one shot
+ *
+ * <I>Special Notes</I>
+ */
+static void
+lwpmudrv_Read_Data_Op (
+    VOID*    param
+)
+{
+    U32         this_cpu = CONTROL_THIS_CPU();
+    DISPATCH    dispatch;
+    U32         dev_idx;
+    DEV_UNC_CONFIG pcfg_unc;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (devices == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Devices is null!");
+        return;
+    }
+    dev_idx = core_to_dev_map[this_cpu];
+    dispatch = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    if (dispatch != NULL && dispatch->read_data != NULL) {
+        dispatch->read_data(param);
+    }
+    for (dev_idx = num_core_devs; dev_idx < num_devices; dev_idx++) {
+        pcfg_unc      = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+        if (pcfg_unc == NULL) {
+            continue;
+        }
+        if (!(DRV_CONFIG_emon_mode(drv_cfg) || DRV_CONFIG_counting_mode(drv_cfg))) {
+            continue;
+        }
+        dispatch  = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+        if (dispatch == NULL) {
+            continue;
+        }
+        if (dispatch->read_data == NULL) {
+            continue;
+        }
+        dispatch->read_data((VOID*)&dev_idx);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Read_MSRs(IOCTL_ARG arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Read all the programmed data counters and accumulate them
+ * @brief  into a single buffer.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Read_MSRs (
+    IOCTL_ARGS    arg
+)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (arg->len_drv_to_usr == 0 || arg->buf_drv_to_usr == NULL ) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments.");
+        return OS_SUCCESS;
+    }
+    //
+    // Transfer the data in the PMU registers to the output buffer
+    //
+    if (!read_counter_info) {
+        read_counter_info = CONTROL_Allocate_Memory(arg->len_drv_to_usr);
+        if (!read_counter_info) {
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure");
+            return OS_NO_MEM;
+        }
+    }
+    if (!prev_counter_data) {
+        prev_counter_data = CONTROL_Allocate_Memory(arg->len_drv_to_usr);
+        if (!prev_counter_data) {
+            read_counter_info = CONTROL_Free_Memory(read_counter_info);
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure");
+            return OS_NO_MEM;
+        }
+    }
+    memset(read_counter_info, 0, arg->len_drv_to_usr);
+
+    CONTROL_Invoke_Parallel(lwpmudrv_Read_Data_Op, NULL);
+
+    if (copy_to_user(arg->buf_drv_to_usr, read_counter_info, arg->len_drv_to_usr)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure");
+        return OS_FAULT;
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static void lwpmudrv_Read_Metrics_Op(PVOID param)
+ *
+ * @param param   - dummy
+ *
+ * @return void
+ *
+ * @brief  Read metrics register IA32_PERF_METRICS to collect topdown metrics
+ *         from PMU
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Read_Metrics_Op (
+    PVOID param
+)
+{
+    U32                   this_cpu;
+    CPU_STATE             pcpu;
+    U32                   offset;
+    U32                   dev_idx;
+    DEV_CONFIG            pcfg;
+    DISPATCH              dispatch;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    this_cpu     = CONTROL_THIS_CPU();
+    pcpu         = &pcb[this_cpu];
+    dev_idx      = core_to_dev_map[this_cpu];
+    pcfg         = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    dispatch     = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    // The pmu metric will be append after core event at thread level (basically treat them as extra core events).
+    // Move the pointer to the end of the core event for this cpu index.
+    offset       = EMON_BUFFER_CORE_EVENT_OFFSET(EMON_BUFFER_DRIVER_HELPER_core_index_to_thread_offset_map(emon_buffer_driver_helper)[this_cpu],
+                                                 EMON_BUFFER_DRIVER_HELPER_core_num_events(emon_buffer_driver_helper));
+
+    if (!DEV_CONFIG_enable_perf_metrics(pcfg) || !DEV_CONFIG_emon_perf_metrics_offset(pcfg) ||
+        (CPU_STATE_current_group(pcpu) != 0)) {
+        return;
+    }
+
+    if (dispatch != NULL && dispatch->read_metrics != NULL) {
+        dispatch->read_metrics(read_counter_info + offset);
+        SEP_DRV_LOG_TRACE("Data read = %llu.", *(read_counter_info + offset));
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Read_Metrics(IOCTL_ARGS args)
+ *
+ * @param args   - pointer to IOCTL_ARGS_NODE structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Read metrics register on all cpus and accumulate them into the output
+ *         buffer
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Read_Metrics(
+    IOCTL_ARGS args
+)
+{
+    U32         this_cpu;
+    CPU_STATE   pcpu;
+    U32         offset;
+    U64        *p_buffer;
+    DEV_CONFIG  pcfg;
+    U32         idx;
+
+    SEP_DRV_LOG_FLOW_IN("Args: %p.", args);
+
+    this_cpu     = CONTROL_THIS_CPU();
+    pcpu         = &pcb[this_cpu];
+    p_buffer     = (U64*)(args->buf_drv_to_usr);
+
+    if (args->len_drv_to_usr == 0 || args->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_FLOW_OUT("Invalid parameters!");
+        return OS_SUCCESS;
+    }
+
+    if (!read_counter_info) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Read_counter_info is NULL!");
+        return OS_FAULT;
+    }
+
+    CONTROL_Invoke_Parallel(lwpmudrv_Read_Metrics_Op, NULL);
+    for (idx = 0; idx < num_core_devs; idx++) {
+        pcfg = LWPMU_DEVICE_pcfg(&devices[idx]);
+        offset = DEV_CONFIG_emon_perf_metrics_offset(pcfg);
+        if (!DEV_CONFIG_enable_perf_metrics(pcfg) || !offset ||
+            (CPU_STATE_current_group(pcpu) != 0)) {
+            continue;
+        }
+        p_buffer += offset;
+        if (copy_to_user((char*)p_buffer, read_counter_info+offset, (sizeof(U64)*num_packages*GLOBAL_STATE_num_cpus(driver_state)*DEV_CONFIG_num_perf_metrics(pcfg)))) {
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Failed copy_to_user for read_counter_info!");
+            return OS_FAULT;
+        }
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success.");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Read_Counters_And_Switch_Group(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Read / Store the counters and switch to the next valid group.
+ *
+ * <I>Special Notes</I>
+ *     This routine is called from the user mode code to handle the multiple group
+ *     situation.  10 distinct steps are taken:
+ *     Step 1:  Save the previous cpu's tsc
+ *     Step 2:  Read the current cpu's tsc
+ *     Step 3:  Pause the counting PMUs
+ *     Step 4:  Calculate the difference between the current and previous cpu's tsc
+ *     Step 5:  Save original buffer ptr and copy cpu's tsc into the output buffer
+ *              Increment the buffer position by number of CPU
+ *     Step 6:  Read the currently programmed data PMUs and copy the data into the output buffer
+ *              Restore the original buffer ptr.
+ *     Step 7:  Write the new group to the PMU
+ *     Step 8:  Write the new group to the PMU
+ *     Step 9:  Read the current cpu's tsc for next collection (so read MSRs time not included in report)
+ *     Step 10: Resume the counting PMUs
+ */
+static OS_STATUS
+lwpmudrv_Read_Counters_And_Switch_Group (
+    IOCTL_ARGS arg
+)
+{
+    U64           *p_buffer             = NULL;
+    char          *orig_r_buf_ptr       = NULL;
+    U64            orig_r_buf_len       = 0;
+    OS_STATUS      status               = OS_SUCCESS;
+    DRV_BOOL       enter_in_pause_state = 0;
+    U32            i                    = 0;
+#if !defined(CONFIG_PREEMPT_COUNT)
+    U64           *tmp                  = NULL;
+#endif
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (arg->buf_drv_to_usr == NULL || arg->len_drv_to_usr == 0) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments.");
+        return OS_FAULT;
+    }
+
+    if (!DRIVER_STATE_IN(GET_DRIVER_STATE(), STATE_BIT_RUNNING | STATE_BIT_PAUSED)) {
+        SEP_DRV_LOG_FLOW_OUT("'Success'/error: driver state is not RUNNING or PAUSED!");
+        return OS_SUCCESS;
+    }
+
+    if (GET_DRIVER_STATE() == DRV_STATE_PAUSED) {
+        enter_in_pause_state = 1;
+    }
+
+    // step 1
+#if !defined(CONFIG_PREEMPT_COUNT)
+    if (DRV_CONFIG_per_cpu_tsc(drv_cfg)) {
+        // swap cpu_tsc and prev_cpu_tsc, so that cpu_tsc is saved in prev_cpu_tsc.
+        tmp          = prev_cpu_tsc;
+        prev_cpu_tsc = cpu_tsc;
+        cpu_tsc      = tmp;
+    }
+    else
+#endif
+    prev_cpu_tsc[0] = cpu_tsc[0];
+
+    // step 2
+    // if per_cpu_tsc is not defined, read cpu0's tsc and save in var cpu_tsc[0]
+    // if per_cpu_tsc is defined, read all cpu's tsc and save in var cpu_tsc by lwpmudrv_Fill_TSC_Info
+#if !defined(CONFIG_PREEMPT_COUNT)
+    if (DRV_CONFIG_per_cpu_tsc(drv_cfg)) {
+        atomic_set(&read_now, GLOBAL_STATE_num_cpus(driver_state));
+        init_waitqueue_head(&read_tsc_now);
+        CONTROL_Invoke_Parallel(lwpmudrv_Fill_TSC_Info, (PVOID)(size_t)0);
+    }
+    else
+#endif
+        CONTROL_Invoke_Cpu (0, lwpmudrv_Read_Specific_TSC, &cpu_tsc[0]);
+
+    // step 3
+    // Counters should be frozen right after time stamped.
+    if (!enter_in_pause_state) {
+        status = lwpmudrv_Pause();
+    }
+
+    // step 4
+    if (DRV_CONFIG_per_cpu_tsc(drv_cfg)) {
+        for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+#if !defined(CONFIG_PREEMPT_COUNT)
+            diff_cpu_tsc[i] = cpu_tsc[i] - prev_cpu_tsc[i];
+#else
+            // if CONFIG_PREEMPT_COUNT is defined, means lwpmudrv_Fill_TSC_Info can not be run.
+            // return all cpu's tsc difference with cpu0's tsc difference instead
+            diff_cpu_tsc[i] = cpu_tsc[0] - prev_cpu_tsc[0];
+#endif
+        }
+    }
+    else {
+        diff_cpu_tsc[0] = cpu_tsc[0] - prev_cpu_tsc[0];
+    }
+
+    // step 5
+    orig_r_buf_ptr = arg->buf_drv_to_usr;
+    orig_r_buf_len = arg->len_drv_to_usr;
+
+    if (copy_to_user(arg->buf_drv_to_usr, diff_cpu_tsc, GLOBAL_STATE_num_cpus(driver_state) * sizeof(U64))) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure!");
+        return OS_FAULT;
+    }
+
+    p_buffer   = (U64 *)(arg->buf_drv_to_usr);
+    p_buffer   += GLOBAL_STATE_num_cpus(driver_state);
+    arg->buf_drv_to_usr = (char *)p_buffer;
+    arg->len_drv_to_usr -= GLOBAL_STATE_num_cpus(driver_state) * sizeof(U64);
+
+    // step 6
+    status = lwpmudrv_Read_MSRs(arg);
+
+    status = lwpmudrv_Read_Metrics(arg);
+
+    arg->buf_drv_to_usr = orig_r_buf_ptr;
+    arg->len_drv_to_usr = orig_r_buf_len;
+
+    // step 7
+    // for each processor, increment its current group number
+    lwpmudrv_Switch_To_Next_Group();
+
+    // step 8
+    CONTROL_Invoke_Parallel(lwpmudrv_Write_Op, NULL);
+
+    // step 9
+    // if per_cpu_tsc is defined, read all cpu's tsc and save in cpu_tsc for next run
+#if !defined(CONFIG_PREEMPT_COUNT)
+    if (DRV_CONFIG_per_cpu_tsc(drv_cfg)) {
+        atomic_set(&read_now, GLOBAL_STATE_num_cpus(driver_state));
+        init_waitqueue_head(&read_tsc_now);
+        CONTROL_Invoke_Parallel(lwpmudrv_Fill_TSC_Info, (PVOID)(size_t)0);
+    }
+    else
+#endif
+        CONTROL_Invoke_Cpu (0, lwpmudrv_Read_Specific_TSC, &cpu_tsc[0]);
+
+    // step 10
+    if (!enter_in_pause_state) {
+        status = lwpmudrv_Resume();
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d", status);
+    return status;
+}
+
+/*
+ * @fn  static OS_STATUS lwpmudrv_Read_And_Reset_Counters(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Read the current value of the counters, and reset them all to 0.
+ *
+ * <I>Special Notes</I>
+ *     This routine is called from the user mode code to handle the multiple group
+ *     situation. 9 distinct steps are taken:
+ *     Step 1: Save the previous cpu's tsc
+ *     Step 2: Read the current cpu's tsc
+ *     Step 3: Pause the counting PMUs
+ *     Step 4: Calculate the difference between the current and previous cpu's tsc
+ *     Step 5: Save original buffer ptr and copy cpu's tsc into the output buffer
+ *             Increment the buffer position by number of CPU
+ *     Step 6: Read the currently programmed data PMUs and copy the data into the output buffer
+ *             Restore the original buffer ptr.
+ *     Step 7: Write the new group to the PMU
+ *     Step 8: Read the current cpu's tsc for next collection (so read MSRs time not included in report)
+ *     Step 9: Resume the counting PMUs
+ */
+static OS_STATUS
+lwpmudrv_Read_And_Reset_Counters (
+    IOCTL_ARGS arg
+)
+{
+    U64           *p_buffer             = NULL;
+    char          *orig_r_buf_ptr       = NULL;
+    U64            orig_r_buf_len       = 0;
+    OS_STATUS      status               = OS_SUCCESS;
+    DRV_BOOL       enter_in_pause_state = 0;
+    U32            i                    = 0;
+#if !defined(CONFIG_PREEMPT_COUNT)
+    U64           *tmp                  = NULL;
+#endif
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (arg->buf_drv_to_usr == NULL || arg->len_drv_to_usr == 0) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments.");
+        return OS_FAULT;
+    }
+
+    if (!DRIVER_STATE_IN(GET_DRIVER_STATE(), STATE_BIT_RUNNING | STATE_BIT_PAUSED)) {
+        SEP_DRV_LOG_FLOW_OUT("'Success'/error: driver state is not RUNNING or PAUSED!");
+        return OS_SUCCESS;
+    }
+
+    if (GET_DRIVER_STATE() == DRV_STATE_PAUSED) {
+        enter_in_pause_state = 1;
+    }
+
+    // step 1
+#if !defined(CONFIG_PREEMPT_COUNT)
+    if (DRV_CONFIG_per_cpu_tsc(drv_cfg)) {
+        // swap cpu_tsc and prev_cpu_tsc, so that cpu_tsc is saved in prev_cpu_tsc.
+        tmp          = prev_cpu_tsc;
+        prev_cpu_tsc = cpu_tsc;
+        cpu_tsc      = tmp;
+    }
+    else
+#endif
+    prev_cpu_tsc[0] = cpu_tsc[0];
+
+    // step 2
+    // if per_cpu_tsc is not defined, read cpu0's tsc into var cpu_tsc[0]
+    // if per_cpu_tsc is defined, read all cpu's tsc into var cpu_tsc by lwpmudrv_Fill_TSC_Info
+#if !defined(CONFIG_PREEMPT_COUNT)
+    if (DRV_CONFIG_per_cpu_tsc(drv_cfg)) {
+        atomic_set(&read_now, GLOBAL_STATE_num_cpus(driver_state));
+        init_waitqueue_head(&read_tsc_now);
+        CONTROL_Invoke_Parallel(lwpmudrv_Fill_TSC_Info, (PVOID)(size_t)0);
+    }
+    else
+#endif
+        CONTROL_Invoke_Cpu (0, lwpmudrv_Read_Specific_TSC, &cpu_tsc[0]);
+
+    // step 3
+    // Counters should be frozen right after time stamped.
+    if (!enter_in_pause_state) {
+        status = lwpmudrv_Pause();
+    }
+
+    // step 4
+    if (DRV_CONFIG_per_cpu_tsc(drv_cfg)) {
+        for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+#if !defined(CONFIG_PREEMPT_COUNT)
+            diff_cpu_tsc[i] = cpu_tsc[i] - prev_cpu_tsc[i];
+#else
+            // if CONFIG_PREEMPT_COUNT is defined, means lwpmudrv_Fill_TSC_Info can not be run.
+            // return all cpu's tsc difference with cpu0's tsc difference instead
+            diff_cpu_tsc[i] = cpu_tsc[0] - prev_cpu_tsc[0];
+#endif
+        }
+    }
+    else {
+        diff_cpu_tsc[0] = cpu_tsc[0] - prev_cpu_tsc[0];
+    }
+
+    // step 5
+    orig_r_buf_ptr = arg->buf_drv_to_usr;
+    orig_r_buf_len = arg->len_drv_to_usr;
+
+    if (copy_to_user(arg->buf_drv_to_usr, diff_cpu_tsc, GLOBAL_STATE_num_cpus(driver_state) * sizeof(U64))) {
+        return OS_FAULT;
+    }
+
+    p_buffer   = (U64 *)(arg->buf_drv_to_usr);
+    p_buffer   += GLOBAL_STATE_num_cpus(driver_state);
+    arg->buf_drv_to_usr = (char *)p_buffer;
+    arg->len_drv_to_usr -= GLOBAL_STATE_num_cpus(driver_state) * sizeof(U64);
+
+    // step 6
+    status = lwpmudrv_Read_MSRs(arg);
+
+    status = lwpmudrv_Read_Metrics(arg);
+
+    arg->buf_drv_to_usr = orig_r_buf_ptr;
+    arg->len_drv_to_usr = orig_r_buf_len;
+
+    // step 7
+    CONTROL_Invoke_Parallel(lwpmudrv_Write_Op, NULL);
+
+    // step 8
+    // if per_cpu_tsc is defined, read all cpu's tsc and save in cpu_tsc for next run
+#if !defined(CONFIG_PREEMPT_COUNT)
+    if (DRV_CONFIG_per_cpu_tsc(drv_cfg)) {
+        atomic_set(&read_now, GLOBAL_STATE_num_cpus(driver_state));
+        init_waitqueue_head(&read_tsc_now);
+        CONTROL_Invoke_Parallel(lwpmudrv_Fill_TSC_Info, (PVOID)(size_t)0);
+    }
+    else
+#endif
+        CONTROL_Invoke_Cpu (0, lwpmudrv_Read_Specific_TSC, &cpu_tsc[0]);
+
+    // step 9
+    if (!enter_in_pause_state) {
+        status = lwpmudrv_Resume();
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d", status);
+    return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Set_Num_EM_Groups(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief Configure the event multiplexing group.
+ *
+ * <I>Special Notes</I>
+ *     None
+ */
+static OS_STATUS
+lwpmudrv_Set_EM_Config (
+    IOCTL_ARGS arg
+)
+{
+    EVENT_CONFIG ec;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: Driver state is not IDLE!");
+        return OS_IN_PROGRESS;
+    }
+
+    if (arg->buf_usr_to_drv == NULL || arg->len_usr_to_drv != sizeof(EVENT_CONFIG_NODE)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments.");
+        return OS_INVALID;
+    }
+
+    LWPMU_DEVICE_ec(&devices[cur_device]) = CONTROL_Allocate_Memory(sizeof(EVENT_CONFIG_NODE));
+    if (!LWPMU_DEVICE_ec(&devices[cur_device])) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for ec!");
+        return OS_NO_MEM;
+    }
+
+    if (copy_from_user(LWPMU_DEVICE_ec(&devices[cur_device]), arg->buf_usr_to_drv, sizeof(EVENT_CONFIG_NODE))) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure (event config)!");
+        return OS_FAULT;
+    }
+
+    ec = (EVENT_CONFIG)LWPMU_DEVICE_ec(&devices[cur_device]);
+    LWPMU_DEVICE_PMU_register_data(&devices[cur_device]) = CONTROL_Allocate_Memory(EVENT_CONFIG_num_groups(ec) *
+                                                                                   sizeof(VOID *));
+    if (!LWPMU_DEVICE_PMU_register_data(&devices[cur_device])) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for PMU_register_data!");
+        return OS_NO_MEM;
+    }
+
+    EVENTMUX_Initialize();
+
+    SEP_DRV_LOG_FLOW_OUT("OS_SUCCESS.");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Set_EM_Config_UNC(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Set the number of em groups in the global state node.
+ * @brief  Also, copy the EVENT_CONFIG struct that has been passed in,
+ * @brief  into a global location for now.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Set_EM_Config_UNC (
+    IOCTL_ARGS arg
+)
+{
+    EVENT_CONFIG    ec;
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: driver state is not IDLE!");
+        return OS_IN_PROGRESS;
+    }
+
+    // allocate memory
+    LWPMU_DEVICE_ec(&devices[cur_device]) = CONTROL_Allocate_Memory(sizeof(EVENT_CONFIG_NODE));
+    if (copy_from_user(LWPMU_DEVICE_ec(&devices[cur_device]), arg->buf_usr_to_drv, arg->len_usr_to_drv)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for LWPMU_device_ec!");
+        return OS_FAULT;
+    }
+    // configure num_groups from ec of the specific device
+    ec = (EVENT_CONFIG)LWPMU_DEVICE_ec(&devices[cur_device]);
+    SEP_DRV_LOG_TRACE("Num Groups UNCORE: %d.", EVENT_CONFIG_num_groups_unc(ec));
+    LWPMU_DEVICE_PMU_register_data(&devices[cur_device]) = CONTROL_Allocate_Memory(EVENT_CONFIG_num_groups_unc(ec) *
+                                                                                   sizeof(VOID *));
+    if (!LWPMU_DEVICE_PMU_register_data(&devices[cur_device])) {
+        LWPMU_DEVICE_ec(&devices[cur_device]) = CONTROL_Free_Memory(LWPMU_DEVICE_ec(&devices[cur_device]));
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for LWPMU_DEVICE_PMU_register_data");
+        return OS_NO_MEM;
+    }
+    LWPMU_DEVICE_em_groups_count(&devices[cur_device]) = 0;
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Configure_events(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Copies one group of events into kernel space at
+ * @brief  PMU_register_data[em_groups_count].
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Configure_Events (
+    IOCTL_ARGS arg
+)
+{
+    U32          group_id;
+    ECB          ecb;
+    U32          em_groups_count;
+    EVENT_CONFIG ec;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: driver state is not IDLE!");
+        return OS_IN_PROGRESS;
+    }
+
+    ec              = (EVENT_CONFIG)LWPMU_DEVICE_ec(&devices[cur_device]);
+    em_groups_count = LWPMU_DEVICE_em_groups_count(&devices[cur_device]);
+
+    if (em_groups_count >= EVENT_CONFIG_num_groups(ec)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: EM groups number exceeded initial configuration!");
+        return OS_INVALID;
+    }
+    if (arg->buf_usr_to_drv == NULL || arg->len_usr_to_drv < sizeof(ECB_NODE)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments.");
+        return OS_INVALID;
+    }
+
+    ecb = CONTROL_Allocate_Memory(arg->len_usr_to_drv);
+    if (!ecb) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for ecb!");
+        return OS_NO_MEM;
+    }
+    if (copy_from_user(ecb, arg->buf_usr_to_drv, arg->len_usr_to_drv)) {
+        CONTROL_Free_Memory(ecb);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for ecb data!");
+        return OS_FAULT;
+    }
+    group_id                    = ECB_group_id(ecb);
+
+    if (group_id >= EVENT_CONFIG_num_groups(ec)) {
+        CONTROL_Free_Memory(ecb);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Group_id is larger than total number of groups!");
+        return OS_INVALID;
+    }
+
+    LWPMU_DEVICE_PMU_register_data(&devices[cur_device])[group_id] = ecb;
+    LWPMU_DEVICE_em_groups_count(&devices[cur_device])             = group_id + 1;
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Configure_events_UNC(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Make a copy of the uncore registers that need to be programmed
+ * @brief  for the next event set used for event multiplexing
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Configure_Events_UNC (
+    IOCTL_ARGS arg
+)
+{
+    VOID              **PMU_register_data_unc;
+    S32               em_groups_count_unc;
+    ECB               ecb;
+    EVENT_CONFIG      ec_unc;
+    DEV_UNC_CONFIG    pcfg_unc;
+    U32               group_id = 0;
+    ECB               in_ecb   = NULL;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: driver state is not IDLE!");
+        return OS_IN_PROGRESS;
+    }
+
+    em_groups_count_unc = LWPMU_DEVICE_em_groups_count(&devices[cur_device]);
+    PMU_register_data_unc = LWPMU_DEVICE_PMU_register_data(&devices[cur_device]);
+    ec_unc                = LWPMU_DEVICE_ec(&devices[cur_device]);
+    pcfg_unc              = LWPMU_DEVICE_pcfg(&devices[cur_device]);
+
+    if (pcfg_unc == NULL || ec_unc == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Pcfg_unc or ec_unc NULL!");
+        return OS_INVALID;
+    }
+
+    if (em_groups_count_unc >= (S32)EVENT_CONFIG_num_groups_unc(ec_unc)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Uncore EM groups number exceeded initial configuration!");
+        return OS_INVALID;
+    }
+     if (arg->buf_usr_to_drv == NULL || arg->len_usr_to_drv < sizeof(ECB_NODE)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments.");
+        return OS_INVALID;
+    }
+
+    in_ecb = CONTROL_Allocate_Memory(arg->len_usr_to_drv);
+    if (!in_ecb) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for uncore ecb!");
+        return OS_NO_MEM;
+    }
+    if (copy_from_user(in_ecb, arg->buf_usr_to_drv, arg->len_usr_to_drv)) {
+        CONTROL_Free_Memory(in_ecb);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for uncore ecb data!");
+        return OS_FAULT;
+    }
+    group_id = ECB_group_id(in_ecb);
+
+    if (group_id >= EVENT_CONFIG_num_groups_unc(ec_unc)) {
+        CONTROL_Free_Memory(in_ecb);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Group_id is larger than total number of groups!");
+        return OS_INVALID;
+    }
+
+    PMU_register_data_unc[group_id] = in_ecb;
+    // at this point, we know the number of uncore events for this device,
+    // so allocate the results buffer per thread for uncore only for SEP event based uncore counting
+    ecb = PMU_register_data_unc[group_id];
+    if (ecb == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Encountered NULL ECB!");
+        return OS_INVALID;
+    }
+    LWPMU_DEVICE_num_events(&devices[cur_device]) = ECB_num_events(ecb);
+    LWPMU_DEVICE_em_groups_count(&devices[cur_device]) = group_id + 1;
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Set_Sample_Descriptors(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Set the number of descriptor groups in the global state node.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Set_Sample_Descriptors (
+    IOCTL_ARGS    arg
+)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: driver state is not IDLE!");
+        return OS_IN_PROGRESS;
+    }
+    if (arg->len_usr_to_drv != sizeof(U32) || arg->buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (Unknown size of Sample Descriptors!).");
+        return OS_INVALID;
+    }
+
+    desc_count = 0;
+    if (copy_from_user(&GLOBAL_STATE_num_descriptors(driver_state),
+                       arg->buf_usr_to_drv,
+                       sizeof(U32))) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure");
+        return OS_FAULT;
+    }
+
+    desc_data  = CONTROL_Allocate_Memory(GLOBAL_STATE_num_descriptors(driver_state) *
+                                                sizeof(VOID *));
+    if (desc_data == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for desc_data!");
+        return OS_NO_MEM;
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Configure_Descriptors(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ * @return OS_STATUS
+ *
+ * @brief Make a copy of the descriptors that need to be read in order
+ * @brief to configure a sample record.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Configure_Descriptors (
+    IOCTL_ARGS    arg
+)
+{
+    U32 uncopied;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: driver state is not IDLE!");
+        return OS_IN_PROGRESS;
+    }
+
+    if (desc_count >= GLOBAL_STATE_num_descriptors(driver_state)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Descriptor groups number exceeded initial configuration!");
+        return OS_INVALID;
+    }
+
+    if (arg->len_usr_to_drv == 0 || arg->buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arg value!");
+        return OS_INVALID;
+    }
+    if (desc_data == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("NULL desc_data!");
+        return OS_INVALID;
+    }
+    //
+    // First things first: Make a copy of the data for global use.
+    //
+    desc_data[desc_count] = CONTROL_Allocate_Memory(arg->len_usr_to_drv);
+    uncopied = copy_from_user(desc_data[desc_count], arg->buf_usr_to_drv, arg->len_usr_to_drv);
+    if (uncopied > 0) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Unable to copy desc_data from user!");
+        return OS_NO_MEM;
+    }
+    SEP_DRV_LOG_TRACE("Added descriptor # %d.", desc_count);
+    desc_count++;
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_LBR_Info(IOCTL_ARGS arg)
+ *
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ * @return OS_STATUS
+ *
+ * @brief Make a copy of the LBR information that is passed in.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_LBR_Info (
+    IOCTL_ARGS    arg
+)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: driver state is not IDLE!");
+        return OS_IN_PROGRESS;
+    }
+
+    if (cur_pcfg == NULL || DEV_CONFIG_collect_lbrs(cur_pcfg) == FALSE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("LBR capture has not been configured!");
+        return OS_INVALID;
+    }
+
+    if (arg->len_usr_to_drv == 0 || arg->buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments!");
+        return OS_INVALID;
+    }
+
+    //
+    // First things first: Make a copy of the data for global use.
+    //
+
+    LWPMU_DEVICE_lbr(&devices[cur_device]) = CONTROL_Allocate_Memory((int)arg->len_usr_to_drv);
+    if (!LWPMU_DEVICE_lbr(&devices[cur_device])) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Memory allocation failure for lbr!");
+        return OS_NO_MEM;
+    }
+
+    if (copy_from_user(LWPMU_DEVICE_lbr(&devices[cur_device]), arg->buf_usr_to_drv, arg->len_usr_to_drv)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for lbr struct!");
+        return OS_FAULT;
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+#define CR4_PCE  0x00000100    //Performance-monitoring counter enable RDPMC
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static void lwpmudrv_Set_CR4_PCE_Bit(PVOID param)
+ *
+ * @param param - dummy parameter
+ *
+ * @return NONE
+ *
+ * @brief Set CR4's PCE bit on the logical processor
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Set_CR4_PCE_Bit (
+    PVOID  param
+)
+{
+    U32 this_cpu;
+#if defined(DRV_IA32)
+    U32 prev_CR4_value = 0;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    // remember if RDPMC bit previously set
+    // and then enabled it
+    __asm__("movl %%cr4,%%eax\n\t"
+            "movl %%eax,%0\n\t"
+            "orl  %1,%%eax\n\t"
+            "movl %%eax,%%cr4\n\t"
+            :"=irg" (prev_CR4_value)
+            :"irg" (CR4_PCE)
+            :"eax");
+#endif
+#if defined(DRV_EM64T)
+    U64 prev_CR4_value = 0;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    // remember if RDPMC bit previously set
+    // and then enabled it
+    __asm__("movq %%cr4,%%rax\n\t"
+            "movq %%rax,%0\n\t"
+            "orq  %1,%%rax\n\t"
+            "movq %%rax,%%cr4"
+            :"=irg" (prev_CR4_value)
+            :"irg" (CR4_PCE)
+            :"rax");
+#endif
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    preempt_enable();
+
+    // if bit RDPMC bit was set before,
+    // set flag for when we clear it
+    if (prev_CR4_value & CR4_PCE) {
+        prev_set_CR4[this_cpu] = 1;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static void lwpmudrv_Clear_CR4_PCE_Bit(PVOID param)
+ *
+ * @param param - dummy parameter
+ *
+ * @return NONE
+ *
+ * @brief ClearSet CR4's PCE bit on the logical processor
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Clear_CR4_PCE_Bit (
+    PVOID  param
+)
+{
+    U32 this_cpu;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    preempt_enable();
+
+    // only clear the CR4 bit if it wasn't set
+    // before we started
+    if (prev_set_CR4 && !prev_set_CR4[this_cpu]) {
+#if defined(DRV_IA32)
+        __asm__("movl %%cr4,%%eax\n\t"
+                "andl %0,%%eax\n\t"
+                "movl %%eax,%%cr4\n"
+                :
+                :"irg" (~CR4_PCE)
+                :"eax");
+#endif
+#if defined(DRV_EM64T)
+        __asm__("movq %%cr4,%%rax\n\t"
+                "andq %0,%%rax\n\t"
+                "movq %%rax,%%cr4\n"
+                :
+                :"irg" (~CR4_PCE)
+                :"rax");
+#endif
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Start(void)
+ *
+ * @param none
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Local function that handles the LWPMU_IOCTL_START call.
+ * @brief  Set up the OS hooks for process/thread/load notifications.
+ * @brief  Write the initial set of MSRs.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Start (
+    VOID
+)
+{
+    OS_STATUS  status       = OS_SUCCESS;
+#if !defined(CONFIG_PREEMPT_COUNT)
+    U32        cpu_num;
+#endif
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (!CHANGE_DRIVER_STATE(STATE_BIT_IDLE, DRV_STATE_RUNNING)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: driver state is not IDLE!");
+        return OS_IN_PROGRESS;
+    }
+
+    if (drv_cfg == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("NULL drv_cfg!");
+        return OS_INVALID;
+    }
+
+    if (DRV_CONFIG_use_pcl(drv_cfg) == TRUE) {
+        if (DRV_CONFIG_start_paused(drv_cfg)) {
+            CHANGE_DRIVER_STATE(STATE_BIT_RUNNING, DRV_STATE_PAUSED);
+        }
+        SEP_DRV_LOG_FLOW_OUT("[PCL enabled] Early return value: %d", status);
+        return status;
+    }
+
+    prev_set_CR4 = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state) * sizeof(U8));
+    CONTROL_Invoke_Parallel(lwpmudrv_Set_CR4_PCE_Bit, (PVOID)(size_t)0);
+
+#if !defined(CONFIG_PREEMPT_COUNT)
+    atomic_set(&read_now, GLOBAL_STATE_num_cpus(driver_state));
+    init_waitqueue_head(&read_tsc_now);
+    CONTROL_Invoke_Parallel(lwpmudrv_Fill_TSC_Info, (PVOID)(size_t)0);
+#endif
+
+#if !defined(CONFIG_PREEMPT_COUNT)
+    for (cpu_num = 0; cpu_num < GLOBAL_STATE_num_cpus(driver_state); cpu_num++) {
+        if (CPU_STATE_offlined(&pcb[cpu_num])) {
+            cpu_tsc[cpu_num] = cpu_tsc[0];
+        }
+    }
+#else
+    UTILITY_Read_TSC(&cpu_tsc[0]);
+#endif
+
+    if (DRV_CONFIG_start_paused(drv_cfg)) {
+        CHANGE_DRIVER_STATE(STATE_BIT_RUNNING, DRV_STATE_PAUSED);
+    }
+    else {
+        CONTROL_Invoke_Parallel(lwpmudrv_Resume_Op, NULL);
+
+#if defined(BUILD_CHIPSET)
+        if (DRV_CONFIG_enable_chipset(drv_cfg) && cs_dispatch != NULL &&
+            cs_dispatch->start_chipset != NULL) {
+            cs_dispatch->start_chipset();
+        }
+#endif
+
+        EVENTMUX_Start();
+        lwpmudrv_Dump_Tracer ("start", 0);
+
+#if defined(BUILD_GFX)
+        SEP_DRV_LOG_TRACE("Enable_gfx=%d.", (int)DRV_CONFIG_enable_gfx(drv_cfg));
+        if (DRV_CONFIG_enable_gfx(drv_cfg)) {
+            GFX_Start();
+        }
+#endif
+        if (unc_buf_init) {
+            lwpmudrv_Uncore_Start_Timer();
+        }
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d", status);
+    return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Cleanup_Op(void)
+ *
+ * @param - none
+ *
+ * @return OS_STATUS
+ *
+ * @brief Clean up registers after collection
+ *
+ * <I>Special Notes</I>
+ */
+static VOID
+lwpmudrv_Cleanup_Op (
+    PVOID param
+)
+{
+    U32      this_cpu   = CONTROL_THIS_CPU();
+    U32      dev_idx    = core_to_dev_map[this_cpu];
+    DISPATCH dispatch   = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (dispatch != NULL && dispatch->cleanup != NULL) {
+        dispatch->cleanup(&dev_idx);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/*
+ * @fn lwpmudrv_Prepare_Stop();
+ *
+ * @param        NONE
+ * @return       OS_STATUS
+ *
+ * @brief  Local function that handles the DRV_OPERATION_STOP call.
+ * @brief  Cleans up the interrupt handler.
+ */
+static OS_STATUS
+lwpmudrv_Prepare_Stop (
+    VOID
+)
+{
+    S32 i;
+    S32 done                = FALSE;
+    S32 cpu_num;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_TERMINATING) {
+        if (!CHANGE_DRIVER_STATE(STATE_BIT_RUNNING | STATE_BIT_PAUSED, DRV_STATE_PREPARE_STOP)) {
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Unexpected driver state.");
+            return OS_INVALID;
+        }
+    }
+    else {
+        SEP_DRV_LOG_WARNING("Abnormal termination path.");
+    }
+
+    if (drv_cfg == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("drv_cfg is NULL!");
+        return OS_INVALID;
+    }
+
+    if (DRV_CONFIG_use_pcl(drv_cfg) == TRUE) {
+        SEP_DRV_LOG_FLOW_OUT("Success: using PCL");
+        return OS_SUCCESS;
+    }
+
+    for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+        CPU_STATE_accept_interrupt(&pcb[i]) = 0;
+    }
+    while (!done) {
+        done = TRUE;
+        for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+            if (atomic_read(&CPU_STATE_in_interrupt(&pcb[i]))) {
+                done = FALSE;
+            }
+        }
+    }
+    CONTROL_Invoke_Parallel(lwpmudrv_Pause_Op, NULL);
+
+    SEP_DRV_LOG_TRACE("Outside of all interrupts.");
+
+#if defined(BUILD_CHIPSET)
+    if (DRV_CONFIG_enable_chipset(drv_cfg)  &&
+        cs_dispatch != NULL              &&
+        cs_dispatch->stop_chipset != NULL ) {
+        cs_dispatch->stop_chipset();
+    }
+#endif
+
+#if defined(BUILD_GFX)
+    SEP_DRV_LOG_TRACE("Enable_gfx=%d.", (int)DRV_CONFIG_enable_gfx(drv_cfg));
+    if (DRV_CONFIG_enable_gfx(drv_cfg)) {
+        GFX_Stop();
+    }
+#endif
+
+    if (unc_buf_init) {
+        lwpmudrv_Uncore_Stop_Timer();
+    }
+
+    if (drv_cfg == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("drv_cfg is NULL!");
+        return OS_INVALID;
+    }
+
+    /*
+     * Clean up all the control registers
+     */
+    CONTROL_Invoke_Parallel(lwpmudrv_Cleanup_Op, (VOID *)NULL);
+    SEP_DRV_LOG_TRACE("Cleanup finished.");
+    lwpmudrv_Free_Restore_Buffer();
+
+    if (prev_set_CR4) {
+        CONTROL_Invoke_Parallel(lwpmudrv_Clear_CR4_PCE_Bit, (VOID *)(size_t)0);
+        prev_set_CR4 = CONTROL_Free_Memory(prev_set_CR4);
+    }
+
+#if defined(BUILD_CHIPSET)
+    if (DRV_CONFIG_enable_chipset(drv_cfg) &&
+        cs_dispatch && cs_dispatch->fini_chipset) {
+        cs_dispatch->fini_chipset();
+    }
+#endif
+
+    for (cpu_num = 0; cpu_num < GLOBAL_STATE_num_cpus(driver_state); cpu_num++) {
+        SEP_DRV_LOG_TRACE("# of PMU interrupts via NMI triggered on cpu%d: %u.", cpu_num, CPU_STATE_nmi_handled(&pcb[cpu_num]));
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success.");
+    return OS_SUCCESS;
+}
+
+/*
+ * @fn lwpmudrv_Finish_Stop();
+ *
+ * @param  NONE
+ * @return OS_STATUS
+ *
+ * @brief  Local function that handles the DRV_OPERATION_STOP call.
+ * @brief  Cleans up the interrupt handler.
+ */
+static OS_STATUS
+lwpmudrv_Finish_Stop (
+    VOID
+)
+{
+    OS_STATUS  status        = OS_SUCCESS;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_TERMINATING) {
+        if (!CHANGE_DRIVER_STATE(STATE_BIT_PREPARE_STOP, DRV_STATE_STOPPED)) {
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Unexpected driver state!");
+            return OS_FAULT;
+        }
+    }
+    else {
+        SEP_DRV_LOG_WARNING("Abnormal termination path.");
+    }
+
+    if (drv_cfg == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("drv_cfg is NULL!");
+        return OS_INVALID;
+    }
+
+    if (DRV_CONFIG_counting_mode(drv_cfg) == FALSE) {
+        if (GET_DRIVER_STATE() != DRV_STATE_TERMINATING) {
+            CONTROL_Invoke_Parallel(PEBS_Flush_Buffer, NULL);
+            /*
+             *  Make sure that the module buffers are not deallocated and that the module flush
+             *  thread has not been terminated.
+             */
+            if (GET_DRIVER_STATE() != DRV_STATE_TERMINATING) {
+                status = LINUXOS_Enum_Process_Modules(TRUE);
+            }
+            OUTPUT_Flush();
+        }
+        /*
+         * Clean up the interrupt handler via the IDT
+         */
+        CPUMON_Remove_Cpuhooks();
+        PEBS_Destroy();
+        EVENTMUX_Destroy();
+    }
+
+    if (DRV_CONFIG_enable_cp_mode(drv_cfg)) {
+        if (interrupt_counts) {
+            S32 idx, cpu;
+            for (cpu = 0; cpu < GLOBAL_STATE_num_cpus(driver_state); cpu++) {
+                for(idx = 0; idx < DRV_CONFIG_num_events(drv_cfg); idx++) {
+                    SEP_DRV_LOG_TRACE("Interrupt count: CPU %d, event %d = %lld.", cpu, idx, interrupt_counts[cpu * DRV_CONFIG_num_events(drv_cfg) + idx]);
+                }
+            }
+        }
+    }
+
+    read_counter_info         = CONTROL_Free_Memory(read_counter_info);
+    prev_counter_data         = CONTROL_Free_Memory(prev_counter_data);
+    emon_buffer_driver_helper = CONTROL_Free_Memory(emon_buffer_driver_helper);
+    lwpmudrv_Dump_Tracer ("stop", 0);
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d", status);
+    return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Get_Normalized_TSC(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Return the current value of the normalized TSC.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Get_Normalized_TSC (
+    IOCTL_ARGS arg
+)
+{
+    U64    tsc          = 0;
+    U64    this_cpu     = 0;
+    size_t size_to_copy = sizeof(U64);
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (arg->len_drv_to_usr != size_to_copy || arg->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Invalid arguments!");
+        return OS_INVALID;
+    }
+
+    preempt_disable();
+    UTILITY_Read_TSC(&tsc);
+    this_cpu = CONTROL_THIS_CPU();
+    tsc -= TSC_SKEW(CONTROL_THIS_CPU());
+    preempt_enable();
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,32)
+    if (drv_cfg && DRV_CONFIG_use_pcl(drv_cfg) == TRUE) {
+        preempt_disable();
+        tsc = cpu_clock(this_cpu);
+        preempt_enable();
+    }
+    else {
+#endif
+    tsc -= TSC_SKEW(this_cpu);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,32)
+    }
+#endif
+    if (copy_to_user(arg->buf_drv_to_usr, (VOID *)&tsc, size_to_copy)) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Memory copy failure!");
+        return OS_FAULT;
+    }
+    lwpmudrv_Dump_Tracer ("marker", tsc);
+
+    SEP_DRV_LOG_TRACE_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Get_Num_Cores(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Quickly return the (total) number of cpus in the system.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Get_Num_Cores (
+    IOCTL_ARGS   arg
+)
+{
+    OS_STATUS status = OS_SUCCESS;
+    S32 num = GLOBAL_STATE_num_cpus(driver_state);
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (arg->len_drv_to_usr != sizeof(S32) || arg->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Invalid arguments.");
+        return OS_INVALID;
+    }
+
+    SEP_DRV_LOG_TRACE("Num_Cores is %d, buf_usr_to_drv is 0x%p.", num, arg->buf_drv_to_usr);
+    status = put_user(num, (S32*)arg->buf_drv_to_usr);
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d", status);
+    return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Set_CPU_Mask(PVOID buf_usr_to_drv, U32 len_usr_to_drv)
+ *
+ * @param buf_usr_to_drv   - pointer to the CPU mask buffer
+ * @param len_usr_to_drv   - size of the CPU mask buffer
+ *
+ * @return OS_STATUS
+ *
+ * @brief  process the CPU mask as requested by the user
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Set_CPU_Mask (
+    PVOID         buf_usr_to_drv,
+    size_t        len_usr_to_drv
+)
+{
+    U32     cpu_count     = 0;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: driver state is not IDLE!");
+        return OS_IN_PROGRESS;
+    }
+
+    if (len_usr_to_drv == 0 || buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("len_usr_to_drv == 0 or buf_usr_to_drv is NULL!");
+        return OS_INVALID;
+    }
+
+    cpu_mask_bits = CONTROL_Allocate_Memory((int)len_usr_to_drv);
+    if (!cpu_mask_bits) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for cpu_mask_bits!");
+        return OS_NO_MEM;
+    }
+
+    if (copy_from_user(cpu_mask_bits, (S8*)buf_usr_to_drv, (int)len_usr_to_drv)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure!");
+        return OS_FAULT;
+    }
+
+    for (cpu_count = 0; cpu_count < (U32)GLOBAL_STATE_num_cpus(driver_state); cpu_count++) {
+        CPU_STATE_accept_interrupt(&pcb[cpu_count]) = cpu_mask_bits[cpu_count] ? 1 : 0;
+        CPU_STATE_initial_mask(&pcb[cpu_count    ]) = cpu_mask_bits[cpu_count] ? 1 : 0;
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Get_KERNEL_CS(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Return the value of the Kernel symbol KERNEL_CS.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Get_KERNEL_CS (
+    IOCTL_ARGS   arg
+)
+{
+    OS_STATUS status = OS_SUCCESS;
+    S32       num    = __KERNEL_CS;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (arg->len_drv_to_usr != sizeof(S32) || arg->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Invalid arguments.");
+        return OS_INVALID;
+    }
+
+    SEP_DRV_LOG_TRACE("__KERNEL_CS is %d, buf_usr_to_drv is 0x%p.", num, arg->buf_drv_to_usr);
+    status = put_user(num, (S32*)arg->buf_drv_to_usr);
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d.", status);
+    return status;
+}
+
+/*
+ * @fn lwpmudrv_Set_UID
+ *
+ * @param     IN   arg      - pointer to the output buffer
+ * @return   OS_STATUS
+ *
+ * @brief  Receive the value of the UID of the collector process.
+ */
+static OS_STATUS
+lwpmudrv_Set_UID (
+    IOCTL_ARGS   arg
+)
+{
+    OS_STATUS status = OS_SUCCESS;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (arg->len_usr_to_drv != sizeof(uid_t) || arg->buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Invalid arguments.");
+        return OS_INVALID;
+    }
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: driver state is not IDLE!");
+        return OS_IN_PROGRESS;
+    }
+
+    status = get_user(uid, (S32*)arg->buf_usr_to_drv);
+    SEP_DRV_LOG_TRACE("Uid is %d.", uid);
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d.", status);
+    return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Get_TSC_Skew_Info(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ * @brief  Return the current value of the TSC skew data
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Get_TSC_Skew_Info (
+    IOCTL_ARGS arg
+)
+{
+    S64    *skew_array;
+    size_t  skew_array_len;
+    S32     i;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    skew_array_len = GLOBAL_STATE_num_cpus(driver_state) * sizeof(U64);
+    if (arg->len_drv_to_usr < skew_array_len || arg->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Input buffer too small or NULL!");
+        return OS_INVALID;
+    }
+
+    if (!DRV_CONFIG_enable_cp_mode(drv_cfg) &&
+        GET_DRIVER_STATE() != DRV_STATE_STOPPED) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: cp_mode not enabled and driver is not STOPPED!");
+        return OS_IN_PROGRESS;
+    }
+
+    SEP_DRV_LOG_TRACE("Dispatched with len_drv_to_usr=%lld.", arg->len_drv_to_usr);
+
+    skew_array = CONTROL_Allocate_Memory(skew_array_len);
+    if (skew_array == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for skew_array!");
+        return OS_NO_MEM;
+    }
+
+    for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+        skew_array[i] = TSC_SKEW(i);
+    }
+
+    if (copy_to_user(arg->buf_drv_to_usr, skew_array, skew_array_len)) {
+        skew_array = CONTROL_Free_Memory(skew_array);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for skew_array!");
+        return OS_FAULT;
+    }
+
+    skew_array = CONTROL_Free_Memory(skew_array);
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Collect_Sys_Config(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Local function that handles the COLLECT_SYS_CONFIG call.
+ * @brief  Builds and collects the SYS_INFO data needed.
+ * @brief  Writes the result into the argument.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Collect_Sys_Config (
+    IOCTL_ARGS   arg
+)
+{
+    OS_STATUS  status = OS_SUCCESS;
+    U32 num;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    num = SYS_INFO_Build();
+
+    if (arg->len_drv_to_usr < sizeof(S32) || arg->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Invalid arguments.");
+        return OS_INVALID;
+    }
+
+    SEP_DRV_LOG_TRACE("Size of sys info is %d.", num);
+    status = put_user(num, (S32*)arg->buf_drv_to_usr);
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d", status);
+    return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Sys_Config(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Return the current value of the normalized TSC.
+ *
+ * @brief  Transfers the VTSA_SYS_INFO data back to the abstraction layer.
+ * @brief  The buf_usr_to_drv should have enough space to handle the transfer.
+ */
+static OS_STATUS
+lwpmudrv_Sys_Config (
+    IOCTL_ARGS   arg
+)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (arg->len_drv_to_usr == 0 || arg->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Invalid arguments.");
+        return OS_INVALID;
+    }
+
+    SYS_INFO_Transfer(arg->buf_drv_to_usr, arg->len_drv_to_usr);
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Samp_Read_Num_Of_Core_Counters(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Read memory mapped i/o physical location
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Samp_Read_Num_Of_Core_Counters (
+    IOCTL_ARGS   arg
+)
+{
+    U64           rax, rbx, rcx, rdx,num_basic_functions;
+    U32           val    = 0;
+    OS_STATUS     status = OS_SUCCESS;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (arg->len_drv_to_usr == 0 || arg->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Invalid arguments.");
+        return OS_INVALID;
+    }
+
+    UTILITY_Read_Cpuid(0x0,&num_basic_functions,&rbx, &rcx, &rdx);
+
+    if (num_basic_functions >= 0xA) {
+         UTILITY_Read_Cpuid(0xA,&rax,&rbx, &rcx, &rdx);
+         val    = ((U32)(rax >> 8)) & 0xFF;
+    }
+    status = put_user(val, (U32*)arg->buf_drv_to_usr);
+    SEP_DRV_LOG_TRACE("Num of counter is %d.",val);
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d.", status);
+    return status;
+}
+
+
+#if defined(BUILD_CHIPSET)
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static DRV_BOOL lwpmudrv_Is_Physical_Address_Free(U32 physical_addrss)
+ *
+ * @param physical_address - physical address
+ *
+ * @return DRV_BOOL
+ *
+ * @brief  Check if physical address is available
+ *
+ * <I>Special Notes</I>
+ */
+static DRV_BOOL
+lwpmudrv_Is_Physical_Address_Free (
+    U32 physical_address
+)
+{
+    U32 value;
+    U32 new_value;
+    U32 test_value;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_WARNING_TRACE_OUT("FALSE: driver state is not IDLE!");
+        return FALSE;
+    }
+	if (physical_address == 0) {
+        SEP_DRV_LOG_WARNING_TRACE_OUT("FALSE: is NULL!");
+        return FALSE;
+    }
+
+    // First attempt read
+    //
+    PCI_Read_From_Memory_Address(physical_address, &value);
+
+    // Value must be 0xFFFFFFFFF or there is NO chance
+    // that this memory location is available.
+    //
+    if (value != 0xFFFFFFFF) {
+        SEP_DRV_LOG_TRACE_OUT("FALSE: value is not 0xFFFFFFFF!");
+        return FALSE;
+    }
+
+    //
+    // Try to write a bit to a zero (this probably
+    // isn't too safe, but this is just for testing)
+    //
+    new_value = 0xFFFFFFFE;
+    PCI_Write_To_Memory_Address(physical_address, new_value);
+    PCI_Read_From_Memory_Address(physical_address, &test_value);
+
+    // Write back original
+    PCI_Write_To_Memory_Address(physical_address, value);
+
+    if (new_value == test_value) {
+        // The write appeared to change the
+        // memory, it must be mapped already
+        //
+        SEP_DRV_LOG_TRACE_OUT("FALSE: appears to be mapped already!");
+        return FALSE;
+    }
+
+    if (test_value == 0xFFFFFFFF) {
+        // The write did not change the bit, so
+        // apparently, this memory must not be mapped
+        // to anything.
+        //
+        SEP_DRV_LOG_TRACE_OUT("TRUE: appears not to be mapped!");
+        return TRUE;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("FALSE: Odd case!");
+    return FALSE;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Samp_Find_Physical_Address(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Find a free physical address
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Samp_Find_Physical_Address (
+    IOCTL_ARGS    arg
+)
+{
+    CHIPSET_PCI_SEARCH_ADDR_NODE user_addr;
+    CHIPSET_PCI_SEARCH_ADDR      search_addr;
+    U32                          addr;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    search_addr = (CHIPSET_PCI_SEARCH_ADDR)arg->buf_usr_to_drv;
+
+     if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: driver state is not IDLE.");
+        return OS_IN_PROGRESS;
+    }
+
+    if (arg->len_drv_to_usr == 0 || arg->buf_drv_to_usr == NULL ||
+        arg->len_usr_to_drv == 0 || arg->buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments!");
+        return OS_INVALID;
+    }
+
+    if (!search_addr) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Search_addr is NULL!");
+        return OS_FAULT;
+    }
+
+    if (!access_ok(VERIFY_WRITE, search_addr, sizeof(CHIPSET_PCI_SEARCH_ADDR_NODE))) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Access not OK!");
+        return OS_FAULT;
+    }
+
+    if (copy_from_user(&user_addr, search_addr, sizeof(CHIPSET_PCI_SEARCH_ADDR_NODE))) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Memory copy failure for search_addr!");
+        return OS_FAULT;
+    }
+
+    if (CHIPSET_PCI_SEARCH_ADDR_start(&user_addr) > CHIPSET_PCI_SEARCH_ADDR_stop(&user_addr)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("SEARCH_ADDR_start > SEARCH_ADDR_stop!");
+        return OS_INVALID;
+    }
+
+    CHIPSET_PCI_SEARCH_ADDR_address(&user_addr) = 0;
+
+    for (addr = CHIPSET_PCI_SEARCH_ADDR_start(&user_addr);
+        addr <= CHIPSET_PCI_SEARCH_ADDR_stop(&user_addr);
+        addr += CHIPSET_PCI_SEARCH_ADDR_increment(&user_addr)) {
+        SEP_DRV_LOG_TRACE("Addr=%x:", addr);
+        if (lwpmudrv_Is_Physical_Address_Free(addr)) {
+            CHIPSET_PCI_SEARCH_ADDR_address(&user_addr) = addr;
+            break;
+        }
+    }
+
+    if (copy_to_user(arg->buf_drv_to_usr, (VOID *) &user_addr, sizeof(CHIPSET_PCI_SEARCH_ADDR_NODE))) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Memory copy failure for user_addr!");
+        return OS_FAULT;
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Samp_Read_PCI_Config(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Read the PCI Configuration Space
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Samp_Read_PCI_Config (
+    IOCTL_ARGS    arg
+)
+{
+    CHIPSET_PCI_CONFIG      rd_pci = NULL;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (arg->len_drv_to_usr == 0 || arg->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments!");
+        return OS_FAULT;
+    }
+
+    rd_pci = CONTROL_Allocate_Memory(arg->len_drv_to_usr);
+    if (rd_pci == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for rd_pci!");
+        return OS_NO_MEM;
+    }
+
+    if (copy_from_user(rd_pci, (CHIPSET_PCI_CONFIG)arg->buf_usr_to_drv, sizeof(CHIPSET_PCI_CONFIG_NODE))) {
+        CONTROL_Free_Memory(rd_pci);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for rd_pci!");
+        return OS_FAULT;
+    }
+
+    CHIPSET_PCI_CONFIG_value(rd_pci) = PCI_Read_U32(CHIPSET_PCI_CONFIG_bus(rd_pci),
+                                                    CHIPSET_PCI_CONFIG_device(rd_pci),
+                                                    CHIPSET_PCI_CONFIG_function(rd_pci),
+                                                    CHIPSET_PCI_CONFIG_offset(rd_pci));
+
+    if (copy_to_user(arg->buf_drv_to_usr, (VOID *) rd_pci, sizeof(CHIPSET_PCI_CONFIG_NODE))) {
+        CONTROL_Free_Memory(rd_pci);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for rd_pci!");
+        return OS_FAULT;
+    }
+
+    SEP_DRV_LOG_TRACE("Value at this PCI address:0x%x.",
+                    CHIPSET_PCI_CONFIG_value(rd_pci));
+
+    CONTROL_Free_Memory(rd_pci);
+
+    SEP_DRV_LOG_FLOW_OUT("Success.");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Samp_Write_PCI_Config(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Write to the PCI Configuration Space
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Samp_Write_PCI_Config (
+    IOCTL_ARGS    arg
+)
+{
+    CHIPSET_PCI_CONFIG wr_pci = NULL;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    // the following allows "sep -el -pc" to work, since the command must access the
+    // the driver ioctls before driver is used for a collection
+
+    if (!DRIVER_STATE_IN(GET_DRIVER_STATE(), STATE_BIT_UNINITIALIZED | STATE_BIT_IDLE)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: Driver state is not IDLE or UNINITIALIZED!");
+        return OS_IN_PROGRESS;
+    }
+
+    if (arg->len_usr_to_drv == 0 || arg->buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments!");
+        return OS_INVALID;
+    }
+
+    wr_pci = CONTROL_Allocate_Memory(arg->len_usr_to_drv);
+    if (wr_pci == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for wr_pci!");
+        return OS_NO_MEM;
+    }
+    if (copy_from_user(wr_pci, (CHIPSET_PCI_CONFIG)arg->buf_usr_to_drv, sizeof(CHIPSET_PCI_CONFIG_NODE))) {
+        CONTROL_Free_Memory(wr_pci);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for wr_pci!");
+        return OS_FAULT;
+    }
+
+    PCI_Write_U32(CHIPSET_PCI_CONFIG_bus(wr_pci),
+                  CHIPSET_PCI_CONFIG_device(wr_pci),
+                  CHIPSET_PCI_CONFIG_function(wr_pci),
+                  CHIPSET_PCI_CONFIG_offset(wr_pci),
+                  CHIPSET_PCI_CONFIG_value(wr_pci));
+
+    CONTROL_Free_Memory(wr_pci);
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Samp_Chipset_Init(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Initialize the chipset cnfiguration
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Samp_Chipset_Init (
+    IOCTL_ARGS    arg
+)
+{
+    PVOID         buf_usr_to_drv;
+    U32           len_usr_to_drv;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    buf_usr_to_drv = arg->buf_usr_to_drv;
+    len_usr_to_drv = arg->len_usr_to_drv;
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: driver state is not IDLE!");
+        return OS_IN_PROGRESS;
+    }
+
+    if (buf_usr_to_drv == NULL || len_usr_to_drv == 0) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Invalid arguments!");
+        return OS_INVALID;
+    }
+
+    // First things first: Make a copy of the data for global use.
+    pma = CONTROL_Allocate_Memory(len_usr_to_drv);
+
+    if (pma == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for pma!");
+        return OS_NO_MEM;
+    }
+
+    if (copy_from_user(pma, buf_usr_to_drv, len_usr_to_drv)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for pma!");
+        return OS_FAULT;
+    }
+
+#if defined(MY_DEBUG)
+
+    SEP_DRV_LOG_TRACE("Chipset Configuration follows...");
+    SEP_DRV_LOG_TRACE("pma->length=%d.", CHIPSET_CONFIG_length(pma));
+    SEP_DRV_LOG_TRACE("pma->version=%d.", CHIPSET_CONFIG_major_version(pma));
+    SEP_DRV_LOG_TRACE("pma->processor=%d.", CHIPSET_CONFIG_processor(pma));
+    SEP_DRV_LOG_TRACE("pma->mch_chipset=%d.", CHIPSET_CONFIG_mch_chipset(pma));
+    SEP_DRV_LOG_TRACE("pma->ich_chipset=%d.", CHIPSET_CONFIG_ich_chipset(pma));
+    SEP_DRV_LOG_TRACE("pma->gmch_chipset=%d.", CHIPSET_CONFIG_gmch_chipset(pma));
+    SEP_DRV_LOG_TRACE("pma->mother_board_time=%d.", CHIPSET_CONFIG_motherboard_time(pma));
+    SEP_DRV_LOG_TRACE("pma->host_proc_run=%d.", CHIPSET_CONFIG_host_proc_run(pma));
+    SEP_DRV_LOG_TRACE("pma->noa_chipset=%d.", CHIPSET_CONFIG_noa_chipset(pma));
+    SEP_DRV_LOG_TRACE("pma->bnb_chipset=%d.", CHIPSET_CONFIG_bnb_chipset(pma));
+
+    if (CHIPSET_CONFIG_mch_chipset(pma)) {
+        SEP_DRV_LOG_TRACE("pma->mch->phys_add=0x%llx.", CHIPSET_SEGMENT_physical_address(&CHIPSET_CONFIG_mch(pma)));
+        SEP_DRV_LOG_TRACE("pma->mch->size=%d.", CHIPSET_SEGMENT_size(&CHIPSET_CONFIG_mch(pma)));
+        SEP_DRV_LOG_TRACE("pma->mch->num_counters=%d.", CHIPSET_SEGMENT_num_counters(&CHIPSET_CONFIG_mch(pma)));
+        SEP_DRV_LOG_TRACE("pma->mch->total_events=%d.", CHIPSET_SEGMENT_total_events(&CHIPSET_CONFIG_mch(pma)));
+    }
+
+    if (CHIPSET_CONFIG_ich_chipset(pma)) {
+        SEP_DRV_LOG_TRACE("pma->ich->phys_add=0x%llx.", CHIPSET_SEGMENT_physical_address(&CHIPSET_CONFIG_ich(pma)));
+        SEP_DRV_LOG_TRACE("pma->ich->size=%d.", CHIPSET_SEGMENT_size(&CHIPSET_CONFIG_ich(pma)));
+        SEP_DRV_LOG_TRACE("pma->ich->num_counters=%d.", CHIPSET_SEGMENT_num_counters(&CHIPSET_CONFIG_ich(pma)));
+        SEP_DRV_LOG_TRACE("pma->ich->total_events=%d.", CHIPSET_SEGMENT_total_events(&CHIPSET_CONFIG_ich(pma)));
+    }
+
+    if (CHIPSET_CONFIG_gmch_chipset(pma)) {
+        SEP_DRV_LOG_TRACE("pma->gmch->phys_add=0x%llx.", CHIPSET_SEGMENT_physical_address(&CHIPSET_CONFIG_gmch(pma)));
+        SEP_DRV_LOG_TRACE("pma->gmch->size=%d.", CHIPSET_SEGMENT_size(&CHIPSET_CONFIG_gmch(pma)));
+        SEP_DRV_LOG_TRACE("pma->gmch->num_counters=%d.", CHIPSET_SEGMENT_num_counters(&CHIPSET_CONFIG_gmch(pma)));
+        SEP_DRV_LOG_TRACE("pma->gmch->total_events=%d.", CHIPSET_SEGMENT_total_events(&CHIPSET_CONFIG_gmch(pma)));
+        SEP_DRV_LOG_TRACE("pma->gmch->read_register=0x%x.", CHIPSET_SEGMENT_read_register(&CHIPSET_CONFIG_gmch(pma)));
+        SEP_DRV_LOG_TRACE("pma->gmch->write_register=0x%x.", CHIPSET_SEGMENT_write_register(&CHIPSET_CONFIG_gmch(pma)));
+    }
+
+#endif
+
+    // Set up the global cs_dispatch table
+    cs_dispatch = UTILITY_Configure_Chipset();
+    if (cs_dispatch == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Unknown chipset family!");
+        return OS_INVALID;
+    }
+
+    // Initialize chipset configuration
+    if (cs_dispatch->init_chipset()) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Failed to initialize the chipset!");
+        return OS_INVALID;
+    }
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+#endif
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Get_Platform_Info(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief       Reads the MSR_PLATFORM_INFO register if present
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Get_Platform_Info (
+    IOCTL_ARGS args
+)
+{
+    U32                    size          = sizeof(DRV_PLATFORM_INFO_NODE);
+    OS_STATUS              status        = OS_SUCCESS;
+    DRV_PLATFORM_INFO      platform_data = NULL;
+    U32                   *dispatch_ids  = NULL;
+    DISPATCH               dispatch_ptr  = NULL;
+    U32                    i             = 0;
+    U32                    num_entries; // # dispatch ids to process
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    num_entries   = args->len_usr_to_drv/sizeof(U32); // # dispatch ids to process
+
+    platform_data = CONTROL_Allocate_Memory(sizeof(DRV_PLATFORM_INFO_NODE));
+    if (!platform_data) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for platform_data!");
+        return OS_NO_MEM;
+    }
+
+    memset(platform_data, 0, sizeof(DRV_PLATFORM_INFO_NODE));
+    if (args->len_usr_to_drv > 0 && args->buf_usr_to_drv != NULL) {
+        dispatch_ids = CONTROL_Allocate_Memory(args->len_usr_to_drv);
+        if (!dispatch_ids) {
+            platform_data = CONTROL_Free_Memory(platform_data);
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for dispatch_ids!");
+            return OS_NO_MEM;
+        }
+
+        status = copy_from_user(dispatch_ids, args->buf_usr_to_drv, args->len_usr_to_drv);
+        if (status) {
+            platform_data = CONTROL_Free_Memory(platform_data);
+            dispatch_ids = CONTROL_Free_Memory(dispatch_ids);
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for dispatch_ids!");
+            return status;
+        }
+        for (i = 0; i < num_entries; i++) {
+            if (dispatch_ids[i] > 0) {
+                dispatch_ptr = UTILITY_Configure_CPU(dispatch_ids[i]);
+                if (dispatch_ptr &&
+                    dispatch_ptr->platform_info) {
+                    dispatch_ptr->platform_info((PVOID)platform_data);
+                }
+            }
+        }
+        dispatch_ids = CONTROL_Free_Memory(dispatch_ids);
+    }
+    else if (devices) {
+        dispatch_ptr = LWPMU_DEVICE_dispatch(&devices[0]);  //placeholder, needs to be fixed
+        if (dispatch_ptr && dispatch_ptr->platform_info) {
+            dispatch_ptr->platform_info((PVOID)platform_data);
+        }
+    }
+
+    if (args->len_drv_to_usr < size || args->buf_drv_to_usr == NULL) {
+        platform_data = CONTROL_Free_Memory(platform_data);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Invalid arguments!");
+        return OS_FAULT;
+    }
+
+    status        = copy_to_user(args->buf_drv_to_usr, platform_data, size);
+    platform_data = CONTROL_Free_Memory(platform_data);
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d", status);
+    return status;
+}
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          void lwpmudrv_Setup_Cpu_Topology (value)
+ *
+ * @brief       Sets up the per CPU state structures
+ *
+ * @param       IOCTL_ARGS args
+ *
+ * @return      OS_STATUS
+ *
+ * <I>Special Notes:</I>
+ *              This function was added to support abstract dll creation.
+ */
+static OS_STATUS
+lwpmudrv_Setup_Cpu_Topology (
+    IOCTL_ARGS args
+)
+{
+    S32               cpu_num;
+    S32               iter;
+    DRV_TOPOLOGY_INFO drv_topology, dt;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Skipped: driver state is not IDLE!");
+        return OS_IN_PROGRESS;
+    }
+    if (args->len_usr_to_drv == 0 || args->buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Topology information has been misconfigured!");
+        return OS_INVALID;
+    }
+
+    drv_topology = CONTROL_Allocate_Memory(args->len_usr_to_drv);
+    if (drv_topology == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for drv_topology!");
+        return OS_NO_MEM;
+    }
+
+    if (copy_from_user(drv_topology, (DRV_TOPOLOGY_INFO)(args->buf_usr_to_drv), args->len_usr_to_drv)) {
+        drv_topology = CONTROL_Free_Memory(drv_topology);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for drv_topology!");
+        return OS_FAULT;
+    }
+    /*
+     *   Topology Initializations
+     */
+    num_packages = 0;
+    for (iter = 0; iter < GLOBAL_STATE_num_cpus(driver_state); iter++) {
+        dt                                         = &drv_topology[iter];
+        cpu_num                                    = DRV_TOPOLOGY_INFO_cpu_number(dt);
+        CPU_STATE_socket_master(&pcb[cpu_num])     = DRV_TOPOLOGY_INFO_socket_master(dt);
+        num_packages                              += CPU_STATE_socket_master(&pcb[cpu_num]);
+        CPU_STATE_core_master(&pcb[cpu_num])       = DRV_TOPOLOGY_INFO_core_master(dt);
+        CPU_STATE_thr_master(&pcb[cpu_num])        = DRV_TOPOLOGY_INFO_thr_master(dt);
+        CPU_STATE_core_type(&pcb[cpu_num])         = DRV_TOPOLOGY_INFO_cpu_core_type(dt);
+        CPU_STATE_cpu_module_num(&pcb[cpu_num])    = (U16)DRV_TOPOLOGY_INFO_cpu_module_num(&drv_topology[iter]);
+        CPU_STATE_cpu_module_master(&pcb[cpu_num]) = (U16)DRV_TOPOLOGY_INFO_cpu_module_master(&drv_topology[iter]);
+        CPU_STATE_system_master(&pcb[cpu_num])     = (iter)? 0 : 1;
+        SEP_DRV_LOG_TRACE("Cpu %d sm = %d cm = %d tm = %d.",
+                  cpu_num,
+                  CPU_STATE_socket_master(&pcb[cpu_num]),
+                  CPU_STATE_core_master(&pcb[cpu_num]),
+                  CPU_STATE_thr_master(&pcb[cpu_num]));
+    }
+    drv_topology = CONTROL_Free_Memory(drv_topology);
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Get_Num_Samples(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief       Returns the number of samples collected during the current
+ * @brief       sampling run
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Get_Num_Samples (
+    IOCTL_ARGS args
+)
+{
+    S32               cpu_num;
+    U64               samples = 0;
+    OS_STATUS         status;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (pcb == NULL) {
+        SEP_DRV_LOG_ERROR("PCB was not initialized.");
+        return OS_FAULT;
+    }
+
+    if (args->len_drv_to_usr == 0 || args->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Topology information has been misconfigured!");
+        return OS_INVALID;
+    }
+
+    for (cpu_num = 0; cpu_num < GLOBAL_STATE_num_cpus(driver_state); cpu_num++) {
+        samples += CPU_STATE_num_samples(&pcb[cpu_num]);
+
+        SEP_DRV_LOG_TRACE("Samples for cpu %d = %lld.",
+                        cpu_num,
+                        CPU_STATE_num_samples(&pcb[cpu_num]));
+    }
+    SEP_DRV_LOG_TRACE("Total number of samples %lld.", samples);
+    status = put_user(samples, (U64*)args->buf_drv_to_usr);
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d", status);
+    return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Set_Device_Num_Units(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief       Set the number of devices for the sampling run
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Set_Device_Num_Units (
+    IOCTL_ARGS args
+)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (GET_DRIVER_STATE() != DRV_STATE_IDLE) {
+        SEP_DRV_LOG_FLOW_OUT("'Success'/Skipped: driver state is not IDLE!");
+        return OS_SUCCESS;
+    }
+
+    if (args->len_usr_to_drv == 0 || args->buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Invalid arguments.");
+        return OS_INVALID;
+    }
+
+    if (copy_from_user(&(LWPMU_DEVICE_num_units(&devices[cur_device])),
+                       args->buf_usr_to_drv,
+                       sizeof(U32))) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for device num units!");
+        return OS_FAULT;
+    }
+    SEP_DRV_LOG_TRACE("LWP: num_units = %d cur_device = %d.",
+                    LWPMU_DEVICE_num_units(&devices[cur_device]),
+                    cur_device);
+    // on to the next device.
+    cur_device++;
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Get_Interval_Counts(IOCTL_ARGS arg)
+ *
+ * @param arg - Pointer to the IOCTL structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief       Returns the number of samples collected during the current
+ * @brief       sampling run
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS
+lwpmudrv_Get_Interval_Counts (
+    IOCTL_ARGS args
+)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (!DRV_CONFIG_enable_cp_mode(drv_cfg)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Not in CP mode!");
+        return OS_INVALID;
+    }
+    if (args->len_drv_to_usr == 0 || args->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Interval Counts information has been misconfigured!");
+        return OS_INVALID;
+    }
+    if (!interrupt_counts) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Interrupt_counts is NULL!");
+        return OS_INVALID;
+    }
+
+    if (copy_to_user(args->buf_drv_to_usr, interrupt_counts, args->len_drv_to_usr)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure!");
+        return OS_FAULT;
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U64 lwpmudrv_Set_Uncore_Topology_Info_And_Scan
+ *
+ * @brief       Reads the MSR_PLATFORM_INFO register if present
+ *
+ * @param arg   Pointer to the IOCTL structure
+ *
+ * @return      status
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static OS_STATUS
+lwpmudrv_Set_Uncore_Topology_Info_And_Scan (
+    IOCTL_ARGS args
+)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+    SEP_DRV_LOG_FLOW_OUT("Success [but did not do anything]");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U64 lwpmudrv_Get_Uncore_Topology
+ *
+ * @brief       Reads the MSR_PLATFORM_INFO register if present
+ *
+ * @param arg   Pointer to the IOCTL structure
+ *
+ * @return      status
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static OS_STATUS
+lwpmudrv_Get_Uncore_Topology (
+    IOCTL_ARGS args
+)
+{
+
+    U32                               dev;
+    static UNCORE_TOPOLOGY_INFO_NODE  req_uncore_topology;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (args->buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (buf_usr_to_drv is NULL)!");
+        return OS_INVALID;
+    }
+    if (args->len_usr_to_drv != sizeof(UNCORE_TOPOLOGY_INFO_NODE)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (unexpected len_usr_to_drv value)!");
+        return OS_INVALID;
+    }
+    if (args->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (buf_drv_to_usr is NULL)!");
+        return OS_INVALID;
+    }
+    if (args->len_drv_to_usr != sizeof(UNCORE_TOPOLOGY_INFO_NODE)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (unexpected len_drv_to_usr value)!");
+        return OS_INVALID;
+    }
+
+    memset((char *)&req_uncore_topology, 0, sizeof(UNCORE_TOPOLOGY_INFO_NODE));
+    if (copy_from_user(&req_uncore_topology, args->buf_usr_to_drv, args->len_usr_to_drv)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure!");
+        return OS_FAULT;
+    }
+
+    for (dev = 0; dev < MAX_DEVICES; dev++) {
+        // skip if user does not require to scan this device
+        if (!UNCORE_TOPOLOGY_INFO_device_scan(&req_uncore_topology, dev)) {
+            continue;
+        }
+        // skip if this device has been discovered
+        if (UNCORE_TOPOLOGY_INFO_device_scan(&uncore_topology, dev)) {
+            continue;
+        }
+        memcpy((U8 *)&(UNCORE_TOPOLOGY_INFO_device(&uncore_topology, dev)),
+               (U8 *)&(UNCORE_TOPOLOGY_INFO_device(&req_uncore_topology, dev)),
+               sizeof(UNCORE_PCIDEV_NODE));
+        UNC_COMMON_PCI_Scan_For_Uncore((VOID*)&dev, dev, NULL);
+    }
+
+    if (copy_to_user(args->buf_drv_to_usr, &uncore_topology, args->len_drv_to_usr)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure!");
+        return OS_FAULT;
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U64 lwpmudrv_Get_Platform_Topology
+ *
+ * @brief       Reads the MSR or PCI PLATFORM_INFO register if present
+ *
+ * @param arg   Pointer to the IOCTL structure
+ *
+ * @return      status
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static OS_STATUS
+lwpmudrv_Get_Platform_Topology (
+    IOCTL_ARGS args
+)
+{
+    U32 dev;
+    U32 num_topology_devices = 0;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (args->buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (buf_usr_to_drv is NULL)!");
+        return OS_INVALID;
+    }
+    if (args->len_usr_to_drv != sizeof(PLATFORM_TOPOLOGY_PROG_NODE)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (unexpected len_usr_to_drv value)!");
+        return OS_INVALID;
+    }
+    if (args->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (buf_drv_to_usr is NULL)!");
+        return OS_INVALID;
+    }
+    if (args->len_drv_to_usr != sizeof(PLATFORM_TOPOLOGY_PROG_NODE)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (unexpected len_drv_to_usr value)!");
+        return OS_INVALID;
+    }
+
+    memset((char *)&req_platform_topology_prog_node, 0, sizeof(PLATFORM_TOPOLOGY_PROG_NODE));
+    if (copy_from_user(&req_platform_topology_prog_node, args->buf_usr_to_drv, args->len_usr_to_drv)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for req_platform_topology_prog_node!");
+        return OS_FAULT;
+    }
+
+    num_topology_devices = PLATFORM_TOPOLOGY_PROG_num_devices(&req_platform_topology_prog_node);
+    for (dev = 0; dev < num_topology_devices; dev++) {
+        //skip if we have populated the register values already
+        if (PLATFORM_TOPOLOGY_PROG_topology_device_prog_valid(&platform_topology_prog_node, dev)) {
+            continue;
+        }
+        memcpy((U8 *)&(PLATFORM_TOPOLOGY_PROG_topology_device(&platform_topology_prog_node, dev)),
+               (U8 *)&(PLATFORM_TOPOLOGY_PROG_topology_device(&req_platform_topology_prog_node, dev)),
+               sizeof(PLATFORM_TOPOLOGY_DISCOVERY_NODE));
+        UNC_COMMON_Get_Platform_Topology(dev);
+    }
+
+    if (copy_to_user(args->buf_drv_to_usr, &platform_topology_prog_node, args->len_drv_to_usr)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for platform_topology_prog_node!");
+        return OS_FAULT;
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          OS_STATUS lwpmudrv_Flush(void)
+ *
+ * @brief       Flushes the current contents of sampling buffers
+ *
+ * @param     - none
+ *
+ * @return      status
+ *
+ * <I>Special Notes:</I>
+ */
+static OS_STATUS
+lwpmudrv_Flush (
+    VOID
+)
+{
+    OS_STATUS status = OS_FAULT;
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (!DRV_CONFIG_enable_cp_mode(drv_cfg)) {
+        SEP_DRV_LOG_ERROR("The flush failed. Continuous profiling, -cp, is not enabled!");
+        goto clean_return;
+    }
+
+    if (!DRIVER_STATE_IN(GET_DRIVER_STATE(), STATE_BIT_PAUSED)) {
+        SEP_DRV_LOG_ERROR("The flush failed. The driver should be paused!");
+        goto clean_return;
+    }
+
+    if (multi_pebs_enabled) {
+        CONTROL_Invoke_Parallel(PEBS_Flush_Buffer, NULL);
+    }
+
+    LINUXOS_Uninstall_Hooks();
+    LINUXOS_Enum_Process_Modules(TRUE);
+    status = OUTPUT_Flush();
+    LINUXOS_Install_Hooks();
+
+    clean_return:
+    SEP_DRV_LOG_FLOW_OUT("Status: %d.", status);
+    return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U64 lwpmudrv_Get_Driver_log
+ *
+ * @brief       Dumps the driver log
+ *
+ * @param arg   Pointer to the IOCTL structure
+ *
+ * @return      status
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static OS_STATUS
+lwpmudrv_Get_Driver_Log (
+    IOCTL_ARGS args
+)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (args->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (buf_drv_to_usr is NULL)!");
+        return OS_INVALID;
+    }
+    if (args->len_drv_to_usr < sizeof(*DRV_LOG())) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (unexpected len_drv_to_usr value)!");
+        return OS_INVALID;
+    }
+
+    if (copy_to_user(args->buf_drv_to_usr, DRV_LOG(), sizeof(*DRV_LOG()))) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure!");
+        return OS_FAULT;
+    }
+
+    SEP_DRV_LOG_DISAMBIGUATE(); // keeps the driver log's footprint unique (has the highest disambiguator field)
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U64 lwpmudrv_Control_Driver_log
+ *
+ * @brief       Sets or/and gets the driver log's configuration
+ *
+ * @param arg   Pointer to the IOCTL structure
+ *
+ * @return      status
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static OS_STATUS
+lwpmudrv_Control_Driver_Log (
+    IOCTL_ARGS args
+)
+{
+    DRV_LOG_CONTROL_NODE log_control;
+    U32                  i;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (args->buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (buf_usr_to_drv is NULL)!");
+        return OS_INVALID;
+    }
+    if (args->len_usr_to_drv < sizeof(log_control)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (unexpected len_usr_to_drv value)!");
+        return OS_INVALID;
+    }
+
+    if (copy_from_user(&log_control, args->buf_usr_to_drv, sizeof(log_control))) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure!");
+        return OS_FAULT;
+    }
+
+    if (DRV_LOG_CONTROL_command(&log_control) == DRV_LOG_CONTROL_COMMAND_ADJUST_VERBOSITY) {
+        for (i = 0; i < DRV_NB_LOG_CATEGORIES; i++) {
+            if (DRV_LOG_CONTROL_verbosities(&log_control)[i] == LOG_VERBOSITY_UNSET) {
+                SEP_DRV_LOG_TRACE("Current verbosity mask for '%s' is 0x%x",
+                    (UTILITY_Log_Category_Strings()[i]),
+                    ((U32) DRV_LOG_VERBOSITY(i)));
+                DRV_LOG_CONTROL_verbosities(&log_control)[i] = DRV_LOG_VERBOSITY(i);
+            }
+            else if (DRV_LOG_CONTROL_verbosities(&log_control)[i] == LOG_VERBOSITY_DEFAULT) {
+                U32 verbosity;
+                switch (i) {
+                    case DRV_LOG_CATEGORY_LOAD:
+                        verbosity = DRV_LOG_DEFAULT_LOAD_VERBOSITY;
+                        break;
+                    case DRV_LOG_CATEGORY_INIT:
+                        verbosity = DRV_LOG_DEFAULT_INIT_VERBOSITY;
+                        break;
+                    case DRV_LOG_CATEGORY_DETECTION:
+                        verbosity = DRV_LOG_DEFAULT_DETECTION_VERBOSITY;
+                        break;
+                    case DRV_LOG_CATEGORY_ERROR:
+                        verbosity = DRV_LOG_DEFAULT_ERROR_VERBOSITY;
+                        break;
+                    case DRV_LOG_CATEGORY_STATE_CHANGE:
+                        verbosity = DRV_LOG_DEFAULT_STATE_CHANGE_VERBOSITY;
+                        break;
+                    case DRV_LOG_CATEGORY_MARK:
+                        verbosity = DRV_LOG_DEFAULT_MARK_VERBOSITY;
+                        break;
+                    case DRV_LOG_CATEGORY_DEBUG:
+                        verbosity = DRV_LOG_DEFAULT_DEBUG_VERBOSITY;
+                        break;
+                    case DRV_LOG_CATEGORY_FLOW:
+                        verbosity = DRV_LOG_DEFAULT_FLOW_VERBOSITY;
+                        break;
+                    case DRV_LOG_CATEGORY_ALLOC:
+                        verbosity = DRV_LOG_DEFAULT_ALLOC_VERBOSITY;
+                        break;
+                    case DRV_LOG_CATEGORY_INTERRUPT:
+                        verbosity = DRV_LOG_DEFAULT_INTERRUPT_VERBOSITY;
+                        break;
+                    case DRV_LOG_CATEGORY_TRACE:
+                        verbosity = DRV_LOG_DEFAULT_TRACE_VERBOSITY;
+                        break;
+                    case DRV_LOG_CATEGORY_REGISTER:
+                        verbosity = DRV_LOG_DEFAULT_REGISTER_VERBOSITY;
+                        break;
+                    case DRV_LOG_CATEGORY_NOTIFICATION:
+                        verbosity = DRV_LOG_DEFAULT_NOTIFICATION_VERBOSITY;
+                        break;
+                    case DRV_LOG_CATEGORY_WARNING:
+                        verbosity = DRV_LOG_DEFAULT_WARNING_VERBOSITY;
+                        break;
+
+                    default:
+                        SEP_DRV_LOG_ERROR("Unspecified category '%s' when resetting to default!", UTILITY_Log_Category_Strings()[i]);
+                        verbosity = LOG_VERBOSITY_NONE;
+                        break;
+                }
+                SEP_DRV_LOG_INIT("Resetting verbosity mask for '%s' from 0x%x to 0x%x.",
+                    UTILITY_Log_Category_Strings()[i],
+                    (U32) DRV_LOG_VERBOSITY(i),
+                    verbosity);
+                DRV_LOG_VERBOSITY(i)                         = verbosity;
+                DRV_LOG_CONTROL_verbosities(&log_control)[i] = verbosity;
+            }
+            else {
+                SEP_DRV_LOG_INIT("Changing verbosity mask for '%s' from 0x%x to 0x%x.",
+                    UTILITY_Log_Category_Strings()[i],
+                    (U32) DRV_LOG_VERBOSITY(i),
+                    (U32) DRV_LOG_CONTROL_verbosities(&log_control)[i]);
+                DRV_LOG_VERBOSITY(i) = DRV_LOG_CONTROL_verbosities(&log_control)[i];
+            }
+        }
+
+        for (; i < DRV_MAX_NB_LOG_CATEGORIES; i++) {
+            DRV_LOG_CONTROL_verbosities(&log_control)[i] = LOG_VERBOSITY_UNSET;
+        }
+
+        if (copy_to_user(args->buf_drv_to_usr, &log_control, sizeof(log_control))) {
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure!");
+            return OS_FAULT;
+        }
+    }
+    else if (DRV_LOG_CONTROL_command(&log_control) == DRV_LOG_CONTROL_COMMAND_MARK) {
+        DRV_LOG_CONTROL_message(&log_control)[DRV_LOG_CONTROL_MAX_DATA_SIZE - 1] = 0;
+        SEP_DRV_LOG_MARK("Mark: '%s'.", DRV_LOG_CONTROL_message(&log_control));
+    }
+    else if (DRV_LOG_CONTROL_command(&log_control) == DRV_LOG_CONTROL_COMMAND_QUERY_SIZE) {
+        DRV_LOG_CONTROL_log_size(&log_control) = sizeof(*DRV_LOG());
+        SEP_DRV_LOG_TRACE("Driver log size is %u bytes.", DRV_LOG_CONTROL_log_size(&log_control));
+        if (copy_to_user(args->buf_drv_to_usr, &log_control, sizeof(log_control))) {
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure!");
+            return OS_FAULT;
+        }
+    }
+    else if (DRV_LOG_CONTROL_command(&log_control) == DRV_LOG_CONTROL_COMMAND_BENCHMARK) {
+        U32 nb_iterations = *(U32*)&DRV_LOG_CONTROL_message(&log_control);
+
+        SEP_DRV_LOG_INIT_IN("Starting benchmark (%u iterations)...", nb_iterations);
+        for (i = 0; i < nb_iterations; i++) {
+            (void) i;
+        }
+        SEP_DRV_LOG_INIT_OUT("Benchmark complete (%u/%u iterations).", i, nb_iterations);
+
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U64 lwpmudrv_Get_Drv_Setup_Info
+ *
+ * @brief       Get numerous information of driver
+ *
+ * @param arg   Pointer to the IOCTL structure
+ *
+ * @return      status
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static OS_STATUS
+lwpmudrv_Get_Drv_Setup_Info (
+    IOCTL_ARGS args
+)
+{
+#define VMM_VENDOR_STR_LEN 12
+    U32     pebs_unavailable = 0;
+    U64     rbx, rcx, rdx, num_basic_functions;
+    S8      vmm_vendor_name[VMM_VENDOR_STR_LEN+1];
+    S8     *vmm_vmware_str   = "VMwareVMware";
+    S8     *vmm_kvm_str      = "KVMKVMKVM\0\0\0";
+    S8     *vmm_mshyperv_str = "Microsoft Hv";
+#if defined(DRV_USE_KAISER)
+    int    *kaiser_enabled_ptr;
+#endif
+
+    SEP_DRV_LOG_FLOW_IN("Args: %p.", args);
+
+    if (args->buf_drv_to_usr == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (buf_drv_to_usr is NULL)!");
+        return OS_INVALID;
+    }
+    if (args->len_drv_to_usr != sizeof(DRV_SETUP_INFO_NODE)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Invalid arguments (unexpected len_drv_to_usr value)!");
+        return OS_INVALID;
+    }
+
+    memset((char *)&req_drv_setup_info, 0, sizeof(DRV_SETUP_INFO_NODE));
+
+    DRV_SETUP_INFO_nmi_mode(&req_drv_setup_info) = 1;
+
+    if (boot_cpu_has(X86_FEATURE_HYPERVISOR)) {
+        UTILITY_Read_Cpuid(0x40000000, &num_basic_functions, &rbx, &rcx, &rdx);
+        memcpy(vmm_vendor_name, &rbx, 4);
+        memcpy(vmm_vendor_name+4, &rcx, 4);
+        memcpy(vmm_vendor_name+8, &rdx, 4);
+        memcpy(vmm_vendor_name+12, "\0", 1);
+
+        if (!strncmp(vmm_vendor_name, vmm_vmware_str, VMM_VENDOR_STR_LEN)) {
+            DRV_SETUP_INFO_vmm_mode(&req_drv_setup_info)   = 1;
+            DRV_SETUP_INFO_vmm_vendor(&req_drv_setup_info) = DRV_VMM_VMWARE;
+        }
+        else if (!strncmp(vmm_vendor_name, vmm_kvm_str, VMM_VENDOR_STR_LEN)) {
+            DRV_SETUP_INFO_vmm_mode(&req_drv_setup_info)   = 1;
+            DRV_SETUP_INFO_vmm_vendor(&req_drv_setup_info) = DRV_VMM_KVM;
+        }
+        else if (!strncmp(vmm_vendor_name, vmm_mshyperv_str, VMM_VENDOR_STR_LEN)) {
+            DRV_SETUP_INFO_vmm_mode(&req_drv_setup_info)   = 1;
+            DRV_SETUP_INFO_vmm_vendor(&req_drv_setup_info) = DRV_VMM_HYPERV;
+            if (num_basic_functions >= 0x40000003) {
+                UTILITY_Read_Cpuid(0x40000003, &num_basic_functions, &rbx, &rcx, &rdx);
+                if (rbx & 0x1) {
+                    DRV_SETUP_INFO_vmm_guest_vm(&req_drv_setup_info) = 0;
+                }
+                else {
+                    DRV_SETUP_INFO_vmm_guest_vm(&req_drv_setup_info) = 1;
+                }
+            }
+        }
+    }
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,32)
+    else if (xen_domain()) {
+        DRV_SETUP_INFO_vmm_mode(&req_drv_setup_info)   = 1;
+        DRV_SETUP_INFO_vmm_vendor(&req_drv_setup_info) = DRV_VMM_XEN;
+
+        if (xen_initial_domain()) {
+            DRV_SETUP_INFO_vmm_guest_vm(&req_drv_setup_info) = 0;
+        }
+        else {
+            DRV_SETUP_INFO_vmm_guest_vm(&req_drv_setup_info) = 1;
+        }
+    }
+#endif
+    else {
+        if (LINUXOS_Check_KVM_Guest_Process()) {
+            DRV_SETUP_INFO_vmm_mode(&req_drv_setup_info) = 1;
+            DRV_SETUP_INFO_vmm_vendor(&req_drv_setup_info) = DRV_VMM_KVM;
+        }
+    }
+
+    pebs_unavailable = (SYS_Read_MSR(IA32_MISC_ENABLE) >> 12) & 0x1;
+    if (!pebs_unavailable) {
+        if (!wrmsr_safe(IA32_PEBS_ENABLE, 0, 0)) {
+            DRV_SETUP_INFO_pebs_accessible(&req_drv_setup_info) = 1;
+        }
+    }
+
+#if defined(DRV_USE_KAISER)
+    kaiser_enabled_ptr = (int*) UTILITY_Find_Symbol("kaiser_enabled");
+    if (kaiser_enabled_ptr && *kaiser_enabled_ptr) {
+        SEP_DRV_LOG_INIT("KAISER is enabled! (&kaiser_enable=%p, val: %d).", kaiser_enabled_ptr, *kaiser_enabled_ptr);
+        DRV_SETUP_INFO_page_table_isolation(&req_drv_setup_info) = DRV_SETUP_INFO_PTI_KAISER;
+    }
+    else {
+        if (!kaiser_enabled_ptr) {
+            SEP_DRV_LOG_ERROR("Could not find KAISER information. Assuming no KAISER!");
+        }
+        else {
+            SEP_DRV_LOG_INIT("KAISER is present but disabled!");
+        }
+    }
+#elif defined(DRV_USE_PTI)
+    if (static_cpu_has(X86_FEATURE_PTI)) {
+        SEP_DRV_LOG_INIT("Kernel Page Table Isolation is enabled!");
+        DRV_SETUP_INFO_page_table_isolation(&req_drv_setup_info) = DRV_SETUP_INFO_PTI_KPTI;
+    }
+#endif
+
+    SEP_DRV_LOG_TRACE("DRV_SETUP_INFO nmi_mode %d.", DRV_SETUP_INFO_nmi_mode(&req_drv_setup_info));
+    SEP_DRV_LOG_TRACE("DRV_SETUP_INFO vmm_mode %d.", DRV_SETUP_INFO_vmm_mode(&req_drv_setup_info));
+    SEP_DRV_LOG_TRACE("DRV_SETUP_INFO vmm_vendor %d.", DRV_SETUP_INFO_vmm_vendor(&req_drv_setup_info));
+    SEP_DRV_LOG_TRACE("DRV_SETUP_INFO vmm_guest_vm %d.", DRV_SETUP_INFO_vmm_guest_vm(&req_drv_setup_info));
+    SEP_DRV_LOG_TRACE("DRV_SETUP_INFO pebs_accessible %d.", DRV_SETUP_INFO_pebs_accessible(&req_drv_setup_info));
+    SEP_DRV_LOG_TRACE("DRV_SETUP_INFO page_table_isolation %d.", DRV_SETUP_INFO_page_table_isolation(&req_drv_setup_info));
+
+#if defined(DRV_CPU_HOTPLUG)
+    DRV_SETUP_INFO_cpu_hotplug_mode(&req_drv_setup_info) = 1;
+#endif
+
+    if (copy_to_user(args->buf_drv_to_usr, &req_drv_setup_info, args->len_drv_to_usr)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure!");
+        return OS_FAULT;
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success.");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U64 lwpmudrv_Set_Emon_Buffer_Driver_Helper
+ *
+ * @brief       Setup EMON buffer driver helper
+ *
+ * @param arg   Pointer to the IOCTL structure
+ *
+ * @return      status
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static OS_STATUS
+lwpmudrv_Set_Emon_Buffer_Driver_Helper (
+    IOCTL_ARGS args
+)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+
+    if (args->len_usr_to_drv == 0 || args->buf_usr_to_drv == NULL) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Invalid arguments.");
+        return OS_INVALID;
+    }
+
+    if (!emon_buffer_driver_helper) {
+        emon_buffer_driver_helper = CONTROL_Allocate_Memory(args->len_usr_to_drv);
+        if (emon_buffer_driver_helper == NULL) {
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for emon_buffer_driver_helper!");
+            return OS_NO_MEM;
+        }
+    }
+
+    if (copy_from_user(emon_buffer_driver_helper,
+                       args->buf_usr_to_drv,
+                       args->len_usr_to_drv)) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory copy failure for device num units!");
+        return OS_FAULT;
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("Success");
+    return OS_SUCCESS;
+}
+
+
+/*******************************************************************************
+ *  External Driver functions - Open
+ *      This function is common to all drivers
+ *******************************************************************************/
+
+static int
+lwpmu_Open (
+    struct inode *inode,
+    struct file  *filp
+)
+{
+    SEP_DRV_LOG_TRACE_IN("Maj:%d, min:%d", imajor(inode), iminor(inode));
+
+    filp->private_data = container_of(inode->i_cdev, LWPMU_DEV_NODE, cdev);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return 0;
+}
+
+/*******************************************************************************
+ *  External Driver functions
+ *      These functions are registered into the file operations table that
+ *      controls this device.
+ *      Open, Close, Read, Write, Release
+ *******************************************************************************/
+
+static ssize_t
+lwpmu_Read (
+    struct file  *filp,
+    char         *buf,
+    size_t        count,
+    loff_t       *f_pos
+)
+{
+    unsigned long retval;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    /* Transfering data to user space */
+    SEP_DRV_LOG_TRACE("Dispatched with count=%d.", (S32)count);
+    if (copy_to_user(buf, &LWPMU_DEV_buffer(lwpmu_control), 1)) {
+        retval = OS_FAULT;
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Memory copy failure!");
+        return retval;
+    }
+    /* Changing reading position as best suits */
+    if (*f_pos == 0) {
+        *f_pos+=1;
+        SEP_DRV_LOG_TRACE_OUT("Return value: 1.");
+        return 1;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Return value: 0.");
+    return 0;
+}
+
+static ssize_t
+lwpmu_Write (
+    struct file  *filp,
+    const  char  *buf,
+    size_t        count,
+    loff_t       *f_pos
+)
+{
+    unsigned long retval;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    SEP_DRV_LOG_TRACE("Dispatched with count=%d.", (S32)count);
+    if (copy_from_user(&LWPMU_DEV_buffer(lwpmu_control), buf+count-1, 1)) {
+        retval = OS_FAULT;
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Memory copy failure!");
+        return retval;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Return value: 1.");
+    return 1;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  extern IOCTL_OP_TYPE lwpmu_Service_IOCTL(IOCTL_USE_NODE, filp, cmd, arg)
+ *
+ * @param   IOCTL_USE_INODE       - Used for pre 2.6.32 kernels
+ * @param   struct   file   *filp - file pointer
+ * @param   unsigned int     cmd  - IOCTL command
+ * @param   unsigned long    arg  - args to the IOCTL command
+ *
+ * @return OS_STATUS
+ *
+ * @brief  SEP Worker function that handles IOCTL requests from the user mode.
+ *
+ * <I>Special Notes</I>
+ */
+extern IOCTL_OP_TYPE
+lwpmu_Service_IOCTL (
+    IOCTL_USE_INODE
+    struct   file   *filp,
+    unsigned int     cmd,
+    IOCTL_ARGS_NODE  local_args
+)
+{
+    int              status = OS_SUCCESS;
+
+    SEP_DRV_LOG_TRACE_IN("Command: %d.", cmd);
+
+    if (cmd ==  DRV_OPERATION_GET_DRIVER_STATE) {
+        SEP_DRV_LOG_TRACE("DRV_OPERATION_GET_DRIVER_STATE.");
+        status = lwpmudrv_Get_Driver_State(&local_args);
+        SEP_DRV_LOG_TRACE_OUT("Return value for command %d: %d", cmd, status);
+        return status;
+    }
+    if (cmd == DRV_OPERATION_GET_DRIVER_LOG) {
+        SEP_DRV_LOG_TRACE("DRV_OPERATION_GET_DRIVER_LOG.");
+        status = lwpmudrv_Get_Driver_Log(&local_args);
+        SEP_DRV_LOG_TRACE_OUT("Return value for command %d: %d", cmd, status);
+        return status;
+    }
+    if (cmd == DRV_OPERATION_CONTROL_DRIVER_LOG) {
+        SEP_DRV_LOG_TRACE("DRV_OPERATION_CONTROL_DRIVER_LOG.");
+        status = lwpmudrv_Control_Driver_Log(&local_args);
+        SEP_DRV_LOG_TRACE_OUT("Return value for command %d: %d", cmd, status);
+        return status;
+    }
+    if (GET_DRIVER_STATE() == DRV_STATE_PREPARE_STOP) {
+        SEP_DRV_LOG_TRACE("skipping ioctl -- processing stop.");
+        SEP_DRV_LOG_TRACE_OUT("Return value for command %d: %d", cmd, status);
+        return status;
+    }
+
+    MUTEX_LOCK(ioctl_lock);
+    UTILITY_Driver_Set_Active_Ioctl(cmd);
+
+    switch (cmd) {
+
+       /*
+        * Common IOCTL commands
+        */
+
+        case DRV_OPERATION_VERSION:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_VERSION.");
+            status = lwpmudrv_Version(&local_args);
+            break;
+
+        case DRV_OPERATION_RESERVE:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_RESERVE.");
+            status = lwpmudrv_Reserve(&local_args);
+            break;
+
+        case DRV_OPERATION_INIT_DRIVER:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_INIT_DRIVER.");
+            status = lwpmudrv_Initialize_Driver(local_args.buf_usr_to_drv, local_args.len_usr_to_drv);
+            break;
+
+        case DRV_OPERATION_INIT:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_INIT.");
+            status = lwpmudrv_Initialize(local_args.buf_usr_to_drv, local_args.len_usr_to_drv);
+            break;
+
+        case DRV_OPERATION_INIT_PMU:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_INIT_PMU.");
+            status = lwpmudrv_Init_PMU(&local_args);
+            break;
+
+        case DRV_OPERATION_SET_CPU_MASK:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_SET_CPU_MASK.");
+            status = lwpmudrv_Set_CPU_Mask(local_args.buf_usr_to_drv, local_args.len_usr_to_drv);
+            break;
+
+        case DRV_OPERATION_START:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_START.");
+            status = lwpmudrv_Start();
+            break;
+
+        case DRV_OPERATION_STOP:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_STOP.");
+            status = lwpmudrv_Prepare_Stop();
+            UTILITY_Driver_Set_Active_Ioctl(0);
+            MUTEX_UNLOCK(ioctl_lock);
+
+            MUTEX_LOCK(ioctl_lock);
+            UTILITY_Driver_Set_Active_Ioctl(cmd);
+            if (GET_DRIVER_STATE() == DRV_STATE_PREPARE_STOP) {
+                status = lwpmudrv_Finish_Stop();
+                if (status == OS_SUCCESS) {
+                    // if stop was successful, relevant memory should have been freed,
+                    // so try to compact the memory tracker
+                    CONTROL_Memory_Tracker_Compaction();
+                }
+            }
+            break;
+
+        case DRV_OPERATION_PAUSE:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_PAUSE.");
+            status = lwpmudrv_Pause();
+            break;
+
+        case DRV_OPERATION_RESUME:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_RESUME.");
+            status = lwpmudrv_Resume();
+            break;
+
+        case DRV_OPERATION_EM_GROUPS:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_EM_GROUPS.");
+            status = lwpmudrv_Set_EM_Config(&local_args);
+            break;
+
+        case DRV_OPERATION_EM_CONFIG_NEXT:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_EM_CONFIG_NEXT.");
+            status = lwpmudrv_Configure_Events(&local_args);
+            break;
+
+        case DRV_OPERATION_NUM_DESCRIPTOR:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_NUM_DESCRIPTOR.");
+            status = lwpmudrv_Set_Sample_Descriptors(&local_args);
+            break;
+
+        case DRV_OPERATION_DESC_NEXT:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_DESC_NEXT.");
+            status = lwpmudrv_Configure_Descriptors(&local_args);
+            break;
+
+        case DRV_OPERATION_GET_NORMALIZED_TSC:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_GET_NORMALIZED_TSC.");
+            status = lwpmudrv_Get_Normalized_TSC(&local_args);
+            break;
+
+        case DRV_OPERATION_GET_NORMALIZED_TSC_STANDALONE:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_GET_NORMALIZED_TSC_STANDALONE.");
+            status = lwpmudrv_Get_Normalized_TSC(&local_args);
+            break;
+
+        case DRV_OPERATION_NUM_CORES:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_NUM_CORES.");
+            status = lwpmudrv_Get_Num_Cores(&local_args);
+            break;
+
+        case DRV_OPERATION_KERNEL_CS:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_KERNEL_CS.");
+            status = lwpmudrv_Get_KERNEL_CS(&local_args);
+            break;
+
+        case DRV_OPERATION_SET_UID:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_SET_UID.");
+            status = lwpmudrv_Set_UID(&local_args);
+            break;
+
+        case DRV_OPERATION_TSC_SKEW_INFO:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_TSC_SKEW_INFO.");
+            status = lwpmudrv_Get_TSC_Skew_Info(&local_args);
+            break;
+
+        case DRV_OPERATION_COLLECT_SYS_CONFIG:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_COLLECT_SYS_CONFIG.");
+            status = lwpmudrv_Collect_Sys_Config(&local_args);
+            break;
+
+        case DRV_OPERATION_GET_SYS_CONFIG:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_GET_SYS_CONFIG.");
+            status = lwpmudrv_Sys_Config(&local_args);
+            break;
+
+        case DRV_OPERATION_TERMINATE:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_TERMINATE.");
+            status = lwpmudrv_Terminate();
+            break;
+
+        case DRV_OPERATION_SET_CPU_TOPOLOGY:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_SET_CPU_TOPOLOGY.");
+            status = lwpmudrv_Setup_Cpu_Topology(&local_args);
+            break;
+
+        case DRV_OPERATION_GET_NUM_CORE_CTRS:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_GET_NUM_CORE_CTRS.");
+            status = lwpmudrv_Samp_Read_Num_Of_Core_Counters(&local_args);
+            break;
+
+        case DRV_OPERATION_GET_PLATFORM_INFO:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_GET_PLATFORM_INFO.");
+            status = lwpmudrv_Get_Platform_Info(&local_args);
+            break;
+
+        case DRV_OPERATION_READ_MSRS:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_READ_MSRs.");
+            status = lwpmudrv_Read_MSRs(&local_args);
+            break;
+
+        case DRV_OPERATION_SWITCH_GROUP:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_SWITCH_GROUP.");
+            status = lwpmudrv_Switch_Group();
+            break;
+
+            /*
+             * EMON-specific IOCTL commands
+             */
+        case DRV_OPERATION_READ_MSR:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_READ_MSR.");
+            status = lwpmudrv_Read_MSR_All_Cores(&local_args);
+            break;
+
+        case DRV_OPERATION_WRITE_MSR:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_WRITE_MSR.");
+            status = lwpmudrv_Write_MSR_All_Cores(&local_args);
+            break;
+
+        case DRV_OPERATION_READ_SWITCH_GROUP:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_READ_SWITCH_GROUP.");
+            status = lwpmudrv_Read_Counters_And_Switch_Group(&local_args);
+            break;
+
+        case DRV_OPERATION_READ_AND_RESET:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_READ_AND_RESET.");
+            status = lwpmudrv_Read_And_Reset_Counters(&local_args);
+            break;
+
+            /*
+             * Platform-specific IOCTL commands (IA32 and Intel64)
+             */
+
+        case DRV_OPERATION_INIT_UNC:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_INIT_UNC.");
+            status = lwpmudrv_Initialize_UNC(local_args.buf_usr_to_drv, local_args.len_usr_to_drv);
+            break;
+
+        case DRV_OPERATION_EM_GROUPS_UNC:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_EM_GROUPS_UNC.");
+            status = lwpmudrv_Set_EM_Config_UNC(&local_args);
+            break;
+
+        case DRV_OPERATION_EM_CONFIG_NEXT_UNC:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_EM_CONFIG_NEXT_UNC.");
+            status = lwpmudrv_Configure_Events_UNC(&local_args);
+            break;
+
+        case DRV_OPERATION_LBR_INFO:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_LBR_INFO.");
+            status = lwpmudrv_LBR_Info(&local_args);
+            break;
+
+        case DRV_OPERATION_PWR_INFO:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_PWR_INFO.");
+            status = lwpmudrv_PWR_Info(&local_args);
+            break;
+
+        case DRV_OPERATION_INIT_NUM_DEV:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_INIT_NUM_DEV.");
+            status = lwpmudrv_Initialize_Num_Devices(&local_args);
+            break;
+        case DRV_OPERATION_GET_NUM_SAMPLES:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_GET_NUM_SAMPLES.");
+            status = lwpmudrv_Get_Num_Samples(&local_args);
+            break;
+
+        case DRV_OPERATION_SET_DEVICE_NUM_UNITS:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_SET_DEVICE_NUM_UNITS.");
+            status = lwpmudrv_Set_Device_Num_Units(&local_args);
+            break;
+
+        case DRV_OPERATION_GET_INTERVAL_COUNTS:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_GET_INTERVAL_COUNTS.");
+            lwpmudrv_Get_Interval_Counts(&local_args);
+            break;
+
+        case DRV_OPERATION_SET_SCAN_UNCORE_TOPOLOGY_INFO:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_SET_SCAN_UNCORE_TOPOLOGY_INFO.");
+            status = lwpmudrv_Set_Uncore_Topology_Info_And_Scan(&local_args);
+            break;
+
+        case DRV_OPERATION_GET_UNCORE_TOPOLOGY:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_GET_UNCORE_TOPOLOGY.");
+            status = lwpmudrv_Get_Uncore_Topology(&local_args);
+            break;
+
+        case DRV_OPERATION_GET_PLATFORM_TOPOLOGY:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_GET_PLATFORM_TOPOLOGY.");
+            status = lwpmudrv_Get_Platform_Topology(&local_args);
+            break;
+
+        case DRV_OPERATION_FLUSH:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_FLUSH.");
+            status = lwpmudrv_Flush();
+            break;
+
+        case DRV_OPERATION_SET_EMON_BUFFER_DRIVER_HELPER:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_SET_EMON_BUFFER_DRIVER_HELPER.");
+            status = lwpmudrv_Set_Emon_Buffer_Driver_Helper(&local_args);
+            break;
+
+            /*
+             * Graphics IOCTL commands
+             */
+
+#if defined(BUILD_GFX)
+        case DRV_OPERATION_SET_GFX_EVENT:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_SET_GFX_EVENT.");
+            SEP_DRV_LOG_TRACE("lwpmudrv_Device_Control: enable_gfx=%d.",
+                    (int)DRV_CONFIG_enable_gfx(drv_cfg));
+            status = GFX_Set_Event_Code(&local_args);
+            break;
+#endif
+
+            /*
+             * Chipset IOCTL commands
+             */
+
+#if defined(BUILD_CHIPSET)
+        case DRV_OPERATION_PCI_READ:
+            {
+                CHIPSET_PCI_ARG_NODE pci_data;
+
+                SEP_DRV_LOG_TRACE("DRV_OPERATION_PCI_READ.");
+
+                if (local_args.buf_usr_to_drv == NULL || local_args.len_usr_to_drv != sizeof(CHIPSET_PCI_ARG_NODE) ||
+                    local_args.buf_drv_to_usr == NULL || local_args.len_drv_to_usr != sizeof(CHIPSET_PCI_ARG_NODE)) {
+                    status = OS_FAULT;
+                    goto cleanup;
+                }
+
+                if (copy_from_user(&pci_data, (CHIPSET_PCI_ARG)local_args.buf_usr_to_drv, sizeof(CHIPSET_PCI_ARG_NODE))) {
+                    status = OS_FAULT;
+                    goto cleanup;
+                }
+
+                status = PCI_Read_From_Memory_Address(CHIPSET_PCI_ARG_address(&pci_data),
+                        &CHIPSET_PCI_ARG_value(&pci_data));
+
+                if (copy_to_user(local_args.buf_drv_to_usr, &pci_data, sizeof(CHIPSET_PCI_ARG_NODE))) {
+                    status =  OS_FAULT;
+                    goto cleanup;
+                }
+
+                break;
+            }
+
+        case DRV_OPERATION_PCI_WRITE:
+            {
+                CHIPSET_PCI_ARG_NODE pci_data;
+
+                SEP_DRV_LOG_TRACE("DRV_OPERATION_PCI_WRITE.");
+
+                if (local_args.buf_usr_to_drv == NULL || local_args.len_usr_to_drv != sizeof(CHIPSET_PCI_ARG_NODE)) {
+                    status = OS_FAULT;
+                    goto cleanup;
+                }
+
+                if (copy_from_user(&pci_data, (CHIPSET_PCI_ARG)local_args.buf_usr_to_drv, sizeof(CHIPSET_PCI_ARG_NODE))) {
+                    status = OS_FAULT;
+                    goto cleanup;
+                }
+
+                status = PCI_Write_To_Memory_Address(CHIPSET_PCI_ARG_address(&pci_data),
+                        CHIPSET_PCI_ARG_value(&pci_data));
+                break;
+            }
+
+        case DRV_OPERATION_FD_PHYS:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_FD_PHYS.");
+            status = lwpmudrv_Samp_Find_Physical_Address(&local_args);
+            break;
+
+        case DRV_OPERATION_READ_PCI_CONFIG:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_READ_PCI_CONFIG.");
+            status = lwpmudrv_Samp_Read_PCI_Config(&local_args);
+            break;
+
+        case DRV_OPERATION_WRITE_PCI_CONFIG:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_WRITE_PCI_CONFIG.");
+            status = lwpmudrv_Samp_Write_PCI_Config(&local_args);
+            break;
+
+        case DRV_OPERATION_CHIPSET_INIT:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_CHIPSET_INIT.");
+            SEP_DRV_LOG_TRACE("Enable_chipset=%d.",
+                    (int)DRV_CONFIG_enable_chipset(drv_cfg));
+            status = lwpmudrv_Samp_Chipset_Init(&local_args);
+            break;
+
+        case DRV_OPERATION_GET_CHIPSET_DEVICE_ID:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_GET_CHIPSET_DEVICE_ID.");
+            status = lwpmudrv_Samp_Read_PCI_Config(&local_args);
+            break;
+#endif
+
+        case DRV_OPERATION_GET_DRV_SETUP_INFO:
+            SEP_DRV_LOG_TRACE("DRV_OPERATION_GET_DRV_SETUP_INFO.");
+            status = lwpmudrv_Get_Drv_Setup_Info(&local_args);
+            break;
+
+            /*
+             * if none of the above, treat as unknown/illegal IOCTL command
+             */
+
+        default:
+            SEP_DRV_LOG_ERROR("Unknown IOCTL number: %d!", cmd);
+            status = OS_ILLEGAL_IOCTL;
+            break;
+    }
+#if defined(BUILD_CHIPSET)
+cleanup:
+#endif
+    UTILITY_Driver_Set_Active_Ioctl(0);
+    MUTEX_UNLOCK(ioctl_lock);
+
+    SEP_DRV_LOG_TRACE_OUT("Return value for command %d: %d.", cmd, status);
+    return status;
+}
+
+extern long
+lwpmu_Device_Control (
+    IOCTL_USE_INODE
+    struct   file   *filp,
+    unsigned int     cmd,
+    unsigned long    arg
+)
+{
+    int              status = OS_SUCCESS;
+    IOCTL_ARGS_NODE  local_args;
+
+    SEP_DRV_LOG_TRACE_IN("Cmd type: %d, subcommand: %d.", _IOC_TYPE(cmd), _IOC_NR(cmd));
+
+#if !defined(DRV_USE_UNLOCKED_IOCTL)
+    SEP_DRV_LOG_TRACE("Cmd: 0x%x, called on inode maj:%d, min:%d.",
+            cmd, imajor(inode), iminor(inode));
+#endif
+    SEP_DRV_LOG_TRACE("Type: %d, subcommand: %d.", _IOC_TYPE(cmd), _IOC_NR(cmd));
+
+    if (_IOC_TYPE(cmd) != LWPMU_IOC_MAGIC) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Unknown IOCTL magic: %d!", _IOC_TYPE(cmd));
+        return OS_ILLEGAL_IOCTL;
+    }
+
+    if (arg) {
+        status = copy_from_user(&local_args, (IOCTL_ARGS)arg, sizeof(IOCTL_ARGS_NODE));
+    }
+
+    status = lwpmu_Service_IOCTL (IOCTL_USE_INODE filp, _IOC_NR(cmd), local_args);
+
+    SEP_DRV_LOG_TRACE_OUT("Return value: %d.", status);
+    return status;
+}
+
+#if defined(CONFIG_COMPAT) && defined(DRV_EM64T)
+extern long
+lwpmu_Device_Control_Compat (
+    struct   file   *filp,
+    unsigned int     cmd,
+    unsigned long    arg
+)
+{
+    int                     status = OS_SUCCESS;
+    IOCTL_COMPAT_ARGS_NODE  local_args_compat;
+    IOCTL_ARGS_NODE         local_args;
+
+    SEP_DRV_LOG_TRACE_IN("Compat: type: %d, subcommand: %d.", _IOC_TYPE(cmd), _IOC_NR(cmd));
+
+    memset(&local_args_compat, 0, sizeof(IOCTL_COMPAT_ARGS_NODE));
+    SEP_DRV_LOG_TRACE("Compat: type: %d, subcommand: %d.", _IOC_TYPE(cmd), _IOC_NR(cmd));
+
+    if (_IOC_TYPE(cmd) != LWPMU_IOC_MAGIC) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Unknown IOCTL magic: %d!", _IOC_TYPE(cmd));
+        return OS_ILLEGAL_IOCTL;
+    }
+
+    if (arg) {
+        status = copy_from_user(&local_args_compat, (IOCTL_COMPAT_ARGS)arg, sizeof(IOCTL_COMPAT_ARGS_NODE));
+    } // NB: status defined above is not being used...
+    local_args.len_drv_to_usr = local_args_compat.len_drv_to_usr;
+    local_args.len_usr_to_drv = local_args_compat.len_usr_to_drv;
+    local_args.buf_drv_to_usr = (char *) compat_ptr(local_args_compat.buf_drv_to_usr);
+    local_args.buf_usr_to_drv = (char *) compat_ptr(local_args_compat.buf_usr_to_drv);
+
+    status = lwpmu_Service_IOCTL (filp, _IOC_NR(cmd), local_args);
+
+    SEP_DRV_LOG_TRACE_OUT("Return value: %d", status);
+    return status;
+}
+#endif
+
+/*
+ * @fn        LWPMUDRV_Abnormal_Terminate(void)
+ *
+ * @brief     This routine is called from linuxos_Exit_Task_Notify if the user process has
+ *            been killed by an uncatchable signal (example kill -9).  The state variable
+ *            abormal_terminate is set to 1 and the clean up routines are called.  In this
+ *            code path the OS notifier hooks should not be unloaded.
+ *
+ * @param     None
+ *
+ * @return    OS_STATUS
+ *
+ * <I>Special Notes:</I>
+ *     <none>
+ */
+extern int
+LWPMUDRV_Abnormal_Terminate (
+    void
+)
+{
+    int              status = OS_SUCCESS;
+    SEP_DRV_LOG_FLOW_IN("");
+
+    SEP_DRV_LOG_TRACE("Calling lwpmudrv_Prepare_Stop.");
+    status = lwpmudrv_Prepare_Stop();
+    SEP_DRV_LOG_TRACE("Calling lwpmudrv_Finish_Stop.");
+    status = lwpmudrv_Finish_Stop();
+    SEP_DRV_LOG_TRACE("Calling lwpmudrv_Terminate.");
+    status = lwpmudrv_Terminate();
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d.", status);
+    return status;
+}
+
+
+static int
+lwpmudrv_Abnormal_Handler(void *data)
+{
+    SEP_DRV_LOG_FLOW_IN("");
+
+    while (!kthread_should_stop()) {
+        if (wait_event_interruptible_timeout(wait_exit,
+                                             GET_DRIVER_STATE() == DRV_STATE_TERMINATING,
+                                             msecs_to_jiffies(350))) {
+            SEP_DRV_LOG_WARNING("Processing abnormal termination...");
+            MUTEX_LOCK(ioctl_lock);
+            SEP_DRV_LOG_TRACE("Locked ioctl_lock...");
+            LWPMUDRV_Abnormal_Terminate();
+            SEP_DRV_LOG_TRACE("Unlocking ioctl_lock...");
+            MUTEX_UNLOCK(ioctl_lock);
+        }
+    }
+
+    SEP_DRV_LOG_FLOW_OUT("End of thread.");
+    return 0;
+}
+
+
+
+/*****************************************************************************************
+ *
+ *   Driver Entry / Exit functions that will be called on when the driver is loaded and
+ *   unloaded
+ *
+ ****************************************************************************************/
+
+/*
+ * Structure that declares the usual file access functions
+ * First one is for lwpmu_c, the control functions
+ */
+static struct file_operations lwpmu_Fops = {
+    .owner =   THIS_MODULE,
+    IOCTL_OP = lwpmu_Device_Control,
+#if defined(CONFIG_COMPAT) && defined(DRV_EM64T)
+    .compat_ioctl = lwpmu_Device_Control_Compat,
+#endif
+    .read =    lwpmu_Read,
+    .write =   lwpmu_Write,
+    .open =    lwpmu_Open,
+    .release = NULL,
+    .llseek =  NULL,
+};
+
+/*
+ * Second one is for lwpmu_m, the module notification functions
+ */
+static struct file_operations lwmod_Fops = {
+    .owner =   THIS_MODULE,
+    IOCTL_OP = NULL,                //None needed
+    .read =    OUTPUT_Module_Read,
+    .write =   NULL,                //No writing accepted
+    .open =    lwpmu_Open,
+    .release = NULL,
+    .llseek =  NULL,
+};
+
+/*
+ * Third one is for lwsamp_nn, the sampling functions
+ */
+static struct file_operations lwsamp_Fops = {
+    .owner =   THIS_MODULE,
+    IOCTL_OP = NULL,                //None needed
+    .read =    OUTPUT_Sample_Read,
+    .write =   NULL,                //No writing accepted
+    .open =    lwpmu_Open,
+    .release = NULL,
+    .llseek =  NULL,
+};
+
+/*
+ * Fourth one is for lwsamp_sideband, the pebs process info functions
+ */
+static struct file_operations lwsideband_Fops = {
+    .owner =   THIS_MODULE,
+    IOCTL_OP = NULL,                //None needed
+    .read =    OUTPUT_SidebandInfo_Read,
+    .write =   NULL,                //No writing accepted
+    .open =    lwpmu_Open,
+    .release = NULL,
+    .llseek =  NULL,
+};
+
+/*
+ * Fifth one is for lwsampunc_nn, the uncore sampling functions
+ */
+static struct file_operations lwsampunc_Fops = {
+    .owner =   THIS_MODULE,
+    IOCTL_OP = NULL,                //None needed
+    .read =    OUTPUT_UncSample_Read,
+    .write =   NULL,                //No writing accepted
+    .open =    lwpmu_Open,
+    .release = NULL,
+    .llseek =  NULL,
+};
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static int lwpmudrv_setup_cdev(dev, fops, dev_number)
+ *
+ * @param LWPMU_DEV               dev  - pointer to the device object
+ * @param struct file_operations *fops - pointer to the file operations struct
+ * @param dev_t                   dev_number - major/monor device number
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Set up the device object.
+ *
+ * <I>Special Notes</I>
+ */
+static int
+lwpmu_setup_cdev (
+    LWPMU_DEV               dev,
+    struct file_operations *fops,
+    dev_t                   dev_number
+)
+{
+    int res;
+    SEP_DRV_LOG_TRACE_IN("");
+
+    cdev_init(&LWPMU_DEV_cdev(dev), fops);
+    LWPMU_DEV_cdev(dev).owner = THIS_MODULE;
+    LWPMU_DEV_cdev(dev).ops   = fops;
+
+    res = cdev_add(&LWPMU_DEV_cdev(dev), dev_number, 1);
+
+    SEP_DRV_LOG_TRACE_OUT("Return value: %d", res);
+    return res;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static int lwpmu_Load(void)
+ *
+ * @param none
+ *
+ * @return STATUS
+ *
+ * @brief  Load the driver module into the kernel.  Set up the driver object.
+ * @brief  Set up the initial state of the driver and allocate the memory
+ * @brief  needed to keep basic state information.
+ */
+static int
+lwpmu_Load (
+    VOID
+)
+{
+    int        i, num_cpus;
+    dev_t      lwmod_DevNum;
+    OS_STATUS  status      = OS_INVALID;
+    char       dev_name[MAXNAMELEN];
+#if defined(CONFIG_XEN_HAVE_VPMU)
+    xen_pmu_params_t       xenpmu_param;
+    xen_pmu_data_t        *xenpmu_data;
+    unsigned long          pfn;
+#endif
+
+    SEP_DRV_LOG_LOAD("Driver loading...");
+    if (UTILITY_Driver_Log_Init() != OS_SUCCESS) { // Do not use SEP_DRV_LOG_X (where X != LOAD) before this, or if this fails
+        SEP_DRV_LOG_LOAD("Error: could not allocate log buffer.");
+        return OS_NO_MEM;
+    }
+    SEP_DRV_LOG_FLOW_IN("Starting internal log monitoring.");
+
+    CONTROL_Memory_Tracker_Init();
+
+#if !defined(CONFIG_XEN_HAVE_VPMU)
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,32)
+    if (xen_initial_domain()) {
+        SEP_DRV_LOG_LOAD("PMU virtualization is not enabled on XEN dom0!");
+    }
+#endif
+#endif
+
+    /* Get one major device number and two minor numbers. */
+    /*   The result is formatted as major+minor(0) */
+    /*   One minor number is for control (lwpmu_c), */
+    /*   the other (lwpmu_m) is for modules */
+    SEP_DRV_LOG_INIT("About to register chrdev...");
+
+    lwpmu_DevNum = MKDEV(0, 0);
+    status = alloc_chrdev_region(&lwpmu_DevNum, 0, PMU_DEVICES, SEP_DRIVER_NAME);
+    SEP_DRV_LOG_INIT("Result of alloc_chrdev_region is %d.", status);
+    if (status<0) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Failed to alloc chrdev_region (return = %d).", status);
+        return status;
+    }
+    SEP_DRV_LOG_LOAD("Major number is %d", MAJOR(lwpmu_DevNum));
+    status = lwpmudrv_Initialize_State();
+    if (status<0) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Failed to initialize state (return = %d)!", status);
+        return status;
+    }
+    num_cpus = GLOBAL_STATE_num_cpus(driver_state);
+    SEP_DRV_LOG_LOAD("Detected %d total CPUs and %d active CPUs.", num_cpus, GLOBAL_STATE_active_cpus(driver_state));
+
+#if defined(CONFIG_XEN_HAVE_VPMU)
+    if (xen_initial_domain()) {
+        xenpmu_param.version.maj = XENPMU_VER_MAJ;
+        xenpmu_param.version.min = XENPMU_VER_MIN;
+
+        for (i = 0; i < num_cpus; i++) {
+            xenpmu_data = (xen_pmu_data_t *)get_zeroed_page(GFP_KERNEL);;
+            if (!xenpmu_data) {
+                SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for xenpmu_data!");
+                return OS_NO_MEM;
+            }
+            pfn = vmalloc_to_pfn((char *)xenpmu_data);
+
+            xenpmu_param.val = pfn_to_mfn(pfn);
+            xenpmu_param.vcpu = i;
+            status = HYPERVISOR_xenpmu_op(XENPMU_init, (PVOID)&xenpmu_param);
+
+            per_cpu(xenpmu_shared, i) = xenpmu_data;
+        }
+        SEP_DRV_LOG_LOAD("VPMU is initialized on XEN Dom0.");
+    }
+#endif
+
+    PCI_Initialize();
+
+    /* Allocate memory for the control structures */
+    lwpmu_control      = CONTROL_Allocate_Memory(sizeof(LWPMU_DEV_NODE));
+    lwmod_control      = CONTROL_Allocate_Memory(sizeof(LWPMU_DEV_NODE));
+    lwsamp_control     = CONTROL_Allocate_Memory(num_cpus*sizeof(LWPMU_DEV_NODE));
+    lwsideband_control = CONTROL_Allocate_Memory(num_cpus*sizeof(LWPMU_DEV_NODE));
+
+    if (!lwsideband_control || !lwsamp_control || !lwpmu_control || !lwmod_control) {
+        CONTROL_Free_Memory(lwpmu_control);
+        CONTROL_Free_Memory(lwmod_control);
+        CONTROL_Free_Memory(lwsamp_control);
+        CONTROL_Free_Memory(lwsideband_control);
+
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for control structures!");
+        return OS_NO_MEM;
+    }
+
+    /* Register the file operations with the OS */
+
+    pmu_class = class_create(THIS_MODULE, SEP_DRIVER_NAME);
+    if (IS_ERR(pmu_class)) {
+        SEP_DRV_LOG_ERROR("Error registering SEP control class!");
+    }
+    device_create(pmu_class, NULL, lwpmu_DevNum, NULL, SEP_DRIVER_NAME DRV_DEVICE_DELIMITER"c");
+
+    status = lwpmu_setup_cdev(lwpmu_control,&lwpmu_Fops,lwpmu_DevNum);
+    if (status) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error %d when adding lwpmu as char device!", status);
+        return status;
+    }
+    /* _c init was fine, now try _m */
+    lwmod_DevNum = MKDEV(MAJOR(lwpmu_DevNum),MINOR(lwpmu_DevNum)+1);
+
+    device_create(pmu_class, NULL, lwmod_DevNum, NULL, SEP_DRIVER_NAME DRV_DEVICE_DELIMITER"m");
+
+    status       = lwpmu_setup_cdev(lwmod_control,&lwmod_Fops,lwmod_DevNum);
+    if (status) {
+        cdev_del(&LWPMU_DEV_cdev(lwpmu_control));
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error %d when adding lwpmu as char device!", status);
+        return status;
+    }
+
+    /* allocate one sampling device per cpu */
+    lwsamp_DevNum = MKDEV(0, 0);
+    status = alloc_chrdev_region(&lwsamp_DevNum, 0, num_cpus, SEP_SAMPLES_NAME);
+
+    if (status < 0) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Failed to alloc chrdev_region (return = %d).", status);
+        return status;
+    }
+
+    /* Register the file operations with the OS */
+    for (i = 0; i < num_cpus; i++) {
+        snprintf(dev_name, MAXNAMELEN, "%s%ss%d", SEP_DRIVER_NAME, DRV_DEVICE_DELIMITER, i);
+        device_create(pmu_class, NULL, lwsamp_DevNum+i, NULL, dev_name);
+        status = lwpmu_setup_cdev(lwsamp_control+i,
+                                  &lwsamp_Fops,
+                                  lwsamp_DevNum+i);
+        if (status) {
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Error %d when adding lwpmu as char device!", status);
+            return status;
+        }
+        else {
+            SEP_DRV_LOG_INIT("Added sampling device %d.", i);
+        }
+    }
+
+    lwsideband_DevNum = MKDEV(0, 0);
+    status = alloc_chrdev_region(&lwsideband_DevNum, 0, num_cpus, SEP_SIDEBAND_NAME);
+
+    if (status < 0) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for chrdev_region for sideband!");
+        return status;
+    }
+
+    for (i = 0; i < num_cpus; i++) {
+        snprintf(dev_name, MAXNAMELEN, "%s%sb%d", SEP_DRIVER_NAME, DRV_DEVICE_DELIMITER, i);
+        device_create(pmu_class, NULL, lwsideband_DevNum+i, NULL, dev_name);
+        status = lwpmu_setup_cdev(lwsideband_control+i,
+                                  &lwsideband_Fops,
+                                  lwsideband_DevNum+i);
+        if (status) {
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Error %d when adding lwsideband as char device!", status);
+            return status;
+        }
+        else {
+            SEP_DRV_LOG_INIT("Added sampling sideband device %d.", i);
+        }
+    }
+
+    cpu_tsc      = (U64 *)CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state) * sizeof(U64));
+    prev_cpu_tsc = (U64 *)CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state) * sizeof(U64));
+    diff_cpu_tsc = (U64 *)CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state) * sizeof(U64));
+
+#if !defined(CONFIG_PREEMPT_COUNT)
+    atomic_set(&read_now, GLOBAL_STATE_num_cpus(driver_state));
+    init_waitqueue_head(&read_tsc_now);
+    CONTROL_Invoke_Parallel(lwpmudrv_Fill_TSC_Info, (PVOID)(size_t)0);
+#endif
+
+    pcb_size            = GLOBAL_STATE_num_cpus(driver_state)*sizeof(CPU_STATE_NODE);
+    pcb                 = CONTROL_Allocate_Memory(pcb_size);
+    if (!pcb) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for PCB!");
+        return OS_NO_MEM;
+    }
+
+    core_to_package_map = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state)*sizeof(U32));
+    if (!core_to_package_map) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for core_to_package_map!");
+        return OS_NO_MEM;
+    }
+
+    core_to_phys_core_map = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state)*sizeof(U32));
+    if (!core_to_phys_core_map) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for core_to_phys_core_map!");
+        return OS_NO_MEM;
+    }
+
+    core_to_thread_map = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state)*sizeof(U32));
+    if (!core_to_thread_map) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for core_to_thread_map!");
+        return OS_NO_MEM;
+    }
+
+    occupied_core_ids = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state)*sizeof(U32));
+    if (!occupied_core_ids) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Memory allocation failure for occupied_core_ids!");
+        return OS_NO_MEM;
+    }
+    SYS_INFO_Build();
+    memset(pcb, 0, pcb_size);
+
+    if (total_ram <= OUTPUT_MEMORY_THRESHOLD) {
+        output_buffer_size = OUTPUT_SMALL_BUFFER;
+    }
+
+    MUTEX_INIT(ioctl_lock);
+
+    status = UNC_COMMON_Init();
+    if (status) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error %d when init uncore struct!", status);
+        return status;
+    }
+
+    /* allocate one sampling device per package (for uncore)*/
+    lwsampunc_control = CONTROL_Allocate_Memory(num_packages*sizeof(LWPMU_DEV_NODE));
+    if (!lwsampunc_control) {
+        CONTROL_Free_Memory(lwsampunc_control);
+        SEP_DRV_LOG_ERROR_FLOW_OUT("lwpmu driver failed to alloc space!\n");
+        return OS_NO_MEM;
+    }
+
+    lwsampunc_DevNum = MKDEV(0, 0);
+    status = alloc_chrdev_region(&lwsampunc_DevNum, 0, num_packages, SEP_UNCORE_NAME);
+
+    if (status < 0) {
+        SEP_DRV_LOG_ERROR_FLOW_OUT("Error: Failed to alloc chrdev_region (return = %d).", status);
+        return status;
+    }
+
+    /* Register the file operations with the OS */
+    for (i = 0; i < num_packages; i++) {
+        snprintf(dev_name, MAXNAMELEN, "%s%su%d", SEP_DRIVER_NAME, DRV_DEVICE_DELIMITER, i);
+        device_create(pmu_class, NULL, lwsampunc_DevNum+i, NULL, dev_name);
+        status = lwpmu_setup_cdev(lwsampunc_control+i,
+                                  &lwsampunc_Fops,
+                                  lwsampunc_DevNum+i);
+        if (status) {
+            SEP_DRV_LOG_ERROR_FLOW_OUT("Error %d when adding lwpmu as char device!", status);
+            return status;
+        }
+        else {
+            SEP_DRV_LOG_INIT("Added sampling device %d.", i);
+        }
+    }
+
+    init_waitqueue_head(&wait_exit);
+    abnormal_handler = kthread_create(lwpmudrv_Abnormal_Handler, NULL, "SEPDRV_ABNORMAL_HANDLER");
+    if (abnormal_handler) {
+        wake_up_process(abnormal_handler);
+    }
+
+#if defined(DRV_CPU_HOTPLUG)
+    /* Register CPU hotplug notifier */
+    LINUXOS_Register_Hotplug();
+#endif
+    /*
+     *  Initialize the SEP driver version (done once at driver load time)
+     */
+    SEP_VERSION_NODE_major(&drv_version) = SEP_MAJOR_VERSION;
+    SEP_VERSION_NODE_minor(&drv_version) = SEP_MINOR_VERSION;
+    SEP_VERSION_NODE_api(&drv_version)   = SEP_API_VERSION;
+    SEP_VERSION_NODE_update(&drv_version)= SEP_UPDATE_VERSION;
+
+    //
+    // Display driver version information
+    //
+    SEP_DRV_LOG_LOAD("PMU collection driver v%d.%d.%d %s has been loaded.",
+              SEP_VERSION_NODE_major(&drv_version),
+              SEP_VERSION_NODE_minor(&drv_version),
+              SEP_VERSION_NODE_api(&drv_version),
+              SEP_RELEASE_STRING);
+
+#if defined(BUILD_CHIPSET)
+    SEP_DRV_LOG_LOAD("Chipset support is enabled.");
+#endif
+
+#if defined(BUILD_GFX)
+    SEP_DRV_LOG_LOAD("Graphics support is enabled.");
+#endif
+
+    SEP_DRV_LOG_LOAD("NMI will be used for handling PMU interrupts.");
+
+    SEP_DRV_LOG_FLOW_OUT("Return value: %d.", status);
+    return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static int lwpmu_Unload(void)
+ *
+ * @param none
+ *
+ * @return none
+ *
+ * @brief  Remove the driver module from the kernel.
+ */
+static VOID
+lwpmu_Unload (
+    VOID
+)
+{
+    int   i = 0;
+    int   num_cpus;
+#if defined(CONFIG_XEN_HAVE_VPMU)
+    xen_pmu_params_t xenpmu_param;
+#endif
+    PVOID tmp_pcb;
+
+    SEP_DRV_LOG_FLOW_IN("");
+
+    SEP_DRV_LOG_LOAD("Driver unloading.");
+
+    num_cpus = GLOBAL_STATE_num_cpus(driver_state);
+
+    if (abnormal_handler) {
+        if (GET_DRIVER_STATE() != DRV_STATE_UNINITIALIZED) {
+            CHANGE_DRIVER_STATE(STATE_BIT_ANY, DRV_STATE_TERMINATING);
+        }
+        wake_up_interruptible_all(&wait_exit);
+        kthread_stop(abnormal_handler);
+        abnormal_handler = NULL;
+    }
+
+#if defined(CONFIG_XEN_HAVE_VPMU)
+    if (xen_initial_domain()) {
+        xenpmu_param.version.maj = XENPMU_VER_MAJ;
+        xenpmu_param.version.min = XENPMU_VER_MIN;
+
+        for (i = 0; i < num_cpus; i++) {
+            xenpmu_param.vcpu = i;
+            HYPERVISOR_xenpmu_op(XENPMU_finish, &xenpmu_param);
+
+            vfree(per_cpu(xenpmu_shared, i));
+            per_cpu(xenpmu_shared, i) = NULL;
+        }
+        SEP_DRV_LOG_LOAD("VPMU was disabled on XEN Dom0.");
+    }
+#endif
+
+    LINUXOS_Uninstall_Hooks();
+    SYS_INFO_Destroy();
+    OUTPUT_Destroy();
+    cpu_buf               = CONTROL_Free_Memory(cpu_buf);
+    unc_buf               = CONTROL_Free_Memory(unc_buf);
+    cpu_sideband_buf      = CONTROL_Free_Memory(cpu_sideband_buf);
+    module_buf            = CONTROL_Free_Memory(module_buf);
+    cpu_tsc               = CONTROL_Free_Memory(cpu_tsc);
+    prev_cpu_tsc          = CONTROL_Free_Memory(prev_cpu_tsc);
+    diff_cpu_tsc          = CONTROL_Free_Memory(diff_cpu_tsc);
+    core_to_package_map   = CONTROL_Free_Memory(core_to_package_map);
+    core_to_phys_core_map = CONTROL_Free_Memory(core_to_phys_core_map);
+    core_to_thread_map    = CONTROL_Free_Memory(core_to_thread_map);
+    occupied_core_ids     = CONTROL_Free_Memory(occupied_core_ids);
+
+    tmp_pcb             = pcb;                          // Ensures there is no log message written (ERROR, ALLOC, ...)
+    pcb                 = NULL;                         // between pcb being freed and pcb being NULL.
+    tmp_pcb             = CONTROL_Free_Memory(tmp_pcb);
+    pcb_size            = 0;
+
+    UNC_COMMON_Clean_Up();
+
+    unregister_chrdev(MAJOR(lwpmu_DevNum), SEP_DRIVER_NAME);
+    device_destroy(pmu_class, lwpmu_DevNum);
+    device_destroy(pmu_class, lwpmu_DevNum+1);
+
+    cdev_del(&LWPMU_DEV_cdev(lwpmu_control));
+    cdev_del(&LWPMU_DEV_cdev(lwmod_control));
+    unregister_chrdev_region(lwpmu_DevNum, PMU_DEVICES);
+
+    unregister_chrdev(MAJOR(lwsamp_DevNum), SEP_SAMPLES_NAME);
+    unregister_chrdev(MAJOR(lwsampunc_DevNum), SEP_UNCORE_NAME);
+    unregister_chrdev(MAJOR(lwsideband_DevNum), SEP_SIDEBAND_NAME);
+
+    for (i = 0; i < num_cpus; i++) {
+        device_destroy(pmu_class, lwsamp_DevNum+i);
+        device_destroy(pmu_class, lwsideband_DevNum+i);
+        cdev_del(&LWPMU_DEV_cdev(&lwsamp_control[i]));
+        cdev_del(&LWPMU_DEV_cdev(&lwsideband_control[i]));
+    }
+
+    for (i = 0; i < num_packages; i++) {
+        device_destroy(pmu_class, lwsampunc_DevNum+i);
+        cdev_del(&LWPMU_DEV_cdev(&lwsampunc_control[i]));
+    }
+
+    class_destroy(pmu_class);
+
+    unregister_chrdev_region(lwsamp_DevNum, num_cpus);
+    unregister_chrdev_region(lwsampunc_DevNum, num_packages);
+    unregister_chrdev_region(lwsideband_DevNum, num_cpus);
+    lwpmu_control      = CONTROL_Free_Memory(lwpmu_control);
+    lwmod_control      = CONTROL_Free_Memory(lwmod_control);
+    lwsamp_control     = CONTROL_Free_Memory(lwsamp_control);
+    lwsampunc_control  = CONTROL_Free_Memory(lwsampunc_control);
+    lwsideband_control = CONTROL_Free_Memory(lwsideband_control);
+
+
+    CONTROL_Memory_Tracker_Free();
+
+#if defined(DRV_CPU_HOTPLUG)
+    /* Unregister CPU hotplug notifier */
+    LINUXOS_Unregister_Hotplug();
+#endif
+
+    SEP_DRV_LOG_FLOW_OUT("Log deallocation. Cannot track further in internal log.");
+    UTILITY_Driver_Log_Free(); // Do not use SEP_DRV_LOG_X (where X != LOAD) after this
+
+    SEP_DRV_LOG_LOAD("PMU collection driver v%d.%d.%d %s has been unloaded.",
+              SEP_VERSION_NODE_major(&drv_version),
+              SEP_VERSION_NODE_minor(&drv_version),
+              SEP_VERSION_NODE_api(&drv_version),
+              SEP_RELEASE_STRING);
+
+    return;
+}
+
+/* Declaration of the init and exit functions */
+module_init(lwpmu_Load);
+module_exit(lwpmu_Unload);
+
diff --git a/drivers/misc/intel/sepdk/sep/output.c b/drivers/misc/intel/sepdk/sep/output.c
new file mode 100644
index 000000000000..436259be03ad
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/output.c
@@ -0,0 +1,1130 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/errno.h>
+#include <linux/sched.h>
+#include <linux/jiffies.h>
+#include <linux/timer.h>
+#include <linux/time.h>
+#include <linux/wait.h>
+#include <linux/fs.h>
+#include <asm/atomic.h>
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv.h"
+#include "lwpmudrv_ioctl.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+
+#include "control.h"
+#include "output.h"
+#include "utility.h"
+#include "inc/linuxos.h"
+#define OTHER_C_DEVICES  1     // one for module
+
+/*
+ *  Global data: Buffer control structure
+ */
+static wait_queue_head_t flush_queue;
+static atomic_t          flush_writers;
+static volatile int      flush = 0;
+extern DRV_CONFIG        drv_cfg;
+extern DRV_BOOL          multi_pebs_enabled;
+extern DRV_BOOL          unc_buf_init;
+
+static void output_NMI_Sample_Buffer(unsigned long data);
+
+/*
+ *  @fn output_Free_Buffers(output, size)
+ *
+ *  @param    IN  outbuf      - The output buffer to manipulate
+ *
+ *  @brief   Deallocate the memory associated with the buffer descriptor
+ *
+ */
+static VOID
+output_Free_Buffers (
+    BUFFER_DESC   buffer,
+    size_t        size
+)
+{
+    int       j;
+    OUTPUT    outbuf;
+
+    SEP_DRV_LOG_TRACE_IN("Buffer: %p, size: %u.", buffer, size);
+
+    if (buffer == NULL) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!buffer).");
+        return;
+    }
+    outbuf = &BUFFER_DESC_outbuf(buffer);
+    for (j = 0; j < OUTPUT_NUM_BUFFERS; j++) {
+        CONTROL_Free_Memory(OUTPUT_buffer(outbuf,j));
+        OUTPUT_buffer(outbuf,j) = NULL;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ *  @fn  int OUTPUT_Reserve_Buffer_Space (OUTPUT      outbuf,
+ *                                        U32         size,
+ *                                        U8          in_notification)
+ *
+ *  @param  outbuf          IN output buffer to manipulate
+ *  @param  size            IN The size of data to reserve
+ *  @param  defer           IN wake up directly if FALSE.
+ *                           Otherwise, see below.
+ *  @param  in_notification IN 1 if in notification, 0 if not
+ *
+ *  @result outloc - to the location where data is to be written
+ *
+ *  Reserve space in the output buffers for data. The behavior of this function
+ *  when a buffer is full will vary depending on the 'defer' and 'in_notification'
+ *  parameters, as described in the special notes section.
+ *
+ * <I>Special Notes:</I>
+ *  -----------------------------------------------------------------------------------------------------------------------
+ *  defer | in_notification |                                         description
+ *  -----------------------------------------------------------------------------------------------------------------------
+ *  FALSE |    FALSE/TRUE   | directly signals the buffer's consumer with wake_up_interruptible_sync
+ *  -----------------------------------------------------------------------------------------------------------------------
+ *   TRUE |      FALSE      | defers the call to wake_up_interruptible_sync using tasklet_schedule [needed because calling
+ *        |                 | it directly is not safe from an NMI]
+ *  -----------------------------------------------------------------------------------------------------------------------
+ *        |                 | do not signal -or explicitly schedule the signaling of- the buffer's consumer [needed because
+ *   TRUE |       TRUE      | neither operation is safe from the sched_switch tracepoint callback in kernel version 4.13].
+ *        |                 | Instead relies on the interrupt handler to do it next time there is an interrupt.
+ *  -----------------------------------------------------------------------------------------------------------------------
+ */
+extern void*
+OUTPUT_Reserve_Buffer_Space (
+    BUFFER_DESC  bd,
+    U32          size,
+    DRV_BOOL     defer,
+    U8           in_notification
+)
+{
+    char   *outloc      = NULL;
+    OUTPUT  outbuf      = &BUFFER_DESC_outbuf(bd);
+    U32     this_cpu;
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_IN(in_notification, "Bd: %p, size: %u, defer: %u, notif: %u.", bd, size, defer, in_notification);
+
+    if (DRV_CONFIG_enable_cp_mode(drv_cfg) && flush) {
+        SEP_DRV_LOG_NOTIFICATION_TRACE_OUT(in_notification, "Res: NULL (cp_mode && flush).");
+        return NULL;
+    }
+
+    if (OUTPUT_remaining_buffer_size(outbuf) >= size) {
+        outloc = (OUTPUT_buffer(outbuf,OUTPUT_current_buffer(outbuf)) +
+          (OUTPUT_total_buffer_size(outbuf) - OUTPUT_remaining_buffer_size(outbuf)));
+    }
+    else {
+        U32  i, j, start;
+        OUTPUT_buffer_full(outbuf,OUTPUT_current_buffer(outbuf)) =
+                OUTPUT_total_buffer_size(outbuf) - OUTPUT_remaining_buffer_size(outbuf);
+
+        //
+        // Massive Naive assumption:  Must find a way to fix it.
+        // In spite of the loop.
+        // The next buffer to fill are monotonically increasing
+        // indicies.
+        //
+        if (!DRV_CONFIG_enable_cp_mode(drv_cfg)) {
+            OUTPUT_signal_full(outbuf) = TRUE;
+        }
+
+        start = OUTPUT_current_buffer(outbuf);
+        for (i = start+1; i < start+OUTPUT_NUM_BUFFERS; i++) {
+
+            j = i%OUTPUT_NUM_BUFFERS;
+
+            //don't check if buffer has data when doing CP
+            if (!OUTPUT_buffer_full(outbuf,j) || (DRV_CONFIG_enable_cp_mode(drv_cfg))) {
+                OUTPUT_current_buffer(outbuf) = j;
+                OUTPUT_remaining_buffer_size(outbuf) = OUTPUT_total_buffer_size(outbuf);
+                outloc = OUTPUT_buffer(outbuf,j);
+                if (DRV_CONFIG_enable_cp_mode(drv_cfg)) {
+                // discarding all the information in the new buffer in CP mode
+                    OUTPUT_buffer_full(outbuf,j) = 0;
+                    break;
+                }
+            }
+#if !(defined(CONFIG_PREEMPT_RT) || defined(CONFIG_PREEMPT_RT_FULL))
+            else {
+                if (!defer) {
+                    OUTPUT_signal_full(outbuf) = FALSE;
+                    SEP_DRV_LOG_NOTIFICATION_WARNING(in_notification, "Output buffers are full. Might be dropping some samples!");
+                    break;
+                }
+            }
+#endif
+        }
+    }
+
+    if (outloc) {
+        OUTPUT_remaining_buffer_size(outbuf) -= size;
+        memset(outloc, 0, size);
+    }
+
+    if (OUTPUT_signal_full(outbuf)) {
+        if (!defer) {
+#if !(defined(CONFIG_PREEMPT_RT) || defined(CONFIG_PREEMPT_RT_FULL))
+            SEP_DRV_LOG_NOTIFICATION_TRACE(in_notification, "Choosing direct wakeup approach.");
+            wake_up_interruptible_sync(&BUFFER_DESC_queue(bd));
+            OUTPUT_signal_full(outbuf) = FALSE;
+#endif
+        }
+        else {
+            if (!OUTPUT_tasklet_queued(outbuf)) {
+                this_cpu = CONTROL_THIS_CPU();
+                if (!in_notification) {
+                    SEP_DRV_LOG_NOTIFICATION_TRACE(in_notification, "Scheduling the tasklet on cpu %u.", this_cpu);
+                    OUTPUT_tasklet_queued(outbuf) = TRUE;
+                    tasklet_schedule(&CPU_STATE_nmi_tasklet(&pcb[this_cpu]));
+                }
+                else {
+                    static U32 cpt = 0;
+                    if (!cpt) {
+                        SEP_DRV_LOG_WARNING("Using interrupt-driven sideband buffer flushes for extra safety.");
+                        SEP_DRV_LOG_WARNING("This may result in fewer context switches being recorded.");
+                    }
+                    SEP_DRV_LOG_TRACE("Lost context switch information (for the %uth time).", ++cpt);
+                }
+            }
+        }
+    }
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_OUT(in_notification, "Res: %p.", outloc);
+    return outloc;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ *
+ * @fn  int  OUTPUT_Buffer_Fill (BUFFER_DESC buf,
+ *                               PVOID  data,
+ *                               U16    size,
+ *                               U8     in_notification)
+ *
+ * @brief     Place a record (can be module, marker, etc) in a buffer
+ *
+ * @param     data            - pointer to a buffer to copy
+ * @param     size            - size of the buffer to cpu
+ * @param     in_notification - 1 if in notification, 0 if not
+ *
+ * @return    number of bytes copied into buffer
+ *
+ * Start by ensuring that output buffer space is available.
+ * If so, then copy the input data to the output buffer and make the necessary
+ * adjustments to manage the output buffers.
+ * If not, signal the read event for this buffer and get another buffer.
+ *
+ * <I>Special Notes:</I>
+ *
+ */
+static int
+output_Buffer_Fill (
+    BUFFER_DESC   bd,
+    PVOID         data,
+    U16           size,
+    U8            in_notification
+)
+{
+    char        *outloc;
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_IN(in_notification, "Bd: %p, data: %p, size: %u.", bd, data, size);
+
+    outloc = OUTPUT_Reserve_Buffer_Space (bd, size, FALSE, in_notification);
+    if (outloc) {
+        memcpy(outloc, data, size);
+        SEP_DRV_LOG_NOTIFICATION_TRACE_OUT(in_notification, "Res: %d (outloc).", size);
+        return size;
+    }
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_OUT(in_notification, "Res: 0 (!outloc).");
+    return 0;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  int  OUTPUT_Module_Fill (PVOID  data,
+ *                               U16    size,
+ *                               U8     in_notification)
+ *
+ * @brief     Place a module record in a buffer
+ *
+ * @param     data              - pointer to a buffer to copy
+ * @param     size              - size of the buffer to cpu
+ * @param     in_notification   - 1 if in notification, 0 if not
+ *
+ * @return    number of bytes copied into buffer
+ *
+ *
+ */
+extern int
+OUTPUT_Module_Fill (
+    PVOID     data,
+    U16       size,
+    U8        in_notification
+)
+{
+    int     ret_size;
+    OUTPUT  outbuf = &BUFFER_DESC_outbuf(module_buf);
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_IN(in_notification, "Data: %p, size: %u.", data, size);
+
+    spin_lock(&OUTPUT_buffer_lock(outbuf));
+    ret_size = output_Buffer_Fill(module_buf, data, size, in_notification);
+    spin_unlock(&OUTPUT_buffer_lock(outbuf));
+
+    SEP_DRV_LOG_NOTIFICATION_TRACE_OUT(in_notification, "Res: %d.", ret_size);
+    return ret_size;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ *  @fn  ssize_t  output_Read(struct file  *filp,
+ *                            char         *buf,
+ *                            size_t        count,
+ *                            loff_t       *f_pos,
+ *                            BUFFER_DESC   kernel_buf)
+ *
+ *  @brief  Return a sample buffer to user-mode. If not full or flush, wait
+ *
+ *  @param *filp          a file pointer
+ *  @param *buf           a sampling buffer
+ *  @param  count         size of the user's buffer
+ *  @param  f_pos         file pointer (current offset in bytes)
+ *  @param  kernel_buf    the kernel output buffer structure
+ *
+ *  @return number of bytes read. zero indicates end of file. Neg means error
+ *
+ *  Place no more than count bytes into the user's buffer.
+ *  Block if unavailable on "BUFFER_DESC_queue(buf)"
+ *
+ * <I>Special Notes:</I>
+ *
+ */
+static ssize_t
+output_Read (
+    struct file  *filp,
+    char         *buf,
+    size_t        count,
+    loff_t       *f_pos,
+    BUFFER_DESC   kernel_buf
+)
+{
+    ssize_t  to_copy = 0;
+    ssize_t  uncopied;
+    OUTPUT   outbuf = &BUFFER_DESC_outbuf(kernel_buf);
+    U32      cur_buf, i;
+/* Buffer is filled by output_fill_modules. */
+
+    SEP_DRV_LOG_TRACE_IN("Filp: %p, buf: %p, count: %u, f_pos: %p, kernel_buf: %p.",
+        filp, buf, (U32)count, f_pos, kernel_buf);
+
+    cur_buf = OUTPUT_current_buffer(outbuf);
+    if (!DRV_CONFIG_enable_cp_mode(drv_cfg) || flush) {
+        for (i=0; i<OUTPUT_NUM_BUFFERS; i++) { //iterate through all buffers
+            cur_buf++;
+            if (cur_buf >= OUTPUT_NUM_BUFFERS) { cur_buf = 0; } //circularly
+            if ((to_copy = OUTPUT_buffer_full(outbuf, cur_buf))) {
+                if (flush && DRV_CONFIG_enable_cp_mode(drv_cfg) && cur_buf == OUTPUT_current_buffer(outbuf)) {
+                    OUTPUT_current_buffer(outbuf)++;
+                    if (OUTPUT_current_buffer(outbuf) >= OUTPUT_NUM_BUFFERS) {
+                        OUTPUT_current_buffer(outbuf) = 0;
+                    }
+                    OUTPUT_remaining_buffer_size(outbuf) = OUTPUT_total_buffer_size(outbuf);
+                }
+                break;
+            }
+        }
+    }
+
+    SEP_DRV_LOG_TRACE("buffer %d has %d bytes ready.", (S32)cur_buf, (S32)to_copy);
+    if (!flush && to_copy == 0) {
+        unsigned long delay = msecs_to_jiffies(1000);
+
+        while (1) {
+            U32 res = wait_event_interruptible_timeout(BUFFER_DESC_queue(kernel_buf),
+                                                       flush || (OUTPUT_buffer_full(outbuf, cur_buf) && !DRV_CONFIG_enable_cp_mode(drv_cfg)),
+                                                       delay);
+
+            if (GET_DRIVER_STATE() == DRV_STATE_TERMINATING) {
+                SEP_DRV_LOG_INIT("Switched to TERMINATING while waiting for BUFFER_DESC_queue!");
+                break;
+            }
+
+            if (res == ERESTARTSYS || res == 0) {
+                SEP_DRV_LOG_TRACE("Wait_event_interruptible_timeout(BUFFER_DESC_queue): %u.", res);
+                continue;
+            }
+
+            break;
+        }
+
+        if (DRV_CONFIG_enable_cp_mode(drv_cfg)) {
+        // reset the current buffer index if in CP mode
+            cur_buf = OUTPUT_current_buffer(outbuf);
+            for (i=0; i<OUTPUT_NUM_BUFFERS; i++) { //iterate through all buffers
+                cur_buf++;
+                if (cur_buf >= OUTPUT_NUM_BUFFERS) { cur_buf = 0; } //circularly
+                if ((to_copy = OUTPUT_buffer_full(outbuf, cur_buf))) {
+                    if (flush && DRV_CONFIG_enable_cp_mode(drv_cfg) && cur_buf == OUTPUT_current_buffer(outbuf)) {
+                        OUTPUT_current_buffer(outbuf)++;
+                        if (OUTPUT_current_buffer(outbuf) >= OUTPUT_NUM_BUFFERS) {
+                            OUTPUT_current_buffer(outbuf) = 0;
+                        }
+                        OUTPUT_remaining_buffer_size(outbuf) = OUTPUT_total_buffer_size(outbuf);
+                    }
+                    break;
+                }
+            }
+        }
+        SEP_DRV_LOG_TRACE("Get to copy %d.", (S32)cur_buf);
+        to_copy = OUTPUT_buffer_full(outbuf, cur_buf);
+        SEP_DRV_LOG_TRACE("output_Read awakened, buffer %d has %d bytes.",cur_buf, (int)to_copy );
+    }
+
+    /* Ensure that the user's buffer is large enough */
+    if (to_copy > count) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("OS_NO_MEM (user buffer is too small!).");
+        return OS_NO_MEM;
+    }
+
+    /* Copy data to user space. Note that we use cur_buf as the source */
+    if (GET_DRIVER_STATE() != DRV_STATE_TERMINATING) {
+        uncopied = copy_to_user(buf,
+                                OUTPUT_buffer(outbuf, cur_buf),
+                                to_copy);
+        /* Mark the buffer empty */
+        OUTPUT_buffer_full(outbuf, cur_buf) = 0;
+        *f_pos += to_copy-uncopied;
+        if (uncopied) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("Res: %u (only copied %u of %u bytes!).",
+                (U32)(to_copy - uncopied), (U32)to_copy, (U32)uncopied);
+            return (to_copy - uncopied);
+        }
+    }
+    else {
+        to_copy = 0;
+        SEP_DRV_LOG_TRACE("To copy set to 0.");
+    }
+
+    // At end-of-file, decrement the count of active buffer writers
+
+    if (to_copy == 0) {
+        DRV_BOOL flush_val = atomic_dec_and_test(&flush_writers);
+        SEP_DRV_LOG_TRACE("Decremented flush_writers.");
+        if (flush_val == TRUE) {
+            wake_up_interruptible_sync(&flush_queue);
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", (U32) to_copy);
+    return to_copy;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ *  @fn  ssize_t  OUTPUT_Module_Read(struct file  *filp,
+ *                                   char         *buf,
+ *                                   size_t        count,
+ *                                   loff_t       *f_pos)
+ *
+ *  @brief  Return a module buffer to user-mode. If not full or flush, wait
+ *
+ *  @param *filp   a file pointer
+ *  @param *buf    a sampling buffer
+ *  @param  count  size of the user's buffer
+ *  @param  f_pos  file pointer (current offset in bytes)
+ *  @param  buf    the kernel output buffer structure
+ *
+ *  @return number of bytes read. zero indicates end of file. Neg means error
+ *
+ *  Place no more than count bytes into the user's buffer.
+ *  Block on "BUFFER_DESC_queue(kernel_buf)" if buffer isn't full.
+ *
+ * <I>Special Notes:</I>
+ *
+ */
+extern ssize_t
+OUTPUT_Module_Read (
+    struct file  *filp,
+    char         *buf,
+    size_t        count,
+    loff_t       *f_pos
+)
+{
+    ssize_t res;
+
+    SEP_DRV_LOG_TRACE_IN("");
+    SEP_DRV_LOG_TRACE("Read request for modules on minor.");
+
+    res = output_Read(filp, buf, count, f_pos, module_buf);
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", (U32) res);
+    return res;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ *  @fn  ssize_t  OUTPUT_Sample_Read(struct file  *filp,
+ *                                   char         *buf,
+ *                                   size_t        count,
+ *                                   loff_t       *f_pos)
+ *
+ *  @brief  Return a sample buffer to user-mode. If not full or flush, wait
+ *
+ *  @param *filp   a file pointer
+ *  @param *buf    a sampling buffer
+ *  @param  count  size of the user's buffer
+ *  @param  f_pos  file pointer (current offset in bytes)
+ *  @param  buf    the kernel output buffer structure
+ *
+ *  @return number of bytes read. zero indicates end of file. Neg means error
+ *
+ *  Place no more than count bytes into the user's buffer.
+ *  Block on "BUFFER_DESC_queue(kernel_buf)" if buffer isn't full.
+ *
+ * <I>Special Notes:</I>
+ *
+ */
+extern ssize_t
+OUTPUT_Sample_Read (
+    struct file  *filp,
+    char         *buf,
+    size_t        count,
+    loff_t       *f_pos
+)
+{
+    int     i;
+    ssize_t res;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    i = iminor(filp->DRV_F_DENTRY->d_inode); // kernel pointer - not user pointer
+    SEP_DRV_LOG_TRACE("Read request for samples on minor %d.", i);
+    res = output_Read(filp, buf, count, f_pos, &(cpu_buf[i]));
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", (U32) res);
+    return res;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ *  @fn  ssize_t  OUTPUT_Sample_Read(struct file  *filp,
+ *                                   char         *buf,
+ *                                   size_t        count,
+ *                                   loff_t       *f_pos)
+ *
+ *  @brief  Return a sample buffer to user-mode. If not full or flush, wait
+ *
+ *  @param *filp   a file pointer
+ *  @param *buf    a sampling buffer
+ *  @param  count  size of the user's buffer
+ *  @param  f_pos  file pointer (current offset in bytes)
+ *  @param  buf    the kernel output buffer structure
+ *
+ *  @return number of bytes read. zero indicates end of file. Neg means error
+ *
+ *  Place no more than count bytes into the user's buffer.
+ *  Block on "BUFFER_DESC_queue(kernel_buf)" if buffer isn't full.
+ *
+ * <I>Special Notes:</I>
+ *
+ */
+extern ssize_t
+OUTPUT_UncSample_Read (
+    struct file  *filp,
+    char         *buf,
+    size_t        count,
+    loff_t       *f_pos
+)
+{
+    int     i;
+    ssize_t res = 0;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    i = iminor(filp->DRV_F_DENTRY->d_inode); // kernel pointer - not user pointer
+    SEP_DRV_LOG_TRACE("Read request for samples on minor %d.", i);
+    if (unc_buf_init) {
+        res = output_Read(filp, buf, count, f_pos, &(unc_buf[i]));
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", (U32) res);
+    return res;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ *  @fn  ssize_t  OUTPUT_SidebandInfo_Read(struct file  *filp,
+ *                                         char         *buf,
+ *                                         size_t        count,
+ *                                         loff_t       *f_pos)
+ *
+ *  @brief  Return a sideband info buffer to user-mode. If not full or flush, wait
+ *
+ *  @param *filp   a file pointer
+ *  @param *buf    a sideband info buffer
+ *  @param  count  size of the user's buffer
+ *  @param  f_pos  file pointer (current offset in bytes)
+ *  @param  buf    the kernel output buffer structure
+ *
+ *  @return number of bytes read. zero indicates end of file. Neg means error
+ *
+ *  Place no more than count bytes into the user's buffer.
+ *  Block on "BUFFER_DESC_queue(kernel_buf)" if buffer isn't full.
+ *
+ * <I>Special Notes:</I>
+ *
+ */
+extern ssize_t
+OUTPUT_SidebandInfo_Read (
+    struct file  *filp,
+    char         *buf,
+    size_t        count,
+    loff_t       *f_pos
+)
+{
+    int     i;
+    ssize_t res = 0;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    i = iminor(filp->DRV_F_DENTRY->d_inode); // kernel pointer - not user pointer
+    SEP_DRV_LOG_TRACE("Read request for pebs process info on minor %d.", i);
+    if (multi_pebs_enabled) {
+        res = output_Read(filp, buf, count, f_pos, &(cpu_sideband_buf[i]));
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", (U32) res);
+    return res;
+}
+
+/*
+ *  @fn output_Initialized_Buffers()
+ *
+ *  @result OUTPUT
+ *  @param  BUFFER_DESC desc   - descriptor for the buffer being initialized
+ *  @param  U32         factor - multiplier for OUTPUT_BUFFER_SIZE.
+ *                               1 for cpu buffers, 2 for module buffers.
+ *
+ *  @brief  Allocate, initialize, and return an output data structure
+ *
+ * <I>Special Notes:</I>
+ *     Multiple (OUTPUT_NUM_BUFFERS) buffers will be allocated
+ *     Each buffer is of size (OUTPUT_BUFFER_SIZE)
+ *     Each field in the buffer is initialized
+ *     The event queue for the OUTPUT is initialized
+ *
+ */
+static BUFFER_DESC
+output_Initialized_Buffers (
+    BUFFER_DESC desc,
+    U32         factor
+)
+{
+    OUTPUT       outbuf;
+    int          j;
+
+    SEP_DRV_LOG_TRACE_IN("Desc: %p, factor: %u.", desc, factor);
+
+/*
+ *  Allocate the BUFFER_DESC, then allocate its buffers
+ */
+    if (desc == NULL) {
+        desc = (BUFFER_DESC)CONTROL_Allocate_Memory(sizeof(BUFFER_DESC_NODE));
+        if (desc == NULL) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("Res: NULL (failed allocation for desc!).");
+            return NULL;
+        }
+    }
+    outbuf = &(BUFFER_DESC_outbuf(desc));
+    spin_lock_init(&OUTPUT_buffer_lock(outbuf));
+    for (j = 0; j < OUTPUT_NUM_BUFFERS; j++) {
+        if (OUTPUT_buffer(outbuf,j) == NULL) {
+            OUTPUT_buffer(outbuf,j) = CONTROL_Allocate_Memory(OUTPUT_BUFFER_SIZE * factor);
+        }
+        OUTPUT_buffer_full(outbuf,j) = 0;
+        if (!OUTPUT_buffer(outbuf,j)) {
+            /*return NULL to tell the caller that allocation failed*/
+            SEP_DRV_LOG_ERROR_TRACE_OUT("Res: NULL (failed alloc for OUTPUT_buffer(output, %d)!).", j);
+            return NULL;
+        }
+    }
+    /*
+     *  Initialize the remaining fields in the BUFFER_DESC
+     */
+    OUTPUT_current_buffer(outbuf)        = 0;
+    OUTPUT_signal_full(outbuf)           = FALSE;
+    OUTPUT_remaining_buffer_size(outbuf) = OUTPUT_BUFFER_SIZE * factor;
+    OUTPUT_total_buffer_size(outbuf)     = OUTPUT_BUFFER_SIZE * factor;
+    OUTPUT_tasklet_queued(outbuf)        = FALSE;
+    init_waitqueue_head(&BUFFER_DESC_queue(desc));
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %p.", desc);
+    return(desc);
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID output_NMI_Sample_Buffer (
+ *                   )
+ *
+ * @brief       Callback from NMI tasklet. The function checks if any buffers
+ *              are full, and if full, signals the reader threads.
+ *
+ * @param       none
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              This callback was added to handle out-of-band event delivery
+ *              when running in NMI mode
+ */
+static void
+output_NMI_Sample_Buffer (
+    unsigned long data
+)
+{
+    U32    cpu_id;
+    OUTPUT outbuf;
+
+    SEP_DRV_LOG_NOTIFICATION_IN("Data: %u.", (U32) data);
+
+    cpu_id = CONTROL_THIS_CPU();
+
+    if (cpu_buf) {
+        outbuf = &BUFFER_DESC_outbuf(&cpu_buf[cpu_id]);
+        if (outbuf && OUTPUT_signal_full(outbuf)) {
+            wake_up_interruptible_sync(&BUFFER_DESC_queue(&cpu_buf[cpu_id]));
+            OUTPUT_signal_full(outbuf) = FALSE;
+            OUTPUT_tasklet_queued(outbuf) = FALSE;
+        }
+    }
+
+    if (cpu_sideband_buf) {
+        outbuf = &BUFFER_DESC_outbuf(&cpu_sideband_buf[cpu_id]);
+        if (outbuf && OUTPUT_signal_full(outbuf)) {
+            wake_up_interruptible_sync(&BUFFER_DESC_queue(&cpu_sideband_buf[cpu_id]));
+            OUTPUT_signal_full(outbuf) = FALSE;
+            OUTPUT_tasklet_queued(outbuf) = FALSE;
+        }
+    }
+
+    SEP_DRV_LOG_NOTIFICATION_OUT("");
+}
+
+
+/*
+ *  @fn extern void OUTPUT_Initialize(void)
+ *
+ *  @returns OS_STATUS
+ *  @brief  Allocate, initialize, and return all output data structure
+ *
+ * <I>Special Notes:</I>
+ *      Initialize the output structures.
+ *      For each CPU in the system, allocate the output buffers.
+ *      Initialize a module buffer and temp file to hold module information
+ *      Initialize the read queues for each sample buffer
+ *
+ */
+extern OS_STATUS
+OUTPUT_Initialize (void)
+{
+    BUFFER_DESC    unused;
+    int            i;
+    OS_STATUS      status = OS_SUCCESS;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    flush = 0;
+    if (saved_buffer_size != OUTPUT_BUFFER_SIZE) {
+        if (saved_buffer_size > 0) {
+            OUTPUT_Destroy();
+        }
+        saved_buffer_size = OUTPUT_BUFFER_SIZE;
+    }
+    for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+        unused = output_Initialized_Buffers(&cpu_buf[i], 1);
+        if (!unused) {
+            OUTPUT_Destroy();
+            SEP_DRV_LOG_ERROR_TRACE_OUT("OS_NO_MEM (failed to allocate cpu output buffers!).");
+            return OS_NO_MEM;
+        }
+    }
+
+    if (multi_pebs_enabled) {
+        for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+            unused = output_Initialized_Buffers(&cpu_sideband_buf[i], 1);
+            if (!unused) {
+                OUTPUT_Destroy();
+                SEP_DRV_LOG_ERROR_TRACE_OUT("OS_NO_MEM (failed to allocate pebs process info output buffers!).");
+                return OS_NO_MEM;
+            }
+        }
+    }
+
+    /*
+     *  Just need one module buffer
+     */
+    unused = output_Initialized_Buffers(module_buf, MODULE_BUFF_SIZE);
+    if (!unused) {
+        OUTPUT_Destroy();
+        SEP_DRV_LOG_ERROR_TRACE_OUT("OS_NO_MEM (failed to create module output buffers!).");
+        return OS_NO_MEM;
+    }
+
+    SEP_DRV_LOG_TRACE("Set up the tasklet for NMI.");
+    for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+        tasklet_init(&CPU_STATE_nmi_tasklet(&pcb[i]), output_NMI_Sample_Buffer, (unsigned long)NULL);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", (U32)status);
+    return status;
+}
+
+#if defined (DRV_USE_TASKLET_WORKAROUND)
+static struct tasklet_struct dummy_tasklet;
+
+/*
+ *  @fn extern void output_tasklet_waker (PVOID ptr)
+ *
+ *  @returns None
+ *  @brief   Schedules a dummy tasklet to wake up the tasklet handler on the current core
+ *
+ * <I>Special Notes:</I>
+ *      Workaround for a rare situation where some tasklets are scheduled, but the core's TASKLET softirq bit was reset.
+ *      [NB: this may be caused by a kernel bug; so far, this issue was only observed on kernel version 3.10.0-123.el7]
+ *      Scheduling a (new) tasklet raises a new softirq, and gives 'forgotten' tasklets another chance to be processed.
+ *      This workaround is not fool-proof: if this new tasklet gets 'forgotten' too, the driver will get stuck in the
+ *      Clean Up routine until it gets processed (thanks to an external event raising the TASKLET softirq on this core),
+ *      which might never happen.
+ *
+ */
+static void output_tasklet_waker (PVOID ptr) {
+    SEP_DRV_LOG_TRACE_IN("");
+    tasklet_schedule(&dummy_tasklet);
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/*
+ *  @fn extern void output_dummy_tasklet_handler (unsigned long dummy)
+ *
+ *  @returns None
+ *  @brief   Dummy tasklet handler.
+ *
+ * <I>Special Notes:</I>
+ *      If this gets executed, the aforementioned workaround was successful.
+ *
+ */
+static void output_dummy_tasklet_handler (unsigned long dummy) {
+    SEP_DRV_LOG_NOTIFICATION_IN("Workaround was successful!");
+    SEP_DRV_LOG_NOTIFICATION_OUT("");
+}
+#endif
+
+
+/*
+ *  @fn extern void OUTPUT_Cleanup (VOID)
+ *
+ *  @returns None
+ *  @brief   Cleans up NMI tasklets if needed
+ *
+ * <I>Special Notes:</I>
+ *      Waits until all NMI tasklets are complete.
+ *
+ */
+extern void
+OUTPUT_Cleanup (VOID)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (!pcb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pcb).");
+        return;
+    }
+    else
+    {
+        int i;
+        SEP_DRV_LOG_TRACE("Killing all NMI tasklets...");
+
+        for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+            SEP_DRV_LOG_TRACE("Killing NMI tasklet %d...", i);
+
+            if(CPU_STATE_nmi_tasklet(&pcb[i]).state) {
+#if defined (DRV_USE_TASKLET_WORKAROUND)
+                SEP_DRV_LOG_ERROR("Tasklet %d is probably stuck! Trying workaround...", i);
+                tasklet_init(&dummy_tasklet, output_dummy_tasklet_handler, 0);
+                CONTROL_Invoke_Cpu(i, output_tasklet_waker, NULL);
+                tasklet_kill(&dummy_tasklet);
+                SEP_DRV_LOG_ERROR("Workaround was successful for tasklet %d.", i);
+#else
+                SEP_DRV_LOG_ERROR("Tasklet %d may be stuck. Try to set USE_TASKLET_WORKAROUND=YES in the Makefile if you observe unexpected behavior (e.g. cannot terminate a collection or initiate a new one).", i);
+#endif
+            }
+
+            tasklet_kill(&CPU_STATE_nmi_tasklet(&pcb[i]));
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+
+/*
+ *  @fn extern void OUTPUT_Initialize_UNC()
+ *
+ *  @returns OS_STATUS
+ *  @brief  Allocate, initialize, and return all output data structure
+ *
+ * <I>Special Notes:</I>
+ *      Initialize the output structures.
+ *      For each CPU in the system, allocate the output buffers.
+ *      Initialize a module buffer and temp file to hold module information
+ *      Initialize the read queues for each sample buffer
+ *
+ */
+extern OS_STATUS
+OUTPUT_Initialize_UNC (void)
+{
+    BUFFER_DESC    unused;
+    int            i;
+    OS_STATUS      status = OS_SUCCESS;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    for (i = 0; i < num_packages; i++) {
+        unused = output_Initialized_Buffers(&unc_buf[i], 1);
+        if (!unused) {
+            OUTPUT_Destroy();
+            SEP_DRV_LOG_ERROR_TRACE_OUT("Failed to allocate package output buffers!");
+            return OS_NO_MEM;
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", (U32)status);
+    return status;
+}
+
+
+/*
+ *  @fn OS_STATUS  OUTPUT_Flush()
+ *
+ *  @brief  Flush the module buffers and sample buffers
+ *
+ *  @return OS_STATUS
+ *
+ *  For each CPU in the system, set buffer full to the byte count to flush.
+ *  Flush the modules buffer, as well.
+ *
+ */
+extern int
+OUTPUT_Flush (
+    VOID
+)
+{
+    int        i;
+    int        writers = 0;
+    OUTPUT     outbuf;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    /*
+     *  Flush all remaining data to files
+     *  set up a flush event
+     */
+    init_waitqueue_head(&flush_queue);
+    SEP_DRV_LOG_TRACE("Waiting for %d writers.",(GLOBAL_STATE_num_cpus(driver_state)+ OTHER_C_DEVICES));
+    for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+        if (CPU_STATE_initial_mask(&pcb[i]) == 0) {
+            continue;
+        }
+        outbuf = &(cpu_buf[i].outbuf);
+        writers += 1;
+
+        OUTPUT_buffer_full(outbuf,OUTPUT_current_buffer(outbuf)) =
+            OUTPUT_total_buffer_size(outbuf) - OUTPUT_remaining_buffer_size(outbuf);
+    }
+
+    if (unc_buf_init) {
+        for (i = 0; i < num_packages; i++) {
+            outbuf = &(unc_buf[i].outbuf);
+            writers += 1;
+
+            OUTPUT_buffer_full(outbuf,OUTPUT_current_buffer(outbuf)) =
+                OUTPUT_total_buffer_size(outbuf) - OUTPUT_remaining_buffer_size(outbuf);
+        }
+    }
+
+    if (multi_pebs_enabled) {
+        for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+            if (CPU_STATE_initial_mask(&pcb[i]) == 0) {
+                continue;
+            }
+            outbuf = &(cpu_sideband_buf[i].outbuf);
+            writers += 1;
+
+            OUTPUT_buffer_full(outbuf,OUTPUT_current_buffer(outbuf)) =
+                OUTPUT_total_buffer_size(outbuf) - OUTPUT_remaining_buffer_size(outbuf);
+        }
+    }
+
+    atomic_set(&flush_writers, writers + OTHER_C_DEVICES);
+    // Flip the switch to terminate the output threads
+    // Do not do this earlier, as threads may terminate before all the data is flushed
+    flush = 1;
+    for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+        if (CPU_STATE_initial_mask(&pcb[i]) == 0) {
+            continue;
+        }
+        outbuf = &BUFFER_DESC_outbuf(&cpu_buf[i]);
+        OUTPUT_buffer_full(outbuf,OUTPUT_current_buffer(outbuf)) =
+            OUTPUT_total_buffer_size(outbuf) - OUTPUT_remaining_buffer_size(outbuf);
+        wake_up_interruptible_sync(&BUFFER_DESC_queue(&cpu_buf[i]));
+    }
+
+    if (unc_buf_init) {
+        for (i = 0; i < num_packages; i++) {
+            outbuf = &BUFFER_DESC_outbuf(&unc_buf[i]);
+            OUTPUT_buffer_full(outbuf,OUTPUT_current_buffer(outbuf)) =
+                OUTPUT_total_buffer_size(outbuf) - OUTPUT_remaining_buffer_size(outbuf);
+            wake_up_interruptible_sync(&BUFFER_DESC_queue(&unc_buf[i]));
+        }
+    }
+
+    if (multi_pebs_enabled) {
+        for (i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+            if (CPU_STATE_initial_mask(&pcb[i]) == 0) {
+                continue;
+            }
+            outbuf = &BUFFER_DESC_outbuf(&cpu_sideband_buf[i]);
+            OUTPUT_buffer_full(outbuf,OUTPUT_current_buffer(outbuf)) =
+                OUTPUT_total_buffer_size(outbuf) - OUTPUT_remaining_buffer_size(outbuf);
+            wake_up_interruptible_sync(&BUFFER_DESC_queue(&cpu_sideband_buf[i]));
+        }
+    }
+    // Flush all data from the module buffers
+
+    outbuf = &BUFFER_DESC_outbuf(module_buf);
+
+    OUTPUT_buffer_full(outbuf,OUTPUT_current_buffer(outbuf)) =
+        OUTPUT_total_buffer_size(outbuf) - OUTPUT_remaining_buffer_size(outbuf);
+
+    SEP_DRV_LOG_TRACE("Waking up module_queue.");
+    wake_up_interruptible_sync(&BUFFER_DESC_queue(module_buf));
+
+    //Wait for buffers to empty
+    while (atomic_read(&flush_writers) != 0) {
+        unsigned long delay;
+        U32           res;
+        delay = msecs_to_jiffies(1000);
+        res = wait_event_interruptible_timeout(flush_queue,
+                                               atomic_read(&flush_writers) == 0,
+                                               delay);
+
+        if (res == ERESTARTSYS || res == 0) {
+            SEP_DRV_LOG_TRACE("Wait_event_interruptible_timeout(flush_queue): %u, %u writers.", res, atomic_read(&flush_writers));
+            continue;
+        }
+    }
+
+    SEP_DRV_LOG_TRACE("Awakened from flush_queue.");
+    flush = 0;
+
+    SEP_DRV_LOG_TRACE_OUT("Res: 0.");
+    return 0;
+}
+
+/*
+ *  @fn extern void OUTPUT_Destroy()
+ *
+ *  @param   buffer  -  seed name of the output file
+ *  @param   len     -  length of the seed name
+ *  @returns OS_STATUS
+ *  @brief   Deallocate output structures
+ *
+ * <I>Special Notes:</I>
+ *      Free the module buffers
+ *      For each CPU in the system, free the sampling buffers
+ */
+extern int
+OUTPUT_Destroy (
+    VOID
+)
+{
+    int    i, n;
+    OUTPUT outbuf;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (module_buf) {
+        outbuf = &BUFFER_DESC_outbuf(module_buf);
+        output_Free_Buffers(module_buf, OUTPUT_total_buffer_size(outbuf));
+    }
+
+    if (cpu_buf != NULL) {
+        n = GLOBAL_STATE_num_cpus(driver_state);
+        for (i = 0; i < n; i++) {
+            outbuf = &BUFFER_DESC_outbuf(&cpu_buf[i]);
+            output_Free_Buffers(&cpu_buf[i], OUTPUT_total_buffer_size(outbuf));
+        }
+    }
+
+    if (unc_buf != NULL) {
+        n = num_packages;
+        for (i = 0; i < n; i++) {
+            outbuf = &BUFFER_DESC_outbuf(&unc_buf[i]);
+            output_Free_Buffers(&unc_buf[i], OUTPUT_total_buffer_size(outbuf));
+        }
+    }
+
+    if (cpu_sideband_buf != NULL) {
+        n = GLOBAL_STATE_num_cpus(driver_state);
+        for (i = 0; i < n; i++) {
+            outbuf = &BUFFER_DESC_outbuf(&cpu_sideband_buf[i]);
+            output_Free_Buffers(&cpu_sideband_buf[i], OUTPUT_total_buffer_size(outbuf));
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: 0.");
+    return 0;
+}
diff --git a/drivers/misc/intel/sepdk/sep/pci.c b/drivers/misc/intel/sepdk/sep/pci.c
new file mode 100644
index 000000000000..38f1c9e79160
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/pci.c
@@ -0,0 +1,680 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include "lwpmudrv_defines.h"
+#include <linux/errno.h>
+#include <linux/pci.h>
+#include <linux/types.h>
+#include <asm/page.h>
+#include <asm/io.h>
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+
+#if defined(BUILD_CHIPSET)
+#include "lwpmudrv_chipset.h"
+#endif
+
+#include "inc/lwpmudrv.h"
+#include "inc/pci.h"
+#include "inc/utility.h"
+
+
+struct pci_bus* pci_buses[MAX_BUSNO] = {0};
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern VOID PCI_Initialize(VOID)
+ *
+ * @param   none
+ *
+ * @return  none
+ *
+ * @brief   Initializes the pci_buses array.
+ *
+ */
+extern VOID PCI_Initialize (
+    VOID
+)
+{
+    U32 i;
+    U32 num_found_buses = 0;
+
+    SEP_DRV_LOG_INIT_IN("Initializing pci_buses...");
+
+    for (i = 0; i < MAX_BUSNO; i++) {
+        pci_buses[i] = pci_find_bus(0, i);
+        if (pci_buses[i]) {
+            SEP_DRV_LOG_DETECTION("Found PCI bus 0x%x at %p.", i, pci_buses[i]);
+            num_found_buses++;
+        }
+        SEP_DRV_LOG_TRACE("pci_buses[%u]: %p.", i, pci_buses[i]);
+    }
+
+    SEP_DRV_LOG_INIT_OUT("Found %u buses.", num_found_buses);
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern U32 PCI_Read_U32(bus, device, function, offset)
+ *
+ * @param    bus        - target bus
+ * @param    device     - target device
+ * @param    function   - target function
+ * @param    offset     - target register offset
+ *
+ * @return  Value at this location
+ *
+ * @brief   Reads a U32 from PCI configuration space
+ *
+ */
+extern U32 PCI_Read_U32 (
+    U32    bus,
+    U32    device,
+    U32    function,
+    U32    offset
+)
+{
+    U32 res   = 0;
+    U32 devfn = (device << 3) | (function & 0x7);
+
+    SEP_DRV_LOG_REGISTER_IN("Will read BDF(%x:%x:%x)[0x%x](4B)...", bus, device, function, offset);
+
+    if (bus < MAX_BUSNO && pci_buses[bus]) {
+        pci_buses[bus]->ops->read(pci_buses[bus], devfn, offset, 4, &res);
+    }
+    else {
+        SEP_DRV_LOG_ERROR("Could not read BDF(%x:%x:%x)[0x%x]: bus not found!", bus, device, function, offset);
+    }
+
+    SEP_DRV_LOG_REGISTER_OUT("Has read BDF(%x:%x:%x)[0x%x](4B): 0x%x.", bus, device, function, offset, res);
+    return res;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern U32 PCI_Read_U32_Valid(bus, device, function, offset, invalid_value)
+ *
+ * @param    bus            - target bus
+ * @param    device         - target device
+ * @param    function       - target function
+ * @param    offset         - target register offset
+ * @param    invalid_value  - value against which to compare the PCI-obtained value
+ *
+ * @return  Value at this location (if value != invalid_value), 0 otherwise
+ *
+ * @brief   Reads a U32 from PCI configuration space
+ *
+ */
+extern U32 PCI_Read_U32_Valid (
+    U32    bus,
+    U32    device,
+    U32    function,
+    U32    offset,
+    U32    invalid_value
+)
+{
+    U32 res   = 0;
+    U32 devfn = (device << 3) | (function & 0x7);
+
+    SEP_DRV_LOG_REGISTER_IN("Will read BDF(%x:%x:%x)[0x%x](4B)...", bus, device, function, offset);
+
+    if (bus < MAX_BUSNO && pci_buses[bus]) {
+        pci_buses[bus]->ops->read(pci_buses[bus], devfn, offset, 4, &res);
+        if (res == invalid_value) {
+            res = 0;
+            SEP_DRV_LOG_REGISTER_OUT("Has read BDF(%x:%x:%x)[0x%x](4B): 0x%x (invalid value).", bus, device, function, offset, res);
+        }
+        else {
+            SEP_DRV_LOG_REGISTER_OUT("Has read BDF(%x:%x:%x)[0x%x](4B): 0x%x.", bus, device, function, offset, res);
+        }
+    }
+    else {
+        SEP_DRV_LOG_REGISTER_OUT("Could not read BDF(%x:%x:%x)[0x%x]: bus not found!", bus, device, function, offset);
+    }
+
+    return res;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern U32 PCI_Read_U64(bus, device, function, offset)
+ *
+ * @param   bus        - target bus
+ * @param   device     - target device
+ * @param   function   - target function
+ * @param   offset     - target register offset
+ *
+ * @return  Value at this location
+ *
+ * @brief   Reads a U64 from PCI configuration space
+ *
+ */
+extern U64 PCI_Read_U64 (
+    U32    bus,
+    U32    device,
+    U32    function,
+    U32    offset
+)
+{
+    U64 res   = 0;
+    U32 devfn = (device << 3) | (function & 0x7);
+
+    SEP_DRV_LOG_REGISTER_IN("Will read BDF(%x:%x:%x)[0x%x](8B)...", bus, device, function, offset);
+
+    if (bus < MAX_BUSNO && pci_buses[bus]) {
+        pci_buses[bus]->ops->read(pci_buses[bus], devfn, offset    , 4, (U32*)&res);
+        pci_buses[bus]->ops->read(pci_buses[bus], devfn, offset + 4, 4, ((U32*)&res) + 1);
+    }
+    else {
+        SEP_DRV_LOG_ERROR("Could not read BDF(%x:%x:%x)[0x%x]: bus not found!", bus, device, function, offset);
+    }
+
+    SEP_DRV_LOG_REGISTER_OUT("Has read BDF(%x:%x:%x)[0x%x](8B): 0x%llx.", bus, device, function, offset, res);
+    return res;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern U32 PCI_Read_U64_Valid(bus, device, function, offset, invalid_value)
+ *
+ * @param   bus             - target bus
+ * @param   device          - target device
+ * @param   function        - target function
+ * @param   offset          - target register offset
+ * @param   invalid_value   - value against which to compare the PCI-obtained value
+ *
+ * @return  Value at this location (if value != invalid_value), 0 otherwise
+ *
+ * @brief   Reads a U64 from PCI configuration space
+ *
+ */
+extern U64 PCI_Read_U64_Valid (
+    U32    bus,
+    U32    device,
+    U32    function,
+    U32    offset,
+    U64    invalid_value
+)
+{
+    U64 res   = 0;
+    U32 devfn = (device << 3) | (function & 0x7);
+
+    SEP_DRV_LOG_REGISTER_IN("Will read BDF(%x:%x:%x)[0x%x](8B)...", bus, device, function, offset);
+
+    if (bus < MAX_BUSNO && pci_buses[bus]) {
+        pci_buses[bus]->ops->read(pci_buses[bus], devfn, offset    , 4, (U32*)&res);
+        pci_buses[bus]->ops->read(pci_buses[bus], devfn, offset + 4, 4, ((U32*)&res) + 1);
+
+        if (res == invalid_value) {
+            res = 0;
+            SEP_DRV_LOG_REGISTER_OUT("Has read BDF(%x:%x:%x)[0x%x](8B): 0x%llx (invalid value).", bus, device, function, offset, res);
+        }
+        else {
+            SEP_DRV_LOG_REGISTER_OUT("Has read BDF(%x:%x:%x)[0x%x](8B): 0x%llx.", bus, device, function, offset, res);
+        }
+    }
+    else {
+        SEP_DRV_LOG_REGISTER_OUT("Could not read BDF(%x:%x:%x)[0x%x]: bus not found!", bus, device, function, offset);
+    }
+
+    return res;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern U32 PCI_Write_U32(bus, device, function, offset, value)
+ *
+ * @param    bus            - target bus
+ * @param    device         - target device
+ * @param    function       - target function
+ * @param    offset         - target register offset
+ * @param    value          - value to write
+ *
+ * @return  0 in case of success, 1 otherwise
+ *
+ * @brief    Writes a U32 to PCI configuration space
+ *
+ */
+extern U32 PCI_Write_U32 (
+    U32    bus,
+    U32    device,
+    U32    function,
+    U32    offset,
+    U32    value
+)
+{
+    U32 res   = 0;
+    U32 devfn = (device << 3) | (function & 0x7);
+
+    SEP_DRV_LOG_REGISTER_IN("Will write BDF(%x:%x:%x)[0x%x](4B): 0x%x...", bus, device, function, offset, value);
+
+    if (bus < MAX_BUSNO && pci_buses[bus]) {
+        pci_buses[bus]->ops->write(pci_buses[bus], devfn, offset, 4, value);
+        SEP_DRV_LOG_REGISTER_OUT("Has written BDF(%x:%x:%x)[0x%x](4B): 0x%x.", bus, device, function, offset, value);
+    }
+    else {
+        SEP_DRV_LOG_ERROR("Could not write BDF(%x:%x:%x)[0x%x]: bus not found!", bus, device, function, offset);
+        res = 1;
+        SEP_DRV_LOG_REGISTER_OUT("Failed to write BDF(%x:%x:%x)[0x%x](4B): 0x%x.", bus, device, function, offset, value);
+    }
+
+    return res;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern U32 PCI_Write_U64(bus, device, function, offset, value)
+ *
+ * @param    bus            - target bus
+ * @param    device         - target device
+ * @param    function       - target function
+ * @param    offset         - target register offset
+ * @param    value          - value to write
+ *
+ * @return  0 in case of success, 1 otherwise
+ *
+ * @brief    Writes a U64 to PCI configuration space
+ *
+ */
+extern U32 PCI_Write_U64 (
+    U32    bus,
+    U32    device,
+    U32    function,
+    U32    offset,
+    U64    value
+)
+{
+    U32 res   = 0;
+    U32 devfn = (device << 3) | (function & 0x7);
+
+    SEP_DRV_LOG_REGISTER_IN("Will write BDF(%x:%x:%x)[0x%x](8B): 0x%llx...", bus, device, function, offset, value);
+
+    if (bus < MAX_BUSNO && pci_buses[bus]) {
+        pci_buses[bus]->ops->write(pci_buses[bus], devfn, offset    , 4, (U32)value);
+        pci_buses[bus]->ops->write(pci_buses[bus], devfn, offset + 4, 4, (U32)(value>>32));
+        SEP_DRV_LOG_REGISTER_OUT("Has written BDF(%x:%x:%x)[0x%x](8B): 0x%llx.", bus, device, function, offset, value);
+    }
+    else {
+        SEP_DRV_LOG_ERROR("Could not write BDF(%x:%x:%x)[0x%x]: bus not found!", bus, device, function, offset);
+        res = 1;
+        SEP_DRV_LOG_REGISTER_OUT("Failed to write BDF(%x:%x:%x)[0x%x](8B): 0x%llx.", bus, device, function, offset, value);
+    }
+
+    return res;
+}
+
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern int PCI_Read_From_Memory_Address(addr, val)
+ *
+ * @param    addr    - physical address in mmio
+ * @param   *value  - value at this address
+ *
+ * @return  status
+ *
+ * @brief   Read memory mapped i/o physical location
+ *
+ */
+extern int
+PCI_Read_From_Memory_Address (
+    U32 addr,
+    U32* val
+)
+{
+    U32 aligned_addr, offset, value;
+    PVOID base;
+
+    SEP_DRV_LOG_TRACE_IN("Addr: %x, val_pointer: %p.", addr, val);
+
+    if (addr <= 0) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("OS_INVALID (addr <= 0!).");
+        return OS_INVALID;
+    }
+
+    SEP_DRV_LOG_TRACE("Preparing to reading physical address: %x.", addr);
+    offset       = addr & ~PAGE_MASK;
+    aligned_addr = addr & PAGE_MASK;
+    SEP_DRV_LOG_TRACE("Aligned physical address: %x, offset: %x.", aligned_addr, offset);
+
+    base = ioremap_nocache(aligned_addr, PAGE_SIZE);
+    if (base == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("OS_INVALID (mapping failed!).");
+        return OS_INVALID;
+    }
+
+    SEP_DRV_LOG_REGISTER_IN("Will read PCI address %u (mapped at %p).", addr, base + offset);
+    value = readl(base+offset);
+    SEP_DRV_LOG_REGISTER_OUT("Read PCI address %u (mapped at %p): %x.", addr, base + offset, value);
+
+    *val = value;
+
+    iounmap(base);
+
+    SEP_DRV_LOG_TRACE_OUT("OS_SUCCESS.");
+    return OS_SUCCESS;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern int PCI_Write_To_Memory_Address(addr, val)
+ *
+ * @param   addr   - physical address in mmio
+ * @param   value  - value to be written
+ *
+ * @return  status
+ *
+ * @brief   Write to memory mapped i/o physical location
+ *
+ */
+extern int
+PCI_Write_To_Memory_Address (
+    U32 addr,
+    U32 val
+)
+{
+    U32 aligned_addr, offset;
+    PVOID base;
+
+    SEP_DRV_LOG_TRACE_IN("Addr: %x, val: %x.", addr, val);
+
+    if (addr <= 0) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("OS_INVALID (addr <= 0!).");
+        return OS_INVALID;
+    }
+
+    SEP_DRV_LOG_TRACE("Preparing to writing physical address: %x (val: %x).", addr, val);
+    offset       = addr & ~PAGE_MASK;
+    aligned_addr = addr & PAGE_MASK;
+    SEP_DRV_LOG_TRACE("Aligned physical address: %x, offset: %x (val: %x).", aligned_addr, offset, val);
+
+    base = ioremap_nocache(aligned_addr, PAGE_SIZE);
+    if (base == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("OS_INVALID (mapping failed!).");
+        return OS_INVALID;
+    }
+
+    SEP_DRV_LOG_REGISTER_IN("Will write PCI address %u (mapped at %p): %x.", addr, base + offset, val);
+    writel(val,base+offset);
+    SEP_DRV_LOG_REGISTER_OUT("Wrote PCI address %u (mapped at %p): %x.", addr, base + offset, val);
+
+    iounmap(base);
+
+    SEP_DRV_LOG_TRACE_OUT("OS_SUCCESS.");
+    return OS_SUCCESS;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern U32 PCI_Map_Memory(SEP_MMIO_NODE *node, U64 phy_address, U64 map_size)
+ *
+ * @param    node        - MAP NODE to use
+ * @param    phy_address - Address to be mapped
+ * @param    map_size    - Amount of memory to map (has to be a multiple of 4k)
+ *
+ * @return   OS_SUCCESS or OS_INVALID
+ *
+ * @brief    Maps a physical address to a virtual address
+ *
+ */
+extern OS_STATUS
+PCI_Map_Memory (
+    SEP_MMIO_NODE *node,
+    U64            phy_address,
+    U32            map_size
+)
+{
+    U8  *res;
+
+    SEP_DRV_LOG_INIT_IN("Node: %p, phy_address: %llx, map_size: %u.", node, phy_address, map_size);
+
+    if (!node              ||
+        !phy_address       ||
+        !map_size          ||
+        (phy_address & 4095)) {
+        SEP_DRV_LOG_ERROR_INIT_OUT("Invalid parameters, aborting!");
+        return OS_INVALID;
+    }
+
+    res = ioremap_nocache(phy_address, map_size);
+    if (!res) {
+        SEP_DRV_LOG_ERROR_INIT_OUT("Map operation failed!");
+        return OS_INVALID;
+    }
+
+    SEP_MMIO_NODE_physical_address(node) = (UIOP)phy_address;
+    SEP_MMIO_NODE_virtual_address(node)  = (UIOP)res;
+    SEP_MMIO_NODE_map_token(node)        = (UIOP)res;
+    SEP_MMIO_NODE_size(node)             = map_size;
+
+    SEP_DRV_LOG_INIT_OUT("Addr:0x%llx->0x%llx,tok:0x%llx,sz:%u.",
+        SEP_MMIO_NODE_physical_address(node),
+        SEP_MMIO_NODE_virtual_address(node),
+        SEP_MMIO_NODE_map_token(node),
+        SEP_MMIO_NODE_size(node));
+    return OS_SUCCESS;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern void PCI_Unmap_Memory(SEP_MMIO_NODE *node)
+ *
+ * @param   node - memory map node to clean up
+ *
+ * @return  none
+ *
+ * @brief   Unmaps previously mapped memory
+ *
+ */
+extern void
+PCI_Unmap_Memory (
+    SEP_MMIO_NODE *node
+)
+{
+    SEP_DRV_LOG_INIT_IN("Unmapping node %p.", node);
+
+    if (node) {
+        if (SEP_MMIO_NODE_size(node)) {
+            SEP_DRV_LOG_TRACE("Unmapping token 0x%llx (0x%llx->0x%llx)[%uB].",
+                SEP_MMIO_NODE_map_token(node),
+                SEP_MMIO_NODE_physical_address(node),
+                SEP_MMIO_NODE_virtual_address(node),
+                SEP_MMIO_NODE_size(node));
+            iounmap((void*)(UIOP)SEP_MMIO_NODE_map_token(node));
+            SEP_MMIO_NODE_size(node)             = 0;
+            SEP_MMIO_NODE_map_token(node)        = 0;
+            SEP_MMIO_NODE_virtual_address(node)  = 0;
+            SEP_MMIO_NODE_physical_address(node) = 0;
+        }
+        else {
+            SEP_DRV_LOG_TRACE("Already unmapped.");
+        }
+    }
+
+    SEP_DRV_LOG_INIT_OUT("Unmapped node %p.", node);
+    return;
+}
+
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn U32 PCI_MMIO_Read_U32(virtual_address_base, offset)
+ *
+ * @param   virtual_address_base   - Virtual address base
+ * @param   offset                 - Register offset
+ *
+ * @return  U32 read from an MMIO register
+ *
+ * @brief   Reads U32 value from MMIO
+ *
+ */
+extern U32
+PCI_MMIO_Read_U32 (
+    U64   virtual_address_base,
+    U32   offset
+)
+{
+    U32  temp_u32 = 0LL;
+    U32 *computed_address;
+
+    computed_address = (U32*)(((char*)(UIOP)virtual_address_base) + offset);
+
+    SEP_DRV_LOG_REGISTER_IN("Will read U32(0x%llx + 0x%x = 0x%p).", virtual_address_base, offset, computed_address);
+
+    if (!virtual_address_base) {
+        SEP_DRV_LOG_ERROR("Invalid base for U32(0x%llx + 0x%x = 0x%p)!", virtual_address_base, offset, computed_address);
+        temp_u32 = 0;
+    }
+    else {
+        temp_u32 = *computed_address;
+    }
+
+    SEP_DRV_LOG_REGISTER_OUT("Has read U32(0x%llx + 0x%x): 0x%x.", virtual_address_base, offset, temp_u32);
+    return temp_u32;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn U64 PCI_MMIO_Read_U64(virtual_address_base, offset)
+ *
+ * @param   virtual_address_base   - Virtual address base
+ * @param   offset                 - Register offset
+ *
+ * @return  U64 read from an MMIO register
+ *
+ * @brief   Reads U64 value from MMIO
+ *
+ */
+extern U64
+PCI_MMIO_Read_U64 (
+    U64   virtual_address_base,
+    U32   offset
+)
+{
+    U64  temp_u64 = 0LL;
+    U64 *computed_address;
+
+    computed_address = (U64*)(((char*)(UIOP)virtual_address_base) + offset);
+
+    SEP_DRV_LOG_REGISTER_IN("Will read U64(0x%llx + 0x%x = 0x%p).", virtual_address_base, offset, computed_address);
+
+    if (!virtual_address_base) {
+        SEP_DRV_LOG_ERROR("Invalid base for U32(0x%llx + 0x%x = 0x%p)!", virtual_address_base, offset, computed_address);
+        temp_u64 = 0;
+    }
+    else {
+        temp_u64 = *computed_address;
+    }
+
+    SEP_DRV_LOG_REGISTER_OUT("Has read U64(0x%llx + 0x%x): 0x%llx.", virtual_address_base, offset, temp_u64);
+    return temp_u64;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void PCI_MMIO_Write_U32(virtual_address_base, offset, value)
+ *
+ * @param   virtual_address_base   - Virtual address base
+ * @param   offset                 - Register offset
+ * @param   value                  - Value to write
+ *
+ * @return  U32 write into an MMIO register
+ *
+ * @brief   Writes U32 value to MMIO
+ *
+ */
+extern void
+PCI_MMIO_Write_U32 (
+    U64   virtual_address_base,
+    U32   offset,
+    U32   value
+)
+{
+    U32 *computed_address;
+
+    computed_address = (U32*)(((char*)(UIOP)virtual_address_base) + offset);
+
+    SEP_DRV_LOG_REGISTER_IN("Writing 0x%x to U32(0x%llx + 0x%x = 0x%p).", value, virtual_address_base, offset, computed_address);
+
+    if (!virtual_address_base) {
+        SEP_DRV_LOG_ERROR("Invalid base for U32(0x%llx + 0x%x = 0x%p)!", virtual_address_base, offset, computed_address);
+    }
+    else {
+        *computed_address = value;
+    }
+
+    SEP_DRV_LOG_REGISTER_OUT("Has written 0x%x to U32(0x%llx + 0x%x).", value, virtual_address_base, offset);
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void PCI_MMIO_Write_U64(virtual_address_base, offset, value)
+ *
+ * @param   virtual_address_base   - Virtual address base
+ * @param   offset                 - Register offset
+ * @param   value                  - Value to write
+ *
+ * @return  U64 write into an MMIO register
+ *
+ * @brief   Writes U64 value to MMIO
+ *
+ */
+extern void
+PCI_MMIO_Write_U64 (
+    U64   virtual_address_base,
+    U32   offset,
+    U64   value
+)
+{
+    U64 *computed_address;
+
+    computed_address = (U64*)(((char*)(UIOP)virtual_address_base) + offset);
+
+    SEP_DRV_LOG_REGISTER_IN("Writing 0x%llx to U64(0x%llx + 0x%x = 0x%p).", value, virtual_address_base, offset, computed_address);
+
+    if (!virtual_address_base) {
+        SEP_DRV_LOG_ERROR("Invalid base for U32(0x%llx + 0x%x = 0x%p)!", virtual_address_base, offset, computed_address);
+    }
+    else {
+        *computed_address = value;
+    }
+
+    SEP_DRV_LOG_REGISTER_OUT("Has written 0x%llx to U64(0x%llx + 0x%x).", value, virtual_address_base, offset);
+    return;
+}
diff --git a/drivers/misc/intel/sepdk/sep/pebs.c b/drivers/misc/intel/sepdk/sep/pebs.c
new file mode 100644
index 000000000000..1ed7a401f801
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/pebs.c
@@ -0,0 +1,1826 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/percpu.h>
+#include <linux/mm.h>
+#include <linux/uaccess.h>
+#include <asm/segment.h>
+#include <asm/page.h>
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+#include "lwpmudrv.h"
+#include "control.h"
+#include "core2.h"
+#include "utility.h"
+#include "output.h"
+#include "ecb_iterators.h"
+#include "pebs.h"
+
+#if defined(DRV_USE_KAISER)
+#include <asm/kaiser.h>
+#include <linux/kallsyms.h>
+int   (*local_kaiser_add_mapping)(unsigned long, unsigned long, unsigned long) = NULL;
+void  (*local_kaiser_remove_mapping)(unsigned long, unsigned long)             = NULL;
+#elif defined(DRV_USE_PTI)
+#include <asm/cpu_entry_area.h>
+#include <linux/kallsyms.h>
+#include <asm/pgtable_types.h>
+#include <asm/intel_ds.h>
+#include <asm/tlbflush.h>
+void  (*local_cea_set_pte)(void *cea_vaddr, phys_addr_t pa, pgprot_t flags) = NULL;
+void  (*local_do_kernel_range_flush)(void *info) = NULL;
+DEFINE_PER_CPU(PVOID, dts_buffer_cea);
+#endif
+
+static PVOID                          pebs_global_memory      = NULL;
+static size_t                         pebs_global_memory_size = 0;
+
+extern DRV_CONFIG              drv_cfg;
+extern DRV_SETUP_INFO_NODE     req_drv_setup_info;
+
+
+#if defined(DRV_USE_PTI)
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID pebs_Update_CEA (S32)
+ *
+ * @brief       Flush the TLB entries related to PEBS buffer in cpu entry area
+ *
+ * @param       this_cpu current cpu
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+pebs_Update_CEA (
+    S32  this_cpu
+)
+{
+    unsigned long cea_start_addr;
+    unsigned long cea_end_addr;
+
+    SEP_DRV_LOG_TRACE_IN("This_cpu: %d.", this_cpu);
+
+    if (per_cpu(dts_buffer_cea, this_cpu)) {
+        cea_start_addr = (unsigned long)per_cpu(dts_buffer_cea, this_cpu);
+        cea_end_addr = cea_start_addr + (unsigned long)CPU_STATE_dts_buffer_size(&pcb[this_cpu]);
+        if (local_do_kernel_range_flush) {
+            struct flush_tlb_info info;
+            info.start = cea_start_addr;
+            info.end = cea_end_addr;
+            local_do_kernel_range_flush(&info);
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+#endif
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID pebs_Corei7_Initialize_Threshold (dts, LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]))
+ *
+ * @brief       The nehalem specific initialization
+ *
+ * @param       dts  - dts description
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+pebs_Corei7_Initialize_Threshold (
+    DTS_BUFFER_EXT   dts
+)
+{
+    U32         this_cpu;
+    U32         dev_idx;
+    DEV_CONFIG  pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("Dts: %p.", dts);
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    DTS_BUFFER_EXT_pebs_threshold(dts)  = DTS_BUFFER_EXT_pebs_base(dts) + (LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]) * DEV_CONFIG_pebs_record_num(pcfg));
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID pebs_Corei7_Overflow ()
+ *
+ * @brief       The Nehalem specific overflow check
+ *
+ * @param       this_cpu        - cpu id
+ *              overflow_status - overflow status
+ *              rec_index       - record index
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *    Check the global overflow field of the buffer descriptor.
+ *    Precise events can be allocated on any of the 4 general purpose
+ *    registers.
+ */
+static U64
+pebs_Corei7_Overflow (
+    S32  this_cpu,
+    U64  overflow_status,
+    U32  rec_index
+)
+{
+    DTS_BUFFER_EXT   dtes;
+    S8              *pebs_base, *pebs_index, *pebs_ptr;
+    PEBS_REC_EXT     pb;
+    U8               pebs_ptr_check = FALSE;
+    U32              dev_idx = core_to_dev_map[this_cpu];
+
+    SEP_DRV_LOG_TRACE_IN("This_cpu: %d, overflow_status: %llx, rec_index: %u.", this_cpu, overflow_status, rec_index);
+
+    dtes = CPU_STATE_dts_buffer(&pcb[this_cpu]);
+
+    SEP_DRV_LOG_TRACE("This_cpu: %d, dtes %p.", this_cpu, dtes);
+
+    if (!dtes) {
+        return overflow_status;
+    }
+    pebs_base      = (S8 *)(UIOP)DTS_BUFFER_EXT_pebs_base(dtes);
+    SEP_DRV_LOG_TRACE("This_cpu: %d, pebs_base %p.", this_cpu, pebs_base);
+    pebs_index     = (S8 *)(UIOP)DTS_BUFFER_EXT_pebs_index(dtes);
+    pebs_ptr       = (S8 *)((UIOP)DTS_BUFFER_EXT_pebs_base(dtes) + (rec_index * LWPMU_DEVICE_pebs_record_size(&devices[dev_idx])));
+    pebs_ptr_check = (pebs_ptr && pebs_base != pebs_index && pebs_ptr < pebs_index);
+    if (pebs_ptr_check) {
+        pb = (PEBS_REC_EXT)pebs_ptr;
+        overflow_status |= PEBS_REC_EXT_glob_perf_overflow(pb);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %llx.", overflow_status);
+    return overflow_status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID pebs_Corei7_Overflow_APEBS ()
+ *
+ * @brief       Overflow check
+ *
+ * @param       this_cpu        - cpu id
+ *              overflow_status - overflow status
+ *              rec_index       - record index
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *    Check the global overflow field of the buffer descriptor.
+ *    Precise events can be allocated on any of the 8 general purpose
+ *    registers or 4 fixed registers.
+ */
+static U64
+pebs_Corei7_Overflow_APEBS (
+    S32  this_cpu,
+    U64  overflow_status,
+    U32  rec_index
+)
+{
+    S8                         *pebs_base, *pebs_index, *pebs_ptr;
+    ADAPTIVE_PEBS_BASIC_INFO    pb;
+    DTS_BUFFER_EXT1             dtes = CPU_STATE_dts_buffer(&pcb[this_cpu]);
+    U8                          pebs_ptr_check = FALSE;
+    U32                         dev_idx = core_to_dev_map[this_cpu];
+    DEV_CONFIG                  pcfg = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (!dtes) {
+        return overflow_status;
+    }
+    pebs_base      = (S8 *)(UIOP)DTS_BUFFER_EXT1_pebs_base(dtes);
+    pebs_index     = (S8 *)(UIOP)DTS_BUFFER_EXT1_pebs_index(dtes);
+    pebs_ptr       = (S8 *)((UIOP)DTS_BUFFER_EXT1_pebs_base(dtes) + (rec_index * LWPMU_DEVICE_pebs_record_size(&devices[dev_idx])));
+    pebs_ptr_check = (pebs_ptr && pebs_base != pebs_index && pebs_ptr < pebs_index);
+
+    if (pebs_ptr_check && DEV_CONFIG_enable_adaptive_pebs(pcfg)) {
+        pb = (ADAPTIVE_PEBS_BASIC_INFO)pebs_ptr;
+        overflow_status |= ADAPTIVE_PEBS_BASIC_INFO_applicable_counters(pb);
+    }
+
+    return overflow_status;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID pebs_Core2_Initialize_Threshold (dts, LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]))
+ *
+ * @brief       The Core2 specific initialization
+ *
+ * @param       dts - dts description
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+pebs_Core2_Initialize_Threshold (
+    DTS_BUFFER_EXT   dts
+)
+{
+    SEP_DRV_LOG_TRACE_IN("Dts: %p.", dts);
+
+    DTS_BUFFER_EXT_pebs_threshold(dts)  = DTS_BUFFER_EXT_pebs_base(dts);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID pebs_Core2_Overflow (dts, LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]))
+ *
+ * @brief       The Core2 specific overflow check
+ *
+ * @param       this_cpu        - cpu id
+ *              overflow_status - overflow status
+ *              rec_index       - record index
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *    Check the base and the index fields of the circular buffer, if they are
+ *    not the same, then a precise event has overflowed.  Precise events are
+ *    allocated only on register#0.
+ */
+static U64
+pebs_Core2_Overflow (
+    S32  this_cpu,
+    U64  overflow_status,
+    U32  rec_index
+)
+{
+    DTS_BUFFER_EXT   dtes;
+    U8               status   = FALSE;
+
+    SEP_DRV_LOG_TRACE_IN("This_cpu: %d, overflow_status: %llx, rec_index: %u.", this_cpu, overflow_status, rec_index);
+
+    dtes = CPU_STATE_dts_buffer(&pcb[this_cpu]);
+
+    if (!dtes) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Res: %llx (dtes is NULL!).", overflow_status);
+        return overflow_status;
+    }
+    status = (U8)((dtes) && (DTS_BUFFER_EXT_pebs_index(dtes) != DTS_BUFFER_EXT_pebs_base(dtes)));
+    if (status) {
+        // Merom allows only for general purpose register 0 to be precise capable
+        overflow_status  |= 0x1;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %llx.", overflow_status);
+    return overflow_status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID pebs_Modify_IP (sample, is_64bit_addr)
+ *
+ * @brief       Change the IP field in the sample to that in the PEBS record
+ *
+ * @param       sample        - sample buffer
+ * @param       is_64bit_addr - are we in a 64 bit module
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static VOID
+pebs_Modify_IP (
+    void        *sample,
+    DRV_BOOL     is_64bit_addr,
+    U32          rec_index
+)
+{
+    SampleRecordPC  *psamp = sample;
+    DTS_BUFFER_EXT   dtes;
+    S8              *pebs_base, *pebs_index, *pebs_ptr;
+    PEBS_REC_EXT     pb;
+    U8               pebs_ptr_check = FALSE;
+    U32              this_cpu;
+    U32              dev_idx;
+
+    SEP_DRV_LOG_TRACE_IN("Sample: %p, is_64bit_addr: %u, rec_index: %u.", sample, is_64bit_addr, rec_index);
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    dtes     = CPU_STATE_dts_buffer(&pcb[this_cpu]);
+
+    if (!dtes || !psamp) {
+        return;
+    }
+    SEP_DRV_LOG_TRACE("In PEBS Fill Buffer: cpu %d.", CONTROL_THIS_CPU());
+    pebs_base      = (S8 *)(UIOP)DTS_BUFFER_EXT_pebs_base(dtes);
+    pebs_index     = (S8 *)(UIOP)DTS_BUFFER_EXT_pebs_index(dtes);
+    pebs_ptr       = (S8 *)((UIOP)DTS_BUFFER_EXT_pebs_base(dtes) + (rec_index * LWPMU_DEVICE_pebs_record_size(&devices[dev_idx])));
+    pebs_ptr_check = (pebs_ptr && pebs_base != pebs_index && pebs_ptr < pebs_index);
+    if (pebs_ptr_check) {
+        pb = (PEBS_REC_EXT)pebs_ptr;
+        if (is_64bit_addr) {
+            SAMPLE_RECORD_iip(psamp)    = PEBS_REC_EXT_linear_ip(pb);
+            SAMPLE_RECORD_ipsr(psamp)   = PEBS_REC_EXT_r_flags(pb);
+        }
+        else {
+            SAMPLE_RECORD_eip(psamp)    = PEBS_REC_EXT_linear_ip(pb) & 0xFFFFFFFF;
+            SAMPLE_RECORD_eflags(psamp) = PEBS_REC_EXT_r_flags(pb) & 0xFFFFFFFF;
+        }
+    }
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID pebs_Modify_IP_With_Eventing_IP (sample, is_64bit_addr)
+ *
+ * @brief       Change the IP field in the sample to that in the PEBS record
+ *
+ * @param       sample        - sample buffer
+ * @param       is_64bit_addr - are we in a 64 bit module
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static VOID
+pebs_Modify_IP_With_Eventing_IP (
+    void        *sample,
+    DRV_BOOL     is_64bit_addr,
+    U32          rec_index
+)
+{
+    SampleRecordPC             *psamp = sample;
+    DTS_BUFFER_EXT              dtes;
+    S8                         *pebs_ptr, *pebs_base, *pebs_index;
+    U64                         ip = 0, flags = 0;
+    U8                          pebs_ptr_check = FALSE;
+    U32                         this_cpu;
+    U32                         dev_idx;
+    DEV_CONFIG                  pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("Sample: %p, is_64bit_addr: %u, rec_index: %u.", sample, is_64bit_addr, rec_index);
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    dtes     = CPU_STATE_dts_buffer(&pcb[this_cpu]);
+
+    if (!dtes || !psamp) {
+        return;
+    }
+
+    pebs_base      = (S8 *)(UIOP)DTS_BUFFER_EXT_pebs_base(dtes);
+    pebs_index     = (S8 *)(UIOP)DTS_BUFFER_EXT_pebs_index(dtes);
+    pebs_ptr       = (S8 *)((UIOP)DTS_BUFFER_EXT_pebs_base(dtes) + (rec_index * LWPMU_DEVICE_pebs_record_size(&devices[dev_idx])));
+    pebs_ptr_check = (pebs_ptr && pebs_base != pebs_index && pebs_ptr < pebs_index);
+
+    if (!pebs_ptr_check) {
+        return;
+    }
+    if (DEV_CONFIG_enable_adaptive_pebs(pcfg)) {
+        ip = ADAPTIVE_PEBS_BASIC_INFO_eventing_ip((ADAPTIVE_PEBS_BASIC_INFO)pebs_ptr);
+        if (DEV_CONFIG_apebs_collect_gpr(pcfg)) {
+            flags = ADAPTIVE_PEBS_GPR_INFO_rflags((ADAPTIVE_PEBS_GPR_INFO)
+                                           (pebs_ptr + LWPMU_DEVICE_apebs_gpr_offset(&devices[dev_idx])));
+        }
+    }
+    else {
+        ip    = PEBS_REC_EXT1_eventing_ip((PEBS_REC_EXT1)pebs_ptr);
+        flags = PEBS_REC_EXT1_r_flags((PEBS_REC_EXT1)pebs_ptr);
+    }
+    if (is_64bit_addr) {
+        SAMPLE_RECORD_iip(psamp) = ip;
+        SAMPLE_RECORD_ipsr(psamp) = flags;
+    }
+    else {
+        SAMPLE_RECORD_eip(psamp)    = ip & 0xFFFFFFFF;
+        SAMPLE_RECORD_eflags(psamp) = flags & 0xFFFFFFFF;
+    }
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID pebs_Modify_TSC (sample)
+ *
+ * @brief       Change the TSC field in the sample to that in the PEBS record
+ *
+ * @param       sample        - sample buffer
+ *              rec_index     - record index
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static VOID
+pebs_Modify_TSC (
+    void        *sample,
+    U32          rec_index
+)
+{
+    SampleRecordPC *psamp = sample;
+    DTS_BUFFER_EXT  dtes;
+    S8             *pebs_base, *pebs_index, *pebs_ptr;
+    U64             tsc;
+    U8              pebs_ptr_check = FALSE;
+    U32             this_cpu;
+    U32             dev_idx;
+    DEV_CONFIG      pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("Sample: %p, rec_index: %u.", sample, rec_index);
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    dtes     = CPU_STATE_dts_buffer(&pcb[this_cpu]);
+
+    if (!dtes || !psamp) {
+        return;
+    }
+    pebs_base      = (S8 *)(UIOP)DTS_BUFFER_EXT_pebs_base(dtes);
+    pebs_index     = (S8 *)(UIOP)DTS_BUFFER_EXT_pebs_index(dtes);
+    pebs_ptr       = (S8 *)((UIOP)DTS_BUFFER_EXT_pebs_base(dtes) + (rec_index * LWPMU_DEVICE_pebs_record_size(&devices[dev_idx])));
+    pebs_ptr_check = (pebs_ptr && pebs_base != pebs_index && pebs_ptr < pebs_index);
+    if (!pebs_ptr_check) {
+        return;
+    }
+
+    if (DEV_CONFIG_enable_adaptive_pebs(pcfg)) {
+        tsc = ADAPTIVE_PEBS_BASIC_INFO_tsc((ADAPTIVE_PEBS_BASIC_INFO)pebs_ptr);
+    }
+    else {
+        tsc = PEBS_REC_EXT2_tsc((PEBS_REC_EXT2)pebs_ptr);
+    }
+    SAMPLE_RECORD_tsc(psamp) = tsc;
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U32 pebs_Get_Num_Records_Filled ()
+ *
+ * @brief       get number of PEBS records filled in PEBS buffer
+ *
+ * @param       NONE
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static U32
+pebs_Get_Num_Records_Filled (
+    VOID
+)
+{
+    U32              num = 0;
+    DTS_BUFFER_EXT   dtes;
+    S8              *pebs_base, *pebs_index;
+    U32              this_cpu;
+    U32              dev_idx;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    dtes     = CPU_STATE_dts_buffer(&pcb[this_cpu]);
+
+    if (!dtes) {
+        return num;
+    }
+    pebs_base  = (S8 *)(UIOP)DTS_BUFFER_EXT_pebs_base(dtes);
+    pebs_index = (S8 *)(UIOP)DTS_BUFFER_EXT_pebs_index(dtes);
+    if (pebs_base != pebs_index) {
+        num = (U32)(pebs_index - pebs_base) / LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", num);
+    return num;
+}
+
+/*
+ * Initialize the pebs micro dispatch tables
+ */
+PEBS_DISPATCH_NODE  core2_pebs =
+{
+     pebs_Core2_Initialize_Threshold,
+     pebs_Core2_Overflow,
+     pebs_Modify_IP,
+     NULL,
+     pebs_Get_Num_Records_Filled
+};
+
+PEBS_DISPATCH_NODE  core2p_pebs =
+{
+     pebs_Corei7_Initialize_Threshold,
+     pebs_Core2_Overflow,
+     pebs_Modify_IP,
+     NULL,
+     pebs_Get_Num_Records_Filled
+};
+
+PEBS_DISPATCH_NODE  corei7_pebs =
+{
+     pebs_Corei7_Initialize_Threshold,
+     pebs_Corei7_Overflow,
+     pebs_Modify_IP,
+     NULL,
+     pebs_Get_Num_Records_Filled
+};
+
+PEBS_DISPATCH_NODE  haswell_pebs =
+{
+     pebs_Corei7_Initialize_Threshold,
+     pebs_Corei7_Overflow,
+     pebs_Modify_IP_With_Eventing_IP,
+     NULL,
+     pebs_Get_Num_Records_Filled
+};
+
+PEBS_DISPATCH_NODE  perfver4_pebs =
+{
+     pebs_Corei7_Initialize_Threshold,
+     pebs_Corei7_Overflow,
+     pebs_Modify_IP_With_Eventing_IP,
+     pebs_Modify_TSC,
+     pebs_Get_Num_Records_Filled
+};
+
+PEBS_DISPATCH_NODE perfver4_apebs = // adaptive PEBS
+{
+    pebs_Corei7_Initialize_Threshold,
+    pebs_Corei7_Overflow_APEBS,
+    pebs_Modify_IP_With_Eventing_IP,
+    pebs_Modify_TSC,
+    pebs_Get_Num_Records_Filled
+};
+
+#define PER_CORE_BUFFER_SIZE(dts_size, record_size, record_num) (dts_size + (record_num + 1) * (record_size) + 64)
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID* pebs_Alloc_DTS_Buffer (VOID)
+ *
+ * @brief       Allocate buffers used for latency and pebs sampling
+ *
+ * @param       NONE
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              Allocate the memory needed to hold the DTS and PEBS records buffer.
+ *              This routine is called by a thread that corresponds to a single core
+ */
+static VOID*
+pebs_Alloc_DTS_Buffer (
+    VOID
+)
+{
+    UIOP            pebs_base;
+    U32             dts_size;
+    PVOID           dts_buffer = NULL;
+    DTS_BUFFER_EXT  dts;
+    int             this_cpu;
+    CPU_STATE       pcpu;
+    U32             dev_idx;
+    DEV_CONFIG      pcfg;
+    PEBS_DISPATCH   pebs_dispatch;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    /*
+     * one PEBS record... need 2 records so that
+     * threshold can be less than absolute max
+     */
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    preempt_enable();
+    dts_size      = sizeof(DTS_BUFFER_EXT_NODE);
+    pcpu          = &pcb[this_cpu];
+    dev_idx       = core_to_dev_map[this_cpu];
+    pcfg          = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    pebs_dispatch = LWPMU_DEVICE_pebs_dispatch(&devices[dev_idx]);
+
+    if (DEV_CONFIG_enable_adaptive_pebs(pcfg) ||
+        DEV_CONFIG_collect_fixed_counter_pebs(pcfg)) {
+        dts_size = sizeof(DTS_BUFFER_EXT1_NODE);
+    }
+
+    /*
+     * account for extra bytes to align PEBS base to cache line boundary
+     */
+    if (DRV_SETUP_INFO_page_table_isolation(&req_drv_setup_info) == DRV_SETUP_INFO_PTI_KPTI) {
+#if defined(DRV_USE_PTI)
+        struct page *page;
+        U32          buffer_size;
+
+        SEP_DRV_LOG_INIT("Allocating PEBS buffer using KPTI approach.");
+        buffer_size = (PER_CORE_BUFFER_SIZE(dts_size, LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]), DEV_CONFIG_pebs_record_num(pcfg)) / PAGE_SIZE + 1) * PAGE_SIZE;
+        if (buffer_size > PEBS_BUFFER_SIZE) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("Can't allocate more buffer than CEA allows!");
+            return NULL;
+        }
+
+        page = __alloc_pages_node(cpu_to_node(this_cpu), GFP_ATOMIC|__GFP_ZERO, get_order(buffer_size));
+        if (!page) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("NULL (failed to allocate space for DTS buffer!).");
+            return NULL;
+        }
+        dts_buffer = page_address(page);
+        per_cpu(dts_buffer_cea, this_cpu) = &get_cpu_entry_area(this_cpu)->cpu_debug_buffers.pebs_buffer;
+        if (!per_cpu(dts_buffer_cea, this_cpu)) {
+            if (dts_buffer) {
+                free_pages((unsigned long)dts_buffer, get_order(buffer_size));
+            }
+            SEP_DRV_LOG_ERROR_TRACE_OUT("CEA pebs_buffer ptr is NULL!");
+            return NULL;
+        }
+
+        CPU_STATE_dts_buffer(pcpu)          = dts_buffer;
+        CPU_STATE_dts_buffer_size(pcpu)     = buffer_size;
+
+        if (local_cea_set_pte) {
+            size_t      idx;
+            phys_addr_t phys_addr;
+            PVOID  cea_ptr = per_cpu(dts_buffer_cea, this_cpu);
+
+            phys_addr = virt_to_phys(dts_buffer);
+
+            preempt_disable();
+            for (idx = 0; idx < buffer_size; idx += PAGE_SIZE, phys_addr += PAGE_SIZE, cea_ptr += PAGE_SIZE) {
+                local_cea_set_pte(cea_ptr, phys_addr, PAGE_KERNEL);
+            }
+            pebs_Update_CEA(this_cpu);
+            preempt_enable();
+        }
+        pebs_base = (UIOP)(per_cpu(dts_buffer_cea, this_cpu)) + dts_size;
+        SEP_DRV_LOG_TRACE("This_cpu: %d, pebs_base %p.", this_cpu, pebs_base);
+
+        dts = (DTS_BUFFER_EXT)(per_cpu(dts_buffer_cea, this_cpu));
+#else
+        SEP_DRV_LOG_ERROR_TRACE_OUT("KPTI is enabled without PAGE_TABLE_ISOLATION kernel configuration!");
+        return NULL;
+#endif
+    }
+    else {
+        dts_buffer = (char *)pebs_global_memory + CPU_STATE_dts_buffer_offset(pcpu);
+        if (!dts_buffer) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("NULL (failed to allocate space for DTS buffer!).");
+            return NULL;
+        }
+        pebs_base = (UIOP)(dts_buffer) + dts_size;
+
+        CPU_STATE_dts_buffer(pcpu)          = dts_buffer;
+        CPU_STATE_dts_buffer_size(pcpu)     = PER_CORE_BUFFER_SIZE(dts_size, LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]), DEV_CONFIG_pebs_record_num(pcfg));
+
+        //  Make 32 byte aligned
+        if ((pebs_base & 0x000001F) != 0x0) {
+            pebs_base = ALIGN_32(pebs_base);
+        }
+
+        dts = (DTS_BUFFER_EXT)dts_buffer;
+    }
+
+    /*
+     * Program the DTES Buffer for Precise EBS.
+     * Set PEBS buffer for one PEBS record
+     */
+    DTS_BUFFER_EXT_base(dts)            = 0;
+    DTS_BUFFER_EXT_index(dts)           = 0;
+    DTS_BUFFER_EXT_max(dts)             = 0;
+    DTS_BUFFER_EXT_threshold(dts)       = 0;
+    DTS_BUFFER_EXT_pebs_base(dts)       = pebs_base;
+    DTS_BUFFER_EXT_pebs_index(dts)      = pebs_base;
+    DTS_BUFFER_EXT_pebs_max(dts)        = pebs_base + (DEV_CONFIG_pebs_record_num(pcfg) + 1) * LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]);
+
+    pebs_dispatch->initialize_threshold(dts);
+
+    SEP_DRV_LOG_TRACE("base --- %llx.", DTS_BUFFER_EXT_pebs_base(dts));
+    SEP_DRV_LOG_TRACE("index --- %llu.", DTS_BUFFER_EXT_pebs_index(dts));
+    SEP_DRV_LOG_TRACE("max --- %llu.", DTS_BUFFER_EXT_pebs_max(dts));
+    SEP_DRV_LOG_TRACE("threahold --- %llu.", DTS_BUFFER_EXT_pebs_threshold(dts));
+    SEP_DRV_LOG_TRACE("DTES buffer allocated for PEBS: %p.", dts_buffer);
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %p.", dts_buffer);
+    return dts;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID* pebs_Allocate_Buffers (VOID *params)
+ *
+ * @brief       Allocate memory and set up MSRs in preparation for PEBS
+ *
+ * @param       NONE
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              Set up the DS area and program the DS_AREA msrs in preparation
+ *              for a PEBS run.  Save away the old value in the DS_AREA.
+ *              This routine is called via the parallel thread call.
+ */
+static VOID
+pebs_Allocate_Buffers (
+    VOID  *params
+)
+{
+    U64         value;
+    U32         this_cpu;
+    CPU_STATE   pcpu;
+    U32         dev_idx;
+    DEV_CONFIG  pcfg;
+    PVOID       dts_ptr = NULL;
+
+    SEP_DRV_LOG_TRACE_IN("Params: %p.", params);
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (!DEV_CONFIG_pebs_mode(pcfg)) {
+        return;
+    }
+
+    SYS_Write_MSR(IA32_PEBS_ENABLE, 0LL);
+    value = SYS_Read_MSR(IA32_MISC_ENABLE);
+    if ((value & 0x80) && !(value & 0x1000)) {
+        CPU_STATE_old_dts_buffer(pcpu) = (PVOID)(UIOP)SYS_Read_MSR(IA32_DS_AREA);
+        dts_ptr     = pebs_Alloc_DTS_Buffer();
+        if (!dts_ptr) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("dts_ptr is NULL!");
+            return;
+        }
+        SEP_DRV_LOG_TRACE("Old dts buffer - %p.", CPU_STATE_old_dts_buffer(pcpu));
+        SEP_DRV_LOG_TRACE("New dts buffer - %p.", dts_ptr);
+        SYS_Write_MSR(IA32_DS_AREA, (U64)(UIOP)dts_ptr);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID pebs_Dellocate_Buffers (VOID *params)
+ *
+ * @brief       Clean up PEBS buffers and restore older values into the DS_AREA
+ *
+ * @param       NONE
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              Clean up the DS area and all restore state prior to the sampling run
+ *              This routine is called via the parallel thread call.
+ */
+static VOID
+pebs_Deallocate_Buffers (
+    VOID  *params
+)
+{
+    CPU_STATE   pcpu;
+    U32         this_cpu;
+    U32         dev_idx;
+    DEV_CONFIG  pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("Params: %p.", params);
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (!DEV_CONFIG_pebs_mode(pcfg)) {
+        return;
+    }
+
+    SEP_DRV_LOG_TRACE("Entered deallocate buffers.");
+    SYS_Write_MSR(IA32_DS_AREA, (U64)(UIOP)CPU_STATE_old_dts_buffer(pcpu));
+
+    if (DRV_SETUP_INFO_page_table_isolation(&req_drv_setup_info) == DRV_SETUP_INFO_PTI_KPTI) {
+#if defined(DRV_USE_PTI)
+        SEP_DRV_LOG_INIT("Freeing PEBS buffer using KPTI approach.");
+
+        if (local_cea_set_pte) {
+            size_t idx;
+            PVOID cea_ptr = per_cpu(dts_buffer_cea, this_cpu);
+            preempt_disable();
+            for (idx = 0; idx < CPU_STATE_dts_buffer_size(pcpu); idx += PAGE_SIZE, cea_ptr += PAGE_SIZE) {
+                local_cea_set_pte(cea_ptr, 0, PAGE_KERNEL);
+            }
+            pebs_Update_CEA(this_cpu);
+            preempt_enable();
+
+        }
+
+        if (CPU_STATE_dts_buffer(pcpu)) {
+            free_pages((unsigned long)CPU_STATE_dts_buffer(pcpu), get_order(CPU_STATE_dts_buffer_size(pcpu)));
+            CPU_STATE_dts_buffer(pcpu) = NULL;
+        }
+#endif
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U64 PEBS_Overflowed (this_cpu, overflow_status)
+ *
+ * @brief       Figure out if the PEBS event caused an overflow
+ *
+ * @param       this_cpu        -- the current cpu
+ *              overflow_status -- current value of the global overflow status
+ *
+ * @return      updated overflow_status
+ *
+ * <I>Special Notes:</I>
+ *              Figure out if the PEBS area has data that need to be transferred
+ *              to the output sample.
+ *              Update the overflow_status that is passed and return this value.
+ *              The overflow_status defines the events/status to be read
+ */
+extern U64
+PEBS_Overflowed (
+    S32  this_cpu,
+    U64  overflow_status,
+    U32  rec_index
+)
+{
+    U64           res;
+    U32           dev_idx;
+    PEBS_DISPATCH pebs_dispatch;
+
+    SEP_DRV_LOG_TRACE_IN("This_cpu: %d, overflow_status: %llx, rec_index: %u.", this_cpu, overflow_status, rec_index);
+
+    dev_idx       = core_to_dev_map[this_cpu];
+    pebs_dispatch = LWPMU_DEVICE_pebs_dispatch(&devices[dev_idx]);
+
+    res = pebs_dispatch->overflow(this_cpu, overflow_status, rec_index);
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %llx.", overflow_status);
+    return res;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID PEBS_Reset_Index (this_cpu)
+ *
+ * @brief       Reset the PEBS index pointer
+ *
+ * @param       this_cpu        -- the current cpu
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              reset index to next PEBS record to base of buffer
+ */
+extern VOID
+PEBS_Reset_Index (
+    S32    this_cpu
+)
+{
+    DTS_BUFFER_EXT   dtes;
+
+    SEP_DRV_LOG_TRACE_IN("This_cpu: %d.", this_cpu);
+
+    dtes = CPU_STATE_dts_buffer(&pcb[this_cpu]);
+
+    if (!dtes) {
+        return;
+    }
+    SEP_DRV_LOG_TRACE("PEBS Reset Index: %d.", this_cpu);
+    DTS_BUFFER_EXT_pebs_index(dtes) = DTS_BUFFER_EXT_pebs_base(dtes);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+extern U32 pmi_Get_CSD (U32, U32*, U32*);
+#define EFLAGS_V86_MASK       0x00020000L
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID PEBS_Flush_Buffer (VOID * param)
+ *
+ * @brief       generate sampling records from PEBS records in PEBS buffer
+ *
+ * @param       param        -- not used
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ */
+extern VOID
+PEBS_Flush_Buffer(
+    VOID * param
+)
+{
+    U32 i, this_cpu, index, desc_id;
+    U64              pebs_overflow_status = 0;
+    U64              lbr_tos_from_ip      = 0ULL;
+    DRV_BOOL         counter_overflowed   = FALSE;
+    ECB              pecb;
+    CPU_STATE        pcpu;
+    EVENT_DESC       evt_desc;
+    BUFFER_DESC      bd;
+    SampleRecordPC  *psamp_pebs;
+    U32              is_64bit_addr    = FALSE;
+    U32              u32PebsRecordNumFilled;
+#if defined(DRV_IA32)
+    U32              seg_cs;
+    U32              csdlo;
+    U32              csdhi;
+#endif
+    U32              dev_idx;
+    DEV_CONFIG       pcfg;
+    U32              cur_grp;
+    DRV_BOOL         multi_pebs_enabled;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    bd       = &cpu_buf[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    multi_pebs_enabled = (DEV_CONFIG_pebs_mode(pcfg) &&
+                          (DEV_CONFIG_pebs_record_num(pcfg) > 1) &&
+                          (DRV_SETUP_INFO_page_table_isolation(&req_drv_setup_info) == DRV_SETUP_INFO_PTI_DISABLED));
+
+    if (!multi_pebs_enabled) {
+        SEP_DRV_LOG_TRACE_OUT("PEBS_Flush_Buffer is not supported.");
+        return;
+    }
+
+    u32PebsRecordNumFilled = PEBS_Get_Num_Records_Filled();
+    for (i = 0; i < u32PebsRecordNumFilled; i++) {
+        pebs_overflow_status = PEBS_Overflowed(this_cpu, 0, i);
+        SEP_DRV_LOG_TRACE("Pebs_overflow_status = 0x%llx, i=%d.", pebs_overflow_status, i);
+
+        pecb = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+        FOR_EACH_DATA_REG(pecb, j) {
+            if ((!DEV_CONFIG_enable_adaptive_pebs(pcfg) && !ECB_entries_is_gp_reg_get(pecb, j)) ||
+                 !ECB_entries_precise_get(pecb, j)) {
+                continue;
+            }
+            if (ECB_entries_fixed_reg_get(pecb, j)) {
+                index = ECB_entries_reg_id(pecb, j) - IA32_FIXED_CTR0;
+                if (pebs_overflow_status & ((U64)1 << (32 + index))) {
+                    counter_overflowed = TRUE;
+                }
+            }
+            else {
+                index = ECB_entries_reg_id(pecb, j) - IA32_PMC0;
+                if (pebs_overflow_status & (U64)1 << index) {
+                    counter_overflowed = TRUE;
+                }
+            }
+            if (counter_overflowed) {
+                desc_id  = ECB_entries_event_id_index(pecb, j);
+                evt_desc = desc_data[desc_id];
+                SEP_DRV_LOG_TRACE("Event_id_index=%u, desc_id=%u.", ECB_entries_event_id_index(pecb, j), desc_id);
+                psamp_pebs = (SampleRecordPC *)OUTPUT_Reserve_Buffer_Space(bd, EVENT_DESC_sample_size(evt_desc), (NMI_mode)? TRUE:FALSE, !SEP_IN_NOTIFICATION);
+                if (!psamp_pebs) {
+                    SEP_DRV_LOG_ERROR("Could not generate samples from PEBS records.");
+                    continue;
+                }
+
+                lbr_tos_from_ip                             = 0ULL;
+                CPU_STATE_num_samples(&pcb[this_cpu])      += 1;
+                SAMPLE_RECORD_descriptor_id(psamp_pebs)     = desc_id;
+                SAMPLE_RECORD_event_index(psamp_pebs)       = ECB_entries_event_id_index(pecb, j);
+                SAMPLE_RECORD_pid_rec_index(psamp_pebs)     = (U32)-1;
+                SAMPLE_RECORD_pid_rec_index_raw(psamp_pebs) = 1;
+                SAMPLE_RECORD_tid(psamp_pebs)               = (U32)-1;
+                SAMPLE_RECORD_cpu_num(psamp_pebs)           = (U16) this_cpu;
+                SAMPLE_RECORD_osid(psamp_pebs)              = 0;
+
+#if defined (DRV_IA32)
+                PEBS_Modify_IP((S8 *)psamp_pebs, is_64bit_addr, i);
+                SAMPLE_RECORD_cs(psamp_pebs)                 = __KERNEL_CS;
+                if (SAMPLE_RECORD_eflags(psamp_pebs) & EFLAGS_V86_MASK) {
+                    csdlo = 0;
+                    csdhi = 0;
+                }
+                else {
+                    seg_cs = SAMPLE_RECORD_cs(psamp_pebs);
+                    SYS_Get_CSD(seg_cs, &csdlo, &csdhi);
+                }
+                SAMPLE_RECORD_csd(psamp_pebs).u1.lowWord  = csdlo;
+                SAMPLE_RECORD_csd(psamp_pebs).u2.highWord = csdhi;
+#elif defined (DRV_EM64T)
+                SAMPLE_RECORD_cs(psamp_pebs)                = __KERNEL_CS;
+                pmi_Get_CSD(SAMPLE_RECORD_cs(psamp_pebs),
+                            &SAMPLE_RECORD_csd(psamp_pebs).u1.lowWord,
+                            &SAMPLE_RECORD_csd(psamp_pebs).u2.highWord);
+                is_64bit_addr = (SAMPLE_RECORD_csd(psamp_pebs).u2.s2.reserved_0 == 1);
+                if (is_64bit_addr) {
+                    SAMPLE_RECORD_ia64_pc(psamp_pebs)       = TRUE;
+                }
+                else {
+                    SAMPLE_RECORD_ia64_pc(psamp_pebs)       = FALSE;
+
+                    SEP_DRV_LOG_TRACE("SAMPLE_RECORD_eip(psamp_pebs) 0x%x.", SAMPLE_RECORD_eip(psamp_pebs));
+                    SEP_DRV_LOG_TRACE("SAMPLE_RECORD_eflags(psamp_pebs) %x.", SAMPLE_RECORD_eflags(psamp_pebs));
+                }
+#endif
+                if (EVENT_DESC_pebs_offset(evt_desc)
+                    || EVENT_DESC_latency_offset_in_sample(evt_desc)) {
+                    lbr_tos_from_ip = PEBS_Fill_Buffer((S8 *)psamp_pebs, evt_desc, i);
+                }
+                PEBS_Modify_IP((S8 *)psamp_pebs, is_64bit_addr, i);
+                PEBS_Modify_TSC((S8 *)psamp_pebs, i);
+                if (ECB_entries_branch_evt_get(pecb, j) &&
+                    DEV_CONFIG_precise_ip_lbrs(pcfg) && lbr_tos_from_ip) {
+                    if (is_64bit_addr) {
+                        SAMPLE_RECORD_iip(psamp_pebs)       = lbr_tos_from_ip;
+                        SEP_DRV_LOG_TRACE("UPDATED SAMPLE_RECORD_iip(psamp) 0x%llx.", SAMPLE_RECORD_iip(psamp_pebs));
+                    }
+                    else {
+                        SAMPLE_RECORD_eip(psamp_pebs)       = (U32) lbr_tos_from_ip;
+                        SEP_DRV_LOG_TRACE("UPDATED SAMPLE_RECORD_eip(psamp) 0x%x.", SAMPLE_RECORD_eip(psamp_pebs));
+                    }
+                }
+            }
+        } END_FOR_EACH_DATA_REG;
+    }
+    PEBS_Reset_Index(this_cpu);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID PEBS_Reset_Counter (this_cpu, index, value)
+ *
+ * @brief       set reset value for PMC after overflow
+ *
+ * @param       this_cpu        -- the current cpu
+ *              index           -- PMC register index
+ *              value           -- reset value for PMC after overflow
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ */
+extern VOID
+PEBS_Reset_Counter (
+    S32        this_cpu,
+    U32        index,
+    U64        value
+)
+{
+    DTS_BUFFER_EXT  dts;
+    DTS_BUFFER_EXT1 dts_ext = NULL;
+    U32             dev_idx;
+    DEV_CONFIG      pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("This_cpu: %d, index: %u, value: %llx.", this_cpu, index, value);
+
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    dts      = CPU_STATE_dts_buffer(&pcb[this_cpu]);
+
+    if (!dts) {
+        return;
+    }
+    SEP_DRV_LOG_TRACE("PEBS Reset GP Counters[0:4]: cpu %d, index=%u, value=%llx.",
+        this_cpu, index, value);
+    switch(index) {
+        case 0:
+            DTS_BUFFER_EXT_counter_reset0(dts)  = value;
+            break;
+        case 1:
+            DTS_BUFFER_EXT_counter_reset1(dts)  = value;
+            break;
+        case 2:
+            DTS_BUFFER_EXT_counter_reset2(dts)  = value;
+            break;
+        case 3:
+            DTS_BUFFER_EXT_counter_reset3(dts)  = value;
+            break;
+    }
+
+    if (DEV_CONFIG_enable_adaptive_pebs(pcfg) ||
+        DEV_CONFIG_collect_fixed_counter_pebs(pcfg)) {
+        dts_ext = CPU_STATE_dts_buffer(&pcb[this_cpu]);
+    }
+    if (!dts_ext) {
+        return;
+    }
+    SEP_DRV_LOG_TRACE("PEBS Reset Fixed Counters and GP Counters[4:7]: cpu %d, index=%u, value=%llx.",
+        this_cpu, index, value);
+    switch(index) {
+        case 4:
+            DTS_BUFFER_EXT1_counter_reset4(dts_ext)  = value;
+            break;
+        case 5:
+            DTS_BUFFER_EXT1_counter_reset5(dts_ext)  = value;
+            break;
+        case 6:
+            DTS_BUFFER_EXT1_counter_reset6(dts_ext)  = value;
+            break;
+        case 7:
+            DTS_BUFFER_EXT1_counter_reset7(dts_ext)  = value;
+            break;
+        case 8:
+            DTS_BUFFER_EXT1_fixed_counter_reset0(dts_ext) = value;
+            break;
+        case 9:
+            DTS_BUFFER_EXT1_fixed_counter_reset1(dts_ext) = value;
+            break;
+        case 10:
+            DTS_BUFFER_EXT1_fixed_counter_reset2(dts_ext) = value;
+            break;
+        case 11:
+            DTS_BUFFER_EXT1_fixed_counter_reset3(dts_ext) = value;
+            break;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID PEBS_Modify_IP (sample, is_64bit_addr)
+ *
+ * @brief       Change the IP field in the sample to that in the PEBS record
+ *
+ * @param       sample        - sample buffer
+ * @param       is_64bit_addr - are we in a 64 bit module
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+extern VOID
+PEBS_Modify_IP (
+    void        *sample,
+    DRV_BOOL     is_64bit_addr,
+    U32          rec_index
+)
+{
+    U32           this_cpu;
+    U32           dev_idx;    
+    PEBS_DISPATCH pebs_dispatch;
+
+    SEP_DRV_LOG_TRACE_IN("Sample: %p, is_64bit_addr: %u, rec_index: %u.", sample, is_64bit_addr, rec_index);
+
+    this_cpu      = CONTROL_THIS_CPU();
+    dev_idx       = core_to_dev_map[this_cpu];
+    pebs_dispatch = LWPMU_DEVICE_pebs_dispatch(&devices[dev_idx]);
+
+    pebs_dispatch->modify_ip(sample, is_64bit_addr, rec_index);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID PEBS_Modify_TSC (sample)
+ *
+ * @brief       Change the TSC field in the sample to that in the PEBS record
+ *
+ * @param       sample        - sample buffer
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+extern VOID
+PEBS_Modify_TSC (
+    void        *sample,
+    U32          rec_index
+)
+{
+    U32           this_cpu;
+    U32           dev_idx;    
+    PEBS_DISPATCH pebs_dispatch;
+
+    SEP_DRV_LOG_TRACE_IN("Sample: %p, rec_index: %u.", sample, rec_index);
+
+    this_cpu      = CONTROL_THIS_CPU();
+    dev_idx       = core_to_dev_map[this_cpu];
+    pebs_dispatch = LWPMU_DEVICE_pebs_dispatch(&devices[dev_idx]);
+
+    if (pebs_dispatch->modify_tsc != NULL) {
+        pebs_dispatch->modify_tsc(sample, rec_index);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+extern U32
+PEBS_Get_Num_Records_Filled (
+    VOID
+)
+{
+    U32           this_cpu;
+    U32           dev_idx;    
+    PEBS_DISPATCH pebs_dispatch;
+    U32           num = 0;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    this_cpu      = CONTROL_THIS_CPU();
+    dev_idx       = core_to_dev_map[this_cpu];
+    pebs_dispatch = LWPMU_DEVICE_pebs_dispatch(&devices[dev_idx]);
+
+    if (pebs_dispatch->get_num_records_filled != NULL) {
+        num = pebs_dispatch->get_num_records_filled();
+        SEP_DRV_LOG_TRACE("Num=%u.", num);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", num);
+    return num;
+}
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID PEBS_Fill_Phy_Addr (LATENCY_INFO latency_info)
+ *
+ * @brief       Fill latency node with phy addr when applicable
+ *
+ * @param       latency_info             - pointer to LATENCY_INFO struct
+ *
+ * @return      NONE 
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+
+extern VOID
+PEBS_Fill_Phy_Addr (
+    LATENCY_INFO latency_info
+)
+{
+#if defined(DRV_EM64T) && LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,0)
+    U64                 lin_addr;
+    U64                 offset;
+    struct page        *page;
+
+    if (!DRV_CONFIG_virt_phys_translation(drv_cfg)) {
+        return;
+    }
+    lin_addr = (U64)LATENCY_INFO_linear_address(latency_info);
+    if (lin_addr != 0) {
+        offset = (U64)(lin_addr & 0x0FFF);
+        if (__virt_addr_valid(lin_addr)) {
+            LATENCY_INFO_phys_addr(latency_info) = (U64)__pa(lin_addr);
+        }
+        else if (lin_addr < __PAGE_OFFSET) {
+            pagefault_disable();
+            if (__get_user_pages_fast(lin_addr, 1, 1, &page)) {
+                LATENCY_INFO_phys_addr(latency_info) = (U64)page_to_phys(page) + offset;
+                put_page(page);
+            }
+            pagefault_enable();
+        }
+    }
+#endif
+    return;
+}
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U64 PEBS_Fill_Buffer (S8 *buffer, EVENT_DESC evt_desc, U32 rec_index)
+ *
+ * @brief       Fill the buffer with the pebs data
+ *
+ * @param       buffer                   -  area to write the data into
+ *              event_desc               -  event descriptor of the pebs event
+                rec_index                - current pebs record index
+ *
+ * @return      if APEBS return LBR_TOS_FROM_IP else return 0
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+extern U64
+PEBS_Fill_Buffer (
+    S8           *buffer,
+    EVENT_DESC    evt_desc,
+    U32           rec_index
+)
+{
+    DTS_BUFFER_EXT      dtes;
+    LATENCY_INFO_NODE   latency_info  = {0};
+    PEBS_REC_EXT1       pebs_base_ext1;
+    PEBS_REC_EXT2       pebs_base_ext2;
+    S8                 *pebs_base, *pebs_index, *pebs_ptr;
+    U8                  pebs_ptr_check = FALSE;
+    U64                 lbr_tos_from_ip = 0ULL;
+    U32                 this_cpu;
+    U32                 dev_idx;
+    DEV_CONFIG          pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("Buffer: %p, evt_desc: %p, rec_index: %u.",
+        buffer, evt_desc, rec_index);
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    dtes     = CPU_STATE_dts_buffer(&pcb[this_cpu]);
+
+    if (DEV_CONFIG_enable_adaptive_pebs(pcfg)) {
+        lbr_tos_from_ip =  APEBS_Fill_Buffer(buffer,
+                                             evt_desc,
+                                             rec_index);
+        return lbr_tos_from_ip;
+    }
+
+    SEP_DRV_LOG_TRACE("In PEBS Fill Buffer: cpu %d.", CONTROL_THIS_CPU());
+
+    if (!dtes) {
+        return lbr_tos_from_ip;
+    }
+    pebs_base      = (S8 *)(UIOP)DTS_BUFFER_EXT_pebs_base(dtes);
+    pebs_index     = (S8 *)(UIOP)DTS_BUFFER_EXT_pebs_index(dtes);
+    pebs_ptr       = (S8 *)((UIOP)DTS_BUFFER_EXT_pebs_base(dtes) + (rec_index *  LWPMU_DEVICE_pebs_record_size(&devices[dev_idx])));
+    pebs_ptr_check = (pebs_ptr && pebs_base != pebs_index && pebs_ptr < pebs_index);
+    if (!pebs_ptr_check) {
+        return lbr_tos_from_ip;
+    }
+    pebs_base = pebs_ptr;
+    if (EVENT_DESC_pebs_offset(evt_desc)) {
+        SEP_DRV_LOG_TRACE("PEBS buffer has data available.");
+        memcpy(buffer + EVENT_DESC_pebs_offset(evt_desc),
+               pebs_base,
+               EVENT_DESC_pebs_size(evt_desc));
+    }
+    if (EVENT_DESC_eventing_ip_offset(evt_desc)) {
+        pebs_base_ext1 = (PEBS_REC_EXT1)pebs_base;
+        *(U64*)(buffer + EVENT_DESC_eventing_ip_offset(evt_desc)) = PEBS_REC_EXT1_eventing_ip(pebs_base_ext1);
+    }
+    if (EVENT_DESC_hle_offset(evt_desc)) {
+        pebs_base_ext1 = (PEBS_REC_EXT1)pebs_base;
+        *(U64*)(buffer + EVENT_DESC_hle_offset(evt_desc)) = PEBS_REC_EXT1_hle_info(pebs_base_ext1);
+    }
+    if (EVENT_DESC_latency_offset_in_sample(evt_desc)) {
+        pebs_base_ext1 = (PEBS_REC_EXT1)pebs_base;
+        memcpy(&latency_info,
+                pebs_base + EVENT_DESC_latency_offset_in_pebs_record(evt_desc),
+                EVENT_DESC_latency_size_from_pebs_record(evt_desc));
+        memcpy(&LATENCY_INFO_stack_pointer(&latency_info),
+               &PEBS_REC_EXT1_rsp(pebs_base_ext1),
+               sizeof(U64));
+
+        LATENCY_INFO_phys_addr(&latency_info) = 0;
+        PEBS_Fill_Phy_Addr(&latency_info);
+
+        memcpy(buffer + EVENT_DESC_latency_offset_in_sample(evt_desc),
+               &latency_info,
+               sizeof(LATENCY_INFO_NODE) );
+    }
+    if (EVENT_DESC_pebs_tsc_offset(evt_desc)) {
+        pebs_base_ext2 = (PEBS_REC_EXT2)pebs_base;
+        *(U64*)(buffer + EVENT_DESC_pebs_tsc_offset(evt_desc)) = PEBS_REC_EXT2_tsc(pebs_base_ext2);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return lbr_tos_from_ip;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U64 APEBS_Fill_Buffer (S8 *buffer, EVENT_DESC evt_desc, U32 rec_index)
+ *
+ * @brief       Fill the buffer with the pebs data
+ *
+ * @param       buffer                   -  area to write the data into
+ *              event_desc               -  event descriptor of the pebs event
+ *              rec_index                - current pebs record index
+ *
+ * @return      LBR_TOS_FROM_IP
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+extern U64
+APEBS_Fill_Buffer (
+    S8           *buffer,
+    EVENT_DESC    evt_desc,
+    U32           rec_index
+)
+{
+    DTS_BUFFER_EXT1             dtes;
+    LATENCY_INFO_NODE           latency_info       = {0};
+    U64                         dtes_record_size   = 0;
+    U64                         dtes_record_format = 0;
+    ADAPTIVE_PEBS_MEM_INFO      apebs_mem          = NULL;
+    ADAPTIVE_PEBS_GPR_INFO      apebs_gpr          = NULL;
+    ADAPTIVE_PEBS_BASIC_INFO    apebs_basic        = NULL;
+    S8                         *pebs_base, *pebs_index, *pebs_ptr;
+    U8                          pebs_ptr_check     = FALSE;
+    U64                         lbr_tos_from_ip    = 0ULL;
+    U32                         this_cpu;
+    U32                         dev_idx;
+    DEV_CONFIG                  pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("Buffer: %p, evt_desc: %p, rec_index: %u.",
+        buffer, evt_desc, rec_index);
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    dtes     = CPU_STATE_dts_buffer(&pcb[this_cpu]);
+
+    SEP_DRV_LOG_TRACE("In APEBS Fill Buffer: cpu %d.", this_cpu);
+
+    if (!dtes || !DEV_CONFIG_enable_adaptive_pebs(pcfg)) {
+        return lbr_tos_from_ip;
+    }
+
+    pebs_base      = (S8 *)(UIOP)DTS_BUFFER_EXT1_pebs_base(dtes);
+    pebs_index     = (S8 *)(UIOP)DTS_BUFFER_EXT1_pebs_index(dtes);
+    pebs_ptr       = (S8 *)((UIOP)DTS_BUFFER_EXT1_pebs_base(dtes) + (rec_index *  LWPMU_DEVICE_pebs_record_size(&devices[dev_idx])));
+    pebs_ptr_check = (pebs_ptr && pebs_base != pebs_index && pebs_ptr < pebs_index);
+    if (!pebs_ptr_check) {
+        return lbr_tos_from_ip;
+    }
+
+    pebs_base = pebs_ptr;
+    apebs_basic        = (ADAPTIVE_PEBS_BASIC_INFO)(pebs_base + LWPMU_DEVICE_apebs_basic_offset(&devices[dev_idx]));
+    dtes_record_size   = (ADAPTIVE_PEBS_BASIC_INFO_record_info(apebs_basic) & APEBS_RECORD_SIZE_MASK) >> 48; // [63:48]
+    dtes_record_format = (ADAPTIVE_PEBS_BASIC_INFO_record_info(apebs_basic) & APEBS_RECORD_FORMAT_MASK); // [47:0]
+
+    if (dtes_record_size != LWPMU_DEVICE_pebs_record_size(&devices[dev_idx])) {
+        SEP_DRV_LOG_TRACE("PEBS record size does not match with ucode\n");
+    }
+    if (EVENT_DESC_pebs_offset(evt_desc)) {
+        *(U64*)(buffer + EVENT_DESC_pebs_offset(evt_desc)) = ADAPTIVE_PEBS_BASIC_INFO_record_info(apebs_basic);
+    }
+    if (EVENT_DESC_eventing_ip_offset(evt_desc)) {
+        *(U64*)(buffer + EVENT_DESC_eventing_ip_offset(evt_desc)) = ADAPTIVE_PEBS_BASIC_INFO_eventing_ip(apebs_basic);
+    }
+    if (EVENT_DESC_pebs_tsc_offset(evt_desc)) {
+        *(U64*)(buffer + EVENT_DESC_pebs_tsc_offset(evt_desc)) = ADAPTIVE_PEBS_BASIC_INFO_tsc(apebs_basic);
+    }
+    if (EVENT_DESC_applicable_counters_offset(evt_desc)) {
+        *(U64*)(buffer + EVENT_DESC_applicable_counters_offset(evt_desc)) = ADAPTIVE_PEBS_BASIC_INFO_applicable_counters(apebs_basic);
+    }
+    if (DEV_CONFIG_apebs_collect_gpr(pcfg) && EVENT_DESC_gpr_info_offset(evt_desc)) {
+        if (!(dtes_record_format & APEBS_GPR_RECORD_FORMAT_MASK)) {
+            SEP_DRV_LOG_WARNING("GPR info not found in DS PEBS record.");
+        }
+        memcpy(buffer    + EVENT_DESC_gpr_info_offset(evt_desc),
+               pebs_base + LWPMU_DEVICE_apebs_gpr_offset(&devices[dev_idx]),
+               EVENT_DESC_gpr_info_size(evt_desc));
+    }
+    if (DEV_CONFIG_apebs_collect_mem_info(pcfg) && EVENT_DESC_latency_offset_in_sample(evt_desc)) {
+        if (!(dtes_record_format & APEBS_MEM_RECORD_FORMAT_MASK)) {
+            SEP_DRV_LOG_WARNING("MEM info not found in DS PEBS record.");
+        }
+        apebs_mem = (ADAPTIVE_PEBS_MEM_INFO)(pebs_base + LWPMU_DEVICE_apebs_mem_offset(&devices[dev_idx]));
+        memcpy(&LATENCY_INFO_linear_address(&latency_info),
+               &ADAPTIVE_PEBS_MEM_INFO_data_linear_address(apebs_mem),
+               sizeof(U64));
+        memcpy(&LATENCY_INFO_data_source(&latency_info),
+               &ADAPTIVE_PEBS_MEM_INFO_data_source(apebs_mem),
+               sizeof(U64));
+        memcpy(&LATENCY_INFO_latency(&latency_info),
+               &ADAPTIVE_PEBS_MEM_INFO_latency(apebs_mem),
+               sizeof(U64));
+        LATENCY_INFO_stack_pointer(&latency_info) = 0;
+        if (DEV_CONFIG_apebs_collect_gpr(pcfg)) {
+            apebs_gpr = (ADAPTIVE_PEBS_GPR_INFO)(pebs_base + LWPMU_DEVICE_apebs_gpr_offset(&devices[dev_idx]));
+            memcpy(&LATENCY_INFO_stack_pointer(&latency_info),
+                   &ADAPTIVE_PEBS_GPR_INFO_rsp(apebs_gpr),
+                   sizeof(U64));
+        }
+
+        LATENCY_INFO_phys_addr(&latency_info) = 0;
+        PEBS_Fill_Phy_Addr(&latency_info);
+        memcpy(buffer + EVENT_DESC_latency_offset_in_sample(evt_desc),
+               &latency_info,
+               sizeof(LATENCY_INFO_NODE));
+    }
+    if (DEV_CONFIG_apebs_collect_mem_info(pcfg) && EVENT_DESC_hle_offset(evt_desc)) {
+        *(U64*)(buffer + EVENT_DESC_hle_offset(evt_desc)) =  ADAPTIVE_PEBS_MEM_INFO_hle_info((ADAPTIVE_PEBS_MEM_INFO)(pebs_base + LWPMU_DEVICE_apebs_mem_offset(&devices[dev_idx])));
+    }
+    if (DEV_CONFIG_apebs_collect_xmm(pcfg) && EVENT_DESC_xmm_info_offset(evt_desc)) {
+        if (!(dtes_record_format & APEBS_XMM_RECORD_FORMAT_MASK)) {
+            SEP_DRV_LOG_WARNING("XMM info not found in DS PEBS record.");
+        }
+        memcpy(buffer    + EVENT_DESC_xmm_info_offset(evt_desc),
+               pebs_base + LWPMU_DEVICE_apebs_xmm_offset(&devices[dev_idx]),
+               EVENT_DESC_xmm_info_size(evt_desc));
+    }
+    if (DEV_CONFIG_apebs_collect_lbrs(pcfg) && EVENT_DESC_lbr_offset(evt_desc)) {
+        if (!(dtes_record_format & APEBS_LBR_RECORD_FORMAT_MASK)) {
+            SEP_DRV_LOG_WARNING("LBR info not found in DS PEBS record\n");
+        }
+        if ((dtes_record_format >> 24) != (DEV_CONFIG_apebs_num_lbr_entries(pcfg)-1)) {
+            SEP_DRV_LOG_WARNING("DRV_CONFIG_apebs_num_lbr_entries does not match with PEBS record\n");
+        }
+        *(U64*)(buffer + EVENT_DESC_lbr_offset(evt_desc)) =
+                                       DEV_CONFIG_apebs_num_lbr_entries(pcfg)-1; //Top-of-Stack(TOS) pointing to last entry
+        //Populating lbr callstack as SST_ENTRY_N to SST_ENTRY_0 in tb util, hence setting TOS to SST_ENTRY_N
+        memcpy(buffer    + EVENT_DESC_lbr_offset(evt_desc) + sizeof(U64),
+               pebs_base + LWPMU_DEVICE_apebs_lbr_offset(&devices[dev_idx]),
+               EVENT_DESC_lbr_info_size(evt_desc)-sizeof(U64));
+        lbr_tos_from_ip = ADAPTIVE_PEBS_LBR_INFO_lbr_from((ADAPTIVE_PEBS_LBR_INFO)(pebs_base + LWPMU_DEVICE_apebs_lbr_offset(&devices[dev_idx])));
+    }
+    return lbr_tos_from_ip;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          OS_STATUS PEBS_Initialize (DEV_CONFIG pcfg)
+ *
+ * @brief       Initialize the pebs buffers
+ *
+ * @param       dev_idx -  Device index
+ *
+ * @return      status
+ *
+ * <I>Special Notes:</I>
+ *              If the user is asking for PEBS information.  Allocate the DS area
+ */
+extern OS_STATUS
+PEBS_Initialize (
+    U32         dev_idx
+)
+{
+    DEV_CONFIG pcfg = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    SEP_DRV_LOG_TRACE_IN("Pcfg: %p.", pcfg);
+
+    if (DEV_CONFIG_pebs_mode(pcfg)) {
+        switch (DEV_CONFIG_pebs_mode(pcfg)) {
+            case 1:
+                SEP_DRV_LOG_INIT("Set up the Core2 dispatch table.");
+                LWPMU_DEVICE_pebs_dispatch(&devices[dev_idx]) = &core2_pebs;
+                LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]) = sizeof(PEBS_REC_NODE);
+                break;
+            case 2:
+                SEP_DRV_LOG_INIT("Set up the Nehalem dispatch.");
+                LWPMU_DEVICE_pebs_dispatch(&devices[dev_idx]) = &corei7_pebs;
+                LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]) = sizeof(PEBS_REC_EXT_NODE);
+                break;
+            case 3:
+                SEP_DRV_LOG_INIT("Set up the Core2 (PNR) dispatch table.");
+                LWPMU_DEVICE_pebs_dispatch(&devices[dev_idx]) = &core2p_pebs;
+                LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]) = sizeof(PEBS_REC_NODE);
+                break;
+            case 4:
+                SEP_DRV_LOG_INIT("Set up the Haswell dispatch table.");
+                LWPMU_DEVICE_pebs_dispatch(&devices[dev_idx]) = &haswell_pebs;
+                LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]) = sizeof(PEBS_REC_EXT1_NODE);
+                break;
+            case 5:
+                SEP_DRV_LOG_INIT("Set up the Perf version4 dispatch table.");
+                LWPMU_DEVICE_pebs_dispatch(&devices[dev_idx]) = &perfver4_pebs;
+                LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]) = sizeof(PEBS_REC_EXT2_NODE);
+                break;
+            case 6:
+                if (!DEV_CONFIG_enable_adaptive_pebs(pcfg)) {
+                    SEP_DRV_LOG_TRACE("APEBS need to be enabled in perf version4 SNC dispatch mode.");
+                }
+                LWPMU_DEVICE_pebs_dispatch(&devices[dev_idx]) = &perfver4_apebs;
+                LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]) = sizeof(ADAPTIVE_PEBS_BASIC_INFO_NODE);
+                if (DEV_CONFIG_apebs_collect_mem_info(pcfg)) {
+                    LWPMU_DEVICE_apebs_mem_offset(&devices[dev_idx])  = LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]);
+                    LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]) += sizeof(ADAPTIVE_PEBS_MEM_INFO_NODE);
+                }
+                if (DEV_CONFIG_apebs_collect_gpr(pcfg)) {
+                    LWPMU_DEVICE_apebs_gpr_offset(&devices[dev_idx])  = LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]);
+                    LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]) += sizeof(ADAPTIVE_PEBS_GPR_INFO_NODE);
+                }
+                if (DEV_CONFIG_apebs_collect_xmm(pcfg)) {
+                    LWPMU_DEVICE_apebs_xmm_offset(&devices[dev_idx])  = LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]);
+                    LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]) += sizeof(ADAPTIVE_PEBS_XMM_INFO_NODE);
+                }
+                if (DEV_CONFIG_apebs_collect_lbrs(pcfg)) {
+                    LWPMU_DEVICE_apebs_lbr_offset(&devices[dev_idx])  = LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]);
+                    LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]) += (sizeof(ADAPTIVE_PEBS_LBR_INFO_NODE) * DEV_CONFIG_apebs_num_lbr_entries(pcfg));
+                }
+                SEP_DRV_LOG_TRACE("Size of adaptive pebs record - %d.", LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]));
+                break;
+            default:
+                SEP_DRV_LOG_INIT("Unknown PEBS type. Will not collect PEBS information.");
+                break;
+        }
+    }
+    if (LWPMU_DEVICE_pebs_dispatch(&devices[dev_idx]) && !DEV_CONFIG_pebs_record_num(pcfg)) {
+        DEV_CONFIG_pebs_record_num(pcfg) = 1;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("OS_SUCCESS");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          OS_STATUS PEBS_Allocate (void)
+ *
+ * @brief       Allocate the pebs related buffers
+ *
+ * @param       NONE
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *             Allocated the DS area used for PEBS capture
+ */
+extern OS_STATUS
+PEBS_Allocate (
+    VOID
+)
+{
+    S32        cpu_num;
+    CPU_STATE  pcpu;
+    U32        dev_idx;
+    U32        dts_size;
+    DEV_CONFIG pcfg;
+
+    SEP_DRV_LOG_INIT_IN("");
+
+    for (cpu_num = 0; cpu_num < GLOBAL_STATE_num_cpus(driver_state); cpu_num++) {
+        pcpu    = &pcb[cpu_num];
+        dev_idx = core_to_dev_map[cpu_num];
+        pcfg    = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+        if (LWPMU_DEVICE_pebs_dispatch(&devices[dev_idx])) {
+            dts_size = sizeof(DTS_BUFFER_EXT_NODE);
+            if (DEV_CONFIG_enable_adaptive_pebs(pcfg)) {
+                dts_size = sizeof(DTS_BUFFER_EXT1_NODE);
+            }
+            CPU_STATE_dts_buffer_offset(pcpu) = pebs_global_memory_size;
+            pebs_global_memory_size += PER_CORE_BUFFER_SIZE(dts_size, LWPMU_DEVICE_pebs_record_size(&devices[dev_idx]), DEV_CONFIG_pebs_record_num(pcfg));
+        }
+    }
+    if (pebs_global_memory_size) {
+        if (DRV_SETUP_INFO_page_table_isolation(&req_drv_setup_info) == DRV_SETUP_INFO_PTI_DISABLED) {
+            SEP_DRV_LOG_INIT("Allocating global PEBS buffer using regular control routine.");
+            pebs_global_memory = (PVOID)CONTROL_Allocate_KMemory(pebs_global_memory_size);
+            if (!pebs_global_memory) {
+                SEP_DRV_LOG_ERROR_TRACE_OUT("Failed to allocate PEBS buffer!");
+                return OS_NO_MEM;
+            }
+            memset(pebs_global_memory, 0, pebs_global_memory_size);
+        }
+        else {
+#if defined(DRV_USE_KAISER)
+            SEP_DRV_LOG_INIT("Allocating PEBS buffer using KAISER-compatible approach.");
+
+            if (!local_kaiser_add_mapping) {
+                local_kaiser_add_mapping = (PVOID) UTILITY_Find_Symbol("kaiser_add_mapping");
+                if (!local_kaiser_add_mapping) {
+                    SEP_DRV_LOG_ERROR("Could not find 'kaiser_add_mapping'!");
+                    goto kaiser_error_handling;
+                }
+            }
+
+            if (!local_kaiser_remove_mapping) {
+                local_kaiser_remove_mapping = (PVOID) UTILITY_Find_Symbol("kaiser_remove_mapping");
+                if (!local_kaiser_remove_mapping) {
+                    SEP_DRV_LOG_ERROR("Could not find 'kaiser_remove_mapping'!");
+                    goto kaiser_error_handling;
+                }
+            }
+
+            pebs_global_memory = (PVOID)__get_free_pages(GFP_KERNEL | __GFP_ZERO, get_order(pebs_global_memory_size));
+
+            if (pebs_global_memory) {
+                SEP_DRV_LOG_TRACE("Successful memory allocation for pebs_global_memory.");
+
+                if (local_kaiser_add_mapping((unsigned long) pebs_global_memory, pebs_global_memory_size, __PAGE_KERNEL) >= 0) {
+                    SEP_DRV_LOG_TRACE("Successful kaiser_add_mapping.");
+                }
+                else {
+                    SEP_DRV_LOG_ERROR("KAISER mapping failed!");
+                    free_pages((unsigned long)pebs_global_memory, get_order(pebs_global_memory_size));
+                    pebs_global_memory = NULL;
+                    goto kaiser_error_handling;
+                }
+            }
+            else {
+                SEP_DRV_LOG_ERROR("Failed memory allocation for pebs_global_memory!");
+            }
+
+kaiser_error_handling:
+            if (!pebs_global_memory) {
+                SEP_DRV_LOG_ERROR_TRACE_OUT("Failed to setup PEBS buffer!");
+                return OS_NO_MEM;
+            }
+#elif defined(DRV_USE_PTI)
+            if (!local_cea_set_pte) {
+                local_cea_set_pte = (PVOID) UTILITY_Find_Symbol("cea_set_pte");
+                if (!local_cea_set_pte) {
+                    SEP_DRV_LOG_ERROR_TRACE_OUT("Could not find 'cea_set_pte'!");
+                    return OS_FAULT;
+                }
+            }
+            if (!local_do_kernel_range_flush) {
+                local_do_kernel_range_flush = (PVOID) UTILITY_Find_Symbol("do_kernel_range_flush");
+                if (!local_do_kernel_range_flush) {
+                    SEP_DRV_LOG_ERROR_TRACE_OUT("Could not find 'do_kernel_range_flush'!");
+                    return OS_FAULT;
+                }
+            }
+#endif // DRV_USE_PTI
+        }
+    }
+
+    CONTROL_Invoke_Parallel(pebs_Allocate_Buffers, (VOID *)NULL);
+
+    SEP_DRV_LOG_INIT_OUT("");
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID PEBS_Destroy (void)
+ *
+ * @brief       Clean up the pebs related buffers
+ *
+ * @param       pcfg  -  Driver Configuration
+ *
+ * @return      NONE
+ *
+ * <I>Special Notes:</I>
+ *             Deallocated the DS area used for PEBS capture
+ */
+extern VOID
+PEBS_Destroy (
+    VOID
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    CONTROL_Invoke_Parallel(pebs_Deallocate_Buffers, (VOID *)(size_t)0);
+    if (pebs_global_memory) {
+        if (DRV_SETUP_INFO_page_table_isolation(&req_drv_setup_info) == DRV_SETUP_INFO_PTI_DISABLED) {
+            SEP_DRV_LOG_INIT("Freeing PEBS buffer using regular control routine.");
+            pebs_global_memory = CONTROL_Free_Memory(pebs_global_memory);
+        }
+#if defined(DRV_USE_KAISER)
+        else if (DRV_SETUP_INFO_page_table_isolation(&req_drv_setup_info) == DRV_SETUP_INFO_PTI_KAISER) {
+            SEP_DRV_LOG_INIT("Freeing PEBS buffer using KAISER-compatible approach.");
+            if (local_kaiser_remove_mapping) {
+                local_kaiser_remove_mapping((unsigned long) pebs_global_memory, pebs_global_memory_size);
+            }
+            else {
+                SEP_DRV_LOG_ERROR("Could not call 'kaiser_remove_mapping'!");
+            }
+            free_pages((unsigned long)pebs_global_memory, get_order(pebs_global_memory_size));
+            pebs_global_memory = NULL;
+        }
+#endif // DRV_USE_KAISER
+
+        pebs_global_memory_size = 0;
+        SEP_DRV_LOG_INIT("PEBS buffer successfully freed.");
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
diff --git a/drivers/misc/intel/sepdk/sep/perfver4.c b/drivers/misc/intel/sepdk/sep/perfver4.c
new file mode 100644
index 000000000000..96fb26556668
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/perfver4.c
@@ -0,0 +1,1443 @@
+/****
+    Copyright(C) 2013-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/wait.h>
+#include <linux/fs.h>
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+#include "lwpmudrv.h"
+#include "utility.h"
+#include "control.h"
+#include "output.h"
+#include "perfver4.h"
+#include "ecb_iterators.h"
+#include "pebs.h"
+#include "apic.h"
+
+
+extern U64                       *read_counter_info;
+extern DRV_CONFIG                 drv_cfg;
+extern U64                       *interrupt_counts;
+extern DRV_SETUP_INFO_NODE        req_drv_setup_info;
+extern EMON_BUFFER_DRIVER_HELPER  emon_buffer_driver_helper;
+static U64                        perf_metrics_counter_reload_value = 0;
+
+typedef struct SADDR_S {
+    S64 addr:PERFVER4_LBR_DATA_BITS;
+} SADDR;
+
+static U32 restore_reg_addr[3];
+
+#define SADDR_addr(x)                  (x).addr
+#define MSR_ENERGY_MULTIPLIER          0x606        // Energy Multiplier MSR
+
+#define IS_FIXED_CTR_ENABLED(ia32_perf_global_ctrl_reg_val)                          \
+                            ((ia32_perf_global_ctrl_reg_val) & 0x700000000ULL)
+#define IS_FOUR_FIXED_CTR_ENABLED(ia32_perf_global_ctrl_reg_val)                     \
+                            ((ia32_perf_global_ctrl_reg_val) & 0xF00000000ULL)
+#define IS_PMC_PEBS_ENABLED_GP(ia32_perf_global_ctrl_reg_val, ia32_pebs_enable_reg_val) \
+                              (((ia32_perf_global_ctrl_reg_val) & 0xfULL) == ((ia32_pebs_enable_reg_val) & 0xfULL))
+#define IS_PMC_PEBS_ENABLED_FP_AND_GP(ia32_perf_global_ctrl_reg_val, ia32_pebs_enable_reg_val) \
+                                 (((ia32_perf_global_ctrl_reg_val) & 0xf000000ffULL) == ((ia32_pebs_enable_reg_val) & 0xf000000ffULL))
+
+#define DISABLE_FRZ_ON_PMI(ia32_debug_ctrl_reg_val)                                  \
+                            (0xefff & (ia32_debug_ctrl_reg_val))
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void perfver4_Write_PMU(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Initial set up of the PMU registers
+ *
+ * <I>Special Notes</I>
+ *         Initial write of PMU registers.
+ *         Walk through the enties and write the value of the register accordingly.
+ *         Assumption:  For CCCR registers the enable bit is set to value 0.
+ *         When current_group = 0, then this is the first time this routine is called,
+ *         initialize the locks and set up EM tables.
+ */
+static VOID
+perfver4_Write_PMU (
+    VOID  *param
+)
+{
+    U32            this_cpu;
+    CPU_STATE      pcpu;
+    ECB            pecb;
+    U32            dev_idx;
+    U32            cur_grp;
+    EVENT_CONFIG   ec;
+    DISPATCH       dispatch;
+    DEV_CONFIG     pcfg;
+    U32            counter_index = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    ec       = LWPMU_DEVICE_ec(&devices[dev_idx]);
+    dispatch = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    if (CPU_STATE_current_group(pcpu) == 0) {
+        if (EVENT_CONFIG_mode(ec) != EM_DISABLED) {
+            U32            index;
+            U32            st_index;
+            U32            j;
+
+            /* Save all the initialization values away into an array for Event Multiplexing. */
+            for (j = 0; j < EVENT_CONFIG_num_groups(ec); j++) {
+                CPU_STATE_current_group(pcpu) = j;
+                st_index   = CPU_STATE_current_group(pcpu) * EVENT_CONFIG_max_gp_events(ec);
+                FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_GP) {
+                    index = st_index + i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+                    CPU_STATE_em_tables(pcpu)[index] = ECB_entries_reg_value(pecb,i);
+                } END_FOR_EACH_REG_CORE_OPERATION;
+            }
+            /* Reset the current group to the very first one. */
+            CPU_STATE_current_group(pcpu) = this_cpu % EVENT_CONFIG_num_groups(ec);
+        }
+    }
+
+    if (dispatch->hw_errata) {
+        dispatch->hw_errata();
+    }
+
+    /* Clear outstanding frozen bits */
+    SYS_Write_MSR(IA32_PERF_GLOBAL_OVF_CTRL, PERFVER4_FROZEN_BIT_MASK);
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_ALL_REG) {
+        /*
+         * Writing the GLOBAL Control register enables the PMU to start counting.
+         * So write 0 into the register to prevent any counting from starting.
+         */
+        if (i == ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)) {
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+            continue;
+        }
+        /*
+         *  PEBS is enabled for this collection session
+         */
+        if (DRV_SETUP_INFO_pebs_accessible(&req_drv_setup_info) &&
+            i == ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS) &&
+            ECB_entries_reg_value(pecb,i)) {
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+            continue;
+        }
+
+        if (DEV_CONFIG_pebs_mode(pcfg)
+            && (ECB_entries_precise_get(pecb, i) == 1)) {
+        if (ECB_entries_fixed_reg_get(pecb, i)) {
+            counter_index = (ECB_entries_reg_id(pecb,i) - IA32_FIXED_CTR0 + 8);
+        }
+        else {
+            counter_index = (ECB_entries_reg_id(pecb, i) - IA32_PMC0);
+        }
+        PEBS_Reset_Counter(this_cpu,
+                           counter_index,
+                           ECB_entries_reg_value(pecb,i));
+        }
+
+        SYS_Write_MSR(ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i));
+#if defined(MYDEBUG)
+        {
+            U64 val = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+            SEP_DRV_LOG_TRACE("Write reg 0x%x --- value 0x%llx -- read 0x%llx.",
+                            ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i), val);
+        }
+#endif
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void perfver4_Disable_PMU(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Zero out the global control register.  This automatically disables the PMU counters.
+ *
+ */
+static VOID
+perfver4_Disable_PMU (
+    PVOID  param
+)
+{
+    U32         this_cpu;
+    CPU_STATE   pcpu;
+    ECB         pecb;
+    U32         dev_idx;
+    U32         cur_grp;
+    DEV_CONFIG  pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (!pecb) {
+        // no programming for this device for this group
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    if (GET_DRIVER_STATE() != DRV_STATE_RUNNING) {
+        SEP_DRV_LOG_TRACE("Driver state = %d.", GET_DRIVER_STATE());
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), 0LL);
+        if (DEV_CONFIG_pebs_mode(pcfg)) {
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), 0LL);
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void perfver4_Enable_PMU(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Set the enable bit for all the Control registers
+ *
+ */
+static VOID
+perfver4_Enable_PMU (
+    PVOID   param
+)
+{
+    /*
+     * Get the value from the event block
+     *   0 == location of the global control reg for this block.
+     *   Generalize this location awareness when possible
+     */
+    U32         this_cpu;
+    CPU_STATE   pcpu;
+    ECB         pecb;
+    U32         dev_idx;
+    U32         cur_grp;
+    DEV_CONFIG  pcfg;
+    U64         global_control_val;
+    U64         pebs_enable_val;
+    DRV_BOOL    multi_pebs_enabled;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (!pecb) {
+        // no programming for this device for this group
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    if (KVM_guest_mode) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX (pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), 0LL);
+    }
+    if (GET_DRIVER_STATE() == DRV_STATE_RUNNING) {
+        APIC_Enable_Pmi();
+
+        /* Clear outstanding frozen bits */
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX (pecb, GLOBAL_OVF_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                      PERFVER4_FROZEN_BIT_MASK);
+
+        if (CPU_STATE_reset_mask(pcpu)) {
+            SEP_DRV_LOG_TRACE("Overflow reset mask %llx.", CPU_STATE_reset_mask(pcpu));
+            // Reinitialize the global overflow control register
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            CPU_STATE_reset_mask(pcpu) = 0LL;
+        }
+        if (CPU_STATE_group_swap(pcpu)) {
+            CPU_STATE_group_swap(pcpu) = 0;
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            if (DEV_CONFIG_pebs_mode(pcfg) || DEV_CONFIG_latency_capture(pcfg)) {
+                SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                              ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            }
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+#if defined(MYDEBUG)
+            {
+                U64 val;
+                val = SYS_Read_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+                SEP_DRV_LOG_TRACE("Write reg 0x%x--- read 0x%llx.",
+                        ECB_entries_reg_id(pecb,0), val);
+            }
+#endif
+        }
+
+        multi_pebs_enabled = (DEV_CONFIG_pebs_mode(pcfg) &&
+                              (DEV_CONFIG_pebs_record_num(pcfg) > 1) &&
+                              (DRV_SETUP_INFO_page_table_isolation(&req_drv_setup_info) == DRV_SETUP_INFO_PTI_DISABLED));
+
+        // FIXME: workaround for sampling both pebs event and non-pebs event
+        //        with pebs buffer size > 1
+        if (multi_pebs_enabled) {
+            global_control_val = SYS_Read_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            pebs_enable_val    = SYS_Read_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            if (IS_FIXED_CTR_ENABLED(global_control_val)
+                || !IS_PMC_PEBS_ENABLED_GP(global_control_val, pebs_enable_val)) {
+                SEP_DRV_LOG_TRACE("Global_control_val = 0x%llx pebs_enable_val = 0x%llx.",
+                                global_control_val, pebs_enable_val);
+                SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                              DISABLE_FRZ_ON_PMI(ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS))));
+            }
+        }
+    }
+    SEP_DRV_LOG_TRACE("Reenabled PMU with value 0x%llx.", ECB_entries_reg_value(pecb,0));
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn perfver4_Read_PMU_Data(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read all the data MSR's into a buffer.  Called by the interrupt handler.
+ *
+ */
+static void
+perfver4_Read_PMU_Data (
+    PVOID   param
+)
+{
+    U32       j;
+    U64      *buffer     = read_counter_info;
+    U32       this_cpu;
+    CPU_STATE pcpu;
+    ECB       pecb;
+    U32       dev_idx;
+    U32       cur_grp;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    preempt_disable();
+    this_cpu  = CONTROL_THIS_CPU();
+    preempt_enable();
+    pcpu      = &pcb[this_cpu];
+    dev_idx   = core_to_dev_map[this_cpu];
+    cur_grp   = CPU_STATE_current_group(pcpu);
+    pecb      = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    SEP_DRV_LOG_TRACE("PMU control_data 0x%p, buffer 0x%p.", LWPMU_DEVICE_PMU_register_data(&devices[dev_idx]), buffer);
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+
+        j = EMON_BUFFER_CORE_EVENT_OFFSET(EMON_BUFFER_DRIVER_HELPER_core_index_to_thread_offset_map(emon_buffer_driver_helper)[this_cpu],
+                                          ECB_entries_core_event_id(pecb,i));
+
+        buffer[j] = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+        SEP_DRV_LOG_TRACE("j=%u, value=%llu, cpu=%u, event_id=%u", j, buffer[j], this_cpu, ECB_entries_core_event_id(pecb,i));
+
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void perfver4_Check_Overflow(masks)
+ *
+ * @param    masks    the mask structure to populate
+ *
+ * @return   None     No return needed
+ *
+ * @brief  Called by the data processing method to figure out which registers have overflowed.
+ *
+ */
+static void
+perfver4_Check_Overflow (
+    DRV_MASKS    masks
+)
+{
+    U32                 index;
+    U64                 overflow_status     = 0;
+    U32                 this_cpu;
+    BUFFER_DESC         bd;
+    CPU_STATE           pcpu;
+    ECB                 pecb;
+    U32                 dev_idx;
+    U32                 cur_grp;
+    DEV_CONFIG          pcfg;
+    DISPATCH            dispatch;
+    U64                 overflow_status_clr = 0;
+    DRV_EVENT_MASK_NODE event_flag;
+
+    SEP_DRV_LOG_TRACE_IN("Masks: %p.", masks);
+
+    this_cpu = CONTROL_THIS_CPU();
+    bd       = &cpu_buf[this_cpu];
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    dispatch = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    // initialize masks
+    DRV_MASKS_masks_num(masks) = 0;
+
+    overflow_status = SYS_Read_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_STATUS_REG_INDEX, PMU_OPERATION_GLOBAL_STATUS)));
+
+    if (DEV_CONFIG_pebs_mode(pcfg)
+        && (DEV_CONFIG_pebs_record_num(pcfg) == 1)) {
+        overflow_status = PEBS_Overflowed (this_cpu, overflow_status, 0);
+    }
+    overflow_status_clr = overflow_status;
+
+    if (dispatch->check_overflow_gp_errata) {
+        overflow_status = dispatch->check_overflow_gp_errata(pecb,  &overflow_status_clr);
+    }
+    SEP_DRV_LOG_TRACE("Overflow: cpu: %d, status 0x%llx.", this_cpu, overflow_status);
+    index                        = 0;
+    BUFFER_DESC_sample_count(bd) = 0;
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+        if (ECB_entries_fixed_reg_get(pecb, i)) {
+            index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_FIXED) + 0x20;
+            if (dispatch->check_overflow_errata) {
+                overflow_status = dispatch->check_overflow_errata(pecb, i, overflow_status);
+            }
+        }
+        else if (ECB_entries_is_gp_reg_get(pecb, i)) {
+            index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+        }
+        else {
+            continue;
+        }
+        if (overflow_status & ((U64)1 << index)) {
+            SEP_DRV_LOG_TRACE("Overflow: cpu: %d, index %d.", this_cpu, index);
+            SEP_DRV_LOG_TRACE("Register 0x%x --- val 0%llx.",
+                            ECB_entries_reg_id(pecb,i),
+                            SYS_Read_MSR(ECB_entries_reg_id(pecb,i)));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i));
+
+            if (DRV_CONFIG_enable_cp_mode(drv_cfg)) {
+                /* Increment the interrupt count. */
+                if (interrupt_counts) {
+                    interrupt_counts[this_cpu * DRV_CONFIG_num_events(drv_cfg) + ECB_entries_event_id_index(pecb,i)] += 1;
+                }
+            }
+
+            DRV_EVENT_MASK_bitFields1(&event_flag) = (U8) 0;
+            if (ECB_entries_precise_get(pecb, i)) {
+                DRV_EVENT_MASK_precise(&event_flag) = 1;
+            }
+            if (ECB_entries_lbr_value_get(pecb, i)) {
+                DRV_EVENT_MASK_lbr_capture(&event_flag) = 1;
+            }
+            if (ECB_entries_uncore_get(pecb, i)) {
+                DRV_EVENT_MASK_uncore_capture(&event_flag) = 1;
+            }
+            if (ECB_entries_branch_evt_get(pecb, i)) {
+                DRV_EVENT_MASK_branch(&event_flag) = 1;
+            }
+
+            if (DRV_MASKS_masks_num(masks) < MAX_OVERFLOW_EVENTS) {
+                DRV_EVENT_MASK_bitFields1(DRV_MASKS_eventmasks(masks) + DRV_MASKS_masks_num(masks)) = DRV_EVENT_MASK_bitFields1(&event_flag);
+                DRV_EVENT_MASK_event_idx(DRV_MASKS_eventmasks(masks) + DRV_MASKS_masks_num(masks)) = ECB_entries_event_id_index(pecb, i);
+                DRV_MASKS_masks_num(masks)++;
+            }
+            else {
+                SEP_DRV_LOG_ERROR("The array for event masks is full.");
+            }
+
+            SEP_DRV_LOG_TRACE("Overflow -- 0x%llx, index 0x%llx.", overflow_status, (U64)1 << index);
+            SEP_DRV_LOG_TRACE("Slot# %d, reg_id 0x%x, index %d.",
+                            i, ECB_entries_reg_id(pecb, i), index);
+            if (ECB_entries_event_id_index(pecb, i) == CPU_STATE_trigger_event_num(pcpu)) {
+                CPU_STATE_trigger_count(pcpu)--;
+            }
+        }
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    CPU_STATE_reset_mask(pcpu) = overflow_status_clr;
+    /* Clear outstanding overflow bits */
+    SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_OVF_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                  overflow_status_clr & PERFVER4_OVERFLOW_BIT_MASK_HT_ON);
+
+    SEP_DRV_LOG_TRACE("Check overflow completed %d.", this_cpu);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn perfver4_Swap_Group(restart)
+ *
+ * @param    restart    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Perform the mechanics of swapping the event groups for event mux operations
+ *
+ * <I>Special Notes</I>
+ *         Swap function for event multiplexing.
+ *         Freeze the counting.
+ *         Swap the groups.
+ *         Enable the counting.
+ *         Reset the event trigger count
+ *
+ */
+static VOID
+perfver4_Swap_Group (
+    DRV_BOOL  restart
+)
+{
+    U32            index;
+    U32            next_group;
+    U32            st_index;
+    U32            this_cpu;
+    CPU_STATE      pcpu;
+    U32            dev_idx;
+    DISPATCH       dispatch;
+    DEV_CONFIG     pcfg;
+    EVENT_CONFIG   ec;
+    U32            counter_index;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy restart: %u.", restart);
+
+    this_cpu      = CONTROL_THIS_CPU();
+    pcpu          = &pcb[this_cpu];
+    dev_idx       = core_to_dev_map[this_cpu];
+    dispatch      = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    pcfg          = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    ec            = LWPMU_DEVICE_ec(&devices[dev_idx]);
+    counter_index = 0;
+
+    st_index   = CPU_STATE_current_group(pcpu) * EVENT_CONFIG_max_gp_events(ec);
+    next_group = (CPU_STATE_current_group(pcpu) + 1);
+    if (next_group >= EVENT_CONFIG_num_groups(ec)) {
+        next_group = 0;
+    }
+
+    SEP_DRV_LOG_TRACE("Current group : 0x%x.", CPU_STATE_current_group(pcpu));
+    SEP_DRV_LOG_TRACE("Next group : 0x%x.", next_group);
+
+    // Save the counters for the current group
+    if (!DRV_CONFIG_event_based_counts(drv_cfg)) {
+        FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_GP) {
+            index = st_index + i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+            CPU_STATE_em_tables(pcpu)[index] = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+            SEP_DRV_LOG_TRACE("Saved value for reg 0x%x : 0x%llx.",
+                            ECB_entries_reg_id(pecb,i),
+                            CPU_STATE_em_tables(pcpu)[index]);
+        } END_FOR_EACH_REG_CORE_OPERATION;
+    }
+
+    CPU_STATE_current_group(pcpu) = next_group;
+
+    if (dispatch->hw_errata) {
+        dispatch->hw_errata();
+    }
+
+    // First write the GP control registers (eventsel)
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_CTRL_GP) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i));
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    if (DRV_CONFIG_event_based_counts(drv_cfg)) {
+        // In EBC mode, reset the counts for all events except for trigger event
+        FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+            if (ECB_entries_event_id_index(pecb, i) != CPU_STATE_trigger_event_num(pcpu)) {
+                SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+            }
+        } END_FOR_EACH_REG_CORE_OPERATION;
+    }
+    else {
+        // Then write the gp count registers
+        st_index = CPU_STATE_current_group(pcpu) * EVENT_CONFIG_max_gp_events(ec);
+        FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_GP) {
+            index = st_index + i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), CPU_STATE_em_tables(pcpu)[index]);
+            SEP_DRV_LOG_TRACE("Restore value for reg 0x%x : 0x%llx.",
+                            ECB_entries_reg_id(pecb,i),
+                            CPU_STATE_em_tables(pcpu)[index]);
+        } END_FOR_EACH_REG_CORE_OPERATION;
+    }
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_OCR) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, i),ECB_entries_reg_value(pecb, i));
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    if (DEV_CONFIG_pebs_record_num(pcfg)) {
+        FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+            if (ECB_entries_precise_get(pecb, i) == 1) {
+                if (ECB_entries_fixed_reg_get(pecb, i)) {
+                    counter_index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_FIXED) + 8;
+                }
+                else {
+                    counter_index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+                }
+                PEBS_Reset_Counter(this_cpu,
+                                   counter_index,
+                                   ECB_entries_reg_value(pecb,i));
+            }
+        } END_FOR_EACH_REG_CORE_OPERATION;
+    }
+
+    /*
+     *  reset the em factor when a group is swapped
+     */
+    CPU_STATE_trigger_count(pcpu) = EVENT_CONFIG_em_factor(ec);
+
+    /*
+     * The enable routine needs to rewrite the control registers
+     */
+    CPU_STATE_reset_mask(pcpu) = 0LL;
+    CPU_STATE_group_swap(pcpu) = 1;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn perfver4_Initialize(params)
+ *
+ * @param    params    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Initialize the PMU setting up for collection
+ *
+ * <I>Special Notes</I>
+ *         Saves the relevant PMU state (minimal set of MSRs required
+ *         to avoid conflicts with other Linux tools, such as Oprofile).
+ *         This function should be called in parallel across all CPUs
+ *         prior to the start of sampling, before PMU state is changed.
+ *
+ */
+static VOID
+perfver4_Initialize (
+    VOID  *param
+)
+{
+    U32        this_cpu;
+    CPU_STATE  pcpu;
+    U32        dev_idx;
+    DEV_CONFIG pcfg;
+    U32        cur_grp;
+    ECB        pecb     = NULL;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    if (pcb == NULL) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pcb).");
+        return;
+    }
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    CPU_STATE_pmu_state(pcpu) = pmu_state + (this_cpu * 3);
+    if (CPU_STATE_pmu_state(pcpu) == NULL) {
+        SEP_DRV_LOG_WARNING_TRACE_OUT("Unable to save PMU state on CPU %d.", this_cpu);
+        return;
+    }
+
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    restore_reg_addr[0] = ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS));
+    restore_reg_addr[1] = ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS));
+    restore_reg_addr[2] = ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, FIXED_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS));
+
+    // save the original PMU state on this CPU (NOTE: must only be called ONCE per collection)
+    CPU_STATE_pmu_state(pcpu)[0] = SYS_Read_MSR(restore_reg_addr[0]);
+    CPU_STATE_pmu_state(pcpu)[1] = SYS_Read_MSR(restore_reg_addr[1]);
+    CPU_STATE_pmu_state(pcpu)[2] = SYS_Read_MSR(restore_reg_addr[2]);
+
+    if (DRV_CONFIG_ds_area_available(drv_cfg) && DEV_CONFIG_pebs_mode(pcfg)) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), 0LL);
+    }
+
+    SEP_DRV_LOG_TRACE("Saving PMU state on CPU %d:", this_cpu);
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_DEBUG_CTRL)=0x%llx.", CPU_STATE_pmu_state(pcpu)[0]);
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_PERF_GLOBAL_CTRL)=0x%llx.", CPU_STATE_pmu_state(pcpu)[1]);
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_FIXED_CTRL)=0x%llx.", CPU_STATE_pmu_state(pcpu)[2]);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn perfver4_Destroy(params)
+ *
+ * @param    params    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Reset the PMU setting up after collection
+ *
+ * <I>Special Notes</I>
+ *         Restores the previously saved PMU state done in pmv_v4_Initialize.
+ *         This function should be called in parallel across all CPUs
+ *         after sampling collection ends/terminates.
+ *
+ */
+static VOID
+perfver4_Destroy (
+    VOID *param
+)
+{
+    U32        this_cpu;
+    CPU_STATE  pcpu;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    if (pcb == NULL) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pcb).");
+        return;
+    }
+
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    preempt_enable();
+    pcpu = &pcb[this_cpu];
+
+    if (CPU_STATE_pmu_state(pcpu) == NULL) {
+        SEP_DRV_LOG_WARNING_TRACE_OUT("Unable to restore PMU state on CPU %d.", this_cpu);
+        return;
+    }
+
+    SEP_DRV_LOG_TRACE("Clearing PMU state on CPU %d:", this_cpu);
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_DEBUG_CTRL)=0x0.");
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_PERF_GLOBAL_CTRL)=0x0.");
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_FIXED_CTRL)=0x0.");
+
+    SYS_Write_MSR(restore_reg_addr[0], 0);
+    SYS_Write_MSR(restore_reg_addr[1], 0);
+    SYS_Write_MSR(restore_reg_addr[2], 0);
+
+    CPU_STATE_pmu_state(pcpu) = NULL;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*
+ * @fn perfver4_Read_LBRs(buffer)
+ *
+ * @param   IN buffer - pointer to the buffer to write the data into
+ * @return  Last branch source IP address
+ *
+ * @brief   Read all the LBR registers into the buffer provided and return
+ *
+ */
+static U64
+perfver4_Read_LBRs (
+    VOID   *buffer
+)
+{
+    U32   i, count    = 0;
+    U64  *lbr_buf     = NULL;
+    U64   value       = 0;
+    U64   tos_ip_addr = 0;
+    U64   tos_ptr     = 0;
+    SADDR saddr;
+    U32   pairs       = 0;
+    U32   this_cpu;
+    U32   dev_idx;
+    LBR   lbr;
+    DEV_CONFIG pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("Buffer: %p.", buffer);
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    lbr      = LWPMU_DEVICE_lbr(&devices[dev_idx]);
+
+    if (lbr == NULL) {
+        return 0;
+    }
+
+    if (buffer && DEV_CONFIG_store_lbrs(pcfg)) {
+        lbr_buf = (U64 *)buffer;
+    }
+
+    if (LBR_num_entries(lbr) > 0) {
+        pairs = (LBR_num_entries(lbr) - 1)/3;
+    }
+    for (i = 0; i < LBR_num_entries(lbr); i++) {
+        value = SYS_Read_MSR(LBR_entries_reg_id(lbr,i));
+        if (buffer && DEV_CONFIG_store_lbrs(pcfg)) {
+            *lbr_buf = value;
+        }
+        if (DEV_CONFIG_collect_callstacks(pcfg)) {
+            if ((LBR_entries_etype(lbr, i) == LBR_ENTRY_FROM_IP && i > tos_ptr+1) ||
+                (LBR_entries_etype(lbr, i) == LBR_ENTRY_TO_IP && i > tos_ptr+pairs+1) ||
+                (LBR_entries_etype(lbr, i) == LBR_ENTRY_INFO && i > tos_ptr+2*pairs+1)) {
+                if (buffer && DEV_CONFIG_store_lbrs(pcfg)) {
+                    *lbr_buf = 0x0ULL;
+                    lbr_buf++;
+                }
+                continue;
+            }
+        }
+        SEP_DRV_LOG_TRACE("LBR %u, 0x%llx.", i, value);
+        if (i == 0) {
+            tos_ptr = value;
+        }
+        else {
+            if (LBR_entries_etype(lbr, i) == LBR_ENTRY_FROM_IP) { // LBR from register
+                if (tos_ptr == count) {
+                    SADDR_addr(saddr) = value & PERFVER4_LBR_BITMASK;
+                    tos_ip_addr = (U64) SADDR_addr(saddr); // Add signed extension
+                    SEP_DRV_LOG_TRACE("Tos_ip_addr %llu, 0x%llx.", tos_ptr, value);
+                }
+                count++;
+            }
+        }
+        if (buffer && DEV_CONFIG_store_lbrs(pcfg)) {
+            lbr_buf++;
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %llu.", tos_ip_addr);
+    return tos_ip_addr;
+}
+
+/*
+ * @fn perfver4_Clean_Up(param)
+ *
+ * @param   IN param - currently not used
+ *
+ * @brief   Clean up registers in ECB
+ *
+ */
+static VOID
+perfver4_Clean_Up (
+    VOID   *param
+)
+{
+    U32              this_cpu;
+    CPU_STATE        pcpu;
+    ECB              pecb = NULL;
+    U32              dev_idx;
+    U32              cur_grp;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_ALL_REG) {
+        if (ECB_entries_clean_up_get(pecb,i)) {
+            SEP_DRV_LOG_TRACE("Clean up set --- RegId --- %x.", ECB_entries_reg_id(pecb, i));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+        }
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    /* Clear outstanding frozen bits */
+    if (pecb) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_OVF_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                      PERFVER4_FROZEN_BIT_MASK);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void perfver4_Check_Overflow_Htoff_Mode(masks)
+ *
+ * @param    masks    the mask structure to populate
+ *
+ * @return   None     No return needed
+ *
+ * @brief  Called by the data processing method to figure out which registers have overflowed.
+ *
+ */
+static void
+perfver4_Check_Overflow_Htoff_Mode (
+    DRV_MASKS    masks
+)
+{
+    U32              index;
+    U64              value               = 0;
+    U64              overflow_status     = 0;
+    U32              this_cpu;
+    BUFFER_DESC      bd;
+    CPU_STATE        pcpu;
+    ECB              pecb;
+    U32              dev_idx;
+    U32              cur_grp;
+    DISPATCH         dispatch;
+    DEV_CONFIG       pcfg;
+    U64              overflow_status_clr = 0;
+    DRV_EVENT_MASK_NODE event_flag;
+
+    SEP_DRV_LOG_TRACE_IN("Masks: %p.", masks);
+
+    this_cpu = CONTROL_THIS_CPU();
+    bd       = &cpu_buf[this_cpu];
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    dispatch = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    // initialize masks
+    DRV_MASKS_masks_num(masks) = 0;
+
+    overflow_status = SYS_Read_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_STATUS_REG_INDEX, PMU_OPERATION_GLOBAL_STATUS)));
+
+    if (DEV_CONFIG_pebs_mode(pcfg)
+        && (DEV_CONFIG_pebs_record_num(pcfg) == 1)) {
+        overflow_status = PEBS_Overflowed (this_cpu, overflow_status, 0);
+    }
+    overflow_status_clr = overflow_status;
+    SEP_DRV_LOG_TRACE("Overflow: cpu: %d, status 0x%llx.", this_cpu, overflow_status);
+    index                        = 0;
+    BUFFER_DESC_sample_count(bd) = 0;
+
+    if (dispatch->check_overflow_gp_errata) {
+        overflow_status = dispatch->check_overflow_gp_errata(pecb,  &overflow_status_clr);
+    }
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+        if (ECB_entries_fixed_reg_get(pecb, i)) {
+            index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_FIXED) + 0x20;
+        }
+        else if (ECB_entries_is_gp_reg_get(pecb,i) && ECB_entries_reg_value(pecb,i) != 0) {
+            index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+            if (index >= 4 &&
+                index <= 7) {
+                value = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+                if (value > 0 && value <= 0x100000000LL) {
+                    overflow_status |= ((U64)1 << index);
+                }
+            }
+        }
+        else {
+            continue;
+        }
+        if (overflow_status & ((U64)1 << index)) {
+            SEP_DRV_LOG_TRACE("Overflow:  cpu: %d, index %d.", this_cpu, index);
+            SEP_DRV_LOG_TRACE("Register 0x%x --- val 0%llx.",
+                            ECB_entries_reg_id(pecb,i),
+                            SYS_Read_MSR(ECB_entries_reg_id(pecb,i)));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i));
+
+            if (DRV_CONFIG_enable_cp_mode(drv_cfg)) {
+                /* Increment the interrupt count. */
+                if (interrupt_counts) {
+                    interrupt_counts[this_cpu * DRV_CONFIG_num_events(drv_cfg) + ECB_entries_event_id_index(pecb,i)] += 1;
+                }
+            }
+
+            DRV_EVENT_MASK_bitFields1(&event_flag) = (U8) 0;
+            if (ECB_entries_precise_get(pecb, i)) {
+                DRV_EVENT_MASK_precise(&event_flag) = 1;
+            }
+            if (ECB_entries_lbr_value_get(pecb, i)) {
+                DRV_EVENT_MASK_lbr_capture(&event_flag) = 1;
+            }
+
+            if (DRV_MASKS_masks_num(masks) < MAX_OVERFLOW_EVENTS) {
+                DRV_EVENT_MASK_bitFields1(DRV_MASKS_eventmasks(masks) + DRV_MASKS_masks_num(masks)) = DRV_EVENT_MASK_bitFields1(&event_flag);
+                DRV_EVENT_MASK_event_idx(DRV_MASKS_eventmasks(masks) + DRV_MASKS_masks_num(masks)) = ECB_entries_event_id_index(pecb, i);
+                DRV_MASKS_masks_num(masks)++;
+            }
+            else {
+                SEP_DRV_LOG_ERROR("The array for event masks is full.");
+            }
+
+            SEP_DRV_LOG_TRACE("Overflow -- 0x%llx, index 0x%llx.", overflow_status, (U64)1 << index);
+            SEP_DRV_LOG_TRACE("Slot# %d, reg_id 0x%x, index %d.",
+                             i, ECB_entries_reg_id(pecb, i), index);
+            if (ECB_entries_event_id_index(pecb, i) == CPU_STATE_trigger_event_num(pcpu)) {
+                CPU_STATE_trigger_count(pcpu)--;
+            }
+        }
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    CPU_STATE_reset_mask(pcpu) = overflow_status_clr;
+    /* Clear outstanding overflow bits */
+    SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_OVF_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                  overflow_status_clr & PERFVER4_OVERFLOW_BIT_MASK_HT_OFF);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+#define MAX_COUNTER                0xFFFFFFFFFFFFLLU
+#define FIXED_CTR3_BIT_INDEX       35
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void perfver4_Check_Overflow_Nonht_Mode(masks)
+ *
+ * @param    masks    the mask structure to populate
+ *
+ * @return   None     No return needed
+ *
+ * @brief  Called by the data processing method to figure out which registers have overflowed.
+ *
+ */
+static VOID
+perfver4_Check_Overflow_Nonht_Mode (
+    DRV_MASKS    masks
+)
+{
+    U32              index;
+    U64              overflow_status     = 0;
+    U32              this_cpu            = CONTROL_THIS_CPU();
+    BUFFER_DESC      bd                  = &cpu_buf[this_cpu];
+    CPU_STATE        pcpu                = &pcb[this_cpu];
+    U32              dev_idx             = core_to_dev_map[this_cpu];
+    U32              cur_grp             = CPU_STATE_current_group(pcpu);
+    DEV_CONFIG       pcfg                = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    ECB              pecb                = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    U64              overflow_status_clr = 0;
+    DRV_EVENT_MASK_NODE event_flag;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    // initialize masks
+    DRV_MASKS_masks_num(masks) = 0;
+
+    overflow_status = SYS_Read_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_STATUS_REG_INDEX, PMU_OPERATION_GLOBAL_STATUS)));
+
+    if (DEV_CONFIG_pebs_mode(pcfg)
+        && (DEV_CONFIG_pebs_record_num(pcfg) == 1)) {
+        overflow_status = PEBS_Overflowed (this_cpu, overflow_status, 0);
+    }
+    overflow_status_clr = overflow_status;
+    SEP_DRV_LOG_TRACE("Overflow:  cpu: %d, status 0x%llx.", this_cpu, overflow_status);
+    index                        = 0;
+    BUFFER_DESC_sample_count(bd) = 0;
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+        if (ECB_entries_fixed_reg_get(pecb, i)) {
+            index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_FIXED) + 0x20;
+        }
+        else if (ECB_entries_is_gp_reg_get(pecb,i) && ECB_entries_reg_value(pecb,i) != 0) {
+            index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+        }
+        else {
+            continue;
+        }
+        if (overflow_status & ((U64)1 << index)) {
+            SEP_DRV_LOG_TRACE("Overflow:  cpu: %d, index %d.", this_cpu, index);
+            SEP_DRV_LOG_TRACE("register 0x%x --- val 0%llx.",
+                            ECB_entries_reg_id(pecb,i),
+                            SYS_Read_MSR(ECB_entries_reg_id(pecb,i)));
+
+            DRV_EVENT_MASK_bitFields1(&event_flag) = (U8) 0;
+            if (DEV_CONFIG_enable_perf_metrics(pcfg) && index == FIXED_CTR3_BIT_INDEX) {
+                perf_metrics_counter_reload_value = ECB_entries_reg_value(pecb,i); // saving reload value
+                // Writing positive SAV into data register before reading metrics
+                SYS_Write_MSR(ECB_entries_reg_id(pecb,i),((~(ECB_entries_reg_value(pecb,i)) + 1) & MAX_COUNTER));
+                DRV_EVENT_MASK_perf_metrics_capture(&event_flag) = 1;
+            }
+            else {
+                 SYS_Write_MSR(ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i));
+            }
+            if (DRV_CONFIG_enable_cp_mode(drv_cfg)) {
+                /* Increment the interrupt count. */
+                if (interrupt_counts) {
+                    interrupt_counts[this_cpu * DRV_CONFIG_num_events(drv_cfg) + ECB_entries_event_id_index(pecb,i)] += 1;
+                }
+            }
+
+            if (ECB_entries_precise_get(pecb, i)) {
+                DRV_EVENT_MASK_precise(&event_flag) = 1;
+            }
+            if (ECB_entries_lbr_value_get(pecb, i)) {
+                DRV_EVENT_MASK_lbr_capture(&event_flag) = 1;
+            }
+            if (ECB_entries_uncore_get(pecb, i)) {
+                DRV_EVENT_MASK_uncore_capture(&event_flag) = 1;
+            }
+            if (ECB_entries_branch_evt_get(pecb, i)) {
+                DRV_EVENT_MASK_branch(&event_flag) = 1;
+            }
+
+            if (DRV_MASKS_masks_num(masks) < MAX_OVERFLOW_EVENTS) {
+                DRV_EVENT_MASK_bitFields1(DRV_MASKS_eventmasks(masks) + DRV_MASKS_masks_num(masks)) = DRV_EVENT_MASK_bitFields1(&event_flag);
+                DRV_EVENT_MASK_event_idx(DRV_MASKS_eventmasks(masks) + DRV_MASKS_masks_num(masks)) = ECB_entries_event_id_index(pecb, i);
+                DRV_MASKS_masks_num(masks)++;
+            }
+            else {
+                SEP_DRV_LOG_ERROR("The array for event masks is full.");
+            }
+
+            SEP_DRV_LOG_TRACE("Overflow -- 0x%llx, index 0x%llx.", overflow_status, (U64)1 << index);
+            SEP_DRV_LOG_TRACE("Slot# %d, reg_id 0x%x, index %d.",
+                             i, ECB_entries_reg_id(pecb, i), index);
+            if (ECB_entries_event_id_index(pecb, i) == CPU_STATE_trigger_event_num(pcpu)) {
+                CPU_STATE_trigger_count(pcpu)--;
+            }
+        }
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    CPU_STATE_reset_mask(pcpu) = overflow_status_clr;
+    /* Clear outstanding overflow bits */
+    SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_OVF_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                  overflow_status_clr & PERFVER4_OVERFLOW_BIT_MASK_NON_HT);
+
+    SEP_DRV_LOG_TRACE("Check Overflow completed %d.", this_cpu);
+}
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void perfver4_Read_Power(buffer)
+ *
+ * @param    buffer   - pointer to the buffer to write the data into
+ *
+ * @return   None     No return needed
+ *
+ * @brief  Read all the power MSRs into the buffer provided and return.
+ *
+ */
+static VOID
+perfver4_Read_Power (
+    VOID   *buffer
+)
+{
+    U32  i;
+    U64 *pwr_buf = (U64 *)buffer;
+    U32  this_cpu;
+    U32  dev_idx;
+    PWR  pwr;
+
+    SEP_DRV_LOG_TRACE_IN("Buffer: %p.", buffer);
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    pwr      = LWPMU_DEVICE_pwr(&devices[dev_idx]);
+
+    for (i = 0; i < PWR_num_entries(pwr); i++) {
+        *pwr_buf = SYS_Read_MSR(PWR_entries_reg_id(pwr,i));
+        pwr_buf++;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn perfver4_Read_Counts(param, id)
+ *
+ * @param    param    The read thread node to process
+ * @param    id       The event id for the which the sample is generated
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read CPU event based counts data and store into the buffer param;
+ *           For the case of the trigger event, store the SAV value.
+ */
+static VOID
+perfver4_Read_Counts (
+    PVOID  param,
+    U32    id
+)
+{
+    U64            *data;
+    U32             this_cpu;
+    CPU_STATE       pcpu;
+    U32             dev_idx;
+    DEV_CONFIG      pcfg;
+    U32             event_id            = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p, id: %u.", param, id);
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (DEV_CONFIG_ebc_group_id_offset(pcfg)) {
+        // Write GroupID
+        data  = (U64 *)((S8*)param + DEV_CONFIG_ebc_group_id_offset(pcfg));
+        *data = CPU_STATE_current_group(pcpu) + 1;
+    }
+
+    FOR_EACH_REG_CORE_OPERATION(pecb,i, PMU_OPERATION_DATA_ALL) {
+        if (ECB_entries_counter_event_offset(pecb,i) == 0) {
+            continue;
+        }
+        data = (U64 *)((S8*)param + ECB_entries_counter_event_offset(pecb,i));
+        event_id = ECB_entries_event_id_index(pecb,i);
+        if (event_id == id) {
+            *data = ~(ECB_entries_reg_value(pecb,i) - 1) &
+                                           ECB_entries_max_bits(pecb,i);;
+        }
+        else {
+            *data = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+        }
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn perfver4_Read_Metrics(buffer, id)
+ *
+ * @param    param        buffer to write metrics into
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read hardware metrics from IA32_PERF_METRICS MSR
+ */
+static VOID
+perfver4_Read_Metrics (
+    PVOID  buffer
+)
+{
+    U64            *data, metrics = 0;
+    U32             j;
+    U32             this_cpu = CONTROL_THIS_CPU();
+    U32             dev_idx = core_to_dev_map[this_cpu];
+    DEV_CONFIG      pcfg = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    data = (U64 *)buffer;
+    FOR_EACH_NONEVENT_REG(pecb,i) {
+        metrics = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+            for (j = 0; j < DEV_CONFIG_num_perf_metrics(pcfg); j++) {
+            *data = (metrics & (0xFFULL << 8*j)) >> 8*j;
+            data++;
+        }
+    } END_FOR_EACH_NONEVENT_REG;
+
+    if (DRV_CONFIG_emon_mode(drv_cfg)) {
+        SYS_Write_MSR(IA32_FIXED_CTR3, 0LL);
+    }
+    else {
+        SYS_Write_MSR(IA32_FIXED_CTR3, perf_metrics_counter_reload_value);
+        perf_metrics_counter_reload_value = 0;
+    }
+
+    SYS_Write_MSR(IA32_PERF_METRICS, 0LL);
+
+    return;
+}
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U64 perfver4_Platform_Info
+ *
+ * @brief       Reads the MSR_PLATFORM_INFO register if present
+ *
+ * @param       void
+ *
+ * @return      value read from the register
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static VOID
+perfver4_Platform_Info (
+    PVOID data
+)
+{
+    DRV_PLATFORM_INFO platform_data = (DRV_PLATFORM_INFO)data;
+    U64               value         = 0;
+    U64               energy_multiplier;
+
+    SEP_DRV_LOG_TRACE_IN("Data: %p.", data);
+
+    if (!platform_data) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!platform_data).");
+        return;
+    }
+
+#define IA32_MSR_PLATFORM_INFO 0xCE
+    value = SYS_Read_MSR(IA32_MSR_PLATFORM_INFO);
+
+    DRV_PLATFORM_INFO_info(platform_data)           = value;
+    DRV_PLATFORM_INFO_ddr_freq_index(platform_data) = 0;
+
+#define IA32_MSR_MISC_ENABLE 0x1A4
+    DRV_PLATFORM_INFO_misc_valid(platform_data)     = 1;
+    value = SYS_Read_MSR(IA32_MSR_MISC_ENABLE);
+    DRV_PLATFORM_INFO_misc_info(platform_data)      = value;
+#undef  IA32_MSR_MISC_ENABLE
+
+    energy_multiplier = SYS_Read_MSR(MSR_ENERGY_MULTIPLIER);
+    SEP_DRV_LOG_TRACE ("MSR_ENERGY_MULTIPLIER: %llx.", energy_multiplier);
+    DRV_PLATFORM_INFO_energy_multiplier(platform_data) = (U32) (energy_multiplier & 0x00001F00) >> 8;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*
+ * Initialize the dispatch table
+ */
+DISPATCH_NODE perfver4_dispatch =
+{
+    .init                     = perfver4_Initialize,
+    .fini                     = perfver4_Destroy,
+    .write                    = perfver4_Write_PMU,
+    .freeze                   = perfver4_Disable_PMU,
+    .restart                  = perfver4_Enable_PMU,
+    .read_data                = perfver4_Read_PMU_Data,
+    .check_overflow           = perfver4_Check_Overflow,
+    .swap_group               = perfver4_Swap_Group,
+    .read_lbrs                = perfver4_Read_LBRs,
+    .cleanup                  = perfver4_Clean_Up,
+    .hw_errata                = NULL,
+    .read_power               = perfver4_Read_Power,
+    .check_overflow_errata    = NULL,
+    .read_counts              = perfver4_Read_Counts,
+    .check_overflow_gp_errata = NULL,
+    .read_ro                  = NULL,
+    .platform_info            = perfver4_Platform_Info,
+    .trigger_read             = NULL,
+    .scan_for_uncore          = NULL,
+    .read_metrics             = NULL
+};
+
+DISPATCH_NODE perfver4_dispatch_htoff_mode =
+{
+    .init                     = perfver4_Initialize,
+    .fini                     = perfver4_Destroy,
+    .write                    = perfver4_Write_PMU,
+    .freeze                   = perfver4_Disable_PMU,
+    .restart                  = perfver4_Enable_PMU,
+    .read_data                = perfver4_Read_PMU_Data,
+    .check_overflow           = perfver4_Check_Overflow_Htoff_Mode,
+    .swap_group               = perfver4_Swap_Group,
+    .read_lbrs                = perfver4_Read_LBRs,
+    .cleanup                  = perfver4_Clean_Up,
+    .hw_errata                = NULL,
+    .read_power               = perfver4_Read_Power,
+    .check_overflow_errata    = NULL,
+    .read_counts              = perfver4_Read_Counts,
+    .check_overflow_gp_errata = NULL,
+    .read_ro                  = NULL,
+    .platform_info            = perfver4_Platform_Info,
+    .trigger_read             = NULL,
+    .scan_for_uncore          = NULL,
+    .read_metrics             = NULL
+};
+
+DISPATCH_NODE perfver4_dispatch_nonht_mode =
+{
+    .init                     = perfver4_Initialize,
+    .fini                     = perfver4_Destroy,
+    .write                    = perfver4_Write_PMU,
+    .freeze                   = perfver4_Disable_PMU,
+    .restart                  = perfver4_Enable_PMU,
+    .read_data                = perfver4_Read_PMU_Data,
+    .check_overflow           = perfver4_Check_Overflow_Nonht_Mode,
+    .swap_group               = perfver4_Swap_Group,
+    .read_lbrs                = perfver4_Read_LBRs,
+    .cleanup                  = perfver4_Clean_Up,
+    .hw_errata                = NULL,
+    .read_power               = perfver4_Read_Power,
+    .check_overflow_errata    = NULL,
+    .read_counts              = perfver4_Read_Counts,
+    .check_overflow_gp_errata = NULL,
+    .read_ro                  = NULL,
+    .platform_info            = perfver4_Platform_Info,
+    .trigger_read             = NULL,
+    .scan_for_uncore          = NULL,
+    .read_metrics             = perfver4_Read_Metrics
+};
diff --git a/drivers/misc/intel/sepdk/sep/pmi.c b/drivers/misc/intel/sepdk/sep/pmi.c
new file mode 100644
index 000000000000..29f8a19055a6
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/pmi.c
@@ -0,0 +1,366 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/ptrace.h>
+#if defined(DRV_EM64T)
+#include <asm/desc.h>
+#endif
+#include <asm/apic.h>
+#include <asm/nmi.h>
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+#include "apic.h"
+#include "lwpmudrv.h"
+#include "output.h"
+#include "control.h"
+#include "pmi.h"
+#include "utility.h"
+#include "pebs.h"
+
+#if defined(BUILD_CHIPSET)
+#include "lwpmudrv_chipset.h"
+#endif
+#include "sepdrv_p_state.h"
+
+// Desc id #0 is used for module records
+#define COMPUTE_DESC_ID(index)     ((index))
+
+extern DRV_CONFIG             drv_cfg;
+extern uid_t                  uid;
+extern DRV_SETUP_INFO_NODE    req_drv_setup_info;
+#define EFLAGS_V86_MASK       0x00020000L
+
+/*********************************************************************
+ * Global Variables / State
+ *********************************************************************/
+
+/*********************************************************************
+ * Interrupt Handler
+ *********************************************************************/
+
+/*
+ *  PMI_Interrupt_Handler
+ *      Arguments
+ *          IntFrame - Pointer to the Interrupt Frame
+ *
+ *      Returns
+ *          None
+ *
+ *      Description
+ *  Grab the data that is needed to populate the sample records
+ */
+#if defined(DRV_EM64T)
+#define IS_LDT_BIT       0x4
+#define SEGMENT_SHIFT    3
+IDTGDT_DESC              gdt_desc;
+
+U32
+pmi_Get_CSD (
+    U32     seg,
+    U32    *low,
+    U32    *high
+)
+{
+    PVOID               gdt_max_addr;
+    struct desc_struct *gdt;
+    CodeDescriptor     *csd;
+
+    SEP_DRV_LOG_TRACE_IN("Seg: %u, low: %p, high: %p.", seg, low, high);
+
+    gdt_max_addr = (PVOID) (((U64) gdt_desc.idtgdt_base) + gdt_desc.idtgdt_limit);
+    gdt          = gdt_desc.idtgdt_base;
+
+    if (seg & IS_LDT_BIT) {
+        *low  = 0;
+        *high = 0;
+        SEP_DRV_LOG_TRACE_OUT("FALSE [%u, %u] (IS_LDT_BIT).", *low, *high);
+        return (FALSE);
+    }
+
+    // segment offset is based on dropping the bottom 3 bits...
+    csd = (CodeDescriptor *) &(gdt[seg >> SEGMENT_SHIFT]);
+
+    if (((PVOID) csd) >= gdt_max_addr) {
+        SEP_DRV_LOG_WARNING_TRACE_OUT("FALSE (segment too big in get_CSD(0x%x)!).", seg);
+        return FALSE;
+    }
+
+    *low  = csd->u1.lowWord;
+    *high = csd->u2.highWord;
+
+    SEP_DRV_LOG_TRACE("Seg 0x%x, low %08x, high %08x, reserved_0: %d.",
+                     seg, *low, *high, csd->u2.s2.reserved_0);
+    SEP_DRV_LOG_TRACE_OUT("TRUE [%u, %u].", *low, *high);
+
+    return TRUE;
+}
+#endif
+
+asmlinkage VOID
+PMI_Interrupt_Handler (
+     struct pt_regs *regs
+)
+{
+    SampleRecordPC         *psamp;
+    CPU_STATE               pcpu;
+    BUFFER_DESC             bd;
+#if defined(DRV_IA32)
+    U32              csdlo;        // low  half code seg descriptor
+    U32              csdhi;        // high half code seg descriptor
+    U32              seg_cs;       // code seg selector
+#endif
+    DRV_MASKS_NODE   event_mask;
+    U32              this_cpu;
+    U32              dev_idx;
+    DISPATCH         dispatch;
+    DEV_CONFIG       pcfg;
+    U32              i;
+    U32              is_64bit_addr    = FALSE;
+    U32              pid;
+    U32              tid;
+    U64              tsc;
+    U32              desc_id;
+    EVENT_DESC       evt_desc;
+    U32              accept_interrupt = 1;
+#if defined(SECURE_SEP)
+    uid_t            l_uid;
+#endif
+    U64              lbr_tos_from_ip = 0;
+    DRV_BOOL         multi_pebs_enabled;
+
+    SEP_DRV_LOG_INTERRUPT_IN("PID: %d, TID: %d.", current->pid, GET_CURRENT_TGID()); // needs to be before function calls for the tracing to make sense
+                                                                                     // may later want to separate the INTERRUPT_IN from the PID/TID logging
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    bd       = &cpu_buf[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    dispatch = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    multi_pebs_enabled = (DEV_CONFIG_pebs_mode(pcfg) &&
+                          (DEV_CONFIG_pebs_record_num(pcfg) > 1) &&
+                          (DRV_SETUP_INFO_page_table_isolation(&req_drv_setup_info) == DRV_SETUP_INFO_PTI_DISABLED));
+    SYS_Locked_Inc(&CPU_STATE_in_interrupt(pcpu)); // needs to be before dispatch->freeze to ensure printk is never called from an interrupt
+
+    // Disable the counter control
+    dispatch->freeze(NULL);
+
+    CPU_STATE_nmi_handled(&pcb[this_cpu])++;
+
+#if defined(SECURE_SEP)
+    l_uid            = DRV_GET_UID(current);
+    accept_interrupt = (l_uid == uid);
+#endif
+    dispatch->check_overflow(&event_mask);
+    if (GET_DRIVER_STATE() != DRV_STATE_RUNNING       ||
+        CPU_STATE_accept_interrupt(&pcb[this_cpu]) != 1) {
+        goto pmi_cleanup;
+    }
+
+    pid  = GET_CURRENT_TGID();
+    tid  = current->pid;
+
+    if (DRV_CONFIG_target_pid(drv_cfg) > 0 && pid != DRV_CONFIG_target_pid(drv_cfg)) {
+        accept_interrupt = 0;
+    }
+
+    if (accept_interrupt == 0) {
+        goto pmi_cleanup;
+    }
+    UTILITY_Read_TSC(&tsc);
+    if (multi_pebs_enabled
+        && PEBS_Get_Num_Records_Filled() > 0) {
+        PEBS_Flush_Buffer(NULL);
+    }
+
+    SEP_DRV_LOG_TRACE("Nb overflowed events: %d.", event_mask.masks_num);
+    for (i = 0; i < event_mask.masks_num; i++) {
+        if (multi_pebs_enabled
+            && (DRV_EVENT_MASK_precise(&event_mask.eventmasks[i]))) {
+            continue;
+        }
+        if (DRV_CONFIG_event_based_counts(drv_cfg) == 0) {
+            desc_id  = COMPUTE_DESC_ID(DRV_EVENT_MASK_event_idx(&event_mask.eventmasks[i]));
+        }
+        else {
+            desc_id = CPU_STATE_current_group(pcpu);
+        }
+        evt_desc = desc_data[desc_id];
+        psamp = (SampleRecordPC *)OUTPUT_Reserve_Buffer_Space(bd, EVENT_DESC_sample_size(evt_desc), (NMI_mode)? TRUE:FALSE, !SEP_IN_NOTIFICATION);
+
+        if (!psamp) {
+            continue;
+        }
+        lbr_tos_from_ip                        = 0;
+        CPU_STATE_num_samples(pcpu)           += 1;
+        SAMPLE_RECORD_descriptor_id(psamp)     = desc_id;
+        SAMPLE_RECORD_tsc(psamp)               = tsc;
+        SAMPLE_RECORD_pid_rec_index_raw(psamp) = 1;
+        SAMPLE_RECORD_pid_rec_index(psamp)     = pid;
+        SAMPLE_RECORD_tid(psamp)               = tid;
+        SAMPLE_RECORD_cpu_num(psamp)           = (U16) this_cpu;
+#if defined(DRV_IA32)
+        SAMPLE_RECORD_eip(psamp)               = REGS_eip(regs);
+        SAMPLE_RECORD_eflags(psamp)            = REGS_eflags(regs);
+        SAMPLE_RECORD_cs(psamp)                = (U16) REGS_xcs(regs);
+
+        if (SAMPLE_RECORD_eflags(psamp) & EFLAGS_V86_MASK) {
+            csdlo = 0;
+            csdhi = 0;
+        }
+        else {
+            seg_cs = SAMPLE_RECORD_cs(psamp);
+            SYS_Get_CSD(seg_cs, &csdlo, &csdhi);
+        }
+        SAMPLE_RECORD_csd(psamp).u1.lowWord  = csdlo;
+        SAMPLE_RECORD_csd(psamp).u2.highWord = csdhi;
+#elif defined(DRV_EM64T)
+        SAMPLE_RECORD_cs(psamp)                = (U16) REGS_cs(regs);
+
+        pmi_Get_CSD(SAMPLE_RECORD_cs(psamp),
+                &SAMPLE_RECORD_csd(psamp).u1.lowWord,
+                &SAMPLE_RECORD_csd(psamp).u2.highWord);
+#endif
+        SEP_DRV_LOG_TRACE("SAMPLE_RECORD_pid_rec_index(psamp) %x.", SAMPLE_RECORD_pid_rec_index(psamp));
+        SEP_DRV_LOG_TRACE("SAMPLE_RECORD_tid(psamp) %x.", SAMPLE_RECORD_tid(psamp));
+#if defined(DRV_IA32)
+        SEP_DRV_LOG_TRACE("SAMPLE_RECORD_eip(psamp) %x.", SAMPLE_RECORD_eip(psamp));
+        SEP_DRV_LOG_TRACE("SAMPLE_RECORD_eflags(psamp) %x.", SAMPLE_RECORD_eflags(psamp));
+#endif
+        SEP_DRV_LOG_TRACE("SAMPLE_RECORD_cpu_num(psamp) %x.", SAMPLE_RECORD_cpu_num(psamp));
+        SEP_DRV_LOG_TRACE("SAMPLE_RECORD_cs(psamp) %x.", SAMPLE_RECORD_cs(psamp));
+        SEP_DRV_LOG_TRACE("SAMPLE_RECORD_csd(psamp).lowWord %x.", SAMPLE_RECORD_csd(psamp).u1.lowWord);
+        SEP_DRV_LOG_TRACE("SAMPLE_RECORD_csd(psamp).highWord %x.", SAMPLE_RECORD_csd(psamp).u2.highWord);
+
+#if defined(DRV_EM64T)
+        is_64bit_addr = (SAMPLE_RECORD_csd(psamp).u2.s2.reserved_0 == 1);
+        if (is_64bit_addr) {
+            SAMPLE_RECORD_iip(psamp)           = REGS_rip(regs);
+            SAMPLE_RECORD_ipsr(psamp)          = (REGS_eflags(regs) & 0xffffffff) |
+                (((U64) SAMPLE_RECORD_csd(psamp).u2.s2.dpl) << 32);
+            SAMPLE_RECORD_ia64_pc(psamp)       = TRUE;
+        }
+        else {
+            SAMPLE_RECORD_eip(psamp)           = REGS_rip(regs);
+            SAMPLE_RECORD_eflags(psamp)        = REGS_eflags(regs);
+            SAMPLE_RECORD_ia64_pc(psamp)       = FALSE;
+
+            SEP_DRV_LOG_TRACE("SAMPLE_RECORD_eip(psamp) 0x%x.", SAMPLE_RECORD_eip(psamp));
+            SEP_DRV_LOG_TRACE("SAMPLE_RECORD_eflags(psamp) %x.", SAMPLE_RECORD_eflags(psamp));
+        }
+#endif
+
+        SAMPLE_RECORD_event_index(psamp) = DRV_EVENT_MASK_event_idx(&event_mask.eventmasks[i]);
+        if (DEV_CONFIG_pebs_mode(pcfg) && DRV_EVENT_MASK_precise(&event_mask.eventmasks[i])) {
+            if (EVENT_DESC_pebs_offset(evt_desc) ||
+                EVENT_DESC_latency_offset_in_sample(evt_desc)) {
+                lbr_tos_from_ip = PEBS_Fill_Buffer((S8 *)psamp,
+                                                    evt_desc,
+                                                    0);
+            }
+            PEBS_Modify_IP((S8 *)psamp, is_64bit_addr, 0);
+            PEBS_Modify_TSC((S8 *)psamp, 0);
+        }
+        if (DEV_CONFIG_collect_lbrs(pcfg) &&
+            DRV_EVENT_MASK_lbr_capture(&event_mask.eventmasks[i]) &&
+           !DEV_CONFIG_apebs_collect_lbrs(pcfg)) {
+            lbr_tos_from_ip = dispatch->read_lbrs(!DEV_CONFIG_store_lbrs(pcfg) ? NULL:((S8 *)(psamp)+EVENT_DESC_lbr_offset(evt_desc)));
+        }
+        if (DRV_EVENT_MASK_branch(&event_mask.eventmasks[i]) &&
+            DEV_CONFIG_precise_ip_lbrs(pcfg)                 &&
+            lbr_tos_from_ip) {
+            if (is_64bit_addr) {
+                SAMPLE_RECORD_iip(psamp)       = lbr_tos_from_ip;
+                SEP_DRV_LOG_TRACE("UPDATED SAMPLE_RECORD_iip(psamp) 0x%llx.", SAMPLE_RECORD_iip(psamp));
+            }
+            else {
+                SAMPLE_RECORD_eip(psamp)       = (U32) lbr_tos_from_ip;
+                SEP_DRV_LOG_TRACE("UPDATED SAMPLE_RECORD_eip(psamp) 0x%x.", SAMPLE_RECORD_eip(psamp));
+            }
+        }
+        if (DEV_CONFIG_power_capture(pcfg)) {
+            dispatch->read_power(((S8 *)(psamp)+EVENT_DESC_power_offset_in_sample(evt_desc)));
+        }
+
+#if defined(BUILD_CHIPSET)
+        if (DRV_CONFIG_enable_chipset(drv_cfg)) {
+            cs_dispatch->read_counters(((S8 *)(psamp)+DRV_CONFIG_chipset_offset(drv_cfg)));
+        }
+#endif
+        if (DRV_CONFIG_event_based_counts(drv_cfg)) {
+            dispatch->read_counts((S8 *)psamp, DRV_EVENT_MASK_event_idx(&event_mask.eventmasks[i]));
+        }
+        if (DEV_CONFIG_enable_perf_metrics(pcfg) && DRV_EVENT_MASK_perf_metrics_capture(&event_mask.eventmasks[i])) {
+            dispatch->read_metrics((S8 *)(psamp)+EVENT_DESC_perfmetrics_offset(evt_desc));
+        }
+        if (DRV_CONFIG_enable_p_state(drv_cfg)) {
+            if (DRV_CONFIG_read_pstate_msrs(drv_cfg) &&
+                (DRV_CONFIG_p_state_trigger_index(drv_cfg) == -1 || SAMPLE_RECORD_event_index(psamp) == DRV_CONFIG_p_state_trigger_index(drv_cfg))) {
+                SEPDRV_P_STATE_Read((S8 *)(psamp)+EVENT_DESC_p_state_offset(evt_desc), pcpu);
+            }
+            if (!DRV_CONFIG_event_based_counts(drv_cfg) && CPU_STATE_p_state_counting(pcpu)) {
+                dispatch->read_counts((S8 *) psamp, DRV_EVENT_MASK_event_idx(&event_mask.eventmasks[i]));
+            }
+        }
+    }
+
+pmi_cleanup:
+    if (DEV_CONFIG_pebs_mode(pcfg)) {
+        if (!multi_pebs_enabled) {
+            PEBS_Reset_Index(this_cpu);
+        }
+        else {
+            if (cpu_sideband_buf) {
+                OUTPUT outbuf = &BUFFER_DESC_outbuf(&cpu_sideband_buf[this_cpu]);
+                if (OUTPUT_signal_full(outbuf) && !OUTPUT_tasklet_queued(outbuf)) {
+                    SEP_DRV_LOG_TRACE("Interrupt-driven sideband buffer flush tasklet scheduling.");
+                    OUTPUT_tasklet_queued(outbuf) = TRUE;
+                    tasklet_schedule(&CPU_STATE_nmi_tasklet(&pcb[this_cpu]));
+                }
+            }
+        }
+    }
+
+    // Reset the data counters
+    if (CPU_STATE_trigger_count(&pcb[this_cpu]) == 0) {
+        dispatch->swap_group(FALSE);
+    }
+    // Re-enable the counter control
+    dispatch->restart(NULL);
+    SYS_Locked_Dec(&CPU_STATE_in_interrupt(&pcb[this_cpu])); // do not use SEP_DRV_LOG_X (where X != INTERRUPT) below this
+
+    SEP_DRV_LOG_INTERRUPT_OUT("");
+    return;
+}
+
diff --git a/drivers/misc/intel/sepdk/sep/sepdrv_p_state.c b/drivers/misc/intel/sepdk/sep/sepdrv_p_state.c
new file mode 100644
index 000000000000..36de22f33a2b
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/sepdrv_p_state.c
@@ -0,0 +1,103 @@
+/****
+    Copyright(C) 2013-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit.
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+
+
+
+
+#include "lwpmudrv_defines.h"
+#include "lwpmudrv_types.h"
+#include "inc/control.h"
+#include "inc/utility.h"
+#include "inc/sepdrv_p_state.h"
+
+/*!
+ * @fn     OS_STATUS SEPDRV_P_STATE_Read
+ *
+ * @brief  Reads the APERF and MPERF counters into the buffer provided for the purpose
+ *
+ * @param  buffer  - buffer to read the counts into
+ *
+ * @param  pcpu - pcpu struct that contains the previous APERF/MPERF values
+ *
+ * @return OS_SUCCESS if read succeeded, otherwise error
+ *
+ * @note
+ */
+extern OS_STATUS
+SEPDRV_P_STATE_Read (
+    S8 *buffer,
+    CPU_STATE pcpu
+)
+{
+    U64  *samp  = (U64 *)buffer;
+    U64  new_APERF = 0;
+    U64  new_MPERF = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Buffer: %p, pcpu: %p.", buffer, pcpu);
+
+    if ((samp == NULL) || (pcpu == NULL)) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("OS_INVALID (!samp || !pcpu).");
+        return OS_INVALID;
+    }
+
+    new_APERF = SYS_Read_MSR(DRV_APERF_MSR);
+    new_MPERF = SYS_Read_MSR(DRV_MPERF_MSR);
+
+    if (CPU_STATE_last_p_state_valid(pcpu)) {
+        // there is a previous APERF/MPERF value
+        if ((CPU_STATE_last_aperf(pcpu)) > new_APERF) {
+            // a wrap-around has occurred.
+            samp[1] = CPU_STATE_last_aperf(pcpu) - new_APERF;
+        }
+        else {
+            samp[1] = new_APERF - CPU_STATE_last_aperf(pcpu);
+        }
+
+        if ((CPU_STATE_last_mperf(pcpu)) > new_MPERF) {
+            // a wrap-around has occurred.
+            samp[0] = CPU_STATE_last_mperf(pcpu) - new_MPERF;
+        }
+        else {
+            samp[0] = new_MPERF - CPU_STATE_last_mperf(pcpu);
+        }
+    }
+    else {
+        // there is no previous valid APERF/MPERF values, thus no delta calculations
+        (CPU_STATE_last_p_state_valid(pcpu)) = TRUE;
+        samp[0] = 0;
+        samp[1] = 0;
+    }
+
+    CPU_STATE_last_aperf(pcpu) = new_APERF;
+    CPU_STATE_last_mperf(pcpu) = new_MPERF;
+
+    SEP_DRV_LOG_TRACE_OUT("OS_SUCCESS.");
+    return OS_SUCCESS;
+}
+
diff --git a/drivers/misc/intel/sepdk/sep/silvermont.c b/drivers/misc/intel/sepdk/sep/silvermont.c
new file mode 100644
index 000000000000..258a57d2fb0f
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/silvermont.c
@@ -0,0 +1,1015 @@
+/****
+    Copyright(C) 2011-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/wait.h>
+#include <linux/fs.h>
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+#include "lwpmudrv.h"
+#include "utility.h"
+#include "control.h"
+#include "output.h"
+#include "silvermont.h"
+#include "ecb_iterators.h"
+#include "pebs.h"
+#include "apic.h"
+
+extern U64                       *read_counter_info;
+extern DRV_CONFIG                 drv_cfg;
+extern U64                       *interrupt_counts;
+extern DRV_SETUP_INFO_NODE        req_drv_setup_info;
+extern EMON_BUFFER_DRIVER_HELPER  emon_buffer_driver_helper;
+static U32                        restore_reg_addr[3];
+
+typedef struct SADDR_S {
+    S64 addr:SILVERMONT_LBR_DATA_BITS;
+} SADDR;
+
+#define SADDR_addr(x)               (x).addr
+#define ADD_ERRATA_FIX_FOR_FIXED_CTR0
+#define MSR_ENERGY_MULTIPLIER       0x606        // Energy Multiplier MSR
+
+#if defined(DRV_IA32)
+#define ENABLE_IA32_PERFEVTSEL0_CTR 0x00400000
+#define ENABLE_FIXED_CTR0           0x00000003
+#elif defined(DRV_EM64T)
+#define ENABLE_IA32_PERFEVTSEL0_CTR 0x0000000000400000
+#define ENABLE_FIXED_CTR0           0x0000000000000003
+#else
+#error "Unexpected Architecture seen"
+#endif
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void silvermont_Write_PMU(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Initial set up of the PMU registers
+ *
+ * <I>Special Notes</I>
+ *         Initial write of PMU registers.
+ *         Walk through the enties and write the value of the register accordingly.
+ *         Assumption:  For CCCR registers the enable bit is set to value 0.
+ *         When current_group = 0, then this is the first time this routine is called,
+ *         initialize the locks and set up EM tables.
+ */
+static VOID
+silvermont_Write_PMU (
+    VOID  *param
+)
+{
+    U32          this_cpu;
+    CPU_STATE    pcpu;
+    U32          dev_idx;
+    DISPATCH     dispatch;
+    EVENT_CONFIG ec;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    ec       = LWPMU_DEVICE_ec(&devices[dev_idx]);
+    dispatch = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+
+    if (CPU_STATE_current_group(pcpu) == 0) {
+        if (EVENT_CONFIG_mode(ec) != EM_DISABLED) {
+            U32            index;
+            U32            st_index;
+            U32            j;
+
+            /* Save all the initialization values away into an array for Event Multiplexing. */
+            for (j = 0; j < EVENT_CONFIG_num_groups(ec); j++) {
+                CPU_STATE_current_group(pcpu) = j;
+                st_index   = CPU_STATE_current_group(pcpu) * EVENT_CONFIG_max_gp_events(ec);
+                FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_GP) {
+                    index = st_index + i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+                    CPU_STATE_em_tables(pcpu)[index] = ECB_entries_reg_value(pecb,i);
+                } END_FOR_EACH_REG_CORE_OPERATION;
+            }
+            /* Reset the current group to the very first one. */
+            CPU_STATE_current_group(pcpu) = this_cpu % EVENT_CONFIG_num_groups(ec);
+        }
+    }
+
+    if (dispatch->hw_errata) {
+        dispatch->hw_errata();
+    }
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_ALL_REG) {
+        /*
+         * Writing the GLOBAL Control register enables the PMU to start counting.
+         * So write 0 into the register to prevent any counting from starting.
+         */
+        if (i == ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)) {
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+            continue;
+        }
+        /*
+         *  PEBS is enabled for this collection session
+         */
+        if (DRV_SETUP_INFO_pebs_accessible(&req_drv_setup_info) &&
+            i == ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS) &&
+            ECB_entries_reg_value(pecb,i)) {
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+            continue;
+        }
+        SYS_Write_MSR(ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i));
+#if defined(MYDEBUG)
+        {
+            U64 val = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+            SEP_DRV_LOG_TRACE("Write reg 0x%x --- value 0x%llx -- read 0x%llx.",
+                            ECB_entries_reg_id(pecb,i),
+                            ECB_entries_reg_value(pecb,i),
+                            val);
+        }
+#endif
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+#if defined(ADD_ERRATA_FIX_FOR_FIXED_CTR0)
+    {
+        U64 fixed_ctr0 = SYS_Read_MSR(IA32_FIXED_CTRL);
+        fixed_ctr0 = (fixed_ctr0 & (ENABLE_FIXED_CTR0));
+        if (fixed_ctr0 != 0x0) {
+            U64 val = SYS_Read_MSR(IA32_PERFEVTSEL0);
+            val |= ENABLE_IA32_PERFEVTSEL0_CTR;
+            SYS_Write_MSR(IA32_PERFEVTSEL0, val);
+        }
+    }
+#endif
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void silvermont_Disable_PMU(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Zero out the global control register.  This automatically disables the PMU counters.
+ *
+ */
+static VOID
+silvermont_Disable_PMU (
+    PVOID  param
+)
+{
+    U32         this_cpu;
+    CPU_STATE   pcpu;
+    ECB         pecb;
+    U32         dev_idx;
+    U32         cur_grp;
+    DEV_CONFIG  pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("No programming for this device in this group.");
+        return;
+    }
+
+    if (GET_DRIVER_STATE() != DRV_STATE_RUNNING) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), 0LL);
+        if (DEV_CONFIG_pebs_mode(pcfg)) {
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), 0LL);
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void silvermont_Enable_PMU(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Set the enable bit for all the Control registers
+ *
+ */
+static VOID
+silvermont_Enable_PMU (
+    PVOID   param
+)
+{
+    /*
+     * Get the value from the event block
+     *   0 == location of the global control reg for this block.
+     *   Generalize this location awareness when possible
+     */
+    U32       this_cpu;
+    CPU_STATE pcpu;
+    ECB       pecb;
+    U32       dev_idx;
+    U32       cur_grp;
+    DEV_CONFIG pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    if (KVM_guest_mode) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX (pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), 0LL);
+    }
+    if (GET_DRIVER_STATE() == DRV_STATE_RUNNING) {
+        APIC_Enable_Pmi();
+        if (CPU_STATE_reset_mask(pcpu)) {
+            SEP_DRV_LOG_TRACE("Overflow reset mask %llx.", CPU_STATE_reset_mask(pcpu));
+            // Reinitialize the global overflow control register
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            CPU_STATE_reset_mask(pcpu) = 0LL;
+        }
+        if (CPU_STATE_group_swap(pcpu)) {
+            CPU_STATE_group_swap(pcpu) = 0;
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            if (DEV_CONFIG_pebs_mode(pcfg)) {
+                SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                              ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, PEBS_ENABLE_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+            }
+            SYS_Write_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)),
+                          ECB_entries_reg_value(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+#if defined(MYDEBUG)
+            {
+                U64 val;
+                val = SYS_Read_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)));
+                SEP_DRV_LOG_TRACE("Write reg 0x%x--- read 0x%llx.",
+                                ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS)), val);
+            }
+#endif
+        }
+    }
+    SEP_DRV_LOG_TRACE("Reenabled PMU with value 0x%llx.", ECB_entries_reg_value(pecb, 0));
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn silvermont_Read_PMU_Data(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read all the data MSR's into a buffer.  Called by the interrupt handler.
+ *
+ */
+static void
+silvermont_Read_PMU_Data (
+    PVOID   param
+)
+{
+    U32       j;
+    U64      *buffer          = read_counter_info;
+    U32       this_cpu;
+    CPU_STATE pcpu;
+    ECB       pecb;
+    U32       dev_idx;
+    U32       cur_grp;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    preempt_disable();
+    this_cpu  = CONTROL_THIS_CPU();
+    preempt_enable();
+    pcpu      = &pcb[this_cpu];
+    dev_idx   = core_to_dev_map[this_cpu];
+    cur_grp   = CPU_STATE_current_group(pcpu);
+    pecb      = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    SEP_DRV_LOG_TRACE("PMU control_data 0x%p, buffer 0x%p.",
+                    LWPMU_DEVICE_PMU_register_data(&devices[dev_idx]),
+                    buffer);
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+
+        j = EMON_BUFFER_CORE_EVENT_OFFSET(EMON_BUFFER_DRIVER_HELPER_core_index_to_thread_offset_map(emon_buffer_driver_helper)[this_cpu],
+                                          ECB_entries_core_event_id(pecb,i));
+
+        buffer[j] = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+        SEP_DRV_LOG_TRACE("j=%u, value=%llu, cpu=%u, event_id=%u", j, buffer[j], this_cpu, ECB_entries_core_event_id(pecb,i));
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn void silvermont_Check_Overflow(masks)
+ *
+ * @param    masks    the mask structure to populate
+ *
+ * @return   None     No return needed
+ *
+ * @brief  Called by the data processing method to figure out which registers have overflowed.
+ *
+ */
+static void
+silvermont_Check_Overflow (
+    DRV_MASKS    masks
+)
+{
+    U32              index;
+    U64              overflow_status     = 0;
+    U32              this_cpu;
+    BUFFER_DESC      bd;
+    CPU_STATE        pcpu;
+    ECB              pecb;
+    U32              dev_idx;
+    U32              cur_grp;
+    DEV_CONFIG       pcfg;
+    DISPATCH         dispatch;
+    U64              overflow_status_clr = 0;
+    DRV_EVENT_MASK_NODE event_flag;
+
+    SEP_DRV_LOG_TRACE_IN("Masks: %p.", masks);
+
+    this_cpu = CONTROL_THIS_CPU();
+    bd       = &cpu_buf[this_cpu];
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    dispatch = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    // initialize masks
+    DRV_MASKS_masks_num(masks) = 0;
+
+    overflow_status = SYS_Read_MSR(ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_STATUS_REG_INDEX, PMU_OPERATION_GLOBAL_STATUS)));
+
+    if (DEV_CONFIG_pebs_mode(pcfg)) {
+        overflow_status = PEBS_Overflowed (this_cpu, overflow_status, 0);
+    }
+    overflow_status_clr = overflow_status;
+
+    if (dispatch->check_overflow_gp_errata) {
+        overflow_status = dispatch->check_overflow_gp_errata(pecb,  &overflow_status_clr);
+    }
+    SEP_DRV_LOG_TRACE("Overflow: cpu: %d, status 0x%llx.", this_cpu, overflow_status);
+    index                        = 0;
+    BUFFER_DESC_sample_count(bd) = 0;
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+        if (ECB_entries_fixed_reg_get(pecb, i)) {
+            index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_FIXED) + 0x20;
+            if (dispatch->check_overflow_errata) {
+                overflow_status = dispatch->check_overflow_errata(pecb, i, overflow_status);
+            }
+        }
+        else if (ECB_entries_is_gp_reg_get(pecb, i)) {
+            index = i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+        }
+        else {
+            continue;
+        }
+        if (overflow_status & ((U64)1 << index)) {
+            SEP_DRV_LOG_TRACE("Overflow: cpu: %d, index %d.", this_cpu, index);
+            SEP_DRV_LOG_TRACE("Register 0x%x --- val 0%llx.",
+                            ECB_entries_reg_id(pecb,i),
+                            SYS_Read_MSR(ECB_entries_reg_id(pecb,i)));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i));
+
+            if (DRV_CONFIG_enable_cp_mode(drv_cfg)) {
+                /* Increment the interrupt count. */
+                if (interrupt_counts) {
+                    interrupt_counts[this_cpu * DRV_CONFIG_num_events(drv_cfg) + ECB_entries_event_id_index(pecb,i)] += 1;
+                }
+            }
+
+            DRV_EVENT_MASK_bitFields1(&event_flag) = (U8) 0;
+            if (ECB_entries_fixed_reg_get(pecb, i)) {
+                CPU_STATE_p_state_counting(pcpu) = 1;
+            }
+            if (ECB_entries_precise_get(pecb, i)) {
+                DRV_EVENT_MASK_precise(&event_flag) = 1;
+            }
+            if (ECB_entries_lbr_value_get(pecb, i)) {
+                DRV_EVENT_MASK_lbr_capture(&event_flag) = 1;
+            }
+            if (ECB_entries_uncore_get(pecb, i)) {
+                DRV_EVENT_MASK_uncore_capture(&event_flag) = 1;
+            }
+
+            if (DRV_MASKS_masks_num(masks) < MAX_OVERFLOW_EVENTS) {
+                DRV_EVENT_MASK_bitFields1(DRV_MASKS_eventmasks(masks) + DRV_MASKS_masks_num(masks)) = DRV_EVENT_MASK_bitFields1(&event_flag);
+                DRV_EVENT_MASK_event_idx(DRV_MASKS_eventmasks(masks) + DRV_MASKS_masks_num(masks)) = ECB_entries_event_id_index(pecb, i);
+                DRV_MASKS_masks_num(masks)++;
+            }
+            else {
+                SEP_DRV_LOG_ERROR("The array for event masks is full.");
+            }
+
+            SEP_DRV_LOG_TRACE("Overflow -- 0x%llx, index 0x%llx.", overflow_status, (U64)1 << index);
+            SEP_DRV_LOG_TRACE("Slot# %d, reg_id 0x%x, index %d.",
+                            i, ECB_entries_reg_id(pecb, i), index);
+            if (ECB_entries_event_id_index(pecb, i) == CPU_STATE_trigger_event_num(pcpu)) {
+                CPU_STATE_trigger_count(pcpu)--;
+            }
+        }
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+
+    CPU_STATE_reset_mask(pcpu) = overflow_status_clr;
+    // Reinitialize the global overflow control register
+    SYS_Write_MSR(IA32_PERF_GLOBAL_OVF_CTRL, overflow_status_clr);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn silvermont_Swap_Group(restart)
+ *
+ * @param    restart    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Perform the mechanics of swapping the event groups for event mux operations
+ *
+ * <I>Special Notes</I>
+ *         Swap function for event multiplexing.
+ *         Freeze the counting.
+ *         Swap the groups.
+ *         Enable the counting.
+ *         Reset the event trigger count
+ *
+ */
+static VOID
+silvermont_Swap_Group (
+    DRV_BOOL  restart
+)
+{
+    U32            index;
+    U32            next_group;
+    U32            st_index;
+    U32            this_cpu = CONTROL_THIS_CPU();
+    CPU_STATE      pcpu     = &pcb[this_cpu];
+    U32            dev_idx;
+    DISPATCH       dispatch;
+    EVENT_CONFIG   ec;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy restart: %u.", restart);
+
+    this_cpu   = CONTROL_THIS_CPU();
+    pcpu       = &pcb[this_cpu];
+    dev_idx    = core_to_dev_map[this_cpu];
+    dispatch   = LWPMU_DEVICE_dispatch(&devices[dev_idx]);
+    ec         = LWPMU_DEVICE_ec(&devices[dev_idx]);
+    st_index   = CPU_STATE_current_group(pcpu) * EVENT_CONFIG_max_gp_events(ec);
+    next_group = (CPU_STATE_current_group(pcpu) + 1);
+
+    if (next_group >= EVENT_CONFIG_num_groups(ec)) {
+        next_group = 0;
+    }
+
+    SEP_DRV_LOG_TRACE("Current group : 0x%x.", CPU_STATE_current_group(pcpu));
+    SEP_DRV_LOG_TRACE("Next group : 0x%x.", next_group);
+
+    // Save the counters for the current group
+    if (!DRV_CONFIG_event_based_counts(drv_cfg)) {
+        FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_GP) {
+            index = st_index + i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+            CPU_STATE_em_tables(pcpu)[index] = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+            SEP_DRV_LOG_TRACE("Saved value for reg 0x%x : 0x%llx.",
+                            ECB_entries_reg_id(pecb,i),
+                            CPU_STATE_em_tables(pcpu)[index]);
+        } END_FOR_EACH_REG_CORE_OPERATION;
+    }
+
+    CPU_STATE_current_group(pcpu) = next_group;
+
+    if (dispatch->hw_errata) {
+        dispatch->hw_errata();
+    }
+
+    // First write the GP control registers (eventsel)
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_CTRL_GP) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb,i), ECB_entries_reg_value(pecb,i));
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    if (DRV_CONFIG_event_based_counts(drv_cfg)) {
+        // In EBC mode, reset the counts for all events except for trigger event
+        FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+            if (ECB_entries_event_id_index(pecb, i) != CPU_STATE_trigger_event_num(pcpu)) {
+                SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+            }
+        } END_FOR_EACH_REG_CORE_OPERATION;
+    }
+    else {
+        // Then write the gp count registers
+        st_index = CPU_STATE_current_group(pcpu) * EVENT_CONFIG_max_gp_events(ec);
+        FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_GP) {
+            index = st_index + i - ECB_operations_register_start(pecb, PMU_OPERATION_DATA_GP);
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), CPU_STATE_em_tables(pcpu)[index]);
+            SEP_DRV_LOG_TRACE("Restore value for reg 0x%x : 0x%llx.",
+                            ECB_entries_reg_id(pecb,i),
+                            CPU_STATE_em_tables(pcpu)[index]);
+        } END_FOR_EACH_REG_CORE_OPERATION;
+    }
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_OCR) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb, i),ECB_entries_reg_value(pecb, i));
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    /*
+     *  reset the em factor when a group is swapped
+     */
+    CPU_STATE_trigger_count(pcpu) = EVENT_CONFIG_em_factor(ec);
+
+    /*
+     * The enable routine needs to rewrite the control registers
+     */
+    CPU_STATE_reset_mask(pcpu) = 0LL;
+    CPU_STATE_group_swap(pcpu) = 1;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn silvermont_Initialize(params)
+ *
+ * @param    params    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Initialize the PMU setting up for collection
+ *
+ * <I>Special Notes</I>
+ *         Saves the relevant PMU state (minimal set of MSRs required
+ *         to avoid conflicts with other Linux tools, such as Oprofile).
+ *         This function should be called in parallel across all CPUs
+ *         prior to the start of sampling, before PMU state is changed.
+ *
+ */
+static VOID
+silvermont_Initialize (
+    VOID  *param
+)
+{
+    U32        this_cpu;
+    CPU_STATE  pcpu;
+    ECB        pecb;
+    U32        dev_idx;
+    U32        cur_grp;
+    DEV_CONFIG pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (pcb == NULL) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pcb).");
+        return;
+    }
+
+    pcpu     = &pcb[this_cpu];
+    cur_grp  = CPU_STATE_current_group(pcpu);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+
+    CPU_STATE_pmu_state(pcpu) = pmu_state + (this_cpu * 3);
+    if (CPU_STATE_pmu_state(pcpu) == NULL) {
+        SEP_DRV_LOG_WARNING_TRACE_OUT("Unable to save PMU state on CPU %d!", this_cpu);
+        return;
+    }
+
+    restore_reg_addr[0] = ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, DEBUG_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS));
+    restore_reg_addr[1] = ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, GLOBAL_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS));
+    restore_reg_addr[2] = ECB_entries_reg_id(pecb, ECB_SECTION_REG_INDEX(pecb, FIXED_CTRL_REG_INDEX, PMU_OPERATION_GLOBAL_REGS));
+
+    // save the original PMU state on this CPU (NOTE: must only be called ONCE per collection)
+    CPU_STATE_pmu_state(pcpu)[0] = SYS_Read_MSR(restore_reg_addr[0]);
+    CPU_STATE_pmu_state(pcpu)[1] = SYS_Read_MSR(restore_reg_addr[1]);
+    CPU_STATE_pmu_state(pcpu)[2] = SYS_Read_MSR(restore_reg_addr[2]);
+
+    SEP_DRV_LOG_TRACE("Saving PMU state on CPU %d:", this_cpu);
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_DEBUG_CTRL)=0x%llx.", CPU_STATE_pmu_state(pcpu)[0]);
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_PERF_GLOBAL_CTRL)=0x%llx.", CPU_STATE_pmu_state(pcpu)[1]);
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_FIXED_CTRL)=0x%llx.", CPU_STATE_pmu_state(pcpu)[2]);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn silvermont_Destroy(params)
+ *
+ * @param    params    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Reset the PMU setting up after collection
+ *
+ * <I>Special Notes</I>
+ *         Restores the previously saved PMU state done in core2_Initialize.
+ *         This function should be called in parallel across all CPUs
+ *         after sampling collection ends/terminates.
+ *
+ */
+static VOID
+silvermont_Destroy (
+    VOID *param
+)
+{
+    U32        this_cpu;
+    CPU_STATE  pcpu;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    if (pcb == NULL) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pcb).");
+        return;
+    }
+
+    preempt_disable();
+    this_cpu = CONTROL_THIS_CPU();
+    preempt_enable();
+    pcpu = &pcb[this_cpu];
+
+    if (CPU_STATE_pmu_state(pcpu) == NULL) {
+        SEP_DRV_LOG_WARNING_TRACE_OUT("Unable to restore PMU state on CPU %d!", this_cpu);
+        return;
+    }
+
+    SEP_DRV_LOG_TRACE("Clearing PMU state on CPU %d:", this_cpu);
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_DEBUG_CTRL)=0x0.");
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_PERF_GLOBAL_CTRL)=0x0.");
+    SEP_DRV_LOG_TRACE("    msr_val(IA32_FIXED_CTRL)=0.");
+
+    SYS_Write_MSR(restore_reg_addr[0], 0);
+    SYS_Write_MSR(restore_reg_addr[1], 0);
+    SYS_Write_MSR(restore_reg_addr[2], 0);
+
+    CPU_STATE_pmu_state(pcpu) = NULL;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*
+ * @fn silvermont_Read_LBRs(buffer)
+ *
+ * @param   IN buffer - pointer to the buffer to write the data into
+ * @return  None
+ *
+ * @brief   Read all the LBR registers into the buffer provided and return
+ *
+ */
+static U64
+silvermont_Read_LBRs (
+    VOID   *buffer
+)
+{
+    U32   i, count = 0;
+    U64  *lbr_buf = NULL;
+    U64   value;
+    U64   tos_ip_addr = 0;
+    U64   tos_ptr = 0;
+    SADDR saddr;
+    U32   this_cpu;
+    U32   dev_idx;
+    LBR   lbr;
+    DEV_CONFIG pcfg;
+
+    SEP_DRV_LOG_TRACE_IN("Buffer: %p.", buffer);
+
+    this_cpu = CONTROL_THIS_CPU();
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    lbr      = LWPMU_DEVICE_lbr(&devices[dev_idx]);
+
+    if (buffer && DEV_CONFIG_store_lbrs(pcfg)) {
+        lbr_buf = (U64 *)buffer;
+    }
+
+    for (i = 0; i < LBR_num_entries(lbr); i++) {
+        value = SYS_Read_MSR(LBR_entries_reg_id(lbr,i));
+        if (buffer && DEV_CONFIG_store_lbrs(pcfg)) {
+            *lbr_buf = value;
+        }
+        SEP_DRV_LOG_TRACE("LBR %u, 0x%llx.", i, value);
+        if (i == 0) {
+            tos_ptr = value;
+        }
+        else {
+            if (LBR_entries_etype(lbr, i) == LBR_ENTRY_FROM_IP) {
+                if (tos_ptr == count) {
+                    SADDR_addr(saddr) = value & SILVERMONT_LBR_BITMASK;
+                    tos_ip_addr = (U64) SADDR_addr(saddr); // Add signed extension
+                    SEP_DRV_LOG_TRACE("Tos_ip_addr %llu, 0x%llx.", tos_ptr, value);
+                }
+                count++;
+            }
+        }
+        if (buffer && DEV_CONFIG_store_lbrs(pcfg)) {
+            lbr_buf++;
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %llu.", tos_ip_addr);
+    return tos_ip_addr;
+}
+
+static VOID
+silvermont_Clean_Up (
+    VOID   *param
+)
+{
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_ALL_REG) {
+        if (ECB_entries_clean_up_get(pecb,i)) {
+            SEP_DRV_LOG_TRACE("Clean up set --- RegId --- %x.", ECB_entries_reg_id(pecb, i));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+        }
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn silvermont_Read_Counts(param, id)
+ *
+ * @param    param    The read thread node to process
+ * @param    id       The event id for the which the sample is generated
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read CPU event based counts data and store into the buffer param;
+ *           For the case of the trigger event, store the SAV value.
+ */
+static VOID
+silvermont_Read_Counts (
+    PVOID  param,
+    U32    id
+)
+{
+    U64            *data;
+    U32             this_cpu;
+    CPU_STATE       pcpu;
+    U32             dev_idx;
+    DEV_CONFIG      pcfg;
+    U32             event_id     = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p, id: %u.", param, id);
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_idx  = core_to_dev_map[this_cpu];
+    pcfg     = LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+
+    if (DEV_CONFIG_ebc_group_id_offset(pcfg)) {
+        // Write GroupID
+        data  = (U64 *)((S8*)param + DEV_CONFIG_ebc_group_id_offset(pcfg));
+        *data = CPU_STATE_current_group(pcpu) + 1;
+    }
+
+    FOR_EACH_REG_CORE_OPERATION(pecb, i, PMU_OPERATION_DATA_ALL) {
+        if (ECB_entries_counter_event_offset(pecb,i) == 0) {
+            continue;
+        }
+        data = (U64 *)((S8*)param + ECB_entries_counter_event_offset(pecb,i));
+        event_id = ECB_entries_event_id_index(pecb,i);
+        if (event_id == id) {
+            *data = ~(ECB_entries_reg_value(pecb,i) - 1) &
+                                           ECB_entries_max_bits(pecb,i);
+        }
+        else {
+            *data = SYS_Read_MSR(ECB_entries_reg_id(pecb,i));
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+        }
+    } END_FOR_EACH_REG_CORE_OPERATION;
+
+    if (DRV_CONFIG_enable_p_state(drv_cfg)) {
+        CPU_STATE_p_state_counting(pcpu) = 0;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          U64 silvermont_Platform_Info
+ *
+ * @brief       Reads the MSR_PLATFORM_INFO register if present
+ *
+ * @param       void
+ *
+ * @return      value read from the register
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static void
+silvermont_Platform_Info (
+    PVOID data
+)
+{
+    U64                    index         = 0;
+    DRV_PLATFORM_INFO      platform_data = (DRV_PLATFORM_INFO)data;
+    U64                    value         = 0;
+    U64                    clock_value   = 0;
+    U64                    energy_multiplier;
+
+    SEP_DRV_LOG_TRACE_IN("Data: %p.", data);
+
+    if (!platform_data) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!platform_data).");
+        return;
+    }
+
+#define IA32_MSR_PLATFORM_INFO 0xCE
+    value = SYS_Read_MSR(IA32_MSR_PLATFORM_INFO);
+
+#define IA32_MSR_PSB_CLOCK_STS  0xCD
+#define FREQ_MASK_BITS          0x03
+
+    clock_value = SYS_Read_MSR(IA32_MSR_PSB_CLOCK_STS);
+    index = clock_value & FREQ_MASK_BITS;
+    DRV_PLATFORM_INFO_info(platform_data)           = value;
+    DRV_PLATFORM_INFO_ddr_freq_index(platform_data) = index;
+
+#undef IA32_MSR_PLATFORM_INFO
+#undef IA32_MSR_PSB_CLOCK_STS
+#undef FREQ_MASK_BITS
+    energy_multiplier = SYS_Read_MSR(MSR_ENERGY_MULTIPLIER);
+    SEP_DRV_LOG_TRACE ("MSR_ENERGY_MULTIPLIER: %llx.", energy_multiplier);
+    DRV_PLATFORM_INFO_energy_multiplier(platform_data) = (U32) (energy_multiplier & 0x00001F00) >> 8;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn          VOID knights_Platform_Info
+ *
+ * @brief       Reads the MSR_PLATFORM_INFO register if present
+ *
+ * @param       void
+ *
+ * @return      value read from the register
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+static VOID
+knights_Platform_Info (
+    PVOID data
+)
+{
+    DRV_PLATFORM_INFO      platform_data = (DRV_PLATFORM_INFO)data;
+    U64                    value         = 0;
+    U64                    energy_multiplier;
+
+    SEP_DRV_LOG_TRACE_IN("Data: %p.", data);
+
+    if (!platform_data) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!platform_data).");
+        return;
+    }
+
+#define IA32_MSR_PLATFORM_INFO 0xCE
+    value = SYS_Read_MSR(IA32_MSR_PLATFORM_INFO);
+
+    DRV_PLATFORM_INFO_info(platform_data)           = value;
+    DRV_PLATFORM_INFO_ddr_freq_index(platform_data) = 0;
+    energy_multiplier = SYS_Read_MSR(MSR_ENERGY_MULTIPLIER);
+    SEP_DRV_LOG_TRACE ("MSR_ENERGY_MULTIPLIER: %llx.", energy_multiplier);
+    DRV_PLATFORM_INFO_energy_multiplier(platform_data) = (U32) (energy_multiplier & 0x00001F00) >> 8;
+
+    return;
+}
+
+
+/*
+ * Initialize the dispatch table
+ */
+DISPATCH_NODE  silvermont_dispatch =
+{
+    .init                     = silvermont_Initialize,
+    .fini                     = silvermont_Destroy,
+    .write                    = silvermont_Write_PMU,
+    .freeze                   = silvermont_Disable_PMU,
+    .restart                  = silvermont_Enable_PMU,
+    .read_data                = silvermont_Read_PMU_Data,
+    .check_overflow           = silvermont_Check_Overflow,
+    .swap_group               = silvermont_Swap_Group,
+    .read_lbrs                = silvermont_Read_LBRs,
+    .cleanup                  = silvermont_Clean_Up,
+    .hw_errata                = NULL,
+    .read_power               = NULL,
+    .check_overflow_errata    = NULL,
+    .read_counts              = silvermont_Read_Counts,
+    .check_overflow_gp_errata = NULL,
+    .read_ro                  = NULL,
+    .platform_info            = silvermont_Platform_Info,
+    .trigger_read             = NULL,
+    .scan_for_uncore          = NULL,
+    .read_metrics             = NULL
+};
+
+DISPATCH_NODE  knights_dispatch =
+{
+    .init                     = silvermont_Initialize,
+    .fini                     = silvermont_Destroy,
+    .write                    = silvermont_Write_PMU,
+    .freeze                   = silvermont_Disable_PMU,
+    .restart                  = silvermont_Enable_PMU,
+    .read_data                = silvermont_Read_PMU_Data,
+    .check_overflow           = silvermont_Check_Overflow,
+    .swap_group               = silvermont_Swap_Group,
+    .read_lbrs                = silvermont_Read_LBRs,
+    .cleanup                  = silvermont_Clean_Up,
+    .hw_errata                = NULL,
+    .read_power               = NULL,
+    .check_overflow_errata    = NULL,
+    .read_counts              = silvermont_Read_Counts,
+    .check_overflow_gp_errata = NULL,
+    .read_ro                  = NULL,
+    .platform_info            = knights_Platform_Info,
+    .trigger_read             = NULL,
+    .scan_for_uncore          = NULL,
+    .read_metrics             = NULL
+};
diff --git a/drivers/misc/intel/sepdk/sep/sys32.S b/drivers/misc/intel/sepdk/sep/sys32.S
new file mode 100644
index 000000000000..dee3b8d5c9cd
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/sys32.S
@@ -0,0 +1,204 @@
+#     Copyright(C) 2002-2018 Intel Corporation.  All Rights Reserved.
+# 
+#     This file is part of SEP Development Kit
+# 
+#     SEP Development Kit is free software; you can redistribute it
+#     and/or modify it under the terms of the GNU General Public License
+#     version 2 as published by the Free Software Foundation.
+# 
+#     SEP Development Kit is distributed in the hope that it will be useful,
+#     but WITHOUT ANY WARRANTY; without even the implied warranty of
+#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+#     GNU General Public License for more details.
+# 
+#     You should have received a copy of the GNU General Public License
+#     along with SEP Development Kit; if not, write to the Free Software
+#     Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+# 
+#     As a special exception, you may use this file as part of a free software
+#     library without restriction.  Specifically, if other files instantiate
+#     templates or use macros or inline functions from this file, or you compile
+#     this file and link it with other files to produce an executable, this
+#     file does not by itself cause the resulting executable to be covered by
+#     the GNU General Public License.  This exception does not however
+#     invalidate any other reasons why the executable file might be covered by
+#     the GNU General Public License.
+
+
+#include <linux/version.h>
+#include <asm/segment.h>
+
+#if LINUX_VERSION_CODE == KERNEL_VERSION(2,6,20)
+#define USE_KERNEL_PERCPU_SEGMENT_GS
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,21) && LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,29)
+#define USE_KERNEL_PERCPU_SEGMENT_FS
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,30)
+#define USE_KERNEL_PERCPU_SEGMENT_FS
+#define USE_KERNEL_PERCPU_SEGMENT_GS
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,20)
+#if !defined(__KERNEL_PERCPU)
+#define __KERNEL_PERCPU __KERNEL_PDA
+#endif
+#endif
+
+#if defined(USE_KERNEL_PERCPU_SEGMENT_GS)
+#if defined(__KERNEL_STACK_CANARY)
+#define SEP_GS_SEG_VALUE __KERNEL_STACK_CANARY
+#else
+#define SEP_GS_SEG_VALUE __KERNEL_PERCPU
+#endif
+#endif
+
+#***********************************************************************
+#
+#    SYS_Get_IDT_Base_HWR
+#            Get the IDT Desc address
+#
+#    Entry: none
+#
+#    Exit:  base address in eax
+#
+# void SYS_Get_IDT_Base_HWR(U64 *pIdtDesc);
+#
+#***********************************************************************
+        .text
+        .align  4
+	.global SYS_IO_Delay
+SYS_IO_Delay:
+	ret
+
+        .global SYS_Get_IDT_Base_HWR
+SYS_Get_IDT_Base_HWR:
+        subl    $8,%esp
+        sidt    2(%esp)
+	movl    4(%esp),%eax
+	addl    $8,%esp
+        ret
+	.global SYS_Get_cs
+SYS_Get_cs:
+	mov	%cs, %ax
+	andl	$0x0000ffff, %eax
+	ret
+	
+	.global SYS_Get_TSC
+SYS_Get_TSC:
+	rdtsc
+	ret
+        .text
+        .align  4
+        .global SYS_Perfvec_Handler
+SYS_Perfvec_Handler:
+                                        # This is the same as KERNEL's
+        pushl   %eax                    # Filler for Error Code
+
+        cld
+        pushl   %es                     # SAVE_ALL macro to access pt_regs
+        pushl   %ds                     # inside our ISR.
+#if defined(USE_KERNEL_PERCPU_SEGMENT_GS)
+        pushl   %gs
+#endif
+#if defined(USE_KERNEL_PERCPU_SEGMENT_FS)
+        pushl   %fs
+#endif
+        pushl   %eax
+        pushl   %ebp
+        pushl   %edi
+        pushl   %esi
+        pushl   %edx
+        pushl   %ecx
+        pushl   %ebx
+
+        movl    $(__KERNEL_DS), %edx    # Use KERNEL DS selector
+        movl    %edx,%ds                # Make sure we set Kernel
+        movl    %edx,%es                # DS into local DS and ES
+
+#if defined(USE_KERNEL_PERCPU_SEGMENT_GS)
+        movl    $(SEP_GS_SEG_VALUE), %edx    # Use kernel percpu segment
+        movl    %edx,%gs                    # ... and load it into %gs
+#endif
+#if defined(USE_KERNEL_PERCPU_SEGMENT_FS)
+        movl    $(__KERNEL_PERCPU), %edx    # Use kernel percpu segment
+        movl    %edx,%fs                    # ... and load it into %fs
+#endif
+
+	movl	%esp, %ebx		# get ready to put *pt_regs on stack
+        
+        pushl   %ebx			# put *pt_regs on the stack
+        call PMI_Interrupt_Handler
+        addl $0x4, %esp			# pop to nowhere...
+ 
+       pop     %ebx                    # restore register set
+        pop     %ecx
+        pop     %edx
+        pop     %esi
+        pop     %edi
+        pop     %ebp
+        pop     %eax
+#if defined(USE_KERNEL_PERCPU_SEGMENT_FS)
+        pop     %fs
+#endif
+#if defined(USE_KERNEL_PERCPU_SEGMENT_GS)
+        pop     %gs
+#endif
+        pop     %ds
+        pop     %es
+        pop     %eax
+        
+        iret
+# ----------------------------------------------------------------------------
+# name:         get_CSD
+#
+# description:  get the CS descriptor
+#
+# input:        code segment selector
+#
+# output:       code segment descriptor
+# ----------------------------------------------------------------------------
+        .text
+        .align  4
+        .globl  SYS_Get_CSD
+
+SYS_Get_CSD:
+        pushl   %ebp
+        movl    %esp, %ebp
+        pushal                                  # save regs
+
+        subl    $8,%esp
+        xorl    %eax, %eax
+        movw    8(%ebp), %ax                    # eax.lo = cs
+        sgdt    (%esp)                          # store gdt reg
+        leal    (%esp), %ebx                    # ebx = gdt reg ptr
+        movl    2(%ebx), %ecx                   # ecx = gdt base
+        xorl    %edx, %edx
+        movw    %ax, %dx
+        andl    $4, %edx
+        cmpl    $0, %edx                        # test ti. GDT?
+        jz      .bsr_10                         # ..yes
+        xorl    %edx, %edx
+        sldt    %dx                             # ..no dx=ldtsel
+        andb    $0xf8, %dl                      # clear ti,rpl
+        addl    2(%ebx), %edx                   # add gdt base
+        movb    7(%edx), %cl                    # ecx = ldt base
+        shll    $8, %ecx                        # ..
+        movb    4(%edx), %cl                    # ..
+        shll    $16, %ecx                       # ..
+        movw    2(%edx), %cx                    # ..
+.bsr_10:
+        andb    $0xf8, %al                      # clear ti & rpl
+        addl    %eax, %ecx                      # add to gdt/ldt
+        movl    (%ecx), %eax                    # copy code seg
+        movl    12(%ebp), %edx                  # ..descriptor (csdlo)
+        movl    %eax, (%edx)                    # ..descriptor (csdlo)
+        movl    4(%ecx), %eax                   # ..from gdt or
+        movl    16(%ebp), %edx                  # ..ldt to sample (csdhi)
+        movl    %eax, (%edx)                    # ..ldt to sample (csdhi)
+        addl    $8,%esp
+        popal                                   # restore regs
+        leave
+        ret
diff --git a/drivers/misc/intel/sepdk/sep/sys64.S b/drivers/misc/intel/sepdk/sep/sys64.S
new file mode 100644
index 000000000000..00eaadd58f06
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/sys64.S
@@ -0,0 +1,144 @@
+#     Copyright(C) 2002-2018 Intel Corporation.  All Rights Reserved.
+# 
+#     This file is part of SEP Development Kit
+# 
+#     SEP Development Kit is free software; you can redistribute it
+#     and/or modify it under the terms of the GNU General Public License
+#     version 2 as published by the Free Software Foundation.
+# 
+#     SEP Development Kit is distributed in the hope that it will be useful,
+#     but WITHOUT ANY WARRANTY; without even the implied warranty of
+#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+#     GNU General Public License for more details.
+# 
+#     You should have received a copy of the GNU General Public License
+#     along with SEP Development Kit; if not, write to the Free Software
+#     Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+# 
+#     As a special exception, you may use this file as part of a free software
+#     library without restriction.  Specifically, if other files instantiate
+#     templates or use macros or inline functions from this file, or you compile
+#     this file and link it with other files to produce an executable, this
+#     file does not by itself cause the resulting executable to be covered by
+#     the GNU General Public License.  This exception does not however
+#     invalidate any other reasons why the executable file might be covered by
+#     the GNU General Public License.
+
+#include "inc/asm_helper.h"
+#include <asm/msr.h>
+
+.text
+
+#***********************************************************************
+#
+#    SYS_Get_IDT_Base
+#            Get the IDT Desc address
+#
+#    Entry:  pointer to location to store idt Desc
+#
+#    Exit:  none 
+#
+# void SYS_Get_IDT_Base(U64 *pIdtDesc);
+#
+#***********************************************************************
+        .global SYS_Get_IDT_Base
+SYS_Get_IDT_Base:
+        SIDT (%rdi)
+        ret
+
+#***********************************************************************
+#
+#    SYS_Get_GDT_Base
+#            Get the GDT Desc address
+#
+#    Entry:  pointer to location to store gdt Desc
+#
+#    Exit:  none 
+#
+# void SYS_Get_GDT_Base(U64 *pGdtDesc);
+#
+#***********************************************************************
+        .global SYS_Get_GDT_Base
+SYS_Get_GDT_Base:
+        SGDT (%rdi)
+        ret
+
+#***********************************************************************
+#
+#    SYS_Get_TSC
+#            Get the current TSC
+#
+#    Entry:  pointer to location to store gdt Desc
+#
+#    Exit:  none 
+#
+# void SYS_Get_TSC(U64 *tsc);
+#
+#***********************************************************************
+#        .global SYS_Get_TSC
+#SYS_Get_TSC:
+#        rdtsc
+#        ret
+
+#***********************************************************************
+#
+#    SYS_IO_Delay
+#            Add a short delay to the instruction stream
+#
+#    Entry:  none
+#
+#    Exit:  none 
+#
+# void SYS_IO_Delay(void);
+#
+#***********************************************************************
+        .global SYS_IO_Delay
+SYS_IO_Delay:
+         ret
+
+# ----------------------------------------------------------------------------
+# name:         SYS_PerfVec_Handler
+#
+# description:  ISR entry for local APIC PERF interrupt vector
+#
+# Input:        n/a
+#
+# Output:       n/a 
+# ----------------------------------------------------------------------------
+
+        .global SYS_Perfvec_Handler
+SYS_Perfvec_Handler:
+	CFI_STARTPROC
+        pushq %rax          // fake an error code...
+        cld                 // cause the kernel likes it this way...
+
+        SAVE_ALL            // Save the world!
+
+        movl  $MSR_GS_BASE,%ecx     // for the moment, do the safe swapgs check
+        rdmsr
+        xorl  %ebx,%ebx             // assume no swapgs (ebx == 0)
+        testl %edx,%edx
+        js    1f
+        swapgs
+        movl  $1,%ebx               // ebx == 1 means we did a swapgs
+1:      movq %rsp,%rdi              // pt_regs is the first argument
+
+        //
+        // ebx is zero if no swap, one if swap
+        // ebx is preserved in C calling convention...
+        //
+        // NOTE: the C code is responsible for ACK'ing the APIC!!!
+        //
+        call PMI_Interrupt_Handler
+
+        //
+        // Don't want an interrupt while we are doing the swapgs stuff
+        //
+        cli
+        testl %ebx,%ebx
+        jz 2f
+        swapgs
+2:      RESTORE_ALL
+        popq    %rax
+        iretq
+        CFI_ENDPROC
diff --git a/drivers/misc/intel/sepdk/sep/sys_info.c b/drivers/misc/intel/sepdk/sep/sys_info.c
new file mode 100644
index 000000000000..276a83914087
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/sys_info.c
@@ -0,0 +1,1045 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/mm.h>
+#include <asm/apic.h>
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+#include "lwpmudrv.h"
+#include "control.h"
+#include "utility.h"
+#include "apic.h"
+#include "sys_info.h"
+
+#define VTSA_CPUID VTSA_CPUID_X86
+
+extern U64              total_ram;
+static IOCTL_SYS_INFO  *ioctl_sys_info      = NULL;
+static size_t           ioctl_sys_info_size = 0;
+static U32             *cpuid_entry_count   = NULL;
+static U32             *cpuid_total_count   = NULL;
+       U32             *cpu_built_sysinfo   = NULL;
+
+static U32             cpu_threads_per_core  = 1;
+
+#define VTSA_NA64       ((U64) -1)
+#define VTSA_NA32       ((U32) -1)
+#define VTSA_NA         ((U32) -1)
+
+#define SYS_INFO_NUM_SETS(rcx)             ((rcx) + 1)
+#define SYS_INFO_LINE_SIZE(rbx)            (((rbx) & 0xfff) + 1)
+#define SYS_INFO_LINE_PARTITIONS(rbx)      ((((rbx) >> 12) & 0x3ff) + 1)
+#define SYS_INFO_NUM_WAYS(rbx)             ((((rbx) >> 22) & 0x3ff) + 1)
+
+#define SYS_INFO_CACHE_SIZE(rcx,rbx) (SYS_INFO_NUM_SETS((rcx))        *    \
+                                      SYS_INFO_LINE_SIZE((rbx))       *    \
+                                      SYS_INFO_LINE_PARTITIONS((rbx)) *    \
+                                      SYS_INFO_NUM_WAYS((rbx)))
+
+#define MSR_FB_PCARD_ID_FUSE  0x17    // platform id fuses MSR
+
+#define LOW_PART(x)     (x & 0xFFFFFFFF)
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static U64 sys_info_nbits(number)
+ *
+ * @param number  - the number to check
+ * @return the number of bit.
+ *
+ * @brief  This routine gets the number of useful bits with the given number.
+ *         It will round the number up to power of 2, and adjust to 0 based number.
+ *         sys_info_nbits(0x3) = 2
+ *         sys_info_nbits(0x4) = 2
+ *
+ */
+static U64
+sys_info_nbits (
+    U64    number
+)
+{
+    U64 i;
+
+    SEP_DRV_LOG_TRACE_IN("Number: %llx.", number); // is %llu portable in the kernel?
+
+    if (number < 2) {
+        SEP_DRV_LOG_TRACE_OUT("Res: %u. (early exit)", (U32) number);
+        return number;
+    }
+
+    // adjust to 0 based number, and round up to power of 2
+    number--;
+    for (i = 0; number > 0; i++) {
+        number >>= 1;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", (U32) i);
+    return i;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static U64 sys_info_bitmask(nbits)
+ *
+ * @param number  - the number of bits
+ * @return  the bit mask for the nbits number
+ *
+ * @brief  This routine gets the bitmask for the nbits number.
+ */
+static U64
+sys_info_bitmask (
+    U64    nbits
+)
+{
+    U64 mask = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Nbits: %u.", (U32) nbits);
+
+    mask = (U64)(1<<nbits);
+    mask--;
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %llx.", mask);
+
+    return mask;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static void sys_info_Get_Num_Cpuid_Funcs(basic_funcs, basic_4_funcs, extended_funcs)
+ *
+ * @param basic_functions    - pointer to the number of basic functions
+ * @param basic_4_funcs      - pointer to the basic 4 functions
+ * @param extended_funcs     - pointer to the number of extended functions
+ * @return total number of cpuid functions
+ *
+ * @brief  This routine gets the number of basic and extended cpuid functions.
+ *
+ */
+static U32
+sys_info_Get_Num_Cpuid_Funcs (
+    OUT U32 *basic_funcs,
+    OUT U32 *basic_4_funcs,
+    OUT U32 *extended_funcs
+)
+{
+    U64 num_basic_funcs      = 0x0LL;
+    U64 num_basic_4_funcs    = 0x0LL;
+    U64 num_extended_funcs   = 0x0LL;
+    U64 rax;
+    U64 rbx;
+    U64 rcx;
+    U64 rdx;
+    U64 i;
+    U32 res;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    UTILITY_Read_Cpuid(0, &num_basic_funcs, &rbx, &rcx, &rdx);
+    UTILITY_Read_Cpuid(0x80000000, &num_extended_funcs, &rbx, &rcx, &rdx);
+
+    if (num_extended_funcs & 0x80000000) {
+        num_extended_funcs -= 0x80000000;
+    }
+
+    //
+    // make sure num_extended_funcs is not bogus
+    //
+    if (num_extended_funcs > 0x1000) {
+        num_extended_funcs = 0;
+    }
+
+    //
+    // if number of basic funcs is greater than 4, figure out how many
+    // time we should call CPUID with eax = 0x4.
+    //
+    num_basic_4_funcs = 0;
+    if (num_basic_funcs >= 4) {
+        for (i = 0, rax = (U64)-1; (rax & 0x1f) != 0; i++) {
+            rcx = i;
+            UTILITY_Read_Cpuid(4, &rax, &rbx, &rcx, &rdx);
+        }
+        num_basic_4_funcs = i - 1;
+    }
+    if (num_basic_funcs >= 0xb) {
+        i = 0;
+        do {
+            rcx = i;
+            UTILITY_Read_Cpuid(0xb, &rax, &rbx, &rcx, &rdx);
+            i++;
+        } while (!(LOW_PART(rax) == 0 && LOW_PART(rbx) == 0));
+        num_basic_4_funcs += i;
+    }
+    SEP_DRV_LOG_TRACE("Num_basic_4_funcs = %llx.", num_basic_4_funcs);
+
+    //
+    // adjust number to include 0 and 0x80000000 functions.
+    //
+    num_basic_funcs++;
+    num_extended_funcs++;
+
+    SEP_DRV_LOG_TRACE("num_basic_funcs: %llx, num_extended_funcs: %llx.", num_basic_funcs, num_extended_funcs);
+
+    //
+    // fill-in the parameter for the caller
+    //
+    if (basic_funcs != NULL) {
+        *basic_funcs = (U32) num_basic_funcs;
+    }
+    if (basic_4_funcs != NULL) {
+        *basic_4_funcs = (U32) num_basic_4_funcs;
+    }
+    if (extended_funcs != NULL) {
+        *extended_funcs = (U32) num_extended_funcs;
+    }
+
+    res = (U32) (num_basic_funcs + num_basic_4_funcs + num_extended_funcs);
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", res);
+    return res;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static void sys_info_Get_Cpuid_Entry_Cpunt(buffer)
+ *
+ * @param  buffer    - pointer to the buffer to hold the info
+ * @return None
+ *
+ * @brief  Service Routine to query the CPU for the number of entries needed
+ *
+ */
+static VOID
+sys_info_Get_Cpuid_Entry_Count (
+    PVOID    buffer
+)
+{
+    U32 current_processor;
+    U32 *current_cpu_buffer;
+
+    SEP_DRV_LOG_TRACE_IN("Buffer: %p.", buffer);
+
+    current_processor = CONTROL_THIS_CPU();
+    SEP_DRV_LOG_TRACE("Beginning on CPU %u.", current_processor);
+
+    current_cpu_buffer = (U32 *) ((U8 *) buffer + current_processor * sizeof(U32));
+
+#if defined(ALLOW_ASSERT)
+    ASSERT(((U8 *) current_cpu_buffer + sizeof(U32)) <=
+           ((U8 *) current_cpu_buffer + GLOBAL_STATE_num_cpus(driver_state) * sizeof(U32)));
+#endif
+    *current_cpu_buffer = sys_info_Get_Num_Cpuid_Funcs(NULL, NULL, NULL);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static U32 sys_info_Get_Cpuid_Buffer_Size(cpuid_entries)
+ *
+ * @param    cpuid_entries   - number of cpuid entries
+ * @return   size of buffer needed in bytes
+ *
+ * @brief  This routine returns number of bytes needed to hold the CPU_CS_INFO
+ * @brief  structure.
+ *
+ */
+static U32
+sys_info_Get_Cpuid_Buffer_Size (
+    U32 cpuid_entries
+)
+{
+    U32  cpuid_size;
+    U32  buffer_size;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    cpuid_size  = sizeof(VTSA_CPUID);
+
+    buffer_size = sizeof(IOCTL_SYS_INFO) +
+                  sizeof(VTSA_GEN_ARRAY_HDR) +
+                  sizeof(VTSA_NODE_INFO) +
+                  sizeof(VTSA_GEN_ARRAY_HDR) +
+                  GLOBAL_STATE_num_cpus(driver_state) * sizeof(VTSA_GEN_PER_CPU) +
+                  GLOBAL_STATE_num_cpus(driver_state) * sizeof(VTSA_GEN_ARRAY_HDR) +
+                  cpuid_entries * cpuid_size;
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", buffer_size);
+
+    return buffer_size;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern void sys_info_Fill_CPUID(...)
+ *
+ * @param        num_cpuids,
+ * @param        basic_funcs,
+ * @param        extended_funcs,
+ * @param        cpu,
+ * @param       *current_cpuid
+ * @param       *gen_per_cpu,
+ * @param       *local_gpc
+ *
+ * @return   None
+ *
+ * @brief  This routine is called to build per cpu information.
+ * @brief  Fills in the cpuid for the processor in the right location in the buffer
+ *
+ */
+static void
+sys_info_Fill_CPUID (
+    U32                  num_cpuids,
+    U32                  basic_funcs,
+    U32                  extended_funcs,
+    U32                  cpu,
+    VTSA_CPUID          *current_cpuid,
+    VTSA_GEN_PER_CPU    *gen_per_cpu,
+    VTSA_GEN_PER_CPU    *local_gpc
+)
+{
+    U32                  i, index, j;
+    U64                  cpuid_function;
+    U64                  rax, rbx, rcx, rdx;
+    VTSA_CPUID          *cpuid_el;
+    U32                  shift_nbits_core         = 0;
+    U32                  shift_nbits_pkg          = 0;
+    U32                  family                   = 0;
+    U32                  model                    = 0;
+    DRV_BOOL             ht_supported             = FALSE;
+    U32                  apic_id                  = 0;
+    U32                  num_logical_per_physical = 0;
+    U32                  cores_per_die            = 1;
+    U32                  thread_id                = 0;
+    U32                  core_id                  = 0;
+    U32                  package_id               = 0;
+    U32                  module_id                = 0;
+    U32                  cores_sharing_cache      = 0;
+    U32                  cache_mask_width         = 0;
+    U32                  num_cores                = 0;
+
+    SEP_DRV_LOG_TRACE_IN("CPU: %x.", cpu);
+
+    apic_id = CPU_STATE_apic_id(&pcb[cpu]);
+    SEP_DRV_LOG_TRACE("Cpu %x: apic_id = %d.", cpu, apic_id);
+
+    for (i = 0, index = 0; index < num_cpuids; i++) {
+        cpuid_function = (i < basic_funcs) ? i : (0x80000000 + i - basic_funcs);
+
+        if (cpuid_function == 0x4) {
+            for (j = 0, rax = (U64)-1; (rax & 0x1f) != 0; j++) {
+                rcx = j;
+                UTILITY_Read_Cpuid(cpuid_function, &rax, &rbx, &rcx, &rdx);
+                cpuid_el = &current_cpuid[index];
+                index++;
+
+#if defined(ALLOW_ASSERT)
+                ASSERT(((U8 *)cpuid_el + sizeof(VTSA_CPUID)) <= cpuid_buffer_limit);
+#endif
+
+                VTSA_CPUID_X86_cpuid_eax_input(cpuid_el) = (U32) cpuid_function;
+                VTSA_CPUID_X86_cpuid_eax(cpuid_el)       = (U32) rax;
+                VTSA_CPUID_X86_cpuid_ebx(cpuid_el)       = (U32) rbx;
+                VTSA_CPUID_X86_cpuid_ecx(cpuid_el)       = (U32) rcx;
+                VTSA_CPUID_X86_cpuid_edx(cpuid_el)       = (U32) rdx;
+                SEP_DRV_LOG_TRACE("Function: %x.", (U32)cpuid_function);
+                SEP_DRV_LOG_TRACE("rax: %x, rbx: %x, rcx: %x, rdx: %x.",
+                                (U32)rax, (U32)rbx, (U32)rcx, (U32)rdx);
+
+                if ((rax & 0x1f) != 0) {
+                    local_gpc = &gen_per_cpu[cpu];
+                    if (((rax >> 5) & 0x3) == 2) {
+                        VTSA_GEN_PER_CPU_cpu_cache_L2(local_gpc) =
+                                   (U32)(SYS_INFO_CACHE_SIZE(rcx,rbx) >> 10);
+                        SEP_DRV_LOG_TRACE("L2 Cache: %x.", VTSA_GEN_PER_CPU_cpu_cache_L2(local_gpc));
+                        cores_sharing_cache = ((U16)(rax >> 14) & 0xfff) + 1;
+                        SEP_DRV_LOG_TRACE("CORES_SHARING_CACHE=%d j=%d cpu=%d.", cores_sharing_cache, j, cpu);
+                    }
+
+                    if (((rax >> 5) & 0x3) == 3) {
+                        VTSA_GEN_PER_CPU_cpu_cache_L3(local_gpc) =
+                                    (U32)(SYS_INFO_CACHE_SIZE(rcx,rbx) >> 10);
+                        SEP_DRV_LOG_TRACE("L3 Cache: %x.", VTSA_GEN_PER_CPU_cpu_cache_L3(local_gpc));
+                    }
+                }
+                if (j == 0) {
+                    cores_per_die = ((U16)(rax >> 26) & 0x3f) + 1;
+                }
+            }
+            if (cores_sharing_cache != 0) {
+                cache_mask_width = (U32)sys_info_nbits(cores_sharing_cache);
+                SEP_DRV_LOG_TRACE("CACHE MASK WIDTH=%x.", cache_mask_width);
+            }
+        }
+        else if (cpuid_function == 0xb) {
+            j = 0;
+            do {
+                rcx = j;
+                UTILITY_Read_Cpuid(cpuid_function, &rax, &rbx, &rcx, &rdx);
+                cpuid_el = &current_cpuid[index];
+                index++;
+
+#if defined(ALLOW_ASSERT)
+                ASSERT(((U8 *)cpuid_el + sizeof(VTSA_CPUID_X86)) <= cpuid_buffer_limit);
+#endif
+
+                VTSA_CPUID_X86_cpuid_eax_input(cpuid_el) = (U32) cpuid_function;
+                VTSA_CPUID_X86_cpuid_eax(cpuid_el)       = (U32) rax;
+                VTSA_CPUID_X86_cpuid_ebx(cpuid_el)       = (U32) rbx;
+                VTSA_CPUID_X86_cpuid_ecx(cpuid_el)       = (U32) rcx;
+                VTSA_CPUID_X86_cpuid_edx(cpuid_el)       = (U32) rdx;
+                SEP_DRV_LOG_TRACE("Function: %x.", (U32)cpuid_function);
+                SEP_DRV_LOG_TRACE("rax: %x, rbx: %x, rcx: %x, rdx: %x.",
+                                (U32)rax, (U32)rbx, (U32)rcx, (U32)rdx);
+                if (j == 0) {
+                    shift_nbits_core = rax & 0x1f;   //No. of bits to shift APIC ID to get Core ID
+                }
+                if (j == 1) {
+                    shift_nbits_pkg  = rax & 0x1f;    //No. of bits to shift APIC ID to get Pkg ID
+                }
+                j++;
+            } while (!(LOW_PART(rax) == 0 && LOW_PART(rbx) == 0));
+        }
+        else {
+            UTILITY_Read_Cpuid(cpuid_function, &rax, &rbx, &rcx, &rdx);
+            cpuid_el = &current_cpuid[index];
+            index++;
+
+            SEP_DRV_LOG_TRACE("Cpu %x: num_cpuids = %x i = %x index = %x.",
+                            cpu, num_cpuids, i, index);
+
+#if defined(ALLOW_ASSERT)
+            ASSERT(((U8 *)cpuid_el + sizeof(VTSA_CPUID_X86)) <= cpuid_buffer_limit);
+
+            ASSERT(((U8 *)cpuid_el + sizeof(VTSA_CPUID_X86)) <=
+                   ((U8 *)current_cpuid + (num_cpuids * sizeof(VTSA_CPUID_X86))));
+#endif
+
+            VTSA_CPUID_X86_cpuid_eax_input(cpuid_el) = (U32) cpuid_function;
+            VTSA_CPUID_X86_cpuid_eax(cpuid_el)       = (U32) rax;
+            VTSA_CPUID_X86_cpuid_ebx(cpuid_el)       = (U32) rbx;
+            VTSA_CPUID_X86_cpuid_ecx(cpuid_el)       = (U32) rcx;
+            VTSA_CPUID_X86_cpuid_edx(cpuid_el)       = (U32) rdx;
+            SEP_DRV_LOG_TRACE("Function: %x.", (U32)cpuid_function);
+            SEP_DRV_LOG_TRACE("rax: %x, rbx: %x, rcx: %x, rdx: %x.",
+                            (U32)rax, (U32)rbx, (U32)rcx, (U32)rdx);
+
+            if (cpuid_function == 0) {
+                if ((U32)rbx == 0x756e6547  &&
+                    (U32)rcx == 0x6c65746e  &&
+                    (U32)rdx == 0x49656e69) {
+                    VTSA_GEN_PER_CPU_platform_id(local_gpc) = SYS_Read_MSR(MSR_FB_PCARD_ID_FUSE);
+                }
+            }
+            else if (cpuid_function == 1) {
+                family    = (U32)(rax >>  8 & 0x0f);
+                model     = (U32)(rax >> 12 & 0xf0);  /* extended model bits */
+                model    |= (U32)(rax >>  4 & 0x0f);
+                ht_supported             = (rdx >> 28) & 1 ? TRUE : FALSE;
+                num_logical_per_physical = (U32)((rbx & 0xff0000) >> 16);
+                if (num_logical_per_physical == 0) {
+                    num_logical_per_physical = 1;
+                }
+            }
+            else if (cpuid_function == 0xa) {
+                VTSA_GEN_PER_CPU_arch_perfmon_ver(local_gpc) = (U32)(rax & 0xFF);
+                VTSA_GEN_PER_CPU_num_gp_counters(local_gpc) = (U32)((rax>>8) & 0xFF);
+                VTSA_GEN_PER_CPU_num_fixed_counters(local_gpc) = (U32)(rdx & 0x1F);
+            }
+        }
+    }
+
+    // set cpu_cache_L2 if not already set using 0x80000006 function
+    if (gen_per_cpu[cpu].cpu_cache_L2 == VTSA_NA && extended_funcs >= 6) {
+
+        UTILITY_Read_Cpuid(0x80000006, &rax, &rbx, &rcx, &rdx);
+        VTSA_GEN_PER_CPU_cpu_cache_L2(local_gpc) = (U32)(rcx >> 16);
+    }
+
+    if (!ht_supported || num_logical_per_physical == cores_per_die) {
+        threads_per_core = 1;
+        thread_id        = 0;
+    }
+    else {
+        // each core has 4 threads for MIC system, otherwise, it has 2 threads when ht is enabled
+        threads_per_core = cpu_threads_per_core;
+        thread_id        = (U16)(apic_id & (cpu_threads_per_core-1));
+    }
+
+    core_id    = (apic_id >> shift_nbits_core) & sys_info_bitmask(shift_nbits_pkg - shift_nbits_core);
+    package_id = apic_id >> shift_nbits_pkg;
+
+    if (cache_mask_width) {
+        module_id = (U32)(core_id/2);
+    }
+    SEP_DRV_LOG_TRACE("MODULE ID=%d CORE ID=%d for cpu=%d PACKAGE ID=%d.", module_id, core_id, cpu, package_id);
+    SEP_DRV_LOG_TRACE("Num_logical_per_physical=%d cores_per_die=%d.", num_logical_per_physical, cores_per_die);
+    SEP_DRV_LOG_TRACE("Package_id %d, apic_id %x.", package_id, apic_id);
+    SEP_DRV_LOG_TRACE("Sys_info_nbits[cores_per_die,threads_per_core]: [%lld,%lld].", sys_info_nbits(cores_per_die), sys_info_nbits(threads_per_core));
+
+    VTSA_GEN_PER_CPU_cpu_intel_processor_number(local_gpc) = VTSA_NA32;
+    VTSA_GEN_PER_CPU_cpu_package_num(local_gpc)            = (U16)package_id;
+    VTSA_GEN_PER_CPU_cpu_core_num(local_gpc)               = (U16)core_id;
+    VTSA_GEN_PER_CPU_cpu_hw_thread_num(local_gpc)          = (U16)thread_id;
+    VTSA_GEN_PER_CPU_cpu_threads_per_core(local_gpc)       = (U16)threads_per_core;
+    VTSA_GEN_PER_CPU_cpu_module_num(local_gpc)             = (U16)module_id;
+    num_cores                                              = GLOBAL_STATE_num_cpus(driver_state)/threads_per_core;
+    VTSA_GEN_PER_CPU_cpu_num_modules(local_gpc)            = (U16)(num_cores/2);  // Relavent to Atom processors, Always 2
+    VTSA_GEN_PER_CPU_cpu_core_type(local_gpc)              = 0;
+    GLOBAL_STATE_num_modules(driver_state)                 = VTSA_GEN_PER_CPU_cpu_num_modules(local_gpc);
+    SEP_DRV_LOG_TRACE("MODULE COUNT=%d.", GLOBAL_STATE_num_modules(driver_state));
+
+    core_to_package_map[cpu]   = package_id;
+    core_to_phys_core_map[cpu] = core_id;
+    core_to_thread_map[cpu]    = thread_id;
+    occupied_core_ids[core_id] = 1;
+
+    if (num_packages < package_id + 1) {
+        num_packages = package_id + 1;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+* @fn static void sys_info_Update_Hyperthreading_Info(buffer)
+*
+* @param    buffer  -  points to the base of GEN_PER_CPU structure
+* @return   None
+*
+* @brief  This routine is called to update per cpu information based on HT ON/OFF.
+*
+*/
+static VOID
+sys_info_Update_Hyperthreading_Info (
+    VOID    *buffer
+)
+{
+    U16                 threads_per_core;
+    U32                 cpu;
+    VTSA_GEN_PER_CPU    *gen_per_cpu, *local_gpc;
+    U32                 i = 0;
+    U32                 num_cores = 0;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    cpu        = CONTROL_THIS_CPU();
+
+    // get the GEN_PER_CPU entry for the current processor.
+    gen_per_cpu = (VTSA_GEN_PER_CPU*) buffer;
+
+    // Update GEN_PER_CPU
+    local_gpc                                   = &(gen_per_cpu[cpu]);
+
+    while (i < (U32)GLOBAL_STATE_num_cpus(driver_state)) {
+        if (cpu_built_sysinfo[i] == 1) {
+            i++;
+        }
+    }
+
+    for (i = 0; i < (U32)GLOBAL_STATE_num_cpus(driver_state); i++) {
+        if (occupied_core_ids[i] == 1) {
+            num_cores++;
+        }
+    }
+    threads_per_core = (U16)(GLOBAL_STATE_num_cpus(driver_state)/(num_cores*num_packages));
+    if (VTSA_GEN_PER_CPU_cpu_threads_per_core(local_gpc) != threads_per_core) {
+        VTSA_GEN_PER_CPU_cpu_threads_per_core(local_gpc)       = threads_per_core;
+        VTSA_GEN_PER_CPU_cpu_num_modules(local_gpc)            = (U16)(num_cores/2);
+        GLOBAL_STATE_num_modules(driver_state)                 = VTSA_GEN_PER_CPU_cpu_num_modules(local_gpc);
+    }
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static void sys_info_Build_Percpu(buffer)
+ *
+ * @param    buffer  -  points to the base of GEN_PER_CPU structure
+ * @return   None
+ *
+ * @brief  This routine is called to build per cpu information.
+ *
+ */
+static VOID
+sys_info_Build_Percpu (
+    VOID    *buffer
+)
+{
+    U32                  basic_funcs, basic_4_funcs, extended_funcs;
+    U32                  num_cpuids;
+    U32                  cpu;
+    VTSA_CPUID          *current_cpuid;
+    VTSA_GEN_ARRAY_HDR  *cpuid_gen_array_hdr;
+    VTSA_GEN_PER_CPU    *gen_per_cpu, *local_gpc;
+    VTSA_FIXED_SIZE_PTR *fsp;
+    U8                  *cpuid_gen_array_hdr_base;
+#if defined(ALLOW_ASSERT)
+    U8                  *cpuid_buffer_limit;
+#endif
+
+    SEP_DRV_LOG_TRACE_IN("Buffer: %p.", buffer);
+
+    cpu        = CONTROL_THIS_CPU();
+    num_cpuids = (U32) sys_info_Get_Num_Cpuid_Funcs(&basic_funcs,
+                                                    &basic_4_funcs,
+                                                    &extended_funcs);
+
+    // get the GEN_PER_CPU entry for the current processor.
+    gen_per_cpu = (VTSA_GEN_PER_CPU*) buffer;
+    SEP_DRV_LOG_TRACE("cpu %x: gen_per_cpu = %p.", cpu, gen_per_cpu);
+
+    // get GEN_ARRAY_HDR and cpuid array base
+    cpuid_gen_array_hdr_base = (U8 *) gen_per_cpu +
+                               GLOBAL_STATE_num_cpus(driver_state) * sizeof(VTSA_GEN_PER_CPU);
+
+    SEP_DRV_LOG_TRACE("cpuid_gen_array_hdr_base = %p.", cpuid_gen_array_hdr_base);
+    SEP_DRV_LOG_TRACE("cpu = %x.", cpu);
+    SEP_DRV_LOG_TRACE("cpuid_total_count[cpu] = %x.", cpuid_total_count[cpu]);
+    SEP_DRV_LOG_TRACE("sizeof(VTSA_CPUID) = %lx.", sizeof(VTSA_CPUID));
+
+    cpuid_gen_array_hdr = (VTSA_GEN_ARRAY_HDR *) ((U8 *) cpuid_gen_array_hdr_base  +
+                                                  sizeof(VTSA_GEN_ARRAY_HDR) * cpu +
+                                                  cpuid_total_count[cpu] * sizeof(VTSA_CPUID));
+
+    // get current cpuid array base.
+    current_cpuid = (VTSA_CPUID *) ((U8 *) cpuid_gen_array_hdr + sizeof(VTSA_GEN_ARRAY_HDR));
+#if defined(ALLOW_ASSERT)
+    // get the absolute buffer limit
+    cpuid_buffer_limit = (U8 *)ioctl_sys_info +
+                              GENERIC_IOCTL_size(&IOCTL_SYS_INFO_gen(ioctl_sys_info));
+#endif
+
+    //
+    // Fill in GEN_PER_CPU
+    //
+    local_gpc                                   = &(gen_per_cpu[cpu]);
+
+    if (VTSA_GEN_PER_CPU_cpu_intel_processor_number(local_gpc)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (VTSA_GEN_PER_CPU_cpu_intel_processor_number).");
+        return;
+    }
+    VTSA_GEN_PER_CPU_cpu_number(local_gpc)      = cpu;
+    VTSA_GEN_PER_CPU_cpu_speed_mhz(local_gpc)   = VTSA_NA32;
+    VTSA_GEN_PER_CPU_cpu_fsb_mhz(local_gpc)     = VTSA_NA32;
+
+    fsp                                        = &VTSA_GEN_PER_CPU_cpu_cpuid_array(local_gpc);
+    VTSA_FIXED_SIZE_PTR_is_ptr(fsp)            = 0;
+    VTSA_FIXED_SIZE_PTR_fs_offset(fsp)         = (U64) ((U8 *)cpuid_gen_array_hdr -
+                                                 (U8 *)&IOCTL_SYS_INFO_sys_info(ioctl_sys_info));
+
+    /*
+     * Get the time stamp difference between this cpu and cpu 0.
+     * This value will be used by user mode code to generate standardize
+     * time needed for sampling over time (SOT) functionality.
+     */
+    VTSA_GEN_PER_CPU_cpu_tsc_offset(local_gpc)  =  TSC_SKEW(cpu);
+
+
+    //
+    // fill GEN_ARRAY_HDR
+    //
+    fsp  = &VTSA_GEN_ARRAY_HDR_hdr_next_gen_hdr(cpuid_gen_array_hdr);
+    VTSA_GEN_ARRAY_HDR_hdr_size(cpuid_gen_array_hdr)          = sizeof(VTSA_GEN_ARRAY_HDR);
+    VTSA_FIXED_SIZE_PTR_is_ptr(fsp)                           = 0;
+    VTSA_FIXED_SIZE_PTR_fs_offset(fsp)                        = 0;
+    VTSA_GEN_ARRAY_HDR_array_num_entries(cpuid_gen_array_hdr) = num_cpuids;
+    VTSA_GEN_ARRAY_HDR_array_entry_size(cpuid_gen_array_hdr)  = sizeof(VTSA_CPUID);
+    VTSA_GEN_ARRAY_HDR_array_type(cpuid_gen_array_hdr)        = GT_CPUID;
+#if defined(DRV_IA32)
+    VTSA_GEN_ARRAY_HDR_array_subtype(cpuid_gen_array_hdr)     = GST_X86;
+#elif defined(DRV_EM64T)
+    VTSA_GEN_ARRAY_HDR_array_subtype(cpuid_gen_array_hdr)     = GST_EM64T;
+#endif
+
+    //
+    // fill out cpu id information
+    //
+    sys_info_Fill_CPUID (num_cpuids,
+                         basic_funcs,
+                         extended_funcs,
+                         cpu,
+                         current_cpuid,
+                         gen_per_cpu,
+                         local_gpc);
+    /*
+     *  Mark cpu info on this cpu as successfully built
+     */
+    cpu_built_sysinfo[cpu] = 1;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static void sys_info_Get_Processor_Info(NULL)
+ *
+ * @param    None
+ * @return   None
+ *
+ * @brief  This routine is called to get global informaton on the processor in general,
+ *         it include:
+ *             cpu_thread_per_core
+ *
+ */
+static VOID
+sys_info_Get_Processor_Info (
+    VOID    *param
+)
+{
+    U64          rax;
+    U64          rbx;
+    U64          rcx;
+    U64          rdx;
+    U32          family;
+    U32          model;
+    DRV_BOOL     ht_supported             = FALSE;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    // read cpuid with function 1 to find family/model
+    UTILITY_Read_Cpuid(1, &rax, &rbx, &rcx, &rdx);
+    family    = (U32)(rax >>  8 & 0x0f);
+    model     = (U32)(rax >> 12 & 0xf0);  /* extended model bits */
+    model    |= (U32)(rax >>  4 & 0x0f);
+    if (is_Knights_family(family, model)) {
+        cpu_threads_per_core = 4;
+    }
+    else {
+        ht_supported  = (rdx >> 28) & 1 ? TRUE : FALSE;
+        if  (ht_supported) {
+            cpu_threads_per_core = 2;
+        }
+        else {
+            cpu_threads_per_core = 1;
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern void SYS_Info_Build(void)
+ *
+ * @param    None
+ * @return   None
+ *
+ * @brief  This is the driver routine that constructs the VTSA_SYS_INFO
+ * @brief  structure used to report system information into the tb5 file
+ *
+ */
+extern U32
+SYS_INFO_Build (
+    VOID
+)
+{
+    VTSA_GEN_ARRAY_HDR  *gen_array_hdr;
+    VTSA_NODE_INFO      *node_info;
+    VTSA_SYS_INFO       *sys_info;
+    VTSA_FIXED_SIZE_PTR *fsp;
+    U8                  *gen_per_cpu;
+    U32                  buffer_size;
+    U32                  total_cpuid_entries;
+    S32                  i;
+    struct sysinfo       k_sysinfo;
+    int                  me;
+    U32                  res;
+
+    SEP_DRV_LOG_TRACE_IN("");
+    SEP_DRV_LOG_TRACE("Entered.");
+
+    if (ioctl_sys_info) {
+        /* The sys info has already been computed.  Do not redo */
+        buffer_size = GENERIC_IOCTL_size(&IOCTL_SYS_INFO_gen(ioctl_sys_info));
+        return buffer_size - sizeof(GENERIC_IOCTL);
+    }
+
+    si_meminfo(&k_sysinfo);
+
+    buffer_size = GLOBAL_STATE_num_cpus(driver_state) * sizeof(U32);
+    cpu_built_sysinfo = CONTROL_Allocate_Memory(buffer_size);
+    if (cpu_built_sysinfo == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Cpu_built_sysinfo memory alloc failed!");
+        return 0;
+    }
+
+    cpuid_entry_count = CONTROL_Allocate_Memory(buffer_size);
+    if (cpuid_entry_count == NULL) {
+        cpu_built_sysinfo = CONTROL_Free_Memory(cpu_built_sysinfo);
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Memory alloc failed for cpuid_entry_count!");
+        return 0;
+    }
+
+    cpuid_total_count = CONTROL_Allocate_Memory(buffer_size);
+    if (cpuid_total_count == NULL) {
+        cpu_built_sysinfo = CONTROL_Free_Memory(cpu_built_sysinfo);
+        cpuid_entry_count = CONTROL_Free_Memory(cpuid_entry_count);
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Memory alloc failed for cpuid_total_count!");
+        return 0;
+    }
+
+    // checking on family-model to set threads_per_core as 4: MIC,  2: ht-on; 1: rest
+    sys_info_Get_Processor_Info(NULL);
+    CONTROL_Invoke_Parallel(sys_info_Get_Cpuid_Entry_Count, (VOID *)cpuid_entry_count);
+    total_cpuid_entries = 0;
+    for(i = 0; i < GLOBAL_STATE_num_cpus(driver_state); i++) {
+         //if cpu is offline, set its cpuid count same as cpu0
+         if (cpuid_entry_count[i] == 0) {
+             cpuid_entry_count[i] = cpuid_entry_count[0];
+             cpu_built_sysinfo[i] = 0;
+         }
+         cpuid_total_count[i]  = total_cpuid_entries;
+         total_cpuid_entries  += cpuid_entry_count[i];
+    }
+
+    ioctl_sys_info_size = sys_info_Get_Cpuid_Buffer_Size(total_cpuid_entries);
+    ioctl_sys_info      = CONTROL_Allocate_Memory(ioctl_sys_info_size);
+    if (ioctl_sys_info == NULL) {
+        cpuid_entry_count = CONTROL_Free_Memory(cpuid_entry_count);
+        cpuid_total_count = CONTROL_Free_Memory(cpuid_total_count);
+
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Memory alloc failed for ioctl_sys_info!");
+//        return STATUS_INSUFFICIENT_RESOURCES;
+        return 0;
+    }
+
+    //
+    // fill in ioctl and cpu_cs_info fields.
+    //
+    GENERIC_IOCTL_size(&IOCTL_SYS_INFO_gen(ioctl_sys_info)) = ioctl_sys_info_size;
+    GENERIC_IOCTL_ret(&IOCTL_SYS_INFO_gen(ioctl_sys_info))  = VT_SUCCESS;
+
+    sys_info = &IOCTL_SYS_INFO_sys_info(ioctl_sys_info);
+    VTSA_SYS_INFO_min_app_address(sys_info)        = VTSA_NA64;
+    VTSA_SYS_INFO_max_app_address(sys_info)        = VTSA_NA64;
+    VTSA_SYS_INFO_page_size(sys_info)              = k_sysinfo.mem_unit;
+    VTSA_SYS_INFO_allocation_granularity(sys_info) = k_sysinfo.mem_unit;
+
+    //
+    // offset from ioctl_sys_info
+    //
+    VTSA_FIXED_SIZE_PTR_is_ptr(&VTSA_SYS_INFO_node_array(sys_info))    = 0;
+    VTSA_FIXED_SIZE_PTR_fs_offset(&VTSA_SYS_INFO_node_array(sys_info)) = sizeof(VTSA_SYS_INFO);
+
+    //
+    // fill in node_info array header
+    //
+    gen_array_hdr = (VTSA_GEN_ARRAY_HDR *) ((U8 *) sys_info +
+                     VTSA_FIXED_SIZE_PTR_fs_offset(&VTSA_SYS_INFO_node_array(sys_info)));
+
+    SEP_DRV_LOG_TRACE("Gen_array_hdr = %p.", gen_array_hdr);
+    fsp = &VTSA_GEN_ARRAY_HDR_hdr_next_gen_hdr(gen_array_hdr);
+    VTSA_FIXED_SIZE_PTR_is_ptr(fsp)                     = 0;
+    VTSA_FIXED_SIZE_PTR_fs_offset(fsp)                  = 0;
+
+    VTSA_GEN_ARRAY_HDR_hdr_size(gen_array_hdr)          = sizeof(VTSA_GEN_ARRAY_HDR);
+    VTSA_GEN_ARRAY_HDR_array_num_entries(gen_array_hdr) = 1;
+    VTSA_GEN_ARRAY_HDR_array_entry_size(gen_array_hdr)  = sizeof(VTSA_NODE_INFO);
+    VTSA_GEN_ARRAY_HDR_array_type(gen_array_hdr)        = GT_NODE;
+    VTSA_GEN_ARRAY_HDR_array_subtype(gen_array_hdr)     = GST_UNK;
+
+    //
+    // fill in node_info
+    //
+    node_info = (VTSA_NODE_INFO *) ((U8 *) gen_array_hdr + sizeof(VTSA_GEN_ARRAY_HDR));
+    SEP_DRV_LOG_TRACE("Node_info = %p.", node_info);
+
+    VTSA_NODE_INFO_node_type_from_shell(node_info) = VTSA_NA32;
+
+    VTSA_NODE_INFO_node_id(node_info)              = VTSA_NA32;
+    VTSA_NODE_INFO_node_num_available(node_info)   = GLOBAL_STATE_num_cpus(driver_state);
+    VTSA_NODE_INFO_node_num_used(node_info)        = VTSA_NA32;
+    total_ram                                      = k_sysinfo.totalram << PAGE_SHIFT;
+    VTSA_NODE_INFO_node_physical_memory(node_info) = total_ram;
+
+    fsp = &VTSA_NODE_INFO_node_percpu_array(node_info);
+    VTSA_FIXED_SIZE_PTR_is_ptr(fsp)      = 0;
+    VTSA_FIXED_SIZE_PTR_fs_offset(fsp)   = sizeof(VTSA_SYS_INFO)      +
+                                           sizeof(VTSA_GEN_ARRAY_HDR) +
+                                           sizeof(VTSA_NODE_INFO);
+    //
+    // fill in gen_per_cpu array header
+    //
+    gen_array_hdr = (VTSA_GEN_ARRAY_HDR *) ((U8 *) sys_info + VTSA_FIXED_SIZE_PTR_fs_offset(fsp));
+    SEP_DRV_LOG_TRACE("Gen_array_hdr = %p.", gen_array_hdr);
+
+    fsp = &VTSA_GEN_ARRAY_HDR_hdr_next_gen_hdr(gen_array_hdr);
+    VTSA_FIXED_SIZE_PTR_is_ptr(fsp)                     = 0;
+    VTSA_FIXED_SIZE_PTR_fs_offset(fsp)                  = 0;
+
+    VTSA_GEN_ARRAY_HDR_hdr_size(gen_array_hdr)          = sizeof(VTSA_GEN_ARRAY_HDR);
+    VTSA_GEN_ARRAY_HDR_array_num_entries(gen_array_hdr) = GLOBAL_STATE_num_cpus(driver_state);
+    VTSA_GEN_ARRAY_HDR_array_entry_size(gen_array_hdr)  = sizeof(VTSA_GEN_PER_CPU);
+    VTSA_GEN_ARRAY_HDR_array_type(gen_array_hdr)        = GT_PER_CPU;
+
+#if defined(DRV_IA32)
+    VTSA_GEN_ARRAY_HDR_array_subtype(gen_array_hdr)     = GST_X86;
+#elif defined(DRV_EM64T)
+    VTSA_GEN_ARRAY_HDR_array_subtype(gen_array_hdr)     = GST_EM64T;
+#endif
+
+    gen_per_cpu = (U8 *) gen_array_hdr + sizeof(VTSA_GEN_ARRAY_HDR);
+
+    me     = 0;
+    CONTROL_Invoke_Parallel(APIC_Init, NULL);
+    CONTROL_Invoke_Parallel(sys_info_Build_Percpu, (VOID *)gen_per_cpu);
+    CONTROL_Invoke_Parallel(sys_info_Update_Hyperthreading_Info, (VOID *)gen_per_cpu);
+
+    /*
+     * Cleanup - deallocate memory that is no longer needed
+     */
+    cpuid_entry_count = CONTROL_Free_Memory(cpuid_entry_count);
+
+    res = ioctl_sys_info_size - sizeof(GENERIC_IOCTL);
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", res);
+    return res;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern void SYS_Info_Transfer(buf_usr_to_drv, len_usr_to_drv)
+ *
+ * @param  buf_usr_to_drv      - pointer to the buffer to write the data into
+ * @param  len_usr_to_drv  - length of the buffer passed in
+ *
+ * @brief  Transfer the data collected via the SYS_INFO_Build routine
+ * @brief  back to the caller.
+ *
+ */
+extern VOID
+SYS_INFO_Transfer (
+    PVOID           buf_usr_to_drv,
+    unsigned long   len_usr_to_drv
+)
+{
+    unsigned long exp_size;
+    ssize_t       unused;
+
+    SEP_DRV_LOG_TRACE_IN("Buffer: %p, buffer_len: %u.", buf_usr_to_drv, (U32) len_usr_to_drv);
+
+    if (ioctl_sys_info == NULL || len_usr_to_drv == 0) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Ioctl_sys_info is NULL or len_usr_to_drv is 0!");
+        return;
+    }
+    exp_size = GENERIC_IOCTL_size(&IOCTL_SYS_INFO_gen(ioctl_sys_info)) - sizeof(GENERIC_IOCTL);
+    if (len_usr_to_drv < exp_size) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Insufficient Space!");
+        return;
+    }
+    unused = copy_to_user(buf_usr_to_drv, &(IOCTL_SYS_INFO_sys_info(ioctl_sys_info)), len_usr_to_drv);
+    if (unused) {
+    // no-op ... eliminates "variable not used" compiler warning
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern void SYS_Info_Destroy(void)
+ *
+ * @param    None
+ * @return   None
+ *
+ * @brief  Free any memory associated with the sys info before unloading the driver
+ *
+ */
+extern VOID
+SYS_INFO_Destroy (
+    void
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    cpuid_total_count   = CONTROL_Free_Memory(cpuid_total_count);
+    cpu_built_sysinfo   = CONTROL_Free_Memory(cpu_built_sysinfo);
+    ioctl_sys_info      = CONTROL_Free_Memory(ioctl_sys_info);
+    ioctl_sys_info_size = 0;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern void SYS_INFO_Build_Cpu(PVOID param)
+ *
+ * @param    PVOID param
+ * @return   None
+ *
+ * @brief  call routine to populate cpu info
+ *
+ */
+extern VOID
+SYS_INFO_Build_Cpu(
+    PVOID param
+)
+{
+    VTSA_GEN_ARRAY_HDR  *gen_array_hdr;
+    VTSA_NODE_INFO      *node_info;
+    VTSA_SYS_INFO       *sys_info;
+    VTSA_FIXED_SIZE_PTR *fsp;
+    U8                  *gen_per_cpu;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (!ioctl_sys_info) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Ioctl_sys_info is null!");
+        return;
+    }
+    sys_info = &IOCTL_SYS_INFO_sys_info(ioctl_sys_info);
+    gen_array_hdr = (VTSA_GEN_ARRAY_HDR *) ((U8 *) sys_info +
+                     VTSA_FIXED_SIZE_PTR_fs_offset(&VTSA_SYS_INFO_node_array(sys_info)));
+    SEP_DRV_LOG_TRACE("Gen_array_hdr = %p.", gen_array_hdr);
+
+    node_info = (VTSA_NODE_INFO *) ((U8 *) gen_array_hdr + sizeof(VTSA_GEN_ARRAY_HDR));
+    SEP_DRV_LOG_TRACE("Node_info = %p.", node_info);
+    fsp = &VTSA_NODE_INFO_node_percpu_array(node_info);
+
+    gen_array_hdr = (VTSA_GEN_ARRAY_HDR *) ((U8 *) sys_info + VTSA_FIXED_SIZE_PTR_fs_offset(fsp));
+    SEP_DRV_LOG_TRACE("Gen_array_hdr = %p.", gen_array_hdr);
+    gen_per_cpu = (U8 *) gen_array_hdr + sizeof(VTSA_GEN_ARRAY_HDR);
+
+    sys_info_Build_Percpu((VOID *)gen_per_cpu);
+    sys_info_Update_Hyperthreading_Info((VOID *)gen_per_cpu);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
diff --git a/drivers/misc/intel/sepdk/sep/unc_common.c b/drivers/misc/intel/sepdk/sep/unc_common.c
new file mode 100644
index 000000000000..7efad105ac9d
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/unc_common.c
@@ -0,0 +1,364 @@
+/****
+    Copyright(C) 2012-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit.
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+
+
+
+
+#include "lwpmudrv_defines.h"
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+#include "inc/ecb_iterators.h"
+#include "inc/control.h"
+#include "inc/pci.h"
+#include "inc/unc_common.h"
+#include "inc/utility.h"
+
+extern UNCORE_TOPOLOGY_INFO_NODE        uncore_topology;
+extern PLATFORM_TOPOLOGY_PROG_NODE      platform_topology_prog_node;
+extern U64                             *read_counter_info;
+
+
+/* this is the table to keep pci_bus structure for PCI devices
+ * for both pci config access and mmio access
+ */
+UNC_PCIDEV_NODE  unc_pcidev_map[MAX_DEVICES];
+
+#define GET_PACKAGE_NUM(device_type, cpu)         (((device_type) == DRV_SINGLE_INSTANCE)? 0 : core_to_package_map[cpu])
+
+/************************************************************/
+/*
+ * unc common Dispatch functions
+ *
+ ************************************************************/
+extern  void
+UNC_COMMON_Dummy_Func (
+    PVOID  param
+)
+{
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+    SEP_DRV_LOG_TRACE_OUT("Empty function.");
+    return;
+}
+
+/************************************************************/
+/*
+ * UNC common PCI  based API
+ *
+ ************************************************************/
+
+/*!
+ * @fn          OS_STATUS UNC_COMMON_Add_Bus_Map
+ *
+ * @brief       This code discovers which package's data is read off of which bus.
+ *
+ * @param       None
+ *
+ * @return      OS_STATUS
+ *
+ * <I>Special Notes:</I>
+ *     This probably will move to the UBOX once that is programmed.
+ */
+OS_STATUS
+UNC_COMMON_Add_Bus_Map (
+    U32     uncore_did,
+    U32     dev_node,
+    U32     bus_no
+)
+{
+    U32             i            = 0;
+    U32             entries      = 0;
+
+    if  (!UNC_PCIDEV_busno_list(&(unc_pcidev_map[dev_node]))) {
+        // allocate array for holding bus mapping
+        // package based device: an entry per package, all units in the same package are in the same bus.
+        // system based device:  an entry per unit if in different bus
+        entries = GET_MAX_PCIDEV_ENTRIES(num_packages);
+        UNC_PCIDEV_busno_list(&(unc_pcidev_map[dev_node])) = CONTROL_Allocate_Memory(entries * sizeof(S32));
+        if (UNC_PCIDEV_busno_list(&(unc_pcidev_map[dev_node])) == NULL) {
+            SEP_DRV_LOG_ERROR("Memory allocation failure!");
+            return OS_NO_MEM;
+        }
+        UNC_PCIDEV_num_entries(&(unc_pcidev_map[dev_node])) = 0;
+        UNC_PCIDEV_max_entries(&(unc_pcidev_map[dev_node])) = entries;
+        for (i = 0; i < entries; i++) {
+            UNC_PCIDEV_busno_entry(&(unc_pcidev_map[dev_node]), i) = INVALID_BUS_NUMBER;
+        }
+    }
+    else {
+        entries =  UNC_PCIDEV_max_entries(&(unc_pcidev_map[dev_node]));
+    }
+
+    for (i = 0; i < UNC_PCIDEV_num_entries(&(unc_pcidev_map[dev_node])); i++) {
+        if (UNC_PCIDEV_busno_entry(&(unc_pcidev_map[dev_node]), i) == (S32)bus_no) {
+            SEP_DRV_LOG_TRACE("Already in the map,  another unit, no add.");
+            return OS_SUCCESS;
+        }
+    }
+    if (i < entries) {
+        UNC_PCIDEV_busno_entry(&(unc_pcidev_map[dev_node]), i) = (S32)bus_no;
+        UNC_PCIDEV_num_entries(&(unc_pcidev_map[dev_node]))++;
+        SEP_DRV_LOG_TRACE("Add numpackages=%d busno=%x  devnode=%d.", num_packages, bus_no, dev_node);
+        return OS_SUCCESS;
+    }
+    SEP_DRV_LOG_ERROR_TRACE_OUT("Exceed max map entries, drop this bus map!");
+    return OS_NO_MEM;
+}
+
+
+extern OS_STATUS
+UNC_COMMON_Init (VOID)
+{
+    U32  i           = 0;
+
+    for (i = 0; i < MAX_DEVICES; i++) {
+        memset(&(unc_pcidev_map[i]), 0, sizeof(UNC_PCIDEV_NODE));
+    }
+
+    memset((char *)&uncore_topology, 0, sizeof(UNCORE_TOPOLOGY_INFO_NODE));
+    memset((char*)&platform_topology_prog_node, 0, sizeof(PLATFORM_TOPOLOGY_PROG_NODE));
+
+    return OS_SUCCESS;
+}
+
+
+/*!
+ * @fn         extern VOID UNC_COMMON_Clean_Up(PVOID)
+ *
+ * @brief      clear out out programming
+ *
+ * @param      None
+ *
+ * @return     None
+ */
+extern void
+UNC_COMMON_Clean_Up (VOID)
+{
+    U32 i = 0;
+    for (i = 0; i < MAX_DEVICES; i++) {
+        if (UNC_PCIDEV_busno_list(&(unc_pcidev_map[i]))) {
+            UNC_PCIDEV_busno_list(&(unc_pcidev_map[i])) = CONTROL_Free_Memory(UNC_PCIDEV_busno_list(&(unc_pcidev_map[i])));
+        }
+        if (UNC_PCIDEV_mmio_map(&(unc_pcidev_map[i]))) {
+            UNC_PCIDEV_mmio_map(&(unc_pcidev_map[i])) = CONTROL_Free_Memory(UNC_PCIDEV_mmio_map(&(unc_pcidev_map[i])));
+        }
+        memset(&(unc_pcidev_map[i]), 0, sizeof(UNC_PCIDEV_NODE));
+    }
+    return;
+}
+
+
+/*!
+ * @fn          static VOID UNC_COMMON_PCI_Scan_For_Uncore(VOID*)
+ *
+ * @brief       Initial write of PMU registers
+ *              Walk through the enties and write the value of the register accordingly.
+ *              When current_group = 0, then this is the first time this routine is called,
+ *
+ * @param       None
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ */
+
+extern VOID
+UNC_COMMON_PCI_Scan_For_Uncore(
+    PVOID           param,
+    U32             dev_node,
+    DEVICE_CALLBACK callback
+)
+{
+    U32                        device_id;
+    U32                        value;
+    U32                        vendor_id;
+    U32                        busno;
+    U32                        j, k, l;
+    U32                        device_found = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p, dev_node: %u, callback: %p.", param, dev_node, callback);
+
+    for (busno = 0; busno < 256; busno++) {
+         for (j = 0; j < MAX_PCI_DEVNO; j++) {
+             if (!(UNCORE_TOPOLOGY_INFO_pcidev_valid(&uncore_topology, dev_node, j))) {
+                 continue;
+             }
+             for (k = 0; k < MAX_PCI_FUNCNO; k++) {
+                 if (!(UNCORE_TOPOLOGY_INFO_pcidev_is_devno_funcno_valid(&uncore_topology,dev_node,j,k))) {
+                     continue;
+                 }
+                 device_found = 0;
+                 value = PCI_Read_U32_Valid(busno, j, k, 0, 0);
+                 CONTINUE_IF_NOT_GENUINE_INTEL_DEVICE(value, vendor_id, device_id);
+                 SEP_DRV_LOG_TRACE("Uncore device ID = 0x%x.", device_id);
+
+                 for (l = 0; l <  UNCORE_TOPOLOGY_INFO_num_deviceid_entries(&uncore_topology, dev_node); l++) {
+                     if (UNCORE_TOPOLOGY_INFO_deviceid(&uncore_topology, dev_node, l) == device_id) {
+                         device_found = 1;
+                         break;
+                     }
+                 }
+                 if (device_found) {
+                     if (UNC_COMMON_Add_Bus_Map(device_id, dev_node, busno) == OS_SUCCESS) {
+                         UNCORE_TOPOLOGY_INFO_pcidev_num_entries_found(&uncore_topology, dev_node, j, k)++;
+                         SEP_DRV_LOG_DETECTION("Found device 0x%x at BDF(%x:%x:%x) [%u unit(s) so far].",
+                            device_id, busno, j, k,
+                            UNCORE_TOPOLOGY_INFO_pcidev_num_entries_found(&uncore_topology, dev_node, j, k));
+                     }
+                 }
+             }
+         }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/*!
+ * @fn          extern VOID UNC_COMMON_Get_Platform_Topology()
+ *
+ * @brief       This function will walk through the platform registers to retrieve information and calculate the bus no.
+ *              Reads appropriate pci_config regs and populates the PLATFORM_TOPOLOGY_PROG_NODE structure with the reg value.
+ *
+ * @param       U32             dev_node - Device no.
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ *                   device_num corresponds to Memory controller
+ *                   func_num  corresponds to Channel number
+ *                   reg_offset corresponds to dimm slot
+ */
+extern VOID
+UNC_COMMON_Get_Platform_Topology (
+    U32             dev_node
+)
+{
+    U32                 num_registers     = 0;
+    U32                 device_index      = 0;
+    U32                 bus_num           = 0;
+    U32                 i                 = 0;
+    U32                 func_num          = 0;
+    U32                 num_pkgs          = num_packages;
+    U32                 device_num        = 0;
+    U32                 reg_offset        = 0;
+    U32                 len               = 0;
+    U64                 reg_value         = 0;
+    U32                 device_value      = 0;
+    U64                 reg_mask          = 0;
+    U32                 vendor_id;
+    U32                 device_id;
+    U32                 valid;
+
+    PLATFORM_TOPOLOGY_REG        topology_regs = NULL;
+
+    SEP_DRV_LOG_TRACE_IN("Dev_node: %u.", dev_node);
+    PLATFORM_TOPOLOGY_PROG_topology_device_prog_valid(&platform_topology_prog_node, dev_node) = 1;
+
+    if (num_packages > MAX_PACKAGES) {
+          SEP_DRV_LOG_ERROR("Num_packages %d > MAX_PACKAGE, getting for only %d packages.",
+                           num_packages, MAX_PACKAGES);
+          num_pkgs = MAX_PACKAGES;
+    }
+
+    num_registers     = PLATFORM_TOPOLOGY_PROG_topology_device_num_registers(&platform_topology_prog_node, dev_node);
+    topology_regs     = PLATFORM_TOPOLOGY_PROG_topology_topology_regs(&platform_topology_prog_node, dev_node);
+    device_index      = PLATFORM_TOPOLOGY_PROG_topology_device_device_index(&platform_topology_prog_node, dev_node);
+
+    for (i = 0; i < num_pkgs; i++) {
+        for (len = 0; len < num_registers; len++) {
+            if (PLATFORM_TOPOLOGY_REG_reg_type(topology_regs, len)  == PMU_REG_PROG_MSR) {
+                reg_value = SYS_Read_MSR(PLATFORM_TOPOLOGY_REG_reg_id(topology_regs, len));
+                reg_mask = PLATFORM_TOPOLOGY_REG_reg_mask(topology_regs, len);
+                PLATFORM_TOPOLOGY_REG_reg_value(topology_regs, len, i) = reg_value & reg_mask;
+                SEP_DRV_LOG_TRACE("Read UNCORE_MSR_FREQUENCY 0x%x\n",PLATFORM_TOPOLOGY_REG_reg_id(topology_regs, len));
+            }
+            else
+            {
+                if  (!IS_BUS_MAP_VALID(dev_node, i)) {
+                    continue;
+                }
+                bus_num              = GET_BUS_MAP(dev_node,i);
+                device_num           = PLATFORM_TOPOLOGY_REG_device(topology_regs, len);
+                func_num             = PLATFORM_TOPOLOGY_REG_function(topology_regs, len);
+                reg_offset           = PLATFORM_TOPOLOGY_REG_reg_id(topology_regs, len);
+                device_value         = PCI_Read_U32_Valid(bus_num, device_num, func_num, 0, 0);
+                CHECK_IF_GENUINE_INTEL_DEVICE(device_value, vendor_id, device_id, valid);
+                if (!valid) {
+                    PLATFORM_TOPOLOGY_REG_device_valid(topology_regs, len) = 0;
+                }
+                PLATFORM_TOPOLOGY_REG_reg_value(topology_regs, len, i) = PCI_Read_U32_Valid(bus_num, device_num, func_num, reg_offset, PCI_INVALID_VALUE);
+            }
+        }
+        if (PLATFORM_TOPOLOGY_PROG_topology_device_scope(&platform_topology_prog_node, dev_node) == SYSTEM_EVENT) {
+           break;
+        }
+    }
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/************************************************************/
+/*
+ * UNC common MSR  based API
+ *
+ ************************************************************/
+
+/*!
+ * @fn         VOID UNC_COMMON_MSR_Clean_Up(PVOID)
+ *
+ * @brief      clear out out programming
+ *
+ * @param      None
+ *
+ * @return     None
+ */
+VOID
+UNC_COMMON_MSR_Clean_Up (
+    VOID   *param
+)
+{
+    U32 dev_idx;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+    dev_idx = *((U32*)param);
+    FOR_EACH_REG_ENTRY_UNC(pecb, dev_idx, i) {
+        if (ECB_entries_clean_up_get(pecb,i)) {
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,i), 0LL);
+        }
+    } END_FOR_EACH_REG_ENTRY_UNC;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
diff --git a/drivers/misc/intel/sepdk/sep/unc_gt.c b/drivers/misc/intel/sepdk/sep/unc_gt.c
new file mode 100644
index 000000000000..ba7d37a6fc8a
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/unc_gt.c
@@ -0,0 +1,495 @@
+/****
+    Copyright(C) 2012-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit.
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+
+
+
+
+#include "lwpmudrv_defines.h"
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+#include "inc/ecb_iterators.h"
+#include "inc/control.h"
+#include "inc/unc_common.h"
+#include "inc/utility.h"
+#include "inc/pci.h"
+#include "inc/unc_gt.h"
+
+
+
+extern U64                       *read_counter_info;
+extern EMON_BUFFER_DRIVER_HELPER  emon_buffer_driver_helper;
+
+static U64                        unc_gt_virtual_address = 0;
+static SEP_MMIO_NODE              unc_gt_map;
+static U32                        unc_gt_rc6_reg1;
+static U32                        unc_gt_rc6_reg2;
+static U32                        unc_gt_clk_gt_reg1;
+static U32                        unc_gt_clk_gt_reg2;
+static U32                        unc_gt_clk_gt_reg3;
+static U32                        unc_gt_clk_gt_reg4;
+
+/*!
+ * @fn          static VOID unc_gt_Write_PMU(VOID*)
+ *
+ * @brief       Initial write of PMU registers
+ *              Walk through the enties and write the value of the register accordingly.
+ *
+ * @param       device id
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+unc_gt_Write_PMU (
+    VOID  *param
+)
+{
+    U32                        dev_idx;
+    ECB                        pecb;
+    DRV_PCI_DEVICE_ENTRY_NODE  dpden;
+    U64                        device_id;
+    U32                        vendor_id;
+    U64                        bar_lo;
+    U32                        offset_delta;
+    U32                        tmp_value;
+    U32                        this_cpu;
+    U32                        value;
+    CPU_STATE                  pcpu;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx  = *((U32*)param);
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[0];
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+
+    if (!CPU_STATE_system_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!system_master).");
+        return;
+    }
+
+    dpden = ECB_pcidev_entry_node(pecb);
+    value = PCI_Read_U32(DRV_PCI_DEVICE_ENTRY_bus_no(&dpden),
+                         DRV_PCI_DEVICE_ENTRY_dev_no(&dpden),
+                         DRV_PCI_DEVICE_ENTRY_func_no(&dpden),
+                         0);
+    vendor_id = DRV_GET_PCI_VENDOR_ID(value);
+    device_id = DRV_GET_PCI_DEVICE_ID(value);
+
+    if (DRV_IS_INTEL_VENDOR_ID(vendor_id) && DRV_IS_GT_DEVICE_ID(device_id)){
+        SEP_DRV_LOG_TRACE("Found Desktop GT.");
+    }
+
+    bar_lo  = PCI_Read_U32(DRV_PCI_DEVICE_ENTRY_bus_no(&dpden),
+                          DRV_PCI_DEVICE_ENTRY_dev_no(&dpden),
+                          DRV_PCI_DEVICE_ENTRY_func_no(&dpden),
+                          DRV_PCI_DEVICE_ENTRY_bar_offset(&dpden));
+    bar_lo &= UNC_GT_BAR_MASK;
+
+    PCI_Map_Memory(&unc_gt_map, bar_lo, GT_MMIO_SIZE);
+    unc_gt_virtual_address  = SEP_MMIO_NODE_virtual_address(&unc_gt_map);
+
+   FOR_EACH_PCI_DATA_REG_RAW(pecb,i, dev_idx ) {
+        offset_delta           = ECB_entries_reg_offset(pecb, i);
+        // this is needed for overflow detection of the accumulators.
+        if (LWPMU_DEVICE_counter_mask(&devices[dev_idx]) == 0) {
+            LWPMU_DEVICE_counter_mask(&devices[dev_idx]) = (U64)ECB_entries_max_bits(pecb,i);
+        }
+    } END_FOR_EACH_PCI_CCCR_REG_RAW;
+
+    //enable the global control to clear the counter first
+    SYS_Write_MSR(PERF_GLOBAL_CTRL, ECB_entries_reg_value(pecb,0));
+    FOR_EACH_PCI_CCCR_REG_RAW(pecb,i, dev_idx ) {
+        offset_delta           = ECB_entries_reg_offset(pecb, i);
+        if  (offset_delta == PERF_GLOBAL_CTRL) {
+           continue;
+        }
+        PCI_MMIO_Write_U32(unc_gt_virtual_address,
+                                offset_delta,
+                                GT_CLEAR_COUNTERS);
+
+        SEP_DRV_LOG_TRACE("CCCR offset delta is 0x%x W is clear ctrs.", offset_delta);
+    } END_FOR_EACH_PCI_CCCR_REG_RAW;
+
+    //disable the counters
+    SYS_Write_MSR(PERF_GLOBAL_CTRL, 0LL);
+
+    FOR_EACH_PCI_CCCR_REG_RAW(pecb,i, dev_idx ) {
+        offset_delta           = ECB_entries_reg_offset(pecb, i);
+        if  (offset_delta == PERF_GLOBAL_CTRL) {
+           continue;
+        }
+        PCI_MMIO_Write_U32(unc_gt_virtual_address,
+                                offset_delta,
+                                ((U32)ECB_entries_reg_value(pecb,i)));
+        tmp_value = PCI_MMIO_Read_U32(unc_gt_virtual_address, offset_delta);
+
+        // remove compiler warning on unused variables
+        if (tmp_value) {
+        }
+
+        SEP_DRV_LOG_TRACE("CCCR offset delta is 0x%x R is 0x%x W is 0x%llx.", offset_delta, tmp_value, ECB_entries_reg_value(pecb, i));
+    } END_FOR_EACH_PCI_CCCR_REG_RAW;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*!
+ * @fn          static VOID unc_gt_Disable_RC6_Clock_Gating(VOID)
+ *
+ * @brief       This snippet of code allows GT events to count by
+ *              disabling settings related to clock gating/power
+ * @param       none
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+unc_gt_Disable_RC6_Clock_Gating (
+    VOID
+)
+{
+    U32          tmp;
+
+    SEP_DRV_LOG_TRACE_IN("");
+
+    // Disable RC6
+    unc_gt_rc6_reg1  =  PCI_MMIO_Read_U32(unc_gt_virtual_address, UNC_GT_RC6_REG1);
+    tmp              =  unc_gt_rc6_reg1 | UNC_GT_RC6_REG1_OR_VALUE;
+    unc_gt_rc6_reg2  =  PCI_MMIO_Read_U32(unc_gt_virtual_address, UNC_GT_RC6_REG2);
+
+    PCI_MMIO_Write_U32(unc_gt_virtual_address,
+                       UNC_GT_RC6_REG2,
+                       UNC_GT_RC6_REG2_VALUE);
+    PCI_MMIO_Write_U32(unc_gt_virtual_address,
+                       UNC_GT_RC6_REG1,
+                       tmp);
+
+    SEP_DRV_LOG_TRACE("Original value of RC6 rc6_1 = 0x%x, rc6_2 = 0x%x.", unc_gt_rc6_reg1, unc_gt_rc6_reg2);
+
+    // Disable clock gating
+    // Save
+    unc_gt_clk_gt_reg1 = PCI_MMIO_Read_U32(unc_gt_virtual_address, UNC_GT_GCPUNIT_REG1);
+    unc_gt_clk_gt_reg2 = PCI_MMIO_Read_U32(unc_gt_virtual_address, UNC_GT_GCPUNIT_REG2);
+    unc_gt_clk_gt_reg3 = PCI_MMIO_Read_U32(unc_gt_virtual_address, UNC_GT_GCPUNIT_REG3);
+    unc_gt_clk_gt_reg4 = PCI_MMIO_Read_U32(unc_gt_virtual_address, UNC_GT_GCPUNIT_REG4);
+
+    SEP_DRV_LOG_TRACE("Original value of RC6 ck_1 = 0x%x, ck_2 = 0x%x.", unc_gt_clk_gt_reg1, unc_gt_clk_gt_reg2);
+    SEP_DRV_LOG_TRACE("Original value of RC6 ck_3 = 0x%x, ck_4 = 0x%x.", unc_gt_clk_gt_reg3, unc_gt_clk_gt_reg4);
+
+    // Disable
+    PCI_MMIO_Write_U32(unc_gt_virtual_address,
+                       UNC_GT_GCPUNIT_REG1,
+                       UNC_GT_GCPUNIT_REG1_VALUE);
+    PCI_MMIO_Write_U32(unc_gt_virtual_address,
+                       UNC_GT_GCPUNIT_REG2,
+                       UNC_GT_GCPUNIT_REG2_VALUE);
+    PCI_MMIO_Write_U32(unc_gt_virtual_address,
+                       UNC_GT_GCPUNIT_REG3,
+                       UNC_GT_GCPUNIT_REG3_VALUE);
+    PCI_MMIO_Write_U32(unc_gt_virtual_address,
+                       UNC_GT_GCPUNIT_REG4,
+                       UNC_GT_GCPUNIT_REG4_VALUE);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/*!
+ * @fn          static VOID unc_gt_Restore_RC6_Clock_Gating(VOID)
+ *
+ * @brief       This snippet of code restores the system settings
+ *              for clock gating/power
+ * @param       none
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+unc_gt_Restore_RC6_Clock_Gating (
+    VOID
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    PCI_MMIO_Write_U32(unc_gt_virtual_address,
+                       UNC_GT_RC6_REG2,
+                       unc_gt_rc6_reg2);
+    PCI_MMIO_Write_U32(unc_gt_virtual_address,
+                       UNC_GT_RC6_REG1,
+                       unc_gt_rc6_reg1);
+
+    PCI_MMIO_Write_U32(unc_gt_virtual_address,
+                       UNC_GT_GCPUNIT_REG1,
+                       unc_gt_clk_gt_reg1);
+    PCI_MMIO_Write_U32(unc_gt_virtual_address,
+                       UNC_GT_GCPUNIT_REG2,
+                       unc_gt_clk_gt_reg2);
+    PCI_MMIO_Write_U32(unc_gt_virtual_address,
+                       UNC_GT_GCPUNIT_REG3,
+                       unc_gt_clk_gt_reg3);
+    PCI_MMIO_Write_U32(unc_gt_virtual_address,
+                       UNC_GT_GCPUNIT_REG4,
+                       unc_gt_clk_gt_reg4);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*!
+ * @fn         static VOID unc_gt_Enable_PMU(PVOID)
+ *
+ * @brief      Disable the clock gating and Set the global enable
+ *
+ * @param      device_id
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+unc_gt_Enable_PMU (
+    PVOID   param
+)
+{
+    U32          dev_idx;
+    ECB          pecb;
+    U32          this_cpu;
+    CPU_STATE    pcpu;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx     = *((U32*)param);
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[0];
+    this_cpu    = CONTROL_THIS_CPU();
+    pcpu        = &pcb[this_cpu];
+
+    if (!CPU_STATE_system_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!system_master).");
+        return;
+    }
+
+    unc_gt_Disable_RC6_Clock_Gating();
+
+    if (pecb && GET_DRIVER_STATE() == DRV_STATE_RUNNING) {
+        SYS_Write_MSR(PERF_GLOBAL_CTRL, ECB_entries_reg_value(pecb,0));
+        SEP_DRV_LOG_TRACE("Enabling GT Global control = 0x%llx.", ECB_entries_reg_value(pecb, 0));
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+/*!
+ * @fn         static VOID unc_gt_Disable_PMU(PVOID)
+ *
+ * @brief      Unmap the virtual address when sampling/driver stops
+ *             and restore system values for clock gating settings
+ *
+ * @param      None
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+unc_gt_Disable_PMU (
+    PVOID  param
+)
+{
+    U32          this_cpu;
+    CPU_STATE    pcpu;
+    U32          cur_driver_state;
+
+    SEP_DRV_LOG_TRACE_IN("Dummy param: %p.", param);
+
+    this_cpu         = CONTROL_THIS_CPU();
+    pcpu             = &pcb[this_cpu];
+    cur_driver_state = GET_DRIVER_STATE();
+
+    if (!CPU_STATE_system_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!system_master).");
+        return;
+    }
+    unc_gt_Restore_RC6_Clock_Gating();
+
+    if (unc_gt_virtual_address                   &&
+        (cur_driver_state == DRV_STATE_STOPPED      ||
+         cur_driver_state == DRV_STATE_PREPARE_STOP ||
+         cur_driver_state == DRV_STATE_TERMINATING)) {
+        SYS_Write_MSR(PERF_GLOBAL_CTRL, 0LL);
+        PCI_Unmap_Memory(&unc_gt_map);
+        unc_gt_virtual_address = 0;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/*!
+ * @fn unc_gt_Read_Counts(param, id)
+ *
+ * @param    param    The read thread node to process
+ * @param    id       The id refers to the device index
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the Uncore count data and store into the buffer param;
+ *
+ */
+static VOID
+unc_gt_Read_Counts (
+    PVOID  param,
+    U32    id
+)
+{
+    U64               *data       = (U64*) param;
+    U32                cur_grp;
+    ECB                pecb;
+    U32                offset_delta;
+    U32                tmp_value_lo        = 0;
+    U32                tmp_value_hi        = 0;
+    GT_CTR_NODE        gt_ctr_value;
+    U32                   this_cpu;
+    U32                   package_num;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p, id: %u.", param, id);
+
+    this_cpu    = CONTROL_THIS_CPU();
+    package_num = core_to_package_map[this_cpu];
+    cur_grp     = LWPMU_DEVICE_cur_group(&devices[id])[package_num];
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[id])[cur_grp];
+
+    // Write GroupID
+    data    = (U64*)((S8*)data + ECB_group_offset(pecb));
+    *data   = cur_grp + 1;
+    GT_CTR_NODE_value_reset(gt_ctr_value);
+
+    //Read in the counts into temporary buffe
+    FOR_EACH_PCI_DATA_REG_RAW(pecb, i, id) {
+        offset_delta                     = ECB_entries_reg_offset(pecb, i);
+        tmp_value_lo                     = PCI_MMIO_Read_U32(unc_gt_virtual_address, offset_delta);
+        offset_delta                     = offset_delta + NEXT_ADDR_OFFSET;
+        tmp_value_hi                     = PCI_MMIO_Read_U32(unc_gt_virtual_address, offset_delta);
+        data                             = (U64 *)((S8*)param + ECB_entries_counter_event_offset(pecb,i));
+        GT_CTR_NODE_low(gt_ctr_value)    = tmp_value_lo;
+        GT_CTR_NODE_high(gt_ctr_value)   = tmp_value_hi;
+        *data                            = GT_CTR_NODE_value(gt_ctr_value);
+        SEP_DRV_LOG_TRACE("DATA offset delta is 0x%x R is 0x%llx.", offset_delta, GT_CTR_NODE_value(gt_ctr_value));
+    } END_FOR_EACH_PCI_DATA_REG_RAW;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+static VOID
+unc_gt_Read_PMU_Data (
+    PVOID  param
+)
+{
+    U32                j;
+    U64               *buffer           = read_counter_info;
+    U32                dev_idx;
+    U32                this_cpu;
+    CPU_STATE          pcpu;
+    U32                cur_grp;
+    U32                offset_delta;
+    U32                tmp_value_lo     = 0;
+    U32                tmp_value_hi     = 0;
+    GT_CTR_NODE        gt_ctr_value;
+    U32                package_num      = 0;
+
+    SEP_DRV_LOG_DEBUG_IN("Param: %p.", param);
+
+    dev_idx      = *((U32*)param);
+    this_cpu     = CONTROL_THIS_CPU();
+    pcpu         = &pcb[this_cpu];
+
+    if (!CPU_STATE_system_master(pcpu)) {
+        SEP_DRV_LOG_DEBUG_OUT("Early exit (!system_master).");
+        return;
+    }
+
+    package_num = core_to_package_map[this_cpu];
+    cur_grp     = LWPMU_DEVICE_cur_group(&devices[(dev_idx)])[package_num];
+
+    FOR_EACH_PCI_DATA_REG_RAW(pecb, i, dev_idx) {
+        j = EMON_BUFFER_UNCORE_PACKAGE_EVENT_OFFSET(package_num, EMON_BUFFER_DRIVER_HELPER_num_entries_per_package(emon_buffer_driver_helper),
+                                                    ECB_entries_uncore_buffer_offset_in_package(pecb,i));
+        offset_delta                     = ECB_entries_reg_offset(pecb, i);
+        tmp_value_lo                     = PCI_MMIO_Read_U32(unc_gt_virtual_address, offset_delta);
+        offset_delta                     = offset_delta + NEXT_ADDR_OFFSET;
+        tmp_value_hi                     = PCI_MMIO_Read_U32(unc_gt_virtual_address, offset_delta);
+        GT_CTR_NODE_low(gt_ctr_value)    = tmp_value_lo;
+        GT_CTR_NODE_high(gt_ctr_value)   = tmp_value_hi;
+        buffer[j] =  GT_CTR_NODE_value(gt_ctr_value);
+        SEP_DRV_LOG_TRACE("j=%u, value=%llu, cpu=%u", j, buffer[j], this_cpu);
+
+    } END_FOR_EACH_PCI_DATA_REG_RAW;
+
+    SEP_DRV_LOG_DEBUG_OUT("");
+    return;
+}
+
+/*
+ * Initialize the dispatch table
+ */
+DISPATCH_NODE  unc_gt_dispatch =
+{
+    NULL,                       // initialize
+    NULL,                       // destroy
+    unc_gt_Write_PMU,           // write
+    unc_gt_Disable_PMU,         // freeze
+    unc_gt_Enable_PMU,          // restart
+    unc_gt_Read_PMU_Data,       // read
+    NULL,                       // check for overflow
+    NULL,                       // swap_group
+    NULL,                       // read_lbrs
+    NULL,                       // cleanup
+    NULL,                       // hw_errata
+    NULL,                       // read_power
+    NULL,                       // check_overflow_errata
+    unc_gt_Read_Counts,         // read_counts
+    NULL,                       // check_overflow_gp_errata
+    NULL,                       // read_ro
+    NULL,                       // platform_info
+    unc_gt_Read_Counts,         // trigger read
+    NULL,                       // scan for uncore
+    NULL                        // read metrics
+};
+
diff --git a/drivers/misc/intel/sepdk/sep/unc_mmio.c b/drivers/misc/intel/sepdk/sep/unc_mmio.c
new file mode 100644
index 000000000000..dbcea2e61713
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/unc_mmio.c
@@ -0,0 +1,1001 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include <linux/pci.h>
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/wait.h>
+#include <linux/fs.h>
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+#include "lwpmudrv.h"
+#include "utility.h"
+#include "control.h"
+#include "output.h"
+#include "unc_common.h"
+#include "ecb_iterators.h"
+#include "pebs.h"
+#include "inc/pci.h"
+
+extern U64                        *read_counter_info;
+extern U64                        *prev_counter_data;
+extern DRV_CONFIG                  drv_cfg;
+extern EMON_BUFFER_DRIVER_HELPER   emon_buffer_driver_helper;
+
+
+#define MASK_32BIT             0xffffffff
+#define MASK_64BIT             0xffffffff00000000ULL
+
+#define IS_MASTER(device_type, cpu)               (((device_type) == DRV_SINGLE_INSTANCE)? CPU_STATE_system_master(&pcb[cpu]): CPU_STATE_socket_master(&pcb[(cpu)]))
+#define GET_PACKAGE_NUM(device_type, cpu)         (((device_type) == DRV_SINGLE_INSTANCE)? 0:core_to_package_map[cpu])
+#define IS_64BIT(mask)                            (((mask)>>32) != 0)
+
+#define EVENT_COUNTER_MAX_TRY  30
+
+struct FPGA_CONTROL_NODE_S {
+    union {
+        struct {
+            U64 rst_ctrs         : 1;
+            U64 rsvd1            : 7;
+            U64 frz              : 1;
+            U64 rsvd2            : 7;
+            U64 event_select     : 4;
+            U64 port_id          : 2;
+            U64 rsvd3            : 1;
+            U64 port_enable      : 1;
+            U64 rsvd4            : 40;
+        } bits;
+        U64 bit_field;
+    } u;
+} control_node;
+
+
+/*!
+ * @fn          static VOID unc_mmio_Write_PMU(VOID*)
+ *
+ * @brief       Initial write of PMU registers
+ *              Walk through the enties and write the value of the register accordingly.
+ *              When current_group = 0, then this is the first time this routine is called,
+ *
+ * @param       None
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+unc_mmio_Write_PMU (
+    VOID  *param
+)
+{
+
+
+    U32              dev_idx;
+    U32              offset_delta     = 0;
+    DEV_UNC_CONFIG   pcfg_unc;
+    U32              event_id         = 0;
+    U64              tmp_value        = 0;
+    U32              this_cpu;
+    U32              package_num      = 0;
+    U32              cur_grp;
+    ECB              pecb;
+    U64              virtual_addr    = 0;
+    U32              idx_w           = 0;
+    U32              event_code      = 0;
+    U32              counter         = 0;
+    U32              entry           = 0;
+    U32              dev_node        = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx      = *((U32*)param);
+    this_cpu     = CONTROL_THIS_CPU();
+    pcfg_unc     = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    if (!IS_MASTER(DEV_UNC_CONFIG_device_type(pcfg_unc), this_cpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!is_master).");
+        return;
+    }
+
+    package_num  = GET_PACKAGE_NUM(DEV_UNC_CONFIG_device_type(pcfg_unc), this_cpu);
+    cur_grp      = LWPMU_DEVICE_cur_group(&devices[(dev_idx)])[package_num];
+    pecb         = LWPMU_DEVICE_PMU_register_data(&devices[(dev_idx)])[(cur_grp)];
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    dev_node     = ECB_dev_node(pecb);
+    entry        = package_num;
+    if (!IS_MMIO_MAP_VALID(dev_node, entry)) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Early exit (!IS_MMIO_MAP_VALID).");
+        return;
+    }
+
+    virtual_addr = virtual_address_table(dev_node, entry);
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_WRITE) {
+        PCI_MMIO_Write_U64(virtual_addr, ECB_entries_reg_id(pecb,idx), ECB_entries_reg_value(pecb,idx));
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    if (DRV_CONFIG_emon_mode(drv_cfg)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!event_based_counts).");
+        return;
+    }
+
+    idx_w = ECB_operations_register_start(pecb, PMU_OPERATION_WRITE);
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_READ) {
+        if (ECB_entries_reg_offset(pecb,idx) > DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(&ECB_pcidev_entry_node(pecb))) {
+            offset_delta =  ECB_entries_reg_offset(pecb,idx) -
+                              DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(&ECB_pcidev_entry_node(pecb));
+        }
+        else {
+            offset_delta =  ECB_entries_reg_offset(pecb,idx);
+        }
+
+        if ((DEV_UNC_CONFIG_device_type(pcfg_unc) == DRV_SINGLE_INSTANCE)  &&
+            (GET_NUM_MAP_ENTRIES(dev_node) > 1))   {
+            // multiple MMIO mapping per <dev_no, func_no> device, find virtual_addr per mapping.
+            entry = ECB_entries_unit_id(pecb,idx);
+            virtual_addr = virtual_address_table(dev_node, entry);
+        }
+
+        if ((ECB_entries_counter_type(pecb,idx) == PROG_FREERUN_COUNTER) &&
+            (ECB_entries_unit_id(pecb,idx) == 0)) {
+            //Write event code before reading
+            PCI_MMIO_Write_U64(virtual_addr, ECB_entries_reg_id(pecb,idx_w), ECB_entries_reg_value(pecb,idx_w));
+            event_code = (U32)control_node.u.bits.event_select;
+            idx_w++;
+        }
+
+        // this is needed for overflow detection of the accumulators.
+        if (IS_64BIT((U64)(ECB_entries_max_bits(pecb,idx)))) {
+            if (ECB_entries_counter_type(pecb,idx) == PROG_FREERUN_COUNTER) {
+                do {
+                    if (counter > EVENT_COUNTER_MAX_TRY) {
+                        break;
+                    }
+                    tmp_value = SYS_MMIO_Read64(virtual_addr, offset_delta);
+                    counter++;
+                } while (event_code != (tmp_value >>60));
+            }
+            tmp_value = SYS_MMIO_Read64(virtual_addr, offset_delta);
+        }
+        else {
+            tmp_value = SYS_MMIO_Read32(virtual_addr, offset_delta);
+        }
+        tmp_value &= (U64)ECB_entries_max_bits(pecb,idx);
+
+        LWPMU_DEVICE_prev_value(&devices[dev_idx])[package_num][event_id] = tmp_value;
+        SEP_DRV_LOG_TRACE("unc_mmio_Write_PMU: cpu[%d], device[%d], package[%d], entry %d, event_id %d, value 0x%llu\n",
+                      this_cpu, dev_idx, package_num, entry, event_id, tmp_value);
+        event_id++;
+
+        if (LWPMU_DEVICE_counter_mask(&devices[dev_idx]) == 0) {
+            LWPMU_DEVICE_counter_mask(&devices[dev_idx]) = (U64)ECB_entries_max_bits(pecb,idx);
+        }
+    } END_FOR_EACH_REG_UNC_OPERATION;
+    SEP_DRV_LOG_TRACE("BAR address is 0x%llx and virt is 0x%llx.", DRV_PCI_DEVICE_ENTRY_bar_address(&ECB_pcidev_entry_node(pecb)), virtual_addr);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*!
+ * @fn         static VOID unc_mmio_Enable_PMU(PVOID)
+ *
+ * @brief      Capture the previous values to calculate delta later.
+ *
+ * @param      None
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static void
+unc_mmio_Enable_PMU (
+    PVOID  param
+)
+{
+    U32            j;
+    U64           *buffer       = prev_counter_data;
+    U32            this_cpu;
+    U32            dev_idx;
+    DEV_UNC_CONFIG pcfg_unc;
+    U32            package_num;
+    U32            offset_delta;
+    U32            cur_grp;
+    ECB            pecb;
+    U64            virtual_addr = 0;
+    U64            reg_val      = 0;
+    U32            idx_w        = 0;
+    U32            event_code   = 0;
+    U32            counter      = 0;
+    U32            num_events   = 0;
+    U32            entry        = 0;
+    U32            num_pkgs     = num_packages;
+    U32            dev_node     = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx     = *((U32*)param);
+    this_cpu    = CONTROL_THIS_CPU();
+    pcfg_unc    = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    if (!IS_MASTER(DEV_UNC_CONFIG_device_type(pcfg_unc), this_cpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!IS_MASTER).");
+        return;
+    }
+
+    package_num = GET_PACKAGE_NUM(DEV_UNC_CONFIG_device_type(pcfg_unc), this_cpu);
+    cur_grp     = LWPMU_DEVICE_cur_group(&devices[(dev_idx)])[package_num];
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[(dev_idx)])[(cur_grp)];
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    dev_node    = ECB_dev_node(pecb);
+    entry       = package_num;
+    if (!IS_MMIO_MAP_VALID(dev_node, entry)) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Early exit (!IS_MMIO_MAP_VALID).");
+        return;
+    }
+
+    if (DEV_UNC_CONFIG_device_type(pcfg_unc) == DRV_SINGLE_INSTANCE) {
+        num_pkgs    = 1;
+    }
+
+    virtual_addr = virtual_address_table(dev_node, entry);
+
+    // NOTE THAT the enable function currently captures previous values
+    // for EMON collection to avoid unnecessary memory copy.
+    if (DRV_CONFIG_emon_mode(drv_cfg)) {
+        num_events  = ECB_num_events(pecb);
+        idx_w = ECB_operations_register_start(pecb, PMU_OPERATION_WRITE);
+        FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_READ) {
+
+            if (ECB_entries_reg_offset(pecb,idx) > DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(&ECB_pcidev_entry_node(pecb))) {
+                offset_delta =  ECB_entries_reg_offset(pecb,idx) -
+                                  DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(&ECB_pcidev_entry_node(pecb));
+            }
+            else {
+                offset_delta =  ECB_entries_reg_offset(pecb,idx);
+            }
+
+            if ((DEV_UNC_CONFIG_device_type(pcfg_unc) == DRV_SINGLE_INSTANCE)  &&
+                (GET_NUM_MAP_ENTRIES(dev_node) > 1))   {
+                // multiple MMIO mapping per <dev_no, func_no> device, find virtual_addr per mapping.
+                entry = ECB_entries_unit_id(pecb,idx);
+                virtual_addr = virtual_address_table(dev_node, entry);
+            }
+
+            if ((ECB_entries_counter_type(pecb,idx) == PROG_FREERUN_COUNTER) &&
+                (ECB_entries_unit_id(pecb,idx) == 0)) {
+                PCI_MMIO_Write_U64(virtual_addr, ECB_entries_reg_id(pecb,idx_w), ECB_entries_reg_value(pecb,idx_w));
+                control_node.u.bit_field = ECB_entries_reg_value(pecb,idx_w);
+                event_code = (U32)control_node.u.bits.event_select;
+                idx_w++;
+            }
+
+            if ((ECB_entries_event_scope(pecb,idx) == PACKAGE_EVENT) ||
+                (ECB_entries_event_scope(pecb,idx) == SYSTEM_EVENT)) {
+
+                if (ECB_entries_event_scope(pecb,idx) == SYSTEM_EVENT) {
+                    j = ECB_entries_uncore_buffer_offset_in_system(pecb, idx);
+                }
+                else {
+                    j = EMON_BUFFER_UNCORE_PACKAGE_EVENT_OFFSET(package_num, EMON_BUFFER_DRIVER_HELPER_num_entries_per_package(emon_buffer_driver_helper),
+                                                                ECB_entries_uncore_buffer_offset_in_package(pecb, idx));
+                }
+
+                if (IS_64BIT((U64)(ECB_entries_max_bits(pecb,idx)))) {
+                    if (ECB_entries_counter_type(pecb,idx) == PROG_FREERUN_COUNTER) {
+                        do {
+                            if (counter > EVENT_COUNTER_MAX_TRY) {
+                                break;
+                            }
+                            buffer[j] = SYS_MMIO_Read64(virtual_addr, offset_delta);
+                            counter++;
+                        } while (event_code != (buffer[j] >>60));
+                    }
+                    buffer[j] = SYS_MMIO_Read64(virtual_addr, offset_delta);
+                }
+                else {
+                    buffer[j] = SYS_MMIO_Read32(virtual_addr, offset_delta);
+                }
+                buffer[j] &= (U64)ECB_entries_max_bits(pecb,idx);
+                SEP_DRV_LOG_TRACE("j=%u, value=%llu, cpu=%u, MSR=0x%x", j, buffer[j], this_cpu, ECB_entries_reg_id(pecb,idx));
+            }
+        } END_FOR_EACH_REG_UNC_OPERATION;
+    }
+    virtual_addr = virtual_address_table(dev_node, entry);
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_ENABLE) {
+        if (ECB_entries_reg_rw_type(pecb, idx)  == PMU_REG_RW_READ_WRITE) {
+            reg_val = PCI_MMIO_Read_U64(virtual_addr, ECB_entries_reg_id(pecb,idx));
+            reg_val &= ECB_entries_reg_value(pecb,idx);
+            PCI_MMIO_Write_U64(virtual_addr, ECB_entries_reg_id(pecb,idx), reg_val);
+        }
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*!
+ * @fn         static VOID unc_mmio_Disable_PMU(PVOID)
+ *
+ * @brief      Unmap the virtual address when you stop sampling.
+ *
+ * @param      None
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static void
+unc_mmio_Disable_PMU (
+    PVOID  param
+)
+{
+    U32            dev_idx;
+    U32            this_cpu;
+    U64            virtual_addr  = 0;
+    U64            reg_val       = 0;
+    DEV_UNC_CONFIG pcfg_unc;
+    U32            package_num;
+    U32            dev_node      = 0;
+    U32            cur_grp       = 0;
+    ECB            pecb;
+    U32            entry         = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx     = *((U32*)param);
+    this_cpu    = CONTROL_THIS_CPU();
+    pcfg_unc    = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    if (!IS_MASTER(DEV_UNC_CONFIG_device_type(pcfg_unc), this_cpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!IS_MASTER).");
+        return;
+    }
+
+    package_num = GET_PACKAGE_NUM(DEV_UNC_CONFIG_device_type(pcfg_unc), this_cpu);
+    cur_grp     = LWPMU_DEVICE_cur_group(&devices[dev_idx])[package_num];
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[(cur_grp)];
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    dev_node    = ECB_dev_node(pecb);
+    entry       = package_num;
+    if (!IS_MMIO_MAP_VALID(dev_node, entry)) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Early exit (!IS_MMIO_MAP_VALID).");
+        return;
+    }
+
+    virtual_addr = virtual_address_table(dev_node, entry);
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_DISABLE) {
+        if (ECB_entries_reg_rw_type(pecb, idx)  == PMU_REG_RW_READ_WRITE) {
+            reg_val = PCI_MMIO_Read_U64(virtual_addr, ECB_entries_reg_id(pecb,idx));
+            reg_val |= ECB_entries_reg_value(pecb,idx);
+            PCI_MMIO_Write_U64(virtual_addr, ECB_entries_reg_id(pecb,idx), reg_val);
+        }
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       void unc_mmio_Trigger_Read(id)
+ *
+ * @param    id       Device index
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the Uncore data from counters and store into buffer
+ */
+static  VOID
+unc_mmio_Trigger_Read (
+    PVOID  param,
+    U32    id
+)
+{
+    U32             this_cpu;
+    U32             cur_grp;
+    ECB             pecb;
+    U32             index               = 0;
+    U64             diff                = 0;
+    U32             offset_delta        = 0;
+    U64             value               = 0ULL;
+    U64            *data;
+    U64             virtual_addr        = 0;
+    DEV_UNC_CONFIG  pcfg_unc;
+    U32             package_num;
+    U32             idx_w               = 0;
+    U32             event_code          = 0;
+    U32             counter             = 0;
+    U32             entry               = 0;
+    U32             dev_node            = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p, id: %u.", param, id);
+
+    this_cpu    = CONTROL_THIS_CPU();
+    pcfg_unc    = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(&devices[id]);
+    if (!IS_MASTER(DEV_UNC_CONFIG_device_type(pcfg_unc), this_cpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!IS_MASTER).");
+        return;
+    }
+
+    package_num = GET_PACKAGE_NUM(DEV_UNC_CONFIG_device_type(pcfg_unc), this_cpu);
+    cur_grp     = LWPMU_DEVICE_cur_group(&devices[id])[package_num];
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[id])[(cur_grp)];
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    dev_node    = ECB_dev_node(pecb);
+    entry       = package_num;
+    if (!IS_MMIO_MAP_VALID(dev_node, entry)) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Early exit (!IS_MMIO_MAP_VALID).");
+        return;
+    }
+
+    virtual_addr = virtual_address_table(dev_node, entry);
+
+    // Write GroupID
+    data = (U64*)((S8*)param + ECB_group_offset(pecb));
+    *data = cur_grp + 1;
+    //Read in the counts into temporary buffer
+    idx_w = ECB_operations_register_start(pecb, PMU_OPERATION_WRITE);
+    FOR_EACH_REG_UNC_OPERATION(pecb, id, idx, PMU_OPERATION_READ) {
+        if (ECB_entries_reg_offset(pecb,idx) > DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(&ECB_pcidev_entry_node(pecb))) {
+            offset_delta =  ECB_entries_reg_offset(pecb,idx) -
+                              DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(&ECB_pcidev_entry_node(pecb));
+        }
+        else {
+            offset_delta =  ECB_entries_reg_offset(pecb,idx);
+        }
+
+        if ((DEV_UNC_CONFIG_device_type(pcfg_unc) == DRV_SINGLE_INSTANCE)  &&
+            (GET_NUM_MAP_ENTRIES(dev_node) > 1))   {
+            // multiple MMIO mapping per <dev_no, func_no> device
+            entry = ECB_entries_unit_id(pecb,idx);
+            virtual_addr = virtual_address_table(dev_node, entry);
+        }
+
+        if ((ECB_entries_counter_type(pecb,idx) == PROG_FREERUN_COUNTER) &&
+            (ECB_entries_unit_id(pecb,idx) == 0)) {
+            PCI_MMIO_Write_U64(virtual_addr, ECB_entries_reg_id(pecb,idx_w), ECB_entries_reg_value(pecb,idx_w));
+            control_node.u.bit_field = ECB_entries_reg_value(pecb,idx_w);
+            event_code = (U32)control_node.u.bits.event_select;
+            idx_w++;
+        }
+
+        if (IS_64BIT((U64)(ECB_entries_max_bits(pecb,idx)))) {
+            if (ECB_entries_counter_type(pecb,idx) == PROG_FREERUN_COUNTER) {
+                do {
+                    if (counter > EVENT_COUNTER_MAX_TRY) {
+                        break;
+                    }
+                    value = SYS_MMIO_Read64(virtual_addr, offset_delta);
+                    counter++;
+                } while (event_code != (value >>60));
+            }
+            value = SYS_MMIO_Read64(virtual_addr, offset_delta);
+        }
+        else {
+            value = SYS_MMIO_Read32(virtual_addr, offset_delta);
+        }
+        value &= (U64)ECB_entries_max_bits(pecb,idx);
+
+        data = (U64 *)((S8*)param + ECB_entries_counter_event_offset(pecb,idx));
+        //check for overflow if not a static counter
+        if (ECB_entries_counter_type(pecb,idx) == STATIC_COUNTER) {
+            *data = value;
+        }
+        else {
+            if (value < LWPMU_DEVICE_prev_value(&devices[id])[package_num][index]) {
+                diff = LWPMU_DEVICE_counter_mask(&devices[id]) - LWPMU_DEVICE_prev_value(&devices[id])[package_num][index];
+                diff += value;
+            }
+            else {
+                diff = value - LWPMU_DEVICE_prev_value(&devices[id])[package_num][index];
+            }
+            LWPMU_DEVICE_acc_value(&devices[id])[package_num][cur_grp][index] += diff;
+            LWPMU_DEVICE_prev_value(&devices[id])[package_num][index] = value;
+            *data = LWPMU_DEVICE_acc_value(&devices[id])[package_num][cur_grp][index];
+        }
+        index++;
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn unc_mmio_Read_PMU_Data(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read all the data MSR's into a buffer.  Called by the interrupt handler.
+ *
+ */
+static VOID
+unc_mmio_Read_PMU_Data (
+     PVOID   param
+)
+{
+    U32            j;
+    U64           *buffer       = read_counter_info;
+    U64           *prev_buffer  = prev_counter_data;
+    U32            this_cpu;
+    U32            dev_idx;
+    DEV_UNC_CONFIG pcfg_unc;
+    U32            offset_delta;
+    U32            cur_grp;
+    ECB            pecb;
+    U64            tmp_value    = 0ULL;
+    U64            virtual_addr = 0;
+    U32            idx_w        = 0;
+    U32            event_code   = 0;
+    U32            counter      = 0;
+    U32            num_events   = 0;
+    U32            package_num;
+    U32            entry        = 0;
+    U32            dev_node     = 0;
+    U32            num_pkgs     = num_packages;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx     = *((U32*)param);
+    this_cpu    = CONTROL_THIS_CPU();
+    pcfg_unc    = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(&devices[dev_idx]);
+    if (!IS_MASTER(DEV_UNC_CONFIG_device_type(pcfg_unc), this_cpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!IS_MASTER).");
+        return;
+    }
+
+    package_num = GET_PACKAGE_NUM(DEV_UNC_CONFIG_device_type(pcfg_unc), this_cpu);
+    cur_grp     = LWPMU_DEVICE_cur_group(&devices[(dev_idx)])[package_num];
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[(dev_idx)])[(cur_grp)];
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    dev_node    = ECB_dev_node(pecb);
+    entry       = package_num;
+    if (!IS_MMIO_MAP_VALID(dev_node, entry)) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Early exit (!IS_MMIO_MAP_VALID).");
+        return;
+    }
+    if (DEV_UNC_CONFIG_device_type(pcfg_unc) == DRV_SINGLE_INSTANCE) {
+        num_pkgs    = 1;
+    }
+
+    virtual_addr = virtual_address_table(dev_node, entry);
+
+    num_events = ECB_num_events(pecb);
+
+    idx_w = ECB_operations_register_start(pecb, PMU_OPERATION_WRITE);
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_READ) {
+
+        if (ECB_entries_reg_offset(pecb,idx) > DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(&ECB_pcidev_entry_node(pecb))) {
+            offset_delta =  ECB_entries_reg_offset(pecb,idx) -
+                              DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(&ECB_pcidev_entry_node(pecb));
+        }
+        else {
+            offset_delta =  ECB_entries_reg_offset(pecb,idx);
+        }
+
+        if ((DEV_UNC_CONFIG_device_type(pcfg_unc) == DRV_SINGLE_INSTANCE)  &&
+            (GET_NUM_MAP_ENTRIES(dev_node) > 1))   {
+            // multiple MMIO mapping per <dev_no, func_no> device, find virtual_addr per mapping.
+            entry = ECB_entries_unit_id(pecb,idx);
+            virtual_addr = virtual_address_table(dev_node, entry);
+        }
+
+        if ((ECB_entries_counter_type(pecb,idx) == PROG_FREERUN_COUNTER) &&
+            (ECB_entries_unit_id(pecb,idx) == 0)) {
+            PCI_MMIO_Write_U64(virtual_addr, ECB_entries_reg_id(pecb,idx_w), ECB_entries_reg_value(pecb,idx_w));
+            control_node.u.bit_field = ECB_entries_reg_value(pecb,idx_w);
+            event_code = (U32)control_node.u.bits.event_select;
+            idx_w++;
+        }
+
+        if ((ECB_entries_event_scope(pecb,idx) == PACKAGE_EVENT) ||
+            (ECB_entries_event_scope(pecb,idx) == SYSTEM_EVENT)) {
+
+            if (ECB_entries_event_scope(pecb,idx) == SYSTEM_EVENT) {
+                j = ECB_entries_uncore_buffer_offset_in_system(pecb, idx);
+            }
+            else {
+                j = EMON_BUFFER_UNCORE_PACKAGE_EVENT_OFFSET(package_num, EMON_BUFFER_DRIVER_HELPER_num_entries_per_package(emon_buffer_driver_helper),
+                                                            ECB_entries_uncore_buffer_offset_in_package(pecb, idx));
+            }
+
+            if (IS_64BIT((U64)(ECB_entries_max_bits(pecb,idx)))) {
+                if (ECB_entries_counter_type(pecb,idx) == PROG_FREERUN_COUNTER) {
+                    do {
+                        if (counter > EVENT_COUNTER_MAX_TRY) {
+                            break;
+                        }
+                        tmp_value = SYS_MMIO_Read64(virtual_addr, offset_delta);
+                        counter++;
+                    } while (event_code != (tmp_value >>60));
+                }
+                tmp_value = SYS_MMIO_Read64(virtual_addr, offset_delta);
+            }
+            else {
+                tmp_value = SYS_MMIO_Read32(virtual_addr, offset_delta);
+            }
+            tmp_value &= (U64)ECB_entries_max_bits(pecb,idx);
+            if (ECB_entries_counter_type(pecb,idx) == STATIC_COUNTER) {
+                buffer[j] = tmp_value;
+            }
+            else {
+                if (tmp_value >= prev_buffer[j]) {
+                    buffer[j] = tmp_value - prev_buffer[j];
+                }
+                else {
+                    buffer[j] = tmp_value + (ECB_entries_max_bits(pecb,idx) - prev_buffer[j]);
+                }
+            }
+            SEP_DRV_LOG_TRACE("j=%u, value=%llu, cpu=%u, MSR=0x%x", j, buffer[j], this_cpu, ECB_entries_reg_id(pecb,idx));
+        }
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn unc_mmio_Initialize(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Do the mapping of the physical address (to do the invalidates in the TLB)
+ *           NOTE: this should never be done with SMP call
+ *
+ */
+static VOID
+unc_mmio_Initialize (
+     PVOID   param
+)
+{
+    DRV_PCI_DEVICE_ENTRY_NODE  dpden;
+
+    U64                        bar;
+
+    U64                        physical_address;
+    U32                        dev_idx           = 0;
+    U32                        cur_grp           = 0;
+    ECB                        pecb              = NULL;
+    U32                        dev_node;
+    U32                        i                 = 0;
+    U32                        page_len          = 4096;         // 4K
+
+    U32                        use_default_busno = 0;
+    U32                        entries           = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx  = *((U32*)param);
+    cur_grp  = LWPMU_DEVICE_cur_group(&devices[(dev_idx)])[0];
+    pecb     = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+    dev_node = ECB_dev_node(pecb);
+
+
+    if (IS_MMIO_MAP_VALID(dev_node, 0)) {
+        SEP_DRV_LOG_INIT_TRACE_OUT("Early exit (device[%d] node %d already mapped).", dev_idx, dev_node);
+        return;
+    }
+
+    dpden = ECB_pcidev_entry_node(pecb);
+
+    // use busno found from topology scan if available
+    // otherwise use the default one
+    entries = GET_NUM_MAP_ENTRIES(dev_node);
+    if (entries == 0) {
+        use_default_busno = 1;
+        entries = 1;  // this could the client, does not through the scan
+        UNC_PCIDEV_num_entries(&(unc_pcidev_map[dev_node])) = 1;
+        UNC_PCIDEV_max_entries(&(unc_pcidev_map[dev_node])) = 1;
+    }
+    if (!UNC_PCIDEV_mmio_map(&(unc_pcidev_map[dev_node]))) {
+        // it is better to allocate space in the beginning
+        UNC_PCIDEV_mmio_map(&(unc_pcidev_map[dev_node])) =  CONTROL_Allocate_Memory(entries * sizeof(SEP_MMIO_NODE));
+        if (UNC_PCIDEV_mmio_map(&(unc_pcidev_map[dev_node])) == NULL) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("Early exit (No Memory).");
+            return;
+        }
+        memset(UNC_PCIDEV_mmio_map(&(unc_pcidev_map[dev_node])), 0, entries * sizeof(U64));
+    }
+    for (i = 0; i < entries; i++) {
+        if  (!use_default_busno)               {
+            if (IS_BUS_MAP_VALID(dev_node, i)) {
+                DRV_PCI_DEVICE_ENTRY_bus_no(&dpden) = UNC_PCIDEV_busno_entry(&(unc_pcidev_map[dev_node]), i);
+            }
+        }
+
+        bar  = PCI_Read_U64(DRV_PCI_DEVICE_ENTRY_bus_no(&dpden),
+                            DRV_PCI_DEVICE_ENTRY_dev_no(&dpden),
+                            DRV_PCI_DEVICE_ENTRY_func_no(&dpden),
+                            DRV_PCI_DEVICE_ENTRY_bar_offset(&dpden));
+
+        bar &= DRV_PCI_DEVICE_ENTRY_bar_mask(&dpden);
+
+        DRV_PCI_DEVICE_ENTRY_bar_address(&ECB_pcidev_entry_node(pecb)) = bar;
+        physical_address     = DRV_PCI_DEVICE_ENTRY_bar_address(&ECB_pcidev_entry_node(pecb))
+                                     + DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(&ECB_pcidev_entry_node(pecb));
+
+        PCI_Map_Memory(&UNC_PCIDEV_mmio_map_entry(&(unc_pcidev_map[dev_node]), i), physical_address, page_len);
+    }
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn unc_mmio_fpga_Initialize(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Do the mapping of the physical address (to do the invalidates in the TLB)
+ *           NOTE: this should never be done with SMP call
+ *
+ */
+static VOID
+unc_mmio_fpga_Initialize (
+     PVOID   param
+)
+{
+#if defined(DRV_EM64T)
+    U64              phys_addr;
+    SEP_MMIO_NODE    tmp_map     = {0};
+    U64              virt_addr;
+    U64              dfh;
+    U32              id;
+    U32              offset      = 0;
+    S32              next_offset = -1;
+    U32              dev_idx;
+    U32              cur_grp;
+    ECB              pecb;
+    U32              bus_list[2] = {0x5e, 0xbe};
+    U32              busno;
+    U32              page_len    = 4096;
+    U32              package_num = 0;
+    U32              dev_node    = 0;
+    U32              entries     = 0;
+    DRV_PCI_DEVICE_ENTRY_NODE  dpden;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx = *((U32*)param);
+    cur_grp = LWPMU_DEVICE_cur_group(&devices[(dev_idx)])[0];
+    pecb    = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    dev_node = ECB_dev_node(pecb);
+
+    entries = GET_NUM_MAP_ENTRIES(dev_node);
+    if (entries == 0) {
+        entries = num_packages;
+    }
+
+    if (!UNC_PCIDEV_mmio_map(&(unc_pcidev_map[dev_node]))) {
+        // it is better to allocate space in the beginning
+        UNC_PCIDEV_mmio_map(&(unc_pcidev_map[dev_node])) =  CONTROL_Allocate_Memory(entries * sizeof(SEP_MMIO_NODE));
+        if (UNC_PCIDEV_mmio_map(&(unc_pcidev_map[dev_node])) == NULL) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("Early exit (No Memory).");
+            return;
+        }
+        memset(UNC_PCIDEV_mmio_map(&(unc_pcidev_map[dev_node])), 0, (entries * sizeof(SEP_MMIO_NODE)));
+        UNC_PCIDEV_num_entries(&(unc_pcidev_map[dev_node])) = 0;
+        UNC_PCIDEV_max_entries(&(unc_pcidev_map[dev_node])) = entries;
+    }
+    else {
+        if (virtual_address_table(dev_node, 0) != 0) {
+            SEP_DRV_LOG_INIT_TRACE_OUT("Early exit (device[%d] node %d already mapped).", dev_idx, dev_node);
+            return;
+        }
+    }
+
+    dpden = ECB_pcidev_entry_node(pecb);
+
+    for (package_num = 0; package_num < num_packages; package_num++) {
+        if (package_num < 2) {
+            busno = bus_list[package_num];
+        }
+        else {
+            busno = 0;
+        }
+        phys_addr = PCI_Read_U64(busno,
+                                 DRV_PCI_DEVICE_ENTRY_dev_no(&dpden),
+                                 DRV_PCI_DEVICE_ENTRY_func_no(&dpden),
+                                 DRV_PCI_DEVICE_ENTRY_bar_offset(&dpden));
+        phys_addr &= DRV_PCI_DEVICE_ENTRY_bar_mask(&dpden);
+        if (package_num == 0) {
+            PCI_Map_Memory(&tmp_map, phys_addr, 8 * page_len);
+            virt_addr = SEP_MMIO_NODE_virtual_address(&tmp_map);
+            while (next_offset != 0) {
+                dfh = SYS_MMIO_Read64((U64)virt_addr, offset);
+                next_offset = (U32)((dfh >> 16) & 0xffffff);
+                id = (U32)(dfh & 0xfff);
+                if (offset && (id == DRV_PCI_DEVICE_ENTRY_feature_id(&dpden))) {
+                    break;
+                }
+                offset += next_offset;
+            }
+            PCI_Unmap_Memory(&tmp_map);
+        }
+        phys_addr += offset;
+        PCI_Map_Memory(&UNC_PCIDEV_mmio_map_entry(&(unc_pcidev_map[dev_node]), package_num), phys_addr, 8 * page_len);
+        UNC_PCIDEV_num_entries(&(unc_pcidev_map[dev_node]))++;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+#endif
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn unc_mmio_Destroy(param)
+ *
+ * @param    param    dummy parameter which is not used
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Invalidate the entry in TLB of the physical address
+ *           NOTE: this should never be done with SMP call
+ *
+ */
+static VOID
+unc_mmio_Destroy (
+     PVOID   param
+)
+{
+    U32 dev_idx;
+    U32            i;
+    U64            addr         = 0;
+    U32            cur_grp      = 0;
+    U32            dev_node     = 0;
+    U32            entries      = 0;
+    ECB            pecb;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx = *((U32*)param);
+    cur_grp = LWPMU_DEVICE_cur_group(&devices[(dev_idx)])[0];
+    pecb    = LWPMU_DEVICE_PMU_register_data(&devices[dev_idx])[cur_grp];
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+    dev_node = ECB_dev_node(pecb);
+
+    if (!UNC_PCIDEV_mmio_map(&(unc_pcidev_map[dev_node]))) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (no mapping).");
+        return;
+    }
+
+    entries = GET_NUM_MAP_ENTRIES(dev_node);
+
+    for (i = 0; i < entries; i++) {
+        addr = virtual_address_table(dev_node, i);
+        if (addr) {
+            PCI_Unmap_Memory(&UNC_PCIDEV_mmio_map_entry(&(unc_pcidev_map[dev_node]), i));
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/*
+ * Initialize the dispatch table
+ */
+DISPATCH_NODE  unc_mmio_dispatch =
+{
+    .init                     = unc_mmio_Initialize,
+    .fini                     = unc_mmio_Destroy,
+    .write                    = unc_mmio_Write_PMU,
+    .freeze                   = unc_mmio_Disable_PMU,
+    .restart                  = unc_mmio_Enable_PMU,
+    .read_data                = unc_mmio_Read_PMU_Data,
+    .check_overflow           = NULL,
+    .swap_group               = NULL,
+    .read_lbrs                = NULL,
+    .cleanup                  = UNC_COMMON_Dummy_Func,
+    .hw_errata                = NULL,
+    .read_power               = NULL,
+    .check_overflow_errata    = NULL,
+    .read_counts              = NULL,
+    .check_overflow_gp_errata = NULL,
+    .read_ro                  = NULL,
+    .platform_info            = NULL,
+    .trigger_read             = unc_mmio_Trigger_Read,
+    .scan_for_uncore          = NULL,
+    .read_metrics             = NULL
+};
+
+DISPATCH_NODE  unc_mmio_fpga_dispatch =
+{
+    .init                     = unc_mmio_fpga_Initialize,
+    .fini                     = unc_mmio_Destroy,
+    .write                    = unc_mmio_Write_PMU,
+    .freeze                   = unc_mmio_Disable_PMU,
+    .restart                  = unc_mmio_Enable_PMU,
+    .read_data                = unc_mmio_Read_PMU_Data,
+    .check_overflow           = NULL,
+    .swap_group               = NULL,
+    .read_lbrs                = NULL,
+    .cleanup                  = UNC_COMMON_Dummy_Func,
+    .hw_errata                = NULL,
+    .read_power               = NULL,
+    .check_overflow_errata    = NULL,
+    .read_counts              = NULL,
+    .check_overflow_gp_errata = NULL,
+    .read_ro                  = NULL,
+    .platform_info            = NULL,
+    .trigger_read             = unc_mmio_Trigger_Read,
+    .scan_for_uncore          = NULL,
+    .read_metrics             = NULL
+};
+
+
+
diff --git a/drivers/misc/intel/sepdk/sep/unc_msr.c b/drivers/misc/intel/sepdk/sep/unc_msr.c
new file mode 100644
index 000000000000..21ecacf8b3ec
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/unc_msr.c
@@ -0,0 +1,354 @@
+/****
+    Copyright(C) 2012-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit.
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+
+
+
+
+#include "lwpmudrv_defines.h"
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+#include "inc/ecb_iterators.h"
+#include "inc/control.h"
+#include "inc/unc_common.h"
+#include "inc/utility.h"
+
+extern U64                        *read_counter_info;
+extern EMON_BUFFER_DRIVER_HELPER   emon_buffer_driver_helper;
+extern DRV_CONFIG                  drv_cfg;
+
+/*!
+ * @fn          static VOID UNC_COMMON_MSR_Write_PMU(VOID*)
+ *
+ * @brief       Initial write of PMU registers
+ *              Walk through the enties and write the value of the register accordingly.
+ *              When current_group = 0, then this is the first time this routine is called,
+ *
+ * @param       None
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+UNC_MSR_Write_PMU (
+    PVOID            param
+)
+{
+    U32        dev_idx;
+    U32        this_cpu;
+    CPU_STATE  pcpu;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx  = *((U32*)param);
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+
+    if (!CPU_STATE_socket_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!CPU_STATE_socket_master).");
+        return;
+    }
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_WRITE) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb,idx), ECB_entries_reg_value(pecb,idx));
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_READ) {
+        SYS_Write_MSR(ECB_entries_reg_id(pecb,idx), 0ULL);
+        if (LWPMU_DEVICE_counter_mask(&devices[dev_idx]) == 0) {
+            LWPMU_DEVICE_counter_mask(&devices[dev_idx]) = (U64)ECB_entries_max_bits(pecb,idx);
+        }
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*!
+ * @fn         static VOID UNC_MSR_Enable_PMU(PVOID)
+ *
+ * @brief      Set the enable bit for all the evsel registers
+ *
+ * @param      None
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+UNC_MSR_Enable_PMU (
+    PVOID param
+)
+{
+    U32        dev_idx;
+    U32        this_cpu;
+    CPU_STATE  pcpu;
+    U64        reg_val = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx  = *((U32*)param);
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+
+    if (!CPU_STATE_socket_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!CPU_STATE_socket_master).");
+        return;
+    }
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_ENABLE) {
+        reg_val = ECB_entries_reg_value(pecb,idx);
+        if (ECB_entries_reg_rw_type(pecb, idx)  == PMU_REG_RW_READ_WRITE) {
+            reg_val = SYS_Read_MSR(ECB_entries_reg_id(pecb,idx));
+            if (ECB_entries_reg_type(pecb,idx) == PMU_REG_UNIT_CTRL) {
+                reg_val &= ECB_entries_reg_value(pecb,idx);
+            }
+            else {
+                reg_val |= ECB_entries_reg_value(pecb,idx);
+            }
+        }
+        SYS_Write_MSR(ECB_entries_reg_id(pecb,idx), reg_val);
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/*!
+ * @fn         static VOID UNC_MSR_Disable_PMU(PVOID)
+ *
+ * @brief      Set the enable bit for all the evsel registers
+ *
+ * @param      None
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+UNC_MSR_Disable_PMU (
+    PVOID param
+)
+{
+    U32        dev_idx;
+    U32        this_cpu;
+    CPU_STATE  pcpu;
+    U64        reg_val = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx  = *((U32*)param);
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+
+    if (!CPU_STATE_socket_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!CPU_STATE_socket_master).");
+        return;
+    }
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_DISABLE) {
+        reg_val = ECB_entries_reg_value(pecb,idx);
+        if (ECB_entries_reg_rw_type(pecb, idx)  == PMU_REG_RW_READ_WRITE) {
+            reg_val = SYS_Read_MSR(ECB_entries_reg_id(pecb,idx));
+            if (ECB_entries_reg_type(pecb,idx) == PMU_REG_UNIT_CTRL) {
+                reg_val |= ECB_entries_reg_value(pecb,idx);
+            }
+            else {
+                reg_val &= ECB_entries_reg_value(pecb,idx);
+            }
+        }
+        SYS_Write_MSR(ECB_entries_reg_id(pecb,idx), reg_val);
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*!
+ * @fn static VOID UNC_MSR_Read_PMU_Data(param)
+ *
+ * @param    param    The read thread node to process
+ * @param    id       The id refers to the device index
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the Uncore count data and store into the buffer
+ *           Let us say we have 2 core events in a dual socket JKTN;
+ *           The start_index will be at 32 as it will 2 events in 16 CPU per socket
+ *           The position for first event of QPI will be computed based on its event
+ *
+ */
+static VOID
+UNC_MSR_Read_PMU_Data (
+    PVOID  param
+)
+{
+    U32         j             = 0;
+    U32         dev_idx;
+    U32         this_cpu;
+    U32         package_num   = 0;
+    U64        *buffer;
+    CPU_STATE   pcpu;
+    U32         cur_grp;
+    ECB         pecb;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx     = *((U32*)param);
+    this_cpu    = CONTROL_THIS_CPU();
+    buffer      = read_counter_info;
+    pcpu        = &pcb[this_cpu];
+    package_num = core_to_package_map[this_cpu];
+    cur_grp     = LWPMU_DEVICE_cur_group(&devices[(dev_idx)])[package_num];
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[(dev_idx)])[cur_grp];
+
+    // NOTE THAT the read_pmu function on for EMON collection.
+    if (!DRV_CONFIG_emon_mode(drv_cfg)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!emon_mode).");
+        return;
+    }
+    if (!CPU_STATE_socket_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!CPU_STATE_socket_master).");
+        return;
+    }
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    //Read in the counts into temporary buffer
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_READ) {
+
+        if (ECB_entries_event_scope(pecb,idx) == SYSTEM_EVENT) {
+            j = ECB_entries_uncore_buffer_offset_in_system(pecb, idx);
+        }
+        else {
+            j = EMON_BUFFER_UNCORE_PACKAGE_EVENT_OFFSET(package_num, EMON_BUFFER_DRIVER_HELPER_num_entries_per_package(emon_buffer_driver_helper),
+                                                        ECB_entries_uncore_buffer_offset_in_package(pecb,idx));
+        }
+
+        buffer[j] = SYS_Read_MSR(ECB_entries_reg_id(pecb,idx));
+        SEP_DRV_LOG_TRACE("j=%u, value=%llu, cpu=%u, event_id=%u", j, buffer[j], this_cpu, ECB_entries_core_event_id(pecb,idx));
+
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       static VOID UNC_MSR_Trigger_Read(id)
+ *
+ * @param    id       Device index
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the Uncore data from counters and store into buffer
+ */
+static VOID
+UNC_MSR_Trigger_Read (
+    PVOID  param,
+    U32    id
+)
+{
+    U32             this_cpu;
+    U32             package_num;
+    U32             cur_grp;
+    ECB             pecb;
+    U32             index = 0;
+    U64             diff  = 0;
+    U64             value;
+    U64            *data;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p, id: %u.", param, id);
+
+    this_cpu    = CONTROL_THIS_CPU();
+    package_num = core_to_package_map[this_cpu];
+    cur_grp     = LWPMU_DEVICE_cur_group(&devices[id])[package_num];
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[id])[cur_grp];
+
+    // Write GroupID
+    data = (U64*)((S8*)param + ECB_group_offset(pecb));
+    *data = cur_grp + 1;
+    //Read in the counts into uncore buffer
+    FOR_EACH_REG_UNC_OPERATION(pecb, id, idx, PMU_OPERATION_READ) {
+        value = SYS_Read_MSR(ECB_entries_reg_id(pecb,idx));
+        //check for overflow
+        if (value < LWPMU_DEVICE_prev_value(&devices[id])[package_num][index]) {
+            diff = LWPMU_DEVICE_counter_mask(&devices[id]) - LWPMU_DEVICE_prev_value(&devices[id])[package_num][index];
+            diff += value;
+        }
+        else {
+            diff = value - LWPMU_DEVICE_prev_value(&devices[id])[package_num][index];
+        }
+        LWPMU_DEVICE_acc_value(&devices[id])[package_num][cur_grp][index] += diff;
+        LWPMU_DEVICE_prev_value(&devices[id])[package_num][index] = value;
+        data  = (U64 *)((S8*)param + ECB_entries_counter_event_offset(pecb,idx));
+        *data = LWPMU_DEVICE_acc_value(&devices[id])[package_num][cur_grp][index];
+        index++;
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/*
+ * Initialize the dispatch table
+ */
+DISPATCH_NODE  unc_msr_dispatch =
+{
+    NULL,                                // initialize
+    NULL,                                // destroy
+    UNC_MSR_Write_PMU,                   // write
+    UNC_MSR_Disable_PMU,                 // freeze
+    UNC_MSR_Enable_PMU,                  // restart
+    UNC_MSR_Read_PMU_Data,               // read
+    NULL,                                // check for overflow
+    NULL,                                // swap group
+    NULL,                                // read lbrs
+    UNC_COMMON_MSR_Clean_Up,             // cleanup
+    NULL,                                // hw errata
+    NULL,                                // read power
+    NULL,                                // check overflow errata
+    NULL,                                // read counts
+    NULL,                                // check overflow gp errata
+    NULL,                                // read_ro
+    NULL,                                // platform info
+    UNC_MSR_Trigger_Read,                // trigger read
+    NULL,                                // scan for uncore
+    NULL                                 // read metrics
+};
+
+
diff --git a/drivers/misc/intel/sepdk/sep/unc_pci.c b/drivers/misc/intel/sepdk/sep/unc_pci.c
new file mode 100644
index 000000000000..a1da4ce7ddd1
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/unc_pci.c
@@ -0,0 +1,498 @@
+/****
+    Copyright(C) 2012-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit.
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+
+
+
+
+#include "lwpmudrv_defines.h"
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+#include "inc/ecb_iterators.h"
+#include "inc/control.h"
+#include "inc/unc_common.h"
+#include "inc/utility.h"
+#include "inc/pci.h"
+
+extern U64                        *read_counter_info;
+extern UNCORE_TOPOLOGY_INFO_NODE   uncore_topology;
+extern EMON_BUFFER_DRIVER_HELPER   emon_buffer_driver_helper;
+extern DRV_CONFIG                  drv_cfg;
+
+
+/*!
+ * @fn          static VOID unc_pci_Write_PMU(VOID*)
+ *
+ * @brief       Initial write of PMU registers
+ *              Walk through the enties and write the value of the register accordingly.
+ *              When current_group = 0, then this is the first time this routine is called,
+ *
+ * @param       None
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+unc_pci_Write_PMU (
+    PVOID            param
+)
+{
+    U32         device_id;
+    U32         dev_idx;
+    U32         value;
+    U32         vendor_id;
+    U32         this_cpu;
+    CPU_STATE   pcpu;
+    U32         package_num   = 0;
+    U32         dev_node      = 0;
+    U32         cur_grp;
+    ECB         pecb;
+    U32         busno;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx     = *((U32*)param);
+    this_cpu    = CONTROL_THIS_CPU();
+    pcpu        = &pcb[this_cpu];
+    package_num = core_to_package_map[this_cpu];
+    cur_grp     = LWPMU_DEVICE_cur_group(&devices[(dev_idx)])[package_num];
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[(dev_idx)])[cur_grp];
+
+    if (!CPU_STATE_socket_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!CPU_STATE_socket_master).");
+        return;
+    }
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    // first, figure out which package maps to which bus
+    dev_node = ECB_dev_node(pecb);
+    if (!IS_BUS_MAP_VALID(dev_node, package_num)) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("No UNC_PCIDEV bus map for %u!", dev_node);
+        return;
+    }
+
+    busno = GET_BUS_MAP(dev_node, package_num);
+
+    LWPMU_DEVICE_pci_dev_node_index(&devices[dev_idx]) = dev_node;
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_WRITE) {
+        if (ECB_entries_reg_type(pecb, idx)  == PMU_REG_GLOBAL_CTRL) {
+             //Check if we need to zero this MSR out
+             SYS_Write_MSR(ECB_entries_reg_id(pecb,idx), 0LL);
+             continue;
+        }
+
+        // otherwise, we have a valid entry
+        // now we just need to find the corresponding bus #
+        ECB_entries_bus_no(pecb,idx) = busno;
+        value = PCI_Read_U32(busno, ECB_entries_dev_no(pecb,idx), ECB_entries_func_no(pecb,idx), 0);
+
+        CONTINUE_IF_NOT_GENUINE_INTEL_DEVICE(value, vendor_id, device_id);
+
+        if (ECB_entries_reg_type(pecb, idx)  == PMU_REG_UNIT_CTRL) {
+             // busno can not be stored in ECB because different sockets have different bus no.
+             PCI_Write_U32(busno,
+                       ECB_entries_dev_no(pecb,idx),
+                       ECB_entries_func_no(pecb,idx),
+                       ECB_entries_reg_id(pecb,idx),
+                       (U32)ECB_entries_reg_value(pecb,idx));
+             continue;
+        }
+
+        // now program at the corresponding offset
+        PCI_Write_U32(busno,
+                  ECB_entries_dev_no(pecb,idx),
+                  ECB_entries_func_no(pecb,idx),
+                  ECB_entries_reg_id(pecb,idx),
+                  (U32)ECB_entries_reg_value(pecb,idx));
+
+        if ((ECB_entries_reg_value(pecb,idx) >> NEXT_ADDR_SHIFT) != 0) {
+            PCI_Write_U32(busno,
+                      ECB_entries_dev_no(pecb,idx),
+                      ECB_entries_func_no(pecb,idx),
+                      ECB_entries_reg_id(pecb,idx) + NEXT_ADDR_OFFSET,
+                      (U32)(ECB_entries_reg_value(pecb,idx) >> NEXT_ADDR_SHIFT));
+        }
+
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_READ) {
+        PCI_Write_U64(busno,
+                  ECB_entries_dev_no(pecb,idx),
+                  ECB_entries_func_no(pecb,idx),
+                  ECB_entries_reg_id(pecb,idx),
+                  0);
+
+        // this is needed for overflow detection of the accumulators.
+        if (LWPMU_DEVICE_counter_mask(&devices[dev_idx]) == 0) {
+             LWPMU_DEVICE_counter_mask(&devices[dev_idx]) = (U64)ECB_entries_max_bits(pecb,idx);
+        }
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*!
+ * @fn         static VOID unc_pci_Enable_PMU(PVOID)
+ *
+ * @brief      Set the enable bit for all the EVSEL registers
+ *
+ * @param      Device Index of this PMU unit
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+unc_pci_Enable_PMU (
+    PVOID               param
+)
+{
+    U32            dev_idx;
+    U32            this_cpu;
+    CPU_STATE      pcpu;
+    U32            package_num   = 0;
+    U32            dev_node;
+    U32            reg_val       = 0;
+    U32            busno;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx  = *((U32 *)param);
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+    dev_node = LWPMU_DEVICE_pci_dev_node_index(&devices[dev_idx]);
+
+    if (!CPU_STATE_socket_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!CPU_STATE_socket_master).");
+        return;
+    }
+
+    package_num         = core_to_package_map[this_cpu];
+
+    if (!IS_BUS_MAP_VALID(dev_node, package_num)) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("No UNC_PCIDEV bus map for %u!", dev_node);
+        return;
+    }
+
+    busno = GET_BUS_MAP(dev_node, package_num);
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_ENABLE) {
+        if (ECB_entries_reg_type(pecb, idx)  == PMU_REG_GLOBAL_CTRL) {
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,idx), ECB_entries_reg_value(pecb,idx));
+            continue;
+        }
+        reg_val = (U32)ECB_entries_reg_value(pecb,idx);
+        if (ECB_entries_reg_rw_type(pecb, idx)  == PMU_REG_RW_READ_WRITE) {
+            reg_val = PCI_Read_U32(busno,
+                             ECB_entries_dev_no(pecb,idx),
+                             ECB_entries_func_no(pecb,idx),
+                             ECB_entries_reg_id(pecb,idx));
+            reg_val &= ECB_entries_reg_value(pecb,idx);
+        }
+        PCI_Write_U32(busno,
+               ECB_entries_dev_no(pecb,idx),
+               ECB_entries_func_no(pecb,idx),
+               ECB_entries_reg_id(pecb,idx),
+               reg_val);
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*!
+ * @fn           static VOID unc_pci_Disable_PMU(PVOID)
+ *
+ * @brief        Disable the per unit global control to stop the PMU counters.
+ *
+ * @param        Device Index of this PMU unit
+ * @control_msr  Control MSR address
+ * @enable_val   If counter freeze bit does not work, counter enable bit should be cleared
+ * @disable_val  Disable collection
+ *
+ * @return       None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+unc_pci_Disable_PMU (
+    PVOID               param
+)
+{
+    U32            dev_idx;
+    U32            this_cpu;
+    CPU_STATE      pcpu;
+    U32            package_num   = 0;
+    U32            dev_node;
+    U32            reg_val       = 0;
+    U32            busno;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx      = *((U32 *)param);
+    this_cpu     = CONTROL_THIS_CPU();
+    pcpu         = &pcb[this_cpu];
+    dev_node     = LWPMU_DEVICE_pci_dev_node_index(&devices[dev_idx]);
+
+    if (!CPU_STATE_socket_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!CPU_STATE_socket_master).");
+        return;
+    }
+
+    package_num         = core_to_package_map[this_cpu];
+
+    if (!IS_BUS_MAP_VALID(dev_node, package_num)) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("No UNC_PCIDEV bus map for %u!", dev_node);
+        return;
+    }
+
+    busno = GET_BUS_MAP(dev_node, package_num);
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_DISABLE) {
+        if (ECB_entries_reg_type(pecb, idx)  == PMU_REG_GLOBAL_CTRL) {
+            SYS_Write_MSR(ECB_entries_reg_id(pecb,idx), ECB_entries_reg_value(pecb,idx));
+            continue;
+        }
+        reg_val = (U32)ECB_entries_reg_value(pecb,idx);
+        if (ECB_entries_reg_rw_type(pecb, idx)  == PMU_REG_RW_READ_WRITE) {
+            reg_val = PCI_Read_U32(busno,
+                             ECB_entries_dev_no(pecb,idx),
+                             ECB_entries_func_no(pecb,idx),
+                             ECB_entries_reg_id(pecb,idx));
+            reg_val |= ECB_entries_reg_value(pecb,idx);
+        }
+        PCI_Write_U32(busno,
+               ECB_entries_dev_no(pecb,idx),
+               ECB_entries_func_no(pecb,idx),
+               ECB_entries_reg_id(pecb,idx),
+               reg_val);
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       static VOID unc_pci_Trigger_Read(id)
+ *
+ * @param    id       Device index
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the Uncore data from counters and store into buffer
+ */
+static  VOID
+unc_pci_Trigger_Read (
+    PVOID  param,
+    U32    id
+)
+{
+    U32             this_cpu      = 0;
+    U32             package_num   = 0;
+    U32             dev_node      = 0;
+    U32             cur_grp       = 0;
+    ECB             pecb          = NULL;
+    U32             index         = 0;
+    U64             value_low     = 0;
+    U64             value_high    = 0;
+    U64             diff          = 0;
+    U64             value;
+    U64            *data;
+    U32             busno;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p, id: %u.", param, id);
+
+    this_cpu      = CONTROL_THIS_CPU();
+    package_num   = core_to_package_map[this_cpu];
+    dev_node      = LWPMU_DEVICE_pci_dev_node_index(&devices[id]);
+    cur_grp       = LWPMU_DEVICE_cur_group(&devices[id])[package_num];
+    pecb          = LWPMU_DEVICE_PMU_register_data(&devices[id])[cur_grp];
+
+    if (!IS_BUS_MAP_VALID(dev_node, package_num)) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("No UNC_PCIDEV bus map for %u!", dev_node);
+        return;
+    }
+
+    busno = GET_BUS_MAP(dev_node, package_num);
+
+    // Write GroupID
+    data = (U64*)((S8*)param + ECB_group_offset(pecb));
+    *data = cur_grp + 1;
+    // Read the counts into uncore buffer
+    FOR_EACH_REG_UNC_OPERATION(pecb, id, idx, PMU_OPERATION_READ) {
+        // read lower 4 bytes
+        value_low = PCI_Read_U32(busno,
+                             ECB_entries_dev_no(pecb,idx),
+                             ECB_entries_func_no(pecb,idx),
+                             ECB_entries_reg_id(pecb,idx));
+        value = LOWER_4_BYTES_MASK & value_low;
+
+        // read upper 4 bytes
+        value_high = PCI_Read_U32(busno,
+                              ECB_entries_dev_no(pecb,idx),
+                              ECB_entries_func_no(pecb,idx),
+                              (ECB_entries_reg_id(pecb,idx) + NEXT_ADDR_OFFSET));
+        value |= value_high << NEXT_ADDR_SHIFT;
+        //check for overflow
+        if (value < LWPMU_DEVICE_prev_value(&devices[id])[package_num][index]) {
+            diff = LWPMU_DEVICE_counter_mask(&devices[id]) - LWPMU_DEVICE_prev_value(&devices[id])[package_num][index];
+            diff += value;
+        }
+        else {
+            diff = value - LWPMU_DEVICE_prev_value(&devices[id])[package_num][index];
+        }
+        LWPMU_DEVICE_acc_value(&devices[id])[package_num][cur_grp][index] += diff;
+        LWPMU_DEVICE_prev_value(&devices[id])[package_num][index] = value;
+        data  = (U64 *)((S8*)param + ECB_entries_counter_event_offset(pecb,idx));
+        *data = LWPMU_DEVICE_acc_value(&devices[id])[package_num][cur_grp][index];
+        index++;
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*!
+ * @fn       static   unc_pci_Read_PMU_Data(param)
+ *
+ * @param    param    The device index
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the Uncore count data and store into the buffer;
+ */
+static VOID
+unc_pci_Read_PMU_Data(
+    PVOID           param
+)
+{
+    U32             j                   = 0;
+    U32             dev_idx;
+    U32             this_cpu;
+    U64            *buffer              = read_counter_info;
+    CPU_STATE       pcpu;
+    U32             cur_grp;
+    ECB             pecb;
+    U32             dev_node;
+    U32             package_num         = 0;
+    U32             busno;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx     = *((U32*)param);
+    this_cpu    = CONTROL_THIS_CPU();
+    pcpu        = &pcb[this_cpu];
+    package_num = core_to_package_map[this_cpu];
+    cur_grp     = LWPMU_DEVICE_cur_group(&devices[(dev_idx)])[package_num];
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[(dev_idx)])[cur_grp];
+    dev_node    = LWPMU_DEVICE_pci_dev_node_index(&devices[dev_idx]);
+
+    // NOTE THAT the read_pmu function on for EMON collection.
+    if (!DRV_CONFIG_emon_mode(drv_cfg)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!emon_mode).");
+        return;
+    }
+    if (!CPU_STATE_socket_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!CPU_STATE_socket_master).");
+        return;
+    }
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    if (!IS_BUS_MAP_VALID(dev_node, package_num)) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("No UNC_PCIDEV bus map for %u!", dev_node);
+        return;
+    }
+
+    busno = GET_BUS_MAP(dev_node, package_num);
+
+    //Read in the counts into temporary buffer
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_READ) {
+
+        if (ECB_entries_event_scope(pecb,idx) == SYSTEM_EVENT) {
+            j = ECB_entries_uncore_buffer_offset_in_system(pecb,idx);
+        }
+        else {
+            j = EMON_BUFFER_UNCORE_PACKAGE_EVENT_OFFSET(package_num, EMON_BUFFER_DRIVER_HELPER_num_entries_per_package(emon_buffer_driver_helper),
+                                                        ECB_entries_uncore_buffer_offset_in_package(pecb,idx));
+        }
+
+        buffer[j] = PCI_Read_U64(busno,
+                                 ECB_entries_dev_no(pecb,idx),
+                                 ECB_entries_func_no(pecb,idx),
+                                 ECB_entries_reg_id(pecb,idx));
+
+        SEP_DRV_LOG_TRACE("j=%u, value=%llu, cpu=%u", j, buffer[j], this_cpu);
+
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*
+ * Initialize the dispatch table
+ */
+DISPATCH_NODE  unc_pci_dispatch =
+{
+    NULL,                                // initialize
+    NULL,                                // destroy
+    unc_pci_Write_PMU,                   // write
+    unc_pci_Disable_PMU,                 // freeze
+    unc_pci_Enable_PMU,                  // restart
+    unc_pci_Read_PMU_Data,               // read
+    NULL,                                // check for overflow
+    NULL,                                // swap group
+    NULL,                                // read lbrs
+    NULL,                                // cleanup
+    NULL,                                // hw errata
+    NULL,                                // read power
+    NULL,                                // check overflow errata
+    NULL,                                // read counts
+    NULL,                                // check overflow gp errata
+    NULL,                                // read_ro
+    NULL,                                // platform info
+    unc_pci_Trigger_Read,                // trigger read
+    NULL,                                // scan for uncore
+    NULL                                 // read metrics
+};
+
+
diff --git a/drivers/misc/intel/sepdk/sep/unc_power.c b/drivers/misc/intel/sepdk/sep/unc_power.c
new file mode 100644
index 000000000000..635e15b8e161
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/unc_power.c
@@ -0,0 +1,432 @@
+/****
+    Copyright(C) 2012-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit.
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+
+
+
+
+#include "lwpmudrv_defines.h"
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+#include "inc/ecb_iterators.h"
+#include "inc/control.h"
+#include "inc/unc_common.h"
+#include "inc/utility.h"
+
+
+extern U64                        *read_counter_info;
+extern U64                        *prev_counter_data;
+extern EMON_BUFFER_DRIVER_HELPER   emon_buffer_driver_helper;
+static U64                       **prev_val_per_thread;
+static U64                       **acc_per_thread;
+extern DRV_CONFIG                  drv_cfg;
+
+
+/*!
+ * @fn unc_power_Allocate(param)
+ *
+ * @param    param    device index
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Allocate arrays required for reading counts
+ */
+static VOID
+unc_power_Allocate (
+    PVOID  param
+)
+{
+    U32    id;
+    U32    cur_grp;
+    ECB    pecb;
+    U32    i;
+    U32    j;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    id      = *((U32*)param);
+    cur_grp = LWPMU_DEVICE_cur_group(&devices[id])[0];
+    pecb    = LWPMU_DEVICE_PMU_register_data(&devices[id])[cur_grp];
+
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    acc_per_thread = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state) * sizeof(U64 *));
+    if (acc_per_thread == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Unable to allocate memory for acc_per_thread!");
+        return;
+    }
+
+    prev_val_per_thread = CONTROL_Allocate_Memory(GLOBAL_STATE_num_cpus(driver_state) * sizeof(U64 *));
+    if (prev_val_per_thread == NULL) {
+        SEP_DRV_LOG_ERROR_TRACE_OUT("Unable to allocate memory for prev_val_per_thread!");
+        return;
+    }
+
+    for (i = 0; i < (U32)GLOBAL_STATE_num_cpus(driver_state); i++) {
+        acc_per_thread[i] = CONTROL_Allocate_Memory(ECB_num_events(pecb) * sizeof(U64));
+        if (acc_per_thread[i] == NULL) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("Unable to allocate memory for acc_per_thread[%u]!", i);
+            return;
+        }
+
+        prev_val_per_thread[i] = CONTROL_Allocate_Memory(ECB_num_events(pecb) * sizeof(U64));
+        if (prev_val_per_thread[i] == NULL) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("Unable to allocate memory for prev_val_per_thread[%u]!", i);
+            return;
+        }
+
+        // initialize all values to 0
+        for (j = 0; j < ECB_num_events(pecb); j++) {
+            acc_per_thread[i][j]      = 0LL;
+            prev_val_per_thread[i][j] = 0LL;
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*!
+ * @fn unc_power_Free(param)
+ *
+ * @param    param    device index
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Free arrays required for reading counts
+ */
+static VOID
+unc_power_Free (
+    PVOID  param
+)
+{
+    U32    i;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    if (acc_per_thread) {
+        for (i = 0; i < (U32)GLOBAL_STATE_num_cpus(driver_state); i++) {
+            acc_per_thread[i] = CONTROL_Free_Memory(acc_per_thread[i]);
+        }
+        acc_per_thread = CONTROL_Free_Memory(acc_per_thread);
+    }
+
+    if (prev_val_per_thread) {
+        for (i = 0; i < (U32)GLOBAL_STATE_num_cpus(driver_state); i++) {
+            prev_val_per_thread[i] = CONTROL_Free_Memory(prev_val_per_thread[i]);
+        }
+        prev_val_per_thread = CONTROL_Free_Memory(prev_val_per_thread);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*!
+ * @fn unc_power_Read_Counts(param, id, mask)
+ *
+ * @param    param    pointer to sample buffer
+ * @param    id       device index
+ * @param    mask     The mask bits for value
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the Uncore count data and store into the buffer param
+ */
+static VOID
+unc_power_Trigger_Read (
+    PVOID  param,
+    U32    id
+)
+{
+    U64  *data       = (U64*) param;
+    U32   cur_grp;
+    ECB   pecb;
+    U32   this_cpu;
+    U32   package_num;
+    U32   index      = 0;
+    U64   diff       = 0;
+    U64   value;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    this_cpu    = CONTROL_THIS_CPU();
+    package_num = core_to_package_map[this_cpu];
+    cur_grp     = LWPMU_DEVICE_cur_group(&devices[id])[package_num];
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[id])[cur_grp];
+
+    // Write GroupID
+    data    = (U64*)((S8*)data + ECB_group_offset(pecb));
+    *data   = cur_grp + 1;
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, id, idx, PMU_OPERATION_READ) {
+        data  = (U64 *)((S8*)param + ECB_entries_counter_event_offset(pecb,idx));
+        value = SYS_Read_MSR(ECB_entries_reg_id(pecb,idx));
+        if (ECB_entries_max_bits(pecb,idx)) {
+            value &= ECB_entries_max_bits(pecb,idx);
+        }
+        //check for overflow if not a static counter
+        if (ECB_entries_counter_type(pecb,idx) == STATIC_COUNTER) {
+            *data = value;
+        }
+        else {
+            if (value < prev_val_per_thread[this_cpu][index]) {
+                diff = ECB_entries_max_bits(pecb,idx) - prev_val_per_thread[this_cpu][index];
+                diff += value;
+            }
+            else {
+                diff = value - prev_val_per_thread[this_cpu][index];
+            }
+            acc_per_thread[this_cpu][index] += diff;
+            prev_val_per_thread[this_cpu][index] = value;
+            *data = acc_per_thread[this_cpu][index];
+        }
+        index++;
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn unc_power_Enable_PMU(param)
+ *
+ * @param    None
+ *
+ * @return   None
+ *
+ * @brief    Capture the previous values to calculate delta later.
+ */
+static VOID
+unc_power_Enable_PMU (
+    PVOID  param
+)
+{
+    U32          j;
+    U64         *buffer              = prev_counter_data;
+    U32          dev_idx;
+    U32          this_cpu;
+    CPU_STATE    pcpu;
+    U32          package_event_count = 0;
+    U32          thread_event_count  = 0;
+    U32          module_event_count  = 0;
+    U64          tmp_value           = 0;
+    U32          package_id          = 0;
+    U32          core_id             = 0;
+    U32          thread_id           = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx     = *((U32*)param);
+    this_cpu    = CONTROL_THIS_CPU();
+    pcpu        = &pcb[this_cpu];
+    package_id  = core_to_package_map[this_cpu];
+    core_id     = core_to_phys_core_map[this_cpu];
+    thread_id   = core_to_thread_map[this_cpu];
+
+    // NOTE THAT the enable function currently captures previous values
+    // for EMON collection to avoid unnecessary memory copy.
+    if (!DRV_CONFIG_emon_mode(drv_cfg)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!emon_mode).");
+        return;
+    }
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_READ) {
+
+        if (ECB_entries_event_scope(pecb,idx) == PACKAGE_EVENT) {
+            j = EMON_BUFFER_UNCORE_PACKAGE_POWER_EVENT_OFFSET (
+                    package_id, EMON_BUFFER_DRIVER_HELPER_num_entries_per_package(emon_buffer_driver_helper),
+                    EMON_BUFFER_DRIVER_HELPER_power_device_offset_in_package(emon_buffer_driver_helper),
+                    package_event_count);
+            package_event_count++;
+        }
+        else if (ECB_entries_event_scope(pecb,idx) == MODULE_EVENT) {
+            j = EMON_BUFFER_UNCORE_MODULE_POWER_EVENT_OFFSET (
+                    package_id, EMON_BUFFER_DRIVER_HELPER_num_entries_per_package(emon_buffer_driver_helper),
+                    EMON_BUFFER_DRIVER_HELPER_power_device_offset_in_package(emon_buffer_driver_helper),
+                    EMON_BUFFER_DRIVER_HELPER_power_num_package_events(emon_buffer_driver_helper),
+                    CPU_STATE_cpu_module_master(pcpu), EMON_BUFFER_DRIVER_HELPER_power_num_module_events(emon_buffer_driver_helper),
+                    module_event_count);
+            module_event_count++;
+        }
+        else {
+            j = EMON_BUFFER_UNCORE_THREAD_POWER_EVENT_OFFSET (
+                    package_id, EMON_BUFFER_DRIVER_HELPER_num_entries_per_package(emon_buffer_driver_helper),
+                    EMON_BUFFER_DRIVER_HELPER_power_device_offset_in_package(emon_buffer_driver_helper),
+                    EMON_BUFFER_DRIVER_HELPER_power_num_package_events(emon_buffer_driver_helper),
+                    GLOBAL_STATE_num_modules(driver_state), EMON_BUFFER_DRIVER_HELPER_power_num_module_events(emon_buffer_driver_helper),
+                    core_id, threads_per_core, thread_id, EMON_BUFFER_DRIVER_HELPER_power_num_thread_events(emon_buffer_driver_helper),
+                    thread_event_count);
+            thread_event_count++;
+        }
+
+        tmp_value = SYS_Read_MSR(ECB_entries_reg_id(pecb,idx));
+        if (ECB_entries_max_bits(pecb,idx)) {
+            tmp_value &= ECB_entries_max_bits(pecb,idx);
+        }
+        buffer[j] = tmp_value;
+        SEP_DRV_LOG_TRACE("j=%u, value=%llu, cpu=%u", j, buffer[j], this_cpu);
+
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn unc_power_Read_PMU_Data(param)
+ *
+ * @param    param    The read thread node to process
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the Uncore count data and store into the buffer param;
+ *           Uncore PMU does not support sampling, i.e. ignore the id parameter.
+ */
+static VOID
+unc_power_Read_PMU_Data (
+    PVOID  param
+)
+{
+    U32          j;
+    U64         *buffer              = read_counter_info;
+    U64         *prev_buffer         = prev_counter_data;
+    U32          dev_idx;
+    U32          this_cpu;
+    CPU_STATE    pcpu;
+    U32          package_event_count = 0;
+    U32          thread_event_count  = 0;
+    U32          module_event_count  = 0;
+    U64          tmp_value;
+    U32          package_id          = 0;
+    U32          core_id             = 0;
+    U32          thread_id           = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx     = *((U32*)param);
+    this_cpu    = CONTROL_THIS_CPU();
+    pcpu        = &pcb[this_cpu];
+    package_id  = core_to_package_map[this_cpu];
+    core_id     = core_to_phys_core_map[this_cpu];
+    thread_id   = core_to_thread_map[this_cpu];
+
+    // NOTE THAT the read_pmu function on for EMON collection.
+    if (!DRV_CONFIG_emon_mode(drv_cfg)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!emon_mode).");
+        return;
+    }
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_READ) {
+
+        if (ECB_entries_event_scope(pecb,idx) == PACKAGE_EVENT) {
+            j = EMON_BUFFER_UNCORE_PACKAGE_POWER_EVENT_OFFSET (
+                    package_id, EMON_BUFFER_DRIVER_HELPER_num_entries_per_package(emon_buffer_driver_helper),
+                    EMON_BUFFER_DRIVER_HELPER_power_device_offset_in_package(emon_buffer_driver_helper),
+                    package_event_count);
+            package_event_count++;
+        }
+        else if (ECB_entries_event_scope(pecb,idx) == MODULE_EVENT) {
+            j = EMON_BUFFER_UNCORE_MODULE_POWER_EVENT_OFFSET (
+                    package_id, EMON_BUFFER_DRIVER_HELPER_num_entries_per_package(emon_buffer_driver_helper),
+                    EMON_BUFFER_DRIVER_HELPER_power_device_offset_in_package(emon_buffer_driver_helper),
+                    EMON_BUFFER_DRIVER_HELPER_power_num_package_events(emon_buffer_driver_helper),
+                    CPU_STATE_cpu_module_master(pcpu), EMON_BUFFER_DRIVER_HELPER_power_num_module_events(emon_buffer_driver_helper),
+                    module_event_count);
+            module_event_count++;
+        }
+        else {
+            j = EMON_BUFFER_UNCORE_THREAD_POWER_EVENT_OFFSET (
+                    package_id, EMON_BUFFER_DRIVER_HELPER_num_entries_per_package(emon_buffer_driver_helper),
+                    EMON_BUFFER_DRIVER_HELPER_power_device_offset_in_package(emon_buffer_driver_helper),
+                    EMON_BUFFER_DRIVER_HELPER_power_num_package_events(emon_buffer_driver_helper),
+                    GLOBAL_STATE_num_modules(driver_state), EMON_BUFFER_DRIVER_HELPER_power_num_module_events(emon_buffer_driver_helper),
+                    core_id, threads_per_core, thread_id, EMON_BUFFER_DRIVER_HELPER_power_num_thread_events(emon_buffer_driver_helper),
+                    thread_event_count);
+            thread_event_count++;
+        }
+
+        tmp_value = SYS_Read_MSR(ECB_entries_reg_id(pecb,idx));
+        if (ECB_entries_max_bits(pecb,idx)) {
+            tmp_value &= ECB_entries_max_bits(pecb,idx);
+        }
+        if (ECB_entries_counter_type(pecb,idx) == STATIC_COUNTER) {
+            buffer[j] = tmp_value;
+        }
+        else {
+            if (tmp_value >= prev_buffer[j]) {
+                buffer[j] = tmp_value - prev_buffer[j];
+            }
+            else {
+                buffer[j] = tmp_value + (ECB_entries_max_bits(pecb,idx) - prev_buffer[j]);
+            }
+        }
+        SEP_DRV_LOG_TRACE("j=%u, value=%llu, cpu=%u", j, buffer[j], this_cpu);
+
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/*
+ * Initialize the dispatch table
+ */
+DISPATCH_NODE  unc_power_dispatch =
+{
+    unc_power_Allocate,           // initialize
+    unc_power_Free,               // destroy
+    UNC_COMMON_Dummy_Func,        // write
+    NULL,                         // freeze
+    unc_power_Enable_PMU,         // restart
+    unc_power_Read_PMU_Data,      // read
+    NULL,                         // check for overflow
+    NULL,                         // swap group
+    NULL,                         // read lbrs
+    NULL,                         // cleanup
+    NULL,                         // hw errata
+    NULL,                         // read power
+    NULL,                         // check overflow errata
+    NULL,                         // read counts
+    NULL,                         // check overflow gp errata
+    NULL,                         // read_ro
+    NULL,                         // platform info
+    unc_power_Trigger_Read,       // trigger read
+    NULL,                         // scan for uncore
+    NULL                          // read metrics
+};
+
diff --git a/drivers/misc/intel/sepdk/sep/unc_sa.c b/drivers/misc/intel/sepdk/sep/unc_sa.c
new file mode 100644
index 000000000000..8e6af8937894
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/unc_sa.c
@@ -0,0 +1,194 @@
+/****
+    Copyright(C) 2011-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit.
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+
+
+
+
+#include "lwpmudrv_defines.h"
+#include "lwpmudrv_types.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+#include "inc/ecb_iterators.h"
+#include "inc/control.h"
+#include "inc/haswellunc_sa.h"
+#include "inc/pci.h"
+#include "inc/utility.h"
+
+extern U64           *read_counter_info;
+extern DRV_CONFIG     drv_cfg;
+
+extern VOID SOCPERF_Read_Data3(PVOID data_buffer);
+
+
+
+/*!
+ * @fn         static VOID hswunc_sa_Initialize(PVOID)
+ *
+ * @brief      Initialize any registers or addresses
+ *
+ * @param      param
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+hswunc_sa_Initialize (
+    VOID  *param
+)
+{
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+    SEP_DRV_LOG_TRACE_OUT("Empty function.");
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn hswunc_sa_Read_Counts(param, id)
+ *
+ * @param    param    The read thread node to process
+ * @param    id       The id refers to the device index
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the Uncore count data and store into the buffer param;
+ *
+ */
+static VOID
+hswunc_sa_Trigger_Read (
+    PVOID  param,
+    U32    id
+)
+{
+    U64  *data         = (U64*) param;
+    U32   cur_grp;
+    ECB   pecb;
+    U32   this_cpu;
+    U32   package_num;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p, id: %u.", param, id);
+
+    this_cpu    = CONTROL_THIS_CPU();
+    package_num = core_to_package_map[this_cpu];
+    cur_grp     = LWPMU_DEVICE_cur_group(&devices[id])[package_num];
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[id])[cur_grp];
+
+    // group id
+    data    = (U64*)((S8*)data + ECB_group_offset(pecb));
+    SOCPERF_Read_Data3((void*)data);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn hswunc_sa_Read_PMU_Data(param)
+ *
+ * @param    param    the device index
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the Uncore count data and store into the buffer param;
+ *
+ */
+static VOID
+hswunc_sa_Read_PMU_Data (
+    PVOID  param
+)
+{
+    U32          j;
+    U64         *buffer       = read_counter_info;
+    U32          dev_idx;
+    U32          this_cpu;
+    CPU_STATE    pcpu;
+    U32          event_index  = 0;
+    U64          counter_buffer[HSWUNC_SA_MAX_COUNTERS+1];
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx  = *((U32*)param);
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+
+    // NOTE THAT the read_pmu function on for EMON collection.
+    if (!DRV_CONFIG_emon_mode(drv_cfg)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!emon_mode).");
+        return;
+    }
+    if (!CPU_STATE_system_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!system_master).");
+        return;
+    }
+
+    SOCPERF_Read_Data3((void*)counter_buffer);
+
+    FOR_EACH_PCI_DATA_REG_RAW(pecb, i, dev_idx) {
+        j         = ECB_entries_uncore_buffer_offset_in_system(pecb,i);
+        buffer[j] = counter_buffer[event_index+1];
+        event_index++;
+        SEP_DRV_LOG_TRACE("j=%u, value=%llu, cpu=%u", j, buffer[j], this_cpu);
+
+    } END_FOR_EACH_PCI_DATA_REG_RAW;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/*
+ * Initialize the dispatch table
+ */
+DISPATCH_NODE  hswunc_sa_dispatch =
+{
+    hswunc_sa_Initialize,        // initialize
+    NULL,                        // destroy
+    NULL,                        // write
+    NULL,                        // freeze
+    NULL,                        // restart
+    hswunc_sa_Read_PMU_Data,     // read
+    NULL,                        // check for overflow
+    NULL,                        // swap group
+    NULL,                        // read lbrs
+    NULL,                        // cleanup
+    NULL,                        // hw errata
+    NULL,                        // read power
+    NULL,                        // check overflow errata
+    NULL,                        // read counts
+    NULL,                        // check overflow gp errata
+    NULL,                        // read_ro
+    NULL,                        // platform info
+    hswunc_sa_Trigger_Read,      // trigger read
+    NULL,                        // scan for uncore
+    NULL                         // read metrics
+};
+
diff --git a/drivers/misc/intel/sepdk/sep/utility.c b/drivers/misc/intel/sepdk/sep/utility.c
new file mode 100644
index 000000000000..26d78624036b
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/utility.c
@@ -0,0 +1,1177 @@
+/****
+    Copyright(C) 2005-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+#include "lwpmudrv_defines.h"
+#include <linux/slab.h>
+#include <linux/version.h>
+#include <linux/fs.h>
+#include <linux/kallsyms.h>
+#include <asm/msr.h>
+#include <linux/ptrace.h>
+#include <linux/time.h>
+#include <linux/vmalloc.h>
+
+#include "lwpmudrv_defines.h"
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv.h"
+#include "core2.h"
+#include "silvermont.h"
+#include "perfver4.h"
+#include "valleyview_sochap.h"
+#include "unc_gt.h"
+#include "haswellunc_sa.h"
+#if defined(BUILD_CHIPSET)
+#include "chap.h"
+#endif
+#include "utility.h"
+#if defined(BUILD_CHIPSET)
+#include "lwpmudrv_chipset.h"
+#include "gmch.h"
+#endif
+
+#include "control.h"
+
+volatile int config_done;
+extern  DISPATCH_NODE   unc_msr_dispatch;
+extern  DISPATCH_NODE   unc_pci_dispatch;
+extern  DISPATCH_NODE   unc_mmio_dispatch;
+extern  DISPATCH_NODE   unc_mmio_fpga_dispatch;
+extern  DISPATCH_NODE   unc_power_dispatch;
+
+#if defined(BUILD_CHIPSET)
+extern CHIPSET_CONFIG pma;
+#endif
+
+extern VOID
+UTILITY_down_read_mm (
+    struct mm_struct *mm
+)
+{
+    SEP_DRV_LOG_TRACE_IN("Mm: %p.", mm);
+
+    down_read((struct rw_semaphore *) &mm->mmap_sem);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+extern VOID
+UTILITY_up_read_mm (
+    struct mm_struct *mm
+)
+{
+    SEP_DRV_LOG_TRACE_IN("Mm: %p.", mm);
+
+    up_read((struct rw_semaphore *) &mm->mmap_sem);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+// NOT to be instrumented, used inside DRV_LOG!
+extern VOID
+UTILITY_Read_TSC (
+    U64* pTsc
+)
+{
+    rdtscll(*(pTsc));
+
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       VOID UTILITY_Read_Cpuid
+ *
+ * @brief    executes the cpuid_function of cpuid and returns values
+ *
+ * @param  IN   cpuid_function
+ *         OUT  rax  - results of the cpuid instruction in the
+ *         OUT  rbx  - corresponding registers
+ *         OUT  rcx
+ *         OUT  rdx
+ *
+ * @return   none
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ *
+ */
+extern VOID
+UTILITY_Read_Cpuid (
+    U64   cpuid_function,
+    U64  *rax_value,
+    U64  *rbx_value,
+    U64  *rcx_value,
+    U64  *rdx_value
+)
+{
+    U32 function = (U32)   cpuid_function;
+    U32 *eax     = (U32 *) rax_value;
+    U32 *ebx     = (U32 *) rbx_value;
+    U32 *ecx     = (U32 *) rcx_value;
+    U32 *edx     = (U32 *) rdx_value;
+
+    SEP_DRV_LOG_TRACE_IN("Fn: %llu, rax_p: %p, rbx_p: %p, rcx_p: %p, rdx_p: %p.",
+        cpuid_function, rax_value, rbx_value, rcx_value, rdx_value);
+
+    *eax = function;
+
+    __asm__("cpuid"
+            : "=a" (*eax),
+              "=b" (*ebx),
+              "=c" (*ecx),
+              "=d" (*edx)
+            : "a"  (function),
+              "b"  (*ebx),
+              "c"  (*ecx),
+              "d"  (*edx));
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       VOID UTILITY_Configure_CPU
+ *
+ * @brief    Reads the CPU information from the hardware
+ *
+ * @param    param   dispatch_id -  The id of the dispatch table.
+ *
+ * @return   Pointer to the correct dispatch table for the CPU architecture
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+extern  DISPATCH
+UTILITY_Configure_CPU (
+    U32 dispatch_id
+)
+{
+    DISPATCH     dispatch = NULL;
+
+    SEP_DRV_LOG_TRACE_IN("Dispatch_id: %u.", dispatch_id);
+
+    switch (dispatch_id) {
+        case 1:
+            SEP_DRV_LOG_INIT("Set up the Core(TM)2 processor dispatch table.");
+            dispatch = &core2_dispatch;
+            break;
+        case 6:
+            SEP_DRV_LOG_INIT("Set up the Silvermont dispatch table.");
+            dispatch = &silvermont_dispatch;
+            break;
+        case 7:
+            SEP_DRV_LOG_INIT("Set up the perfver4 HTON dispatch table such as Skylake.");
+            dispatch = &perfver4_dispatch;
+            break;
+        case 8:
+            SEP_DRV_LOG_INIT("Set up the perfver4 HTOFF dispatch table such as Skylake.");
+            dispatch = &perfver4_dispatch_htoff_mode;
+            break;
+        case 11:
+            SEP_DRV_LOG_INIT("Set up the perfver4 NONHT dispatch table such as Icelake.");
+            dispatch = &perfver4_dispatch_nonht_mode;
+            break;
+        case 700:
+        case 701:
+        case 1100:
+            SEP_DRV_LOG_INIT("Set up the Valleyview SA dispatch table.");
+            dispatch = &valleyview_visa_dispatch;
+            break;
+        case 2:
+            SEP_DRV_LOG_INIT("Set up the Core i7(TM) processor dispatch table.");
+            dispatch = &corei7_dispatch;
+            break;
+        case 3:
+            SEP_DRV_LOG_INIT("Set up the Core i7(TM) dispatch table.");
+            dispatch = &corei7_dispatch_htoff_mode;
+            break;
+        case 4:
+            SEP_DRV_LOG_INIT("Set up the Sandybridge processor dispatch table.");
+            dispatch = &corei7_dispatch_2;
+            break;
+        case 5:
+            SEP_DRV_LOG_INIT("Set up the Sandybridge dispatch table.");
+            dispatch = &corei7_dispatch_htoff_mode_2;
+            break;
+        case 9:
+            SEP_DRV_LOG_INIT("Set up the Nehalem, Westemere dispatch table.");
+            dispatch = &corei7_dispatch_nehalem;
+            break;
+        case 10:
+            SEP_DRV_LOG_INIT("Set up the Knights family dispatch table.");
+            dispatch = &knights_dispatch;
+            break;
+        case 100:
+            SEP_DRV_LOG_INIT("Set up the MSR based uncore dispatch table.");
+            dispatch = &unc_msr_dispatch;
+            break;
+        case 110:
+            SEP_DRV_LOG_INIT("Set up the PCI Based Uncore dispatch table.");
+            dispatch = &unc_pci_dispatch;
+            break;
+        case 120:
+            SEP_DRV_LOG_INIT("Set up the MMIO based uncore dispatch table.");
+            dispatch = &unc_mmio_dispatch;
+            break;
+        case 121:
+            SEP_DRV_LOG_INIT("Set up the MMIO based uncore dispatch table for FPGA.");
+            dispatch = &unc_mmio_fpga_dispatch;
+            break;
+        case 130:
+            SEP_DRV_LOG_INIT("Set up the Uncore Power dispatch table.");
+            dispatch = &unc_power_dispatch;
+            break;
+        case 230:
+            SEP_DRV_LOG_INIT("Set up the Haswell SA dispatch table.");
+            dispatch = &hswunc_sa_dispatch;
+            break;
+        case 400:
+            SEP_DRV_LOG_INIT("Set up the GT dispatch table.");
+            dispatch = &unc_gt_dispatch;
+            break;
+        default:
+            dispatch = NULL;
+            SEP_DRV_LOG_ERROR("Architecture not supported (dispatch_id: %d).", dispatch_id);
+            break;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %p.", dispatch);
+    return dispatch;
+}
+
+extern U64
+SYS_MMIO_Read64(
+    U64 baseAddress,
+    U64 offset
+)
+{
+    U64 res = 0;
+#if defined(DRV_EM64T)
+    SEP_DRV_LOG_REGISTER_IN("Will read MMIO *(0x%llx + 0x%llx).", baseAddress, offset);
+
+    if (baseAddress) {
+        volatile U64 *p = (U64*) (baseAddress + offset); // offset is in bytes
+        res = *p;
+    } else {
+        SEP_DRV_LOG_ERROR("BaseAddress is NULL!");
+        res = (U64) -1;                                  // typical value for undefined CSR
+    }
+
+    SEP_DRV_LOG_REGISTER_OUT("Has read MMIO *(0x%llx + 0x%llx): 0x%llx.", baseAddress, offset, res);
+#endif
+    return res;
+}
+
+
+extern U64
+SYS_Read_MSR (
+    U32   msr
+)
+{
+    U64 val   = 0;
+
+#if defined(DRV_DEBUG_MSR)
+    int error;
+    SEP_DRV_LOG_REGISTER_IN("Will safely read MSR 0x%x.", msr);
+    error = rdmsrl_safe(msr, &val);
+    if (error) {
+        SEP_DRV_LOG_ERROR("Failed to read MSR 0x%x.", msr);
+    }
+    SEP_DRV_LOG_REGISTER_OUT("Has read MSR 0x%x: 0x%llx (error: %d).", msr, val, error);
+#else
+    SEP_DRV_LOG_REGISTER_IN("Will read MSR 0x%x.", msr);
+    rdmsrl(msr, val);
+    SEP_DRV_LOG_REGISTER_OUT("Has read MSR 0x%x: 0x%llx.", msr, val);
+#endif
+
+    return val;
+}
+
+
+extern void
+SYS_Write_MSR (
+    U32   msr,
+    U64   val
+)
+{
+#if defined(DRV_DEBUG_MSR)
+    int error;
+    SEP_DRV_LOG_REGISTER_IN("Will safely write MSR 0x%x: 0x%llx.", msr, val);
+    error = wrmsr_safe(msr, (U32)val, (U32)(val >> 32));
+    if (error) {
+        SEP_DRV_LOG_ERROR("Failed to write MSR 0x%x: 0x%llx.", msr, val);
+    }
+    SEP_DRV_LOG_REGISTER_OUT("Wrote MSR 0x%x: 0x%llx (error: %d).", msr, val, error);
+
+#else  // !DRV_DEBUG_MSR
+    SEP_DRV_LOG_REGISTER_IN("Will write MSR 0x%x: 0x%llx.", msr, val);
+#if defined(DRV_IA32)
+    wrmsr(msr, (U32)val, (U32)(val>>32));
+#endif
+#if defined(DRV_EM64T)
+    wrmsrl(msr, val);
+#endif
+    SEP_DRV_LOG_REGISTER_OUT("Wrote MSR 0x%x: 0x%llx.", msr, val);
+
+#endif // !DRV_DEBUG_MSR
+}
+
+
+#if defined(BUILD_CHIPSET)
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       VOID UTILITY_Configure_Chipset
+ *
+ * @brief    Configures the chipset information
+ *
+ * @param    none
+ *
+ * @return   none
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+extern  CS_DISPATCH
+UTILITY_Configure_Chipset (
+    void
+)
+{
+    SEP_DRV_LOG_TRACE_IN("");
+
+    if (CHIPSET_CONFIG_gmch_chipset(pma)) {
+        cs_dispatch = &gmch_dispatch;
+        SEP_DRV_LOG_INIT("Using GMCH dispatch table.");
+    }
+    else if (CHIPSET_CONFIG_mch_chipset(pma) || CHIPSET_CONFIG_ich_chipset(pma)) {
+        cs_dispatch = &chap_dispatch;
+        SEP_DRV_LOG_INIT("Using CHAP dispatch table.");
+    }
+    else {
+        SEP_DRV_LOG_ERROR("Unable to map chipset dispatch table!");
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %p.", cs_dispatch);
+    return cs_dispatch;
+}
+
+#endif
+
+
+#if LINUX_VERSION_CODE == KERNEL_VERSION(2,6,32)
+static unsigned long utility_Compare_Symbol_Names_Return_Value = 0;
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       static int utility_Compare_Symbol_Names (void* ref_name const char* symbol_name, struct module* dummy, unsigned long symbol_address)
+ *
+ * @brief    Comparator for kallsyms_on_each_symbol.
+ *
+ * @param    void         * ref_name        : Symbol we are looking for
+ *           const char   * symbol_name     : Name of the current symbol being evaluated
+ *           struct module* dummy           : Pointer to the module structure. Not needed.
+ *           unsigned long  symbol_address  : Address of the current symbol being evaluated
+ *
+ * @return   1 if ref_name matches symbol_name, 0 otherwise. Fills utility_Compare_Symbol_Names_Return_Value with the symbol's address on success.
+ *
+ * <I>Special Notes:</I>
+ *           Only used as a callback comparator for kallsyms_on_each_symbol.
+ */
+static int
+utility_Compare_Symbol_Names (
+    void           *ref_name,
+    const char     *symbol_name,
+    struct module  *dummy,
+    unsigned long   symbol_address
+)
+{
+    int res = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Ref_name: %p, symbol_name: %p, dummy: %p, symbol_address: %u.",
+                          ref_name, symbol_name, dummy, symbol_address);
+
+    if (strcmp((char*)ref_name, symbol_name) == 0) {
+        utility_Compare_Symbol_Names_Return_Value = symbol_address;
+        res = 1;
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", res);
+    return res;
+}
+#endif
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       extern unsigned long UTILITY_Find_Symbol (const char* name)
+ *
+ * @brief    Finds the address of the specified kernel symbol.
+ *
+ * @param    const char* name - name of the symbol to look for
+ *
+ * @return   Symbol address (0 if could not find)
+ *
+ * <I>Special Notes:</I>
+ *           This wrapper is needed due to kallsyms_lookup_name not being exported
+ *           in kernel version 2.6.32.*.
+ *           Careful! This code is *NOT* multithread-safe or reentrant! Should only
+ *           be called from 1 context at a time!
+ */
+extern unsigned long
+UTILITY_Find_Symbol (
+    const char* name
+)
+{
+    unsigned long res = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Name: %p.", name);                // Not printing the name to follow the log convention: *must not* dereference any pointer in an 'IN' message
+
+#if LINUX_VERSION_CODE == KERNEL_VERSION(2,6,32)
+    if(kallsyms_on_each_symbol(utility_Compare_Symbol_Names, (void*)name)) {
+        res = utility_Compare_Symbol_Names_Return_Value;
+    }
+#else
+    res = kallsyms_lookup_name(name);
+#endif
+
+    SEP_DRV_LOG_INIT("Name: '%s': 0x%llx.", name ? name : "NULL", (unsigned long long)res); // Printing here instead. (Paranoia in case of corrupt pointer.)
+
+    SEP_DRV_LOG_TRACE_OUT("Res: 0x%llx.", (unsigned long long)res);
+    return res;
+}
+
+
+/*
+ ************************************
+ *  DRIVER LOG BUFFER DECLARATIONS  *
+ ************************************
+ */
+
+volatile U8         active_ioctl;
+
+DRV_LOG_BUFFER      driver_log_buffer;
+
+static const char* drv_log_categories[DRV_NB_LOG_CATEGORIES] = {
+    "load",
+    "init",
+    "detection",
+    "error",
+    "state change",
+    "mark",
+    "debug",
+    "flow",
+    "alloc",
+    "interrupt",
+    "trace",
+    "register",
+    "notification",
+    "warning"
+};
+
+#define DRV_LOG_NB_DRIVER_STATES 9
+static const char* drv_log_states[DRV_LOG_NB_DRIVER_STATES] = {
+    "Uninitialized",
+    "Reserved",
+    "Idle",
+    "Paused",
+    "Stopped",
+    "Running",
+    "Pausing",
+    "Prepare_Stop",
+    "Terminating"
+};
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       static VOID utility_Driver_Log_Kprint_Helper (U8 category, char**  category_string,
+ *                                                  U8 secondary, char** secondary_string_1,
+ *                                                  char**  secondary_string_2, char**  secondary_string_3,
+ *                                                  char**  secondary_string_4)
+ *
+ * @brief    Helper function for printing log messages to the system log.
+ *
+ * @param    IN     category            -  message category
+ *           IN/OUT category_string     -  location where to place a pointer to the category's name
+ *           IN     secondary           -  secondary field value for the message
+ *           IN/OUT secondary_string_1  -  location where to place a pointer to the 1st part of the secondary info's decoded information
+ *           IN/OUT secondary_string_2  -  location where to place a pointer to the 2nd part of the secondary info's decoded information
+ *           IN/OUT secondary_string_3  -  location where to place a pointer to the 3rd part of the secondary info's decoded information
+ *           IN/OUT secondary_string_4  -  location where to place a pointer to the 4th part of the secondary info's decoded information
+ *
+ * @return   none
+ *
+ * <I>Special Notes:</I>
+ *           Allows a single format string to be used for all categories (instead of category-specific format
+ *           strings) when calling printk, simplifying the print routine and reducing potential errors.
+ *           There is a performance cost to this approach (forcing printk to process empty strings), but it
+ *           should be dwarved by the cost of calling printk in the first place.
+ *           NB: none of the input string pointers may be NULL!
+ */
+static VOID
+utility_Driver_Log_Kprint_Helper (
+    U8      category,
+    char**  category_string,
+    U8      secondary,
+    char**  secondary_string_1,
+    char**  secondary_string_2,
+    char**  secondary_string_3,
+    char**  secondary_string_4
+)
+{
+    if (category >= DRV_NB_LOG_CATEGORIES) {
+        *category_string = "Unknown category";
+    }
+    else {
+        *category_string = (char*) drv_log_categories[category];
+    }
+
+    *secondary_string_1  = "";
+    *secondary_string_2  = "";
+    *secondary_string_3  = "";
+    *secondary_string_4  = "";
+
+    switch (category) {
+        case DRV_LOG_CATEGORY_FLOW:
+        case DRV_LOG_CATEGORY_TRACE:
+        case DRV_LOG_CATEGORY_INTERRUPT:    // we should *never* be kprinting from an interrupt context...
+            if (secondary != DRV_LOG_NOTHING) {
+                *secondary_string_1 = ", ";
+                if (secondary == DRV_LOG_FLOW_IN) {
+                    *secondary_string_2 = "Entering";
+                }
+                else if (secondary == DRV_LOG_FLOW_OUT) {
+                    *secondary_string_2 = "Leaving";
+                }
+            }
+            break;
+        case DRV_LOG_CATEGORY_STATE_CHANGE:
+            {
+                U8 orig_state, dest_state;
+
+                orig_state = (secondary & 0xF0) >> 4;
+                dest_state =  secondary & 0x0F;
+
+                *secondary_string_1 = ", ";
+
+                if (orig_state < DRV_LOG_NB_DRIVER_STATES) {
+                    *secondary_string_2 = (char*) drv_log_states[orig_state];
+                }
+                else {
+                    *secondary_string_2 = "Unknown_state";
+                }
+
+                *secondary_string_3 = " -> ";
+
+                if (dest_state < DRV_LOG_NB_DRIVER_STATES) {
+                    *secondary_string_4 = (char*) drv_log_states[dest_state];
+                }
+                else {
+                    *secondary_string_4 = "Unknown_state";
+                }
+            }
+            break;
+
+        default:
+            break;
+    }
+
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       static inline VOID utility_Log_Write (
+ *                                    U8 destination, U8 category, U8 secondary,
+ *                                    const char* function_name, U32 func_name_len,
+ *                                    U32 line_number, U64 tsc, U8 ioctl, U16 processor_id,
+ *                                    U8 driver_state, U16 nb_active_interrupts,
+ *                                    U16 nb_active_notifications,
+ *                                    const char* format_string, ...)
+ *
+ * @brief    Checks whether and where the message should be logged, and logs it as appropriate.
+ *
+ * @param    U8          destination             - whether to write to the primary (0) or the auxiliary log buffer (1)
+ *           U8          category                - message category
+ *           U8          secondary               - secondary information field for the message
+ *           const char* function_name           - name of the calling function
+ *           U32         func_name_len           - length of the name of the calling function (more efficient
+ *                                                 to pass it as parameter than finding it back at runtime)
+ *           U32         line_number             - line number of the call site
+ *           U64         tsc                     - time stamp value to use
+ *           U8          ioctl                   - current active ioctl
+ *           U16         processor_id            - id of the active core/thread
+ *           U8          driver_state            - current driver state
+ *           U16         nb_active_interrupts    - number of interrupts currently being processed
+ *           U16         nb_active_notifications - number of notifications currently being processed
+ *           const char* format_string           - classical format string for printf-like functions
+ *           ...                                 - elements to print
+ *
+ * @return   none
+ *
+ * <I>Special Notes:</I>
+ *           Writes the specified message to the specified log buffer.
+ *           The order of writes (integrity tag at the beginning, overflow tag at the very end) matters
+ *           to ensure the logged information can be detected to be only partially written if applicable).
+ *           Much of the needed information (active core, driver state, tsc..) is passed through the
+ *           stack (instead of obtained inside utility_Log_Write) to guarantee entries representing the
+ *           same message (or log call) in different channels use consistent information, letting the
+ *           decoder reliably identify duplicates.
+ */
+static inline VOID
+utility_Log_Write (
+    U8          destination,
+    U8          category,
+    U8          secondary,
+    const char* function_name,
+    U32         function_name_length,
+    U32         line_number,
+    U64         tsc,
+    U8          ioctl,
+    U16         processor_id,
+    U8          driver_state,
+    U16         nb_active_interrupts,
+    U16         nb_active_notifications,
+    const char* format_string,
+    va_list     args
+)
+{
+    U32             entry_id;
+    U16             overflow_tag;
+    DRV_LOG_ENTRY   entry;
+    char*           target_func_buffer;
+    U32             local_func_name_length;
+    U32             i;
+
+    if (destination == 0) { // primary buffer
+        entry_id     = __sync_add_and_fetch(&DRV_LOG_BUFFER_pri_entry_index(DRV_LOG()), 1);
+        overflow_tag = (U16)(entry_id / DRV_LOG_MAX_NB_PRI_ENTRIES);
+        entry        = DRV_LOG_BUFFER_entries(DRV_LOG())        +
+                        entry_id % DRV_LOG_MAX_NB_PRI_ENTRIES;
+    }
+    else {
+        entry_id     = __sync_add_and_fetch(&DRV_LOG_BUFFER_aux_entry_index(DRV_LOG()), 1);
+        overflow_tag = (U16)(entry_id / DRV_LOG_MAX_NB_AUX_ENTRIES);
+        entry        = DRV_LOG_BUFFER_entries(DRV_LOG())        +
+                        DRV_LOG_MAX_NB_PRI_ENTRIES              +
+                        entry_id % DRV_LOG_MAX_NB_AUX_ENTRIES;
+    }
+
+    DRV_LOG_COMPILER_MEM_BARRIER();
+    DRV_LOG_ENTRY_integrity_tag(entry) = overflow_tag;
+    DRV_LOG_COMPILER_MEM_BARRIER();
+
+    if (format_string && *format_string) {          // setting this one first to try to increase MLP
+        DRV_VSNPRINTF(DRV_LOG_ENTRY_message(entry),
+                          DRV_LOG_MESSAGE_LENGTH,
+                          DRV_LOG_MESSAGE_LENGTH,
+                          format_string,
+                          args);
+    }
+    else {
+        DRV_LOG_ENTRY_message(entry)[0] = 0;
+    }
+
+    target_func_buffer     = DRV_LOG_ENTRY_function_name(entry);
+    local_func_name_length = function_name_length < DRV_LOG_FUNCTION_NAME_LENGTH ?
+                             function_name_length : DRV_LOG_FUNCTION_NAME_LENGTH;
+    for (i = 0; i < local_func_name_length - 1; i++) {
+        target_func_buffer[i] = function_name[i];
+    }
+    target_func_buffer[i] = 0;
+
+    DRV_LOG_ENTRY_category(entry)                = category;
+    DRV_LOG_ENTRY_secondary_info(entry)          = secondary;
+    DRV_LOG_ENTRY_line_number(entry)             = line_number;
+    DRV_LOG_ENTRY_active_drv_operation(entry)    = ioctl;
+    DRV_LOG_ENTRY_processor_id(entry)            = processor_id;
+    DRV_LOG_ENTRY_driver_state(entry)            = driver_state;
+    DRV_LOG_ENTRY_nb_active_interrupts(entry)    = nb_active_interrupts;
+    DRV_LOG_ENTRY_nb_active_notifications(entry) = nb_active_notifications;
+    DRV_LOG_ENTRY_tsc(entry)                     = tsc;
+
+    DRV_LOG_COMPILER_MEM_BARRIER();
+    DRV_LOG_ENTRY_temporal_tag(entry)   = overflow_tag;
+    DRV_LOG_COMPILER_MEM_BARRIER();
+
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       extern void UTILITY_Log (U8 category, U8 in_notification, U8 secondary,
+ *                                    const char* function_name, U32 func_name_len,
+ *                                    U32 line_number, const char* format_string, ...)
+ *
+ * @brief    Checks whether and where the message should be logged, and logs it as appropriate.
+ *
+ * @param    U8          category        - message category
+ *           U8          in_notification - whether or not we are in a notification/OS callback context
+ *                                         (this information cannot be reliably obtained without passing
+ *                                         it through the stack)
+ *           U8          secondary       - secondary information field for the message
+ *           const char* function_name   - name of the calling function
+ *           U32         func_name_len   - length of the name of the calling function (more efficient
+ *                                         to pass it as parameter than finding it back at runtime)
+ *           U32         line_number     - line number of the call site
+ *           const char* format_string   - classical format string for printf-like functions
+ *           ...                         - elements to print
+ *
+ * @return   none
+ *
+ * <I>Special Notes:</I>
+ *           Takes a snapshot of various elements (TSC, driver state, etc.) to ensure a single log call
+ *           writes consistent information to all applicable channels (i.e. favoring consistency over
+ *           instantaneous accuracy). See utility_Log_Write for details.
+ */
+extern VOID
+UTILITY_Log (
+    U8          category,
+    U8          in_notification,
+    U8          secondary,
+    const char* function_name,
+    U32         func_name_len,
+    U32         line_number,
+    const char* format_string,
+    ...
+)
+{
+    U64     tsc_snapshot;
+    U8      ioctl_snapshot;
+    U8      driver_state_snapshot;
+    U16     processor_id_snapshot;
+    U16     nb_active_interrupts_snapshot;
+    U16     nb_active_notifications_snapshot;
+    U8      category_verbosity;
+    U8      in_interrupt;
+    U8      is_enabled;
+
+    category_verbosity    = DRV_LOG_VERBOSITY(category);
+    processor_id_snapshot = raw_smp_processor_id();
+    in_interrupt          = ((pcb && atomic_read(&CPU_STATE_in_interrupt(&pcb[processor_id_snapshot]))) +
+                               (category == DRV_LOG_CATEGORY_INTERRUPT));
+    is_enabled            = in_interrupt                          * !!(category_verbosity & LOG_CONTEXT_INTERRUPT) +
+                            in_notification                       * !!(category_verbosity & LOG_CONTEXT_NOTIFICATION) +
+                            (!in_interrupt * !in_notification)    * !!(category_verbosity & LOG_CONTEXT_REGULAR);
+
+
+    if (is_enabled) {
+        va_list args;
+        U32     i;
+
+        ioctl_snapshot                   = active_ioctl;
+        driver_state_snapshot            = GET_DRIVER_STATE();
+        nb_active_interrupts_snapshot    = DRV_LOG_BUFFER_nb_active_interrupts(DRV_LOG());
+        nb_active_notifications_snapshot = DRV_LOG_BUFFER_nb_active_notifications(DRV_LOG());
+        UTILITY_Read_TSC                 (&tsc_snapshot);
+
+        va_start     (args, format_string);
+
+        for (i = 0; i < 2; i++) {
+            if (category_verbosity & (1 << i)) {
+                va_list args_copy;
+                va_copy(args_copy, args);
+                utility_Log_Write(
+                    i,          // 0 for primary log, 1 for auxiliary log
+                    category,
+                    secondary,
+                    function_name,
+                    func_name_len,
+                    line_number,
+                    tsc_snapshot,
+                    ioctl_snapshot,
+                    processor_id_snapshot,
+                    driver_state_snapshot,
+                    nb_active_interrupts_snapshot,
+                    nb_active_notifications_snapshot,
+                    format_string,
+                    args_copy
+                );
+                va_end(args_copy);
+            }
+        }
+        if (category_verbosity & LOG_CHANNEL_PRINTK ||
+            category_verbosity & LOG_CHANNEL_TRACEK) {
+#define     DRV_LOG_DEBUG_ARRAY_SIZE  512
+            char tmp_array[DRV_LOG_DEBUG_ARRAY_SIZE];
+            U32  nb_written_characters;
+            char *category_s, *sec1_s, *sec2_s, *sec3_s, *sec4_s;
+            va_list args_copy;
+            utility_Driver_Log_Kprint_Helper(
+                category,
+                &category_s,
+                secondary,
+                &sec1_s,
+                &sec2_s,
+                &sec3_s,
+                &sec4_s
+            );
+
+            nb_written_characters = DRV_SNPRINTF(tmp_array,
+                DRV_LOG_DEBUG_ARRAY_SIZE - 1,
+                DRV_LOG_DEBUG_ARRAY_SIZE - 1,
+                SEP_MSG_PREFIX " [%s%s%s%s%s] [%s@%d]: ",
+                category_s,
+                sec1_s,
+                sec2_s,
+                sec3_s,
+                sec4_s,
+                function_name,
+                line_number);
+
+            if (nb_written_characters > 0) {
+                va_copy(args_copy, args);
+                nb_written_characters += DRV_VSNPRINTF(tmp_array + nb_written_characters,
+                    DRV_LOG_DEBUG_ARRAY_SIZE - nb_written_characters - 1,
+                    DRV_LOG_DEBUG_ARRAY_SIZE - nb_written_characters - 1,
+                    format_string,
+                    args_copy);
+                va_end(args_copy);
+#undef      DRV_LOG_DEBUG_ARRAY_SIZE
+
+                tmp_array[nb_written_characters++] = '\n';
+                tmp_array[nb_written_characters++] = 0;
+
+                if ((category_verbosity & LOG_CHANNEL_PRINTK) * !in_interrupt * !in_notification) {
+                    if (!in_atomic()) {
+                        switch (category) {
+                            case DRV_LOG_CATEGORY_ERROR:
+                                printk(KERN_ERR     "%s", tmp_array);
+                                break;
+                            case DRV_LOG_CATEGORY_WARNING:
+                                printk(KERN_WARNING "%s", tmp_array);
+                                break;
+                            default:
+                                printk(KERN_INFO    "%s", tmp_array);
+                                break;
+                        }
+                    }
+                }
+
+                if (category_verbosity & LOG_CHANNEL_TRACEK) {
+                    trace_printk("%s", tmp_array);
+                }
+            }
+        }
+
+        va_end       (args);
+    }
+
+    return;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       extern DRV_STATUS UTILITY_Driver_Log_Init (void)
+ *
+ * @brief    Allocates and initializes the driver log buffer.
+ *
+ * @param    none
+ *
+ * @return   OS_SUCCESS on success, OS_NO_MEM on error.
+ *
+ * <I>Special Notes:</I>
+ *           Should be (successfully) run before any non-LOAD log calls.
+ *           Allocates memory without going through CONTROL_Allocate (to avoid
+ *           complicating the instrumentation of CONTROL_* functions): calling
+ *           UTILITY_Driver_Log_Free is necessary to free the log structure.
+ *           Falls back to vmalloc when contiguous physical memory cannot be
+ *           allocated. This does not impact runtime behavior, but may impact
+ *           the easiness of retrieving the log from a core dump if the system
+ *           crashes.
+ */
+extern DRV_STATUS
+UTILITY_Driver_Log_Init (
+    void
+)
+{
+    struct timespec cur_time;
+    U32             size = sizeof(*driver_log_buffer);
+    U8              using_contiguous_physical_memory;
+    U32             bitness;
+
+    if (size < MAX_KMALLOC_SIZE) {                              // allocating outside the regular function to restrict the area of the driver
+        driver_log_buffer = (PVOID)kmalloc(size, GFP_KERNEL);   // where the log might not be initialized
+    }
+    else {
+        driver_log_buffer = (PVOID)__get_free_pages(GFP_KERNEL, get_order(size));
+    }
+
+    if (driver_log_buffer) {
+        using_contiguous_physical_memory = 1;
+    }
+    else {
+        driver_log_buffer = vmalloc(size);
+
+        if (!driver_log_buffer) {
+            return OS_NO_MEM;
+        }
+
+        using_contiguous_physical_memory = 0;
+    }
+
+    memset(driver_log_buffer, DRV_LOG_FILLER_BYTE, sizeof(*driver_log_buffer)); // we don't want zero-filled pages (so that the buffer's pages don't get ommitted in some crash dumps)
+
+    DRV_LOG_COMPILER_MEM_BARRIER();
+    DRV_LOG_BUFFER_header_signature(driver_log_buffer)[0] = DRV_LOG_SIGNATURE_0;
+    DRV_LOG_BUFFER_footer_signature(driver_log_buffer)[0] = DRV_LOG_SIGNATURE_6;
+    DRV_LOG_BUFFER_header_signature(driver_log_buffer)[3] = DRV_LOG_SIGNATURE_3;
+    DRV_LOG_BUFFER_footer_signature(driver_log_buffer)[3] = DRV_LOG_SIGNATURE_3;
+
+    DRV_LOG_COMPILER_MEM_BARRIER();
+    DRV_LOG_BUFFER_header_signature(driver_log_buffer)[2] = DRV_LOG_SIGNATURE_2;
+    DRV_LOG_BUFFER_footer_signature(driver_log_buffer)[2] = DRV_LOG_SIGNATURE_4;
+    DRV_LOG_BUFFER_header_signature(driver_log_buffer)[1] = DRV_LOG_SIGNATURE_1;
+    DRV_LOG_BUFFER_footer_signature(driver_log_buffer)[1] = DRV_LOG_SIGNATURE_5;
+
+
+    DRV_LOG_COMPILER_MEM_BARRIER();
+    DRV_LOG_BUFFER_header_signature(driver_log_buffer)[7] = DRV_LOG_SIGNATURE_7;
+    DRV_LOG_BUFFER_footer_signature(driver_log_buffer)[7] = DRV_LOG_SIGNATURE_7;
+    DRV_LOG_BUFFER_header_signature(driver_log_buffer)[5] = DRV_LOG_SIGNATURE_5;
+    DRV_LOG_BUFFER_footer_signature(driver_log_buffer)[5] = DRV_LOG_SIGNATURE_1;
+
+    DRV_LOG_COMPILER_MEM_BARRIER();
+    DRV_LOG_BUFFER_header_signature(driver_log_buffer)[6] = DRV_LOG_SIGNATURE_6;
+    DRV_LOG_BUFFER_footer_signature(driver_log_buffer)[6] = DRV_LOG_SIGNATURE_0;
+    DRV_LOG_BUFFER_header_signature(driver_log_buffer)[4] = DRV_LOG_SIGNATURE_4;
+    DRV_LOG_BUFFER_footer_signature(driver_log_buffer)[4] = DRV_LOG_SIGNATURE_2;
+
+
+    DRV_LOG_BUFFER_log_size(driver_log_buffer)            = sizeof(*driver_log_buffer);
+    DRV_LOG_BUFFER_max_nb_pri_entries(driver_log_buffer)  = DRV_LOG_MAX_NB_PRI_ENTRIES;
+    DRV_LOG_BUFFER_max_nb_aux_entries(driver_log_buffer)  = DRV_LOG_MAX_NB_AUX_ENTRIES;
+    getnstimeofday(&cur_time);
+    DRV_LOG_BUFFER_init_time(driver_log_buffer)           = cur_time.tv_sec;
+    DRV_LOG_BUFFER_disambiguator(driver_log_buffer)       = 0;
+    DRV_LOG_BUFFER_log_version(driver_log_buffer)         = DRV_LOG_VERSION;
+    DRV_LOG_BUFFER_pri_entry_index(driver_log_buffer)     = (U32)((S32)-1);
+    DRV_LOG_BUFFER_aux_entry_index(driver_log_buffer)     = (U32)((S32)-1);
+
+#if defined(DRV_EM64T)
+    bitness = 64;
+#else
+    bitness = 32;
+#endif
+
+    DRV_SNPRINTF(
+        DRV_LOG_BUFFER_driver_version(driver_log_buffer),
+        DRV_LOG_DRIVER_VERSION_SIZE,
+        DRV_LOG_DRIVER_VERSION_SIZE,
+        "[%u-bit Linux] SEP v%d.%d (update %d). API %d.",
+            bitness,
+            SEP_MAJOR_VERSION,
+            SEP_MINOR_VERSION,
+            SEP_UPDATE_VERSION,
+            SEP_API_VERSION);
+
+    DRV_LOG_BUFFER_driver_state(driver_log_buffer)                = GET_DRIVER_STATE();
+    DRV_LOG_BUFFER_active_drv_operation(driver_log_buffer)        = active_ioctl;
+    DRV_LOG_BUFFER_nb_drv_operations(driver_log_buffer)           = 0;
+    DRV_LOG_BUFFER_nb_interrupts(driver_log_buffer)               = 0;
+    DRV_LOG_BUFFER_nb_active_interrupts(driver_log_buffer)        = 0;
+    DRV_LOG_BUFFER_nb_notifications(driver_log_buffer)            = 0;
+    DRV_LOG_BUFFER_nb_active_notifications(driver_log_buffer)     = 0;
+    DRV_LOG_BUFFER_nb_driver_state_transitions(driver_log_buffer) = 0;
+
+    DRV_LOG_VERBOSITY(DRV_LOG_CATEGORY_LOAD)            = DRV_LOG_DEFAULT_LOAD_VERBOSITY;
+    DRV_LOG_VERBOSITY(DRV_LOG_CATEGORY_INIT)            = DRV_LOG_DEFAULT_INIT_VERBOSITY;
+    DRV_LOG_VERBOSITY(DRV_LOG_CATEGORY_DETECTION)       = DRV_LOG_DEFAULT_DETECTION_VERBOSITY;
+    DRV_LOG_VERBOSITY(DRV_LOG_CATEGORY_ERROR)           = DRV_LOG_DEFAULT_ERROR_VERBOSITY;
+    DRV_LOG_VERBOSITY(DRV_LOG_CATEGORY_STATE_CHANGE)    = DRV_LOG_DEFAULT_STATE_CHANGE_VERBOSITY;
+    DRV_LOG_VERBOSITY(DRV_LOG_CATEGORY_MARK)            = DRV_LOG_DEFAULT_MARK_VERBOSITY;
+    DRV_LOG_VERBOSITY(DRV_LOG_CATEGORY_DEBUG)           = DRV_LOG_DEFAULT_DEBUG_VERBOSITY;
+    DRV_LOG_VERBOSITY(DRV_LOG_CATEGORY_FLOW)            = DRV_LOG_DEFAULT_FLOW_VERBOSITY;
+    DRV_LOG_VERBOSITY(DRV_LOG_CATEGORY_ALLOC)           = DRV_LOG_DEFAULT_ALLOC_VERBOSITY;
+    DRV_LOG_VERBOSITY(DRV_LOG_CATEGORY_INTERRUPT)       = DRV_LOG_DEFAULT_INTERRUPT_VERBOSITY;
+    DRV_LOG_VERBOSITY(DRV_LOG_CATEGORY_TRACE)           = DRV_LOG_DEFAULT_TRACE_VERBOSITY;
+    DRV_LOG_VERBOSITY(DRV_LOG_CATEGORY_REGISTER)        = DRV_LOG_DEFAULT_REGISTER_VERBOSITY;
+    DRV_LOG_VERBOSITY(DRV_LOG_CATEGORY_NOTIFICATION)    = DRV_LOG_DEFAULT_NOTIFICATION_VERBOSITY;
+    DRV_LOG_VERBOSITY(DRV_LOG_CATEGORY_WARNING)         = DRV_LOG_DEFAULT_WARNING_VERBOSITY;
+
+    DRV_LOG_BUFFER_contiguous_physical_memory(driver_log_buffer) = using_contiguous_physical_memory;
+
+    SEP_DRV_LOG_LOAD("Initialized driver log using %scontiguous physical memory.",
+        DRV_LOG_BUFFER_contiguous_physical_memory(driver_log_buffer) ? "" : "non-");
+
+    return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       extern DRV_STATUS UTILITY_Driver_Log_Free (void)
+ *
+ * @brief    Frees the driver log buffer.
+ *
+ * @param    none
+ *
+ * @return   OS_SUCCESS on success, OS_NO_MEM on error.
+ *
+ * <I>Special Notes:</I>
+ *           Should be done before unloading the driver.
+ *           See UTILITY_Driver_Log_Init for details.
+ */
+extern void
+UTILITY_Driver_Log_Free (
+    VOID
+)
+{
+    U32 size = sizeof(*driver_log_buffer);
+
+    if (driver_log_buffer) {
+
+        if (DRV_LOG_BUFFER_contiguous_physical_memory(driver_log_buffer)) {
+            if (size < MAX_KMALLOC_SIZE) {
+                kfree(driver_log_buffer);
+            }
+            else {
+                free_pages((unsigned long)driver_log_buffer, get_order(size));
+            }
+        }
+        else {
+            vfree(driver_log_buffer);
+        }
+
+        driver_log_buffer = NULL;
+    }
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       extern void UTILITY_Driver_Set_Active_Ioctl (U32 ioctl)
+ *
+ * @brief    Sets the 'active_ioctl' global to the specified value.
+ *
+ * @param    U32 ioctl - ioctl/drvop code to use
+ *
+ * @return   none
+ *
+ * <I>Special Notes:</I>
+ *           Used to keep track of the IOCTL operation currently being processed.
+ *           This information is saved in the log buffer (globally), as well as
+ *           in every log entry.
+ *           NB: only IOCTLs for which grabbing the ioctl mutex is necessary
+ *           should be kept track of this way.
+ */
+extern void
+UTILITY_Driver_Set_Active_Ioctl (
+    U32 ioctl
+)
+{
+    active_ioctl = ioctl;
+    if (ioctl) {
+        DRV_LOG_BUFFER_nb_drv_operations(driver_log_buffer)++;
+    }
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       extern const char** UTILITY_Log_Category_Strings (void)
+ *
+ * @brief    Accessor function for the log category string array
+ *
+ * @param    none
+ *
+ * @return   none
+ *
+ * <I>Special Notes:</I>
+ *           Only needed for cosmetic purposes when adjusting category verbosities.
+ */
+extern const char**
+UTILITY_Log_Category_Strings (
+    void
+)
+{
+    return drv_log_categories;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       extern U32 UTILITY_Change_Driver_State (U32 allowed_prior_states, U32 state, const char* func, U32 line_number)
+ *
+ * @brief    Updates the driver state (if the transition is legal).
+ *
+ * @param    U32 allowed_prior_states   - the bitmask representing the states from which the transition is allowed to occur
+ *           U32 state                  - the destination state
+ *           const char* func           - the callsite's function's name
+ *           U32 line_number            - the callsite's line number
+ *
+ * @return   1 in case of success, 0 otherwise
+ *
+ * <I>Special Notes:</I>
+ *
+ */
+extern U32
+UTILITY_Change_Driver_State (
+    U32         allowed_prior_states,
+    U32         state,
+    const char* func,
+    U32         line_number
+)
+{
+    U32 res             = 1;
+    U32 previous_state;
+    U32 current_state   = GET_DRIVER_STATE();
+    U32 nb_attempts     = 0;
+
+    SEP_DRV_LOG_TRACE_IN("Prior states: 0x%x, state: %u, func: %p, line: %u.", allowed_prior_states, state, func, line_number);
+
+    if (state >= DRV_LOG_NB_DRIVER_STATES) {
+        SEP_DRV_LOG_ERROR("Illegal destination state %d (%s@%u)!", state, func, line_number);
+        res = 0;
+        goto clean_return;
+    }
+
+    do {
+        previous_state = current_state;
+        nb_attempts++;
+        SEP_DRV_LOG_TRACE("Attempt #%d to transition to state %s.", nb_attempts, drv_log_states[state]);
+
+        if (DRIVER_STATE_IN(current_state, allowed_prior_states)) {
+            current_state = cmpxchg(&GET_DRIVER_STATE(),
+                                     previous_state,
+                                     state);
+        }
+        else {
+            SEP_DRV_LOG_ERROR("Invalid transition [%s -> %s] (%s@%u)!", drv_log_states[previous_state], drv_log_states[state], func, line_number);
+            res = 0;
+            goto clean_return;
+        }
+
+    } while (previous_state != current_state);
+
+    SEP_DRV_LOG_STATE_TRANSITION(previous_state, state, "From %s@%u.", func, line_number);
+
+    clean_return:
+    SEP_DRV_LOG_TRACE_OUT("Res: %u.", res);
+    return res;
+}
diff --git a/drivers/misc/intel/sepdk/sep/valleyview_sochap.c b/drivers/misc/intel/sepdk/sep/valleyview_sochap.c
new file mode 100644
index 000000000000..2673cda5879e
--- /dev/null
+++ b/drivers/misc/intel/sepdk/sep/valleyview_sochap.c
@@ -0,0 +1,329 @@
+/****
+    Copyright(C) 2012-2018 Intel Corporation.  All Rights Reserved.
+
+    This file is part of SEP Development Kit.
+
+    SEP Development Kit is free software; you can redistribute it
+    and/or modify it under the terms of the GNU General Public License
+    version 2 as published by the Free Software Foundation.
+
+    SEP Development Kit is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with SEP Development Kit; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+
+    As a special exception, you may use this file as part of a free software
+    library without restriction.  Specifically, if other files instantiate
+    templates or use macros or inline functions from this file, or you compile
+    this file and link it with other files to produce an executable, this
+    file does not by itself cause the resulting executable to be covered by
+    the GNU General Public License.  This exception does not however
+    invalidate any other reasons why the executable file might be covered by
+    the GNU General Public License.
+****/
+
+
+
+
+
+#include "lwpmudrv_defines.h"
+#include "lwpmudrv_types.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+#include "inc/ecb_iterators.h"
+#include "inc/control.h"
+#include "inc/utility.h"
+#include "inc/valleyview_sochap.h"
+
+
+extern U64           *read_counter_info;
+static U64           *uncore_current_data = NULL;
+static U64           *uncore_to_read_data = NULL;
+extern DRV_CONFIG     drv_cfg;
+
+extern VOID SOCPERF_Read_Data3(PVOID data_buffer);
+
+
+/*!
+ * @fn         static VOID valleyview_VISA_Initialize(PVOID)
+ *
+ * @brief      Initialize any registers or addresses
+ *
+ * @param      param
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+valleyview_VISA_Initialize (
+    VOID  *param
+)
+{
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    // Allocate memory for reading GMCH counter values + the group id
+    if (!uncore_current_data) {
+        uncore_current_data = CONTROL_Allocate_Memory((VLV_CHAP_MAX_COUNTERS+1)*sizeof(U64));
+        if (!uncore_current_data) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("Early exit (uncore_current_data is NULL!).");
+            return;
+        }
+    }
+    if (!uncore_to_read_data) {
+        uncore_to_read_data = CONTROL_Allocate_Memory((VLV_CHAP_MAX_COUNTERS+1)*sizeof(U64));
+        if (!uncore_to_read_data) {
+            SEP_DRV_LOG_ERROR_TRACE_OUT("Early exit (uncore_to_read_data is NULL!).");
+            return;
+        }
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/*!
+ * @fn         static VOID valleyview_VISA_Enable_PMU(PVOID)
+ *
+ * @brief      Start counting
+ *
+ * @param      param - device index
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+valleyview_VISA_Enable_PMU (
+    PVOID  param
+)
+{
+    U32       this_cpu;
+    CPU_STATE pcpu;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    this_cpu = CONTROL_THIS_CPU();
+    pcpu     = &pcb[this_cpu];
+
+    if (!CPU_STATE_system_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!system_master).");
+        return;
+    }
+
+    SEP_DRV_LOG_TRACE("Starting the counters...");
+    if (uncore_current_data) {
+        memset(uncore_current_data, 0, (VLV_CHAP_MAX_COUNTERS+1)*sizeof(U64));
+    }
+    if (uncore_to_read_data) {
+        memset(uncore_to_read_data, 0, (VLV_CHAP_MAX_COUNTERS+1)*sizeof(U64));
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/*!
+ * @fn         static VOID valleyview_VISA_Disable_PMU(PVOID)
+ *
+ * @brief      Unmap the virtual address when sampling/driver stops
+ *
+ * @param      param - device index
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+valleyview_VISA_Disable_PMU (
+    PVOID  param
+)
+{
+    U32       this_cpu;
+    CPU_STATE pcpu;
+    U32       cur_driver_state;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    this_cpu         = CONTROL_THIS_CPU();
+    pcpu             = &pcb[this_cpu];
+    cur_driver_state = GET_DRIVER_STATE();
+
+    if (!CPU_STATE_system_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!system_master).");
+        return;
+    }
+    SEP_DRV_LOG_TRACE("Stopping the counters...");
+    if (cur_driver_state == DRV_STATE_PREPARE_STOP  ||
+        cur_driver_state == DRV_STATE_STOPPED       ||
+        cur_driver_state == DRV_STATE_TERMINATING)  {
+        uncore_current_data = CONTROL_Free_Memory(uncore_current_data);
+        uncore_to_read_data = CONTROL_Free_Memory(uncore_to_read_data);
+    }
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+
+/*!
+ * @fn         static VOID valleyview_VISA_Clean_Up(PVOID)
+ *
+ * @brief      Reset any registers or addresses
+ *
+ * @param      param
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID
+valleyview_VISA_Clean_Up (
+    VOID   *param
+)
+{
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+    SEP_DRV_LOG_TRACE_OUT("Empty function.");
+    return;
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn valleyview_VISA_Read_PMU_Data(param)
+ *
+ * @param    param    The device index
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the Uncore count data and store into the buffer param;
+ *
+ */
+static VOID
+valleyview_VISA_Read_PMU_Data (
+    PVOID  param
+)
+{
+    U32          j;
+    U64         *buffer       = read_counter_info;
+    U32          dev_idx;
+    U32          this_cpu;
+    CPU_STATE    pcpu;
+    U32          package_num;
+    U32          event_index  = 0;
+    U32          cur_grp;
+    ECB          pecb;
+    U64          counter_buffer[VLV_CHAP_MAX_COUNTERS+1];
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p.", param);
+
+    dev_idx     = *((U32*)param);
+    this_cpu    = CONTROL_THIS_CPU();
+    pcpu        = &pcb[this_cpu];
+    package_num = core_to_package_map[this_cpu];
+    cur_grp     = LWPMU_DEVICE_cur_group(&devices[(dev_idx)])[package_num];
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[(dev_idx)])[cur_grp];
+
+    // NOTE THAT the read_pmu function on for EMON collection.
+    if (!DRV_CONFIG_emon_mode(drv_cfg)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!emon_mode).");
+        return;
+    }
+    if (!CPU_STATE_socket_master(pcpu)) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!socket_master).");
+        return;
+    }
+    if (!pecb) {
+        SEP_DRV_LOG_TRACE_OUT("Early exit (!pecb).");
+        return;
+    }
+
+    SOCPERF_Read_Data3((void*)counter_buffer);
+
+    FOR_EACH_REG_UNC_OPERATION(pecb, dev_idx, idx, PMU_OPERATION_READ) {
+        //the buffer index for this PMU needs to account for each event
+        j         = ECB_entries_uncore_buffer_offset_in_system(pecb,idx);
+        buffer[j] = counter_buffer[event_index+1];
+        event_index++;
+        SEP_DRV_LOG_TRACE("j=%u, value=%llu, cpu=%u", j, buffer[j], this_cpu);
+
+    } END_FOR_EACH_REG_UNC_OPERATION;
+
+    SEP_DRV_LOG_TRACE_OUT("");
+}
+
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn valleyview_Trigger_Read()
+ *
+ * @param    None
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the SoCHAP counters when timer is triggered
+ *
+ */
+static VOID
+valleyview_Trigger_Read (
+    PVOID  param,
+    U32    id
+)
+{
+    U64  *data     = (U64*) param;
+    U32   cur_grp;
+    ECB   pecb;
+    U32   this_cpu;
+    U32   package_num;
+
+    SEP_DRV_LOG_TRACE_IN("Param: %p,, id: %u.", param, id);
+
+    this_cpu    = CONTROL_THIS_CPU();
+    package_num = core_to_package_map[this_cpu];
+    cur_grp     = LWPMU_DEVICE_cur_group(&devices[id])[package_num];
+    pecb        = LWPMU_DEVICE_PMU_register_data(&devices[id])[cur_grp];
+
+    // group id
+    data = (U64*)((S8*)data + ECB_group_offset(pecb));
+    SOCPERF_Read_Data3((void*)data);
+
+    SEP_DRV_LOG_TRACE_OUT("");
+    return;
+}
+
+
+/*
+ * Initialize the dispatch table
+ */
+DISPATCH_NODE  valleyview_visa_dispatch =
+{
+    valleyview_VISA_Initialize,        // initialize
+    NULL,                              // destroy
+    NULL,                              // write
+    valleyview_VISA_Disable_PMU,       // freeze
+    valleyview_VISA_Enable_PMU,        // restart
+    valleyview_VISA_Read_PMU_Data,     // read
+    NULL,                              // check for overflow
+    NULL,                              // swap group
+    NULL,                              // read lbrs
+    valleyview_VISA_Clean_Up,          // cleanup
+    NULL,                              // hw errata
+    NULL,                              // read power
+    NULL,                              // check overflow errata
+    NULL,                              // read counts
+    NULL,                              // check overflow gp errata
+    NULL,                              // read_ro
+    NULL,                              // platform info
+    valleyview_Trigger_Read,           // trigger read
+    NULL,                              // scan for uncore
+    NULL                               // read metrics
+};
+
-- 
2.18.0

